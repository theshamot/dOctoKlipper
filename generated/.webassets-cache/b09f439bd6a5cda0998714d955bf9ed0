V// source: js/lib/hls.js\u000atypeof window !== "undefined" &&\u000a(function webpackUniversalModuleDefinition(root, factory) {\u000a	if(typeof exports === 'object' && typeof module === 'object')\u000a		module.exports = factory();\u000a	else if(typeof define === 'function' && define.amd)\u000a		define([], factory);\u000a	else if(typeof exports === 'object')\u000a		exports["Hls"] = factory();\u000a	else\u000a		root["Hls"] = factory();\u000a})(this, function() {\u000areturn /******/ (function(modules) { // webpackBootstrap\u000a/******/ 	// The module cache\u000a/******/ 	var installedModules = {};\u000a/******/\u000a/******/ 	// The require function\u000a/******/ 	function __webpack_require__(moduleId) {\u000a/******/\u000a/******/ 		// Check if module is in cache\u000a/******/ 		if(installedModules[moduleId]) {\u000a/******/ 			return installedModules[moduleId].exports;\u000a/******/ 		}\u000a/******/ 		// Create a new module (and put it into the cache)\u000a/******/ 		var module = installedModules[moduleId] = {\u000a/******/ 			i: moduleId,\u000a/******/ 			l: false,\u000a/******/ 			exports: {}\u000a/******/ 		};\u000a/******/\u000a/******/ 		// Execute the module function\u000a/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\u000a/******/\u000a/******/ 		// Flag the module as loaded\u000a/******/ 		module.l = true;\u000a/******/\u000a/******/ 		// Return the exports of the module\u000a/******/ 		return module.exports;\u000a/******/ 	}\u000a/******/\u000a/******/\u000a/******/ 	// expose the modules object (__webpack_modules__)\u000a/******/ 	__webpack_require__.m = modules;\u000a/******/\u000a/******/ 	// expose the module cache\u000a/******/ 	__webpack_require__.c = installedModules;\u000a/******/\u000a/******/ 	// define getter function for harmony exports\u000a/******/ 	__webpack_require__.d = function(exports, name, getter) {\u000a/******/ 		if(!__webpack_require__.o(exports, name)) {\u000a/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });\u000a/******/ 		}\u000a/******/ 	};\u000a/******/\u000a/******/ 	// define __esModule on exports\u000a/******/ 	__webpack_require__.r = function(exports) {\u000a/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\u000a/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\u000a/******/ 		}\u000a/******/ 		Object.defineProperty(exports, '__esModule', { value: true });\u000a/******/ 	};\u000a/******/\u000a/******/ 	// create a fake namespace object\u000a/******/ 	// mode & 1: value is a module id, require it\u000a/******/ 	// mode & 2: merge all properties of value into the ns\u000a/******/ 	// mode & 4: return value when already ns object\u000a/******/ 	// mode & 8|1: behave like require\u000a/******/ 	__webpack_require__.t = function(value, mode) {\u000a/******/ 		if(mode & 1) value = __webpack_require__(value);\u000a/******/ 		if(mode & 8) return value;\u000a/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\u000a/******/ 		var ns = Object.create(null);\u000a/******/ 		__webpack_require__.r(ns);\u000a/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });\u000a/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\u000a/******/ 		return ns;\u000a/******/ 	};\u000a/******/\u000a/******/ 	// getDefaultExport function for compatibility with non-harmony modules\u000a/******/ 	__webpack_require__.n = function(module) {\u000a/******/ 		var getter = module && module.__esModule ?\u000a/******/ 			function getDefault() { return module['default']; } :\u000a/******/ 			function getModuleExports() { return module; };\u000a/******/ 		__webpack_require__.d(getter, 'a', getter);\u000a/******/ 		return getter;\u000a/******/ 	};\u000a/******/\u000a/******/ 	// Object.prototype.hasOwnProperty.call\u000a/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\u000a/******/\u000a/******/ 	// __webpack_public_path__\u000a/******/ 	__webpack_require__.p = "/dist/";\u000a/******/\u000a/******/\u000a/******/ 	// Load entry module and return exports\u000a/******/ 	return __webpack_require__(__webpack_require__.s = "./src/hls.ts");\u000a/******/ })\u000a/************************************************************************/\u000a/******/ ({\u000a\u000a/***/ "./node_modules/eventemitter3/index.js":\u000a/*!*********************************************!*\u005c\u000a  !*** ./node_modules/eventemitter3/index.js ***!\u000a  \u005c*********************************************/\u000a/*! no static exports found */\u000a/*! ModuleConcatenation bailout: Module is not an ECMAScript module */\u000a/***/ (function(module, exports, __webpack_require__) {\u000a\u000a"use strict";\u000a\u000a\u000avar has = Object.prototype.hasOwnProperty\u000a  , prefix = '~';\u000a\u000a/**\u000a * Constructor to create a storage for our `EE` objects.\u000a * An `Events` instance is a plain object whose properties are event names.\u000a *\u000a * @constructor\u000a * @private\u000a */\u000afunction Events() {}\u000a\u000a//\u000a// We try to not inherit from `Object.prototype`. In some engines creating an\u000a// instance in this way is faster than calling `Object.create(null)` directly.\u000a// If `Object.create(null)` is not supported we prefix the event names with a\u000a// character to make sure that the built-in object properties are not\u000a// overridden or used as an attack vector.\u000a//\u000aif (Object.create) {\u000a  Events.prototype = Object.create(null);\u000a\u000a  //\u000a  // This hack is needed because the `__proto__` property is still inherited in\u000a  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.\u000a  //\u000a  if (!new Events().__proto__) prefix = false;\u000a}\u000a\u000a/**\u000a * Representation of a single event listener.\u000a *\u000a * @param {Function} fn The listener function.\u000a * @param {*} context The context to invoke the listener with.\u000a * @param {Boolean} [once=false] Specify if the listener is a one-time listener.\u000a * @constructor\u000a * @private\u000a */\u000afunction EE(fn, context, once) {\u000a  this.fn = fn;\u000a  this.context = context;\u000a  this.once = once || false;\u000a}\u000a\u000a/**\u000a * Add a listener for a given event.\u000a *\u000a * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\u000a * @param {(String|Symbol)} event The event name.\u000a * @param {Function} fn The listener function.\u000a * @param {*} context The context to invoke the listener with.\u000a * @param {Boolean} once Specify if the listener is a one-time listener.\u000a * @returns {EventEmitter}\u000a * @private\u000a */\u000afunction addListener(emitter, event, fn, context, once) {\u000a  if (typeof fn !== 'function') {\u000a    throw new TypeError('The listener must be a function');\u000a  }\u000a\u000a  var listener = new EE(fn, context || emitter, once)\u000a    , evt = prefix ? prefix + event : event;\u000a\u000a  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;\u000a  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);\u000a  else emitter._events[evt] = [emitter._events[evt], listener];\u000a\u000a  return emitter;\u000a}\u000a\u000a/**\u000a * Clear event by name.\u000a *\u000a * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\u000a * @param {(String|Symbol)} evt The Event name.\u000a * @private\u000a */\u000afunction clearEvent(emitter, evt) {\u000a  if (--emitter._eventsCount === 0) emitter._events = new Events();\u000a  else delete emitter._events[evt];\u000a}\u000a\u000a/**\u000a * Minimal `EventEmitter` interface that is molded against the Node.js\u000a * `EventEmitter` interface.\u000a *\u000a * @constructor\u000a * @public\u000a */\u000afunction EventEmitter() {\u000a  this._events = new Events();\u000a  this._eventsCount = 0;\u000a}\u000a\u000a/**\u000a * Return an array listing the events for which the emitter has registered\u000a * listeners.\u000a *\u000a * @returns {Array}\u000a * @public\u000a */\u000aEventEmitter.prototype.eventNames = function eventNames() {\u000a  var names = []\u000a    , events\u000a    , name;\u000a\u000a  if (this._eventsCount === 0) return names;\u000a\u000a  for (name in (events = this._events)) {\u000a    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);\u000a  }\u000a\u000a  if (Object.getOwnPropertySymbols) {\u000a    return names.concat(Object.getOwnPropertySymbols(events));\u000a  }\u000a\u000a  return names;\u000a};\u000a\u000a/**\u000a * Return the listeners registered for a given event.\u000a *\u000a * @param {(String|Symbol)} event The event name.\u000a * @returns {Array} The registered listeners.\u000a * @public\u000a */\u000aEventEmitter.prototype.listeners = function listeners(event) {\u000a  var evt = prefix ? prefix + event : event\u000a    , handlers = this._events[evt];\u000a\u000a  if (!handlers) return [];\u000a  if (handlers.fn) return [handlers.fn];\u000a\u000a  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {\u000a    ee[i] = handlers[i].fn;\u000a  }\u000a\u000a  return ee;\u000a};\u000a\u000a/**\u000a * Return the number of listeners listening to a given event.\u000a *\u000a * @param {(String|Symbol)} event The event name.\u000a * @returns {Number} The number of listeners.\u000a * @public\u000a */\u000aEventEmitter.prototype.listenerCount = function listenerCount(event) {\u000a  var evt = prefix ? prefix + event : event\u000a    , listeners = this._events[evt];\u000a\u000a  if (!listeners) return 0;\u000a  if (listeners.fn) return 1;\u000a  return listeners.length;\u000a};\u000a\u000a/**\u000a * Calls each of the listeners registered for a given event.\u000a *\u000a * @param {(String|Symbol)} event The event name.\u000a * @returns {Boolean} `true` if the event had listeners, else `false`.\u000a * @public\u000a */\u000aEventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {\u000a  var evt = prefix ? prefix + event : event;\u000a\u000a  if (!this._events[evt]) return false;\u000a\u000a  var listeners = this._events[evt]\u000a    , len = arguments.length\u000a    , args\u000a    , i;\u000a\u000a  if (listeners.fn) {\u000a    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);\u000a\u000a    switch (len) {\u000a      case 1: return listeners.fn.call(listeners.context), true;\u000a      case 2: return listeners.fn.call(listeners.context, a1), true;\u000a      case 3: return listeners.fn.call(listeners.context, a1, a2), true;\u000a      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;\u000a      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;\u000a      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;\u000a    }\u000a\u000a    for (i = 1, args = new Array(len -1); i < len; i++) {\u000a      args[i - 1] = arguments[i];\u000a    }\u000a\u000a    listeners.fn.apply(listeners.context, args);\u000a  } else {\u000a    var length = listeners.length\u000a      , j;\u000a\u000a    for (i = 0; i < length; i++) {\u000a      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);\u000a\u000a      switch (len) {\u000a        case 1: listeners[i].fn.call(listeners[i].context); break;\u000a        case 2: listeners[i].fn.call(listeners[i].context, a1); break;\u000a        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;\u000a        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;\u000a        default:\u000a          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {\u000a            args[j - 1] = arguments[j];\u000a          }\u000a\u000a          listeners[i].fn.apply(listeners[i].context, args);\u000a      }\u000a    }\u000a  }\u000a\u000a  return true;\u000a};\u000a\u000a/**\u000a * Add a listener for a given event.\u000a *\u000a * @param {(String|Symbol)} event The event name.\u000a * @param {Function} fn The listener function.\u000a * @param {*} [context=this] The context to invoke the listener with.\u000a * @returns {EventEmitter} `this`.\u000a * @public\u000a */\u000aEventEmitter.prototype.on = function on(event, fn, context) {\u000a  return addListener(this, event, fn, context, false);\u000a};\u000a\u000a/**\u000a * Add a one-time listener for a given event.\u000a *\u000a * @param {(String|Symbol)} event The event name.\u000a * @param {Function} fn The listener function.\u000a * @param {*} [context=this] The context to invoke the listener with.\u000a * @returns {EventEmitter} `this`.\u000a * @public\u000a */\u000aEventEmitter.prototype.once = function once(event, fn, context) {\u000a  return addListener(this, event, fn, context, true);\u000a};\u000a\u000a/**\u000a * Remove the listeners of a given event.\u000a *\u000a * @param {(String|Symbol)} event The event name.\u000a * @param {Function} fn Only remove the listeners that match this function.\u000a * @param {*} context Only remove the listeners that have this context.\u000a * @param {Boolean} once Only remove one-time listeners.\u000a * @returns {EventEmitter} `this`.\u000a * @public\u000a */\u000aEventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {\u000a  var evt = prefix ? prefix + event : event;\u000a\u000a  if (!this._events[evt]) return this;\u000a  if (!fn) {\u000a    clearEvent(this, evt);\u000a    return this;\u000a  }\u000a\u000a  var listeners = this._events[evt];\u000a\u000a  if (listeners.fn) {\u000a    if (\u000a      listeners.fn === fn &&\u000a      (!once || listeners.once) &&\u000a      (!context || listeners.context === context)\u000a    ) {\u000a      clearEvent(this, evt);\u000a    }\u000a  } else {\u000a    for (var i = 0, events = [], length = listeners.length; i < length; i++) {\u000a      if (\u000a        listeners[i].fn !== fn ||\u000a        (once && !listeners[i].once) ||\u000a        (context && listeners[i].context !== context)\u000a      ) {\u000a        events.push(listeners[i]);\u000a      }\u000a    }\u000a\u000a    //\u000a    // Reset the array, or remove it completely if we have no more listeners.\u000a    //\u000a    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;\u000a    else clearEvent(this, evt);\u000a  }\u000a\u000a  return this;\u000a};\u000a\u000a/**\u000a * Remove all listeners, or those of the specified event.\u000a *\u000a * @param {(String|Symbol)} [event] The event name.\u000a * @returns {EventEmitter} `this`.\u000a * @public\u000a */\u000aEventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {\u000a  var evt;\u000a\u000a  if (event) {\u000a    evt = prefix ? prefix + event : event;\u000a    if (this._events[evt]) clearEvent(this, evt);\u000a  } else {\u000a    this._events = new Events();\u000a    this._eventsCount = 0;\u000a  }\u000a\u000a  return this;\u000a};\u000a\u000a//\u000a// Alias methods names because people roll like that.\u000a//\u000aEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\u000aEventEmitter.prototype.addListener = EventEmitter.prototype.on;\u000a\u000a//\u000a// Expose the prefix.\u000a//\u000aEventEmitter.prefixed = prefix;\u000a\u000a//\u000a// Allow `EventEmitter` to be imported as module namespace.\u000a//\u000aEventEmitter.EventEmitter = EventEmitter;\u000a\u000a//\u000a// Expose the module.\u000a//\u000aif (true) {\u000a  module.exports = EventEmitter;\u000a}\u000a\u000a\u000a/***/ }),\u000a\u000a/***/ "./node_modules/url-toolkit/src/url-toolkit.js":\u000a/*!*****************************************************!*\u005c\u000a  !*** ./node_modules/url-toolkit/src/url-toolkit.js ***!\u000a  \u005c*****************************************************/\u000a/*! no static exports found */\u000a/*! ModuleConcatenation bailout: Module is not an ECMAScript module */\u000a/***/ (function(module, exports, __webpack_require__) {\u000a\u000a// see https://tools.ietf.org/html/rfc1808\u000a\u000a(function (root) {\u000a  var URL_REGEX = /^((?:[a-zA-Z0-9+\u005c-.]+:)?)(\u005c/\u005c/[^\u005c/?#]*)?((?:[^\u005c/?#]*\u005c/)*[^;?#]*)?(;[^?#]*)?(\u005c?[^#]*)?(#.*)?$/;\u000a  var FIRST_SEGMENT_REGEX = /^([^\u005c/?#]*)(.*)$/;\u000a  var SLASH_DOT_REGEX = /(?:\u005c/|^)\u005c.(?=\u005c/)/g;\u000a  var SLASH_DOT_DOT_REGEX = /(?:\u005c/|^)\u005c.\u005c.\u005c/(?!\u005c.\u005c.\u005c/)[^\u005c/]*(?=\u005c/)/g;\u000a\u000a  var URLToolkit = {\u000a    // If opts.alwaysNormalize is true then the path will always be normalized even when it starts with / or //\u000a    // E.g\u000a    // With opts.alwaysNormalize = false (default, spec compliant)\u000a    // http://a.com/b/cd + /e/f/../g => http://a.com/e/f/../g\u000a    // With opts.alwaysNormalize = true (not spec compliant)\u000a    // http://a.com/b/cd + /e/f/../g => http://a.com/e/g\u000a    buildAbsoluteURL: function (baseURL, relativeURL, opts) {\u000a      opts = opts || {};\u000a      // remove any remaining space and CRLF\u000a      baseURL = baseURL.trim();\u000a      relativeURL = relativeURL.trim();\u000a      if (!relativeURL) {\u000a        // 2a) If the embedded URL is entirely empty, it inherits the\u000a        // entire base URL (i.e., is set equal to the base URL)\u000a        // and we are done.\u000a        if (!opts.alwaysNormalize) {\u000a          return baseURL;\u000a        }\u000a        var basePartsForNormalise = URLToolkit.parseURL(baseURL);\u000a        if (!basePartsForNormalise) {\u000a          throw new Error('Error trying to parse base URL.');\u000a        }\u000a        basePartsForNormalise.path = URLToolkit.normalizePath(\u000a          basePartsForNormalise.path\u000a        );\u000a        return URLToolkit.buildURLFromParts(basePartsForNormalise);\u000a      }\u000a      var relativeParts = URLToolkit.parseURL(relativeURL);\u000a      if (!relativeParts) {\u000a        throw new Error('Error trying to parse relative URL.');\u000a      }\u000a      if (relativeParts.scheme) {\u000a        // 2b) If the embedded URL starts with a scheme name, it is\u000a        // interpreted as an absolute URL and we are done.\u000a        if (!opts.alwaysNormalize) {\u000a          return relativeURL;\u000a        }\u000a        relativeParts.path = URLToolkit.normalizePath(relativeParts.path);\u000a        return URLToolkit.buildURLFromParts(relativeParts);\u000a      }\u000a      var baseParts = URLToolkit.parseURL(baseURL);\u000a      if (!baseParts) {\u000a        throw new Error('Error trying to parse base URL.');\u000a      }\u000a      if (!baseParts.netLoc && baseParts.path && baseParts.path[0] !== '/') {\u000a        // If netLoc missing and path doesn't start with '/', assume everthing before the first '/' is the netLoc\u000a        // This causes 'example.com/a' to be handled as '//example.com/a' instead of '/example.com/a'\u000a        var pathParts = FIRST_SEGMENT_REGEX.exec(baseParts.path);\u000a        baseParts.netLoc = pathParts[1];\u000a        baseParts.path = pathParts[2];\u000a      }\u000a      if (baseParts.netLoc && !baseParts.path) {\u000a        baseParts.path = '/';\u000a      }\u000a      var builtParts = {\u000a        // 2c) Otherwise, the embedded URL inherits the scheme of\u000a        // the base URL.\u000a        scheme: baseParts.scheme,\u000a        netLoc: relativeParts.netLoc,\u000a        path: null,\u000a        params: relativeParts.params,\u000a        query: relativeParts.query,\u000a        fragment: relativeParts.fragment,\u000a      };\u000a      if (!relativeParts.netLoc) {\u000a        // 3) If the embedded URL's <net_loc> is non-empty, we skip to\u000a        // Step 7.  Otherwise, the embedded URL inherits the <net_loc>\u000a        // (if any) of the base URL.\u000a        builtParts.netLoc = baseParts.netLoc;\u000a        // 4) If the embedded URL path is preceded by a slash "/", the\u000a        // path is not relative and we skip to Step 7.\u000a        if (relativeParts.path[0] !== '/') {\u000a          if (!relativeParts.path) {\u000a            // 5) If the embedded URL path is empty (and not preceded by a\u000a            // slash), then the embedded URL inherits the base URL path\u000a            builtParts.path = baseParts.path;\u000a            // 5a) if the embedded URL's <params> is non-empty, we skip to\u000a            // step 7; otherwise, it inherits the <params> of the base\u000a            // URL (if any) and\u000a            if (!relativeParts.params) {\u000a              builtParts.params = baseParts.params;\u000a              // 5b) if the embedded URL's <query> is non-empty, we skip to\u000a              // step 7; otherwise, it inherits the <query> of the base\u000a              // URL (if any) and we skip to step 7.\u000a              if (!relativeParts.query) {\u000a                builtParts.query = baseParts.query;\u000a              }\u000a            }\u000a          } else {\u000a            // 6) The last segment of the base URL's path (anything\u000a            // following the rightmost slash "/", or the entire path if no\u000a            // slash is present) is removed and the embedded URL's path is\u000a            // appended in its place.\u000a            var baseURLPath = baseParts.path;\u000a            var newPath =\u000a              baseURLPath.substring(0, baseURLPath.lastIndexOf('/') + 1) +\u000a              relativeParts.path;\u000a            builtParts.path = URLToolkit.normalizePath(newPath);\u000a          }\u000a        }\u000a      }\u000a      if (builtParts.path === null) {\u000a        builtParts.path = opts.alwaysNormalize\u000a          ? URLToolkit.normalizePath(relativeParts.path)\u000a          : relativeParts.path;\u000a      }\u000a      return URLToolkit.buildURLFromParts(builtParts);\u000a    },\u000a    parseURL: function (url) {\u000a      var parts = URL_REGEX.exec(url);\u000a      if (!parts) {\u000a        return null;\u000a      }\u000a      return {\u000a        scheme: parts[1] || '',\u000a        netLoc: parts[2] || '',\u000a        path: parts[3] || '',\u000a        params: parts[4] || '',\u000a        query: parts[5] || '',\u000a        fragment: parts[6] || '',\u000a      };\u000a    },\u000a    normalizePath: function (path) {\u000a      // The following operations are\u000a      // then applied, in order, to the new path:\u000a      // 6a) All occurrences of "./", where "." is a complete path\u000a      // segment, are removed.\u000a      // 6b) If the path ends with "." as a complete path segment,\u000a      // that "." is removed.\u000a      path = path.split('').reverse().join('').replace(SLASH_DOT_REGEX, '');\u000a      // 6c) All occurrences of "<segment>/../", where <segment> is a\u000a      // complete path segment not equal to "..", are removed.\u000a      // Removal of these path segments is performed iteratively,\u000a      // removing the leftmost matching pattern on each iteration,\u000a      // until no matching pattern remains.\u000a      // 6d) If the path ends with "<segment>/..", where <segment> is a\u000a      // complete path segment not equal to "..", that\u000a      // "<segment>/.." is removed.\u000a      while (\u000a        path.length !== (path = path.replace(SLASH_DOT_DOT_REGEX, '')).length\u000a      ) {}\u000a      return path.split('').reverse().join('');\u000a    },\u000a    buildURLFromParts: function (parts) {\u000a      return (\u000a        parts.scheme +\u000a        parts.netLoc +\u000a        parts.path +\u000a        parts.params +\u000a        parts.query +\u000a        parts.fragment\u000a      );\u000a    },\u000a  };\u000a\u000a  if (true)\u000a    module.exports = URLToolkit;\u000a  else {}\u000a})(this);\u000a\u000a\u000a/***/ }),\u000a\u000a/***/ "./node_modules/webworkify-webpack/index.js":\u000a/*!**************************************************!*\u005c\u000a  !*** ./node_modules/webworkify-webpack/index.js ***!\u000a  \u005c**************************************************/\u000a/*! no static exports found */\u000a/*! ModuleConcatenation bailout: Module is not an ECMAScript module */\u000a/***/ (function(module, exports, __webpack_require__) {\u000a\u000afunction webpackBootstrapFunc (modules) {\u000a/******/  // The module cache\u000a/******/  var installedModules = {};\u000a\u000a/******/  // The require function\u000a/******/  function __webpack_require__(moduleId) {\u000a\u000a/******/    // Check if module is in cache\u000a/******/    if(installedModules[moduleId])\u000a/******/      return installedModules[moduleId].exports;\u000a\u000a/******/    // Create a new module (and put it into the cache)\u000a/******/    var module = installedModules[moduleId] = {\u000a/******/      i: moduleId,\u000a/******/      l: false,\u000a/******/      exports: {}\u000a/******/    };\u000a\u000a/******/    // Execute the module function\u000a/******/    modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\u000a\u000a/******/    // Flag the module as loaded\u000a/******/    module.l = true;\u000a\u000a/******/    // Return the exports of the module\u000a/******/    return module.exports;\u000a/******/  }\u000a\u000a/******/  // expose the modules object (__webpack_modules__)\u000a/******/  __webpack_require__.m = modules;\u000a\u000a/******/  // expose the module cache\u000a/******/  __webpack_require__.c = installedModules;\u000a\u000a/******/  // identity function for calling harmony imports with the correct context\u000a/******/  __webpack_require__.i = function(value) { return value; };\u000a\u000a/******/  // define getter function for harmony exports\u000a/******/  __webpack_require__.d = function(exports, name, getter) {\u000a/******/    if(!__webpack_require__.o(exports, name)) {\u000a/******/      Object.defineProperty(exports, name, {\u000a/******/        configurable: false,\u000a/******/        enumerable: true,\u000a/******/        get: getter\u000a/******/      });\u000a/******/    }\u000a/******/  };\u000a\u000a/******/  // define __esModule on exports\u000a/******/  __webpack_require__.r = function(exports) {\u000a/******/    Object.defineProperty(exports, '__esModule', { value: true });\u000a/******/  };\u000a\u000a/******/  // getDefaultExport function for compatibility with non-harmony modules\u000a/******/  __webpack_require__.n = function(module) {\u000a/******/    var getter = module && module.__esModule ?\u000a/******/      function getDefault() { return module['default']; } :\u000a/******/      function getModuleExports() { return module; };\u000a/******/    __webpack_require__.d(getter, 'a', getter);\u000a/******/    return getter;\u000a/******/  };\u000a\u000a/******/  // Object.prototype.hasOwnProperty.call\u000a/******/  __webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\u000a\u000a/******/  // __webpack_public_path__\u000a/******/  __webpack_require__.p = "/";\u000a\u000a/******/  // on error function for async loading\u000a/******/  __webpack_require__.oe = function(err) { console.error(err); throw err; };\u000a\u000a  var f = __webpack_require__(__webpack_require__.s = ENTRY_MODULE)\u000a  return f.default || f // try to call default if defined to also support babel esmodule exports\u000a}\u000a\u000avar moduleNameReqExp = '[\u005c\u005c.|\u005c\u005c-|\u005c\u005c+|\u005c\u005cw|\u005c/|@]+'\u000avar dependencyRegExp = '\u005c\u005c(\u005c\u005cs*(\u005c/\u005c\u005c*.*?\u005c\u005c*\u005c/)?\u005c\u005cs*.*?(' + moduleNameReqExp + ').*?\u005c\u005c)' // additional chars when output.pathinfo is true\u000a\u000a// http://stackoverflow.com/a/2593661/130442\u000afunction quoteRegExp (str) {\u000a  return (str + '').replace(/[.?*+^$[\u005c]\u005c\u005c(){}|-]/g, '\u005c\u005c$&')\u000a}\u000a\u000afunction isNumeric(n) {\u000a  return !isNaN(1 * n); // 1 * n converts integers, integers as string ("123"), 1e3 and "1e3" to integers and strings to NaN\u000a}\u000a\u000afunction getModuleDependencies (sources, module, queueName) {\u000a  var retval = {}\u000a  retval[queueName] = []\u000a\u000a  var fnString = module.toString()\u000a  var wrapperSignature = fnString.match(/^function\u005cs?\u005cw*\u005c(\u005cw+,\u005cs*\u005cw+,\u005cs*(\u005cw+)\u005c)/)\u000a  if (!wrapperSignature) return retval\u000a  var webpackRequireName = wrapperSignature[1]\u000a\u000a  // main bundle deps\u000a  var re = new RegExp('(\u005c\u005c\u005c\u005cn|\u005c\u005cW)' + quoteRegExp(webpackRequireName) + dependencyRegExp, 'g')\u000a  var match\u000a  while ((match = re.exec(fnString))) {\u000a    if (match[3] === 'dll-reference') continue\u000a    retval[queueName].push(match[3])\u000a  }\u000a\u000a  // dll deps\u000a  re = new RegExp('\u005c\u005c(' + quoteRegExp(webpackRequireName) + '\u005c\u005c("(dll-reference\u005c\u005cs(' + moduleNameReqExp + '))"\u005c\u005c)\u005c\u005c)' + dependencyRegExp, 'g')\u000a  while ((match = re.exec(fnString))) {\u000a    if (!sources[match[2]]) {\u000a      retval[queueName].push(match[1])\u000a      sources[match[2]] = __webpack_require__(match[1]).m\u000a    }\u000a    retval[match[2]] = retval[match[2]] || []\u000a    retval[match[2]].push(match[4])\u000a  }\u000a\u000a  // convert 1e3 back to 1000 - this can be important after uglify-js converted 1000 to 1e3\u000a  var keys = Object.keys(retval);\u000a  for (var i = 0; i < keys.length; i++) {\u000a    for (var j = 0; j < retval[keys[i]].length; j++) {\u000a      if (isNumeric(retval[keys[i]][j])) {\u000a        retval[keys[i]][j] = 1 * retval[keys[i]][j];\u000a      }\u000a    }\u000a  }\u000a\u000a  return retval\u000a}\u000a\u000afunction hasValuesInQueues (queues) {\u000a  var keys = Object.keys(queues)\u000a  return keys.reduce(function (hasValues, key) {\u000a    return hasValues || queues[key].length > 0\u000a  }, false)\u000a}\u000a\u000afunction getRequiredModules (sources, moduleId) {\u000a  var modulesQueue = {\u000a    main: [moduleId]\u000a  }\u000a  var requiredModules = {\u000a    main: []\u000a  }\u000a  var seenModules = {\u000a    main: {}\u000a  }\u000a\u000a  while (hasValuesInQueues(modulesQueue)) {\u000a    var queues = Object.keys(modulesQueue)\u000a    for (var i = 0; i < queues.length; i++) {\u000a      var queueName = queues[i]\u000a      var queue = modulesQueue[queueName]\u000a      var moduleToCheck = queue.pop()\u000a      seenModules[queueName] = seenModules[queueName] || {}\u000a      if (seenModules[queueName][moduleToCheck] || !sources[queueName][moduleToCheck]) continue\u000a      seenModules[queueName][moduleToCheck] = true\u000a      requiredModules[queueName] = requiredModules[queueName] || []\u000a      requiredModules[queueName].push(moduleToCheck)\u000a      var newModules = getModuleDependencies(sources, sources[queueName][moduleToCheck], queueName)\u000a      var newModulesKeys = Object.keys(newModules)\u000a      for (var j = 0; j < newModulesKeys.length; j++) {\u000a        modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]] || []\u000a        modulesQueue[newModulesKeys[j]] = modulesQueue[newModulesKeys[j]].concat(newModules[newModulesKeys[j]])\u000a      }\u000a    }\u000a  }\u000a\u000a  return requiredModules\u000a}\u000a\u000amodule.exports = function (moduleId, options) {\u000a  options = options || {}\u000a  var sources = {\u000a    main: __webpack_require__.m\u000a  }\u000a\u000a  var requiredModules = options.all ? { main: Object.keys(sources.main) } : getRequiredModules(sources, moduleId)\u000a\u000a  var src = ''\u000a\u000a  Object.keys(requiredModules).filter(function (m) { return m !== 'main' }).forEach(function (module) {\u000a    var entryModule = 0\u000a    while (requiredModules[module][entryModule]) {\u000a      entryModule++\u000a    }\u000a    requiredModules[module].push(entryModule)\u000a    sources[module][entryModule] = '(function(module, exports, __webpack_require__) { module.exports = __webpack_require__; })'\u000a    src = src + 'var ' + module + ' = (' + webpackBootstrapFunc.toString().replace('ENTRY_MODULE', JSON.stringify(entryModule)) + ')({' + requiredModules[module].map(function (id) { return '' + JSON.stringify(id) + ': ' + sources[module][id].toString() }).join(',') + '});\u005cn'\u000a  })\u000a\u000a  src = src + 'new ((' + webpackBootstrapFunc.toString().replace('ENTRY_MODULE', JSON.stringify(moduleId)) + ')({' + requiredModules.main.map(function (id) { return '' + JSON.stringify(id) + ': ' + sources.main[id].toString() }).join(',') + '}))(self);'\u000a\u000a  var blob = new window.Blob([src], { type: 'text/javascript' })\u000a  if (options.bare) { return blob }\u000a\u000a  var URL = window.URL || window.webkitURL || window.mozURL || window.msURL\u000a\u000a  var workerUrl = URL.createObjectURL(blob)\u000a  var worker = new window.Worker(workerUrl)\u000a  worker.objectURL = workerUrl\u000a\u000a  return worker\u000a}\u000a\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/crypt/decrypter.js":\u000a/*!********************************************!*\u005c\u000a  !*** ./src/crypt/decrypter.js + 3 modules ***!\u000a  \u005c********************************************/\u000a/*! exports provided: default */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/errors.ts because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/events.js because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/utils/get-self-scope.js because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/utils/logger.js because of ./src/hls.ts */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a// ESM COMPAT FLAG\u000a__webpack_require__.r(__webpack_exports__);\u000a\u000a// CONCATENATED MODULE: ./src/crypt/aes-crypto.js\u000avar AESCrypto = /*#__PURE__*/function () {\u000a  function AESCrypto(subtle, iv) {\u000a    this.subtle = subtle;\u000a    this.aesIV = iv;\u000a  }\u000a\u000a  var _proto = AESCrypto.prototype;\u000a\u000a  _proto.decrypt = function decrypt(data, key) {\u000a    return this.subtle.decrypt({\u000a      name: 'AES-CBC',\u000a      iv: this.aesIV\u000a    }, key, data);\u000a  };\u000a\u000a  return AESCrypto;\u000a}();\u000a\u000a\u000a// CONCATENATED MODULE: ./src/crypt/fast-aes-key.js\u000avar FastAESKey = /*#__PURE__*/function () {\u000a  function FastAESKey(subtle, key) {\u000a    this.subtle = subtle;\u000a    this.key = key;\u000a  }\u000a\u000a  var _proto = FastAESKey.prototype;\u000a\u000a  _proto.expandKey = function expandKey() {\u000a    return this.subtle.importKey('raw', this.key, {\u000a      name: 'AES-CBC'\u000a    }, false, ['encrypt', 'decrypt']);\u000a  };\u000a\u000a  return FastAESKey;\u000a}();\u000a\u000a/* harmony default export */ var fast_aes_key = (FastAESKey);\u000a// CONCATENATED MODULE: ./src/crypt/aes-decryptor.js\u000a// PKCS7\u000afunction removePadding(buffer) {\u000a  var outputBytes = buffer.byteLength;\u000a  var paddingBytes = outputBytes && new DataView(buffer).getUint8(outputBytes - 1);\u000a\u000a  if (paddingBytes) {\u000a    return buffer.slice(0, outputBytes - paddingBytes);\u000a  } else {\u000a    return buffer;\u000a  }\u000a}\u000a\u000avar AESDecryptor = /*#__PURE__*/function () {\u000a  function AESDecryptor() {\u000a    // Static after running initTable\u000a    this.rcon = [0x0, 0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36];\u000a    this.subMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\u000a    this.invSubMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\u000a    this.sBox = new Uint32Array(256);\u000a    this.invSBox = new Uint32Array(256); // Changes during runtime\u000a\u000a    this.key = new Uint32Array(0);\u000a    this.initTable();\u000a  } // Using view.getUint32() also swaps the byte order.\u000a\u000a\u000a  var _proto = AESDecryptor.prototype;\u000a\u000a  _proto.uint8ArrayToUint32Array_ = function uint8ArrayToUint32Array_(arrayBuffer) {\u000a    var view = new DataView(arrayBuffer);\u000a    var newArray = new Uint32Array(4);\u000a\u000a    for (var i = 0; i < 4; i++) {\u000a      newArray[i] = view.getUint32(i * 4);\u000a    }\u000a\u000a    return newArray;\u000a  };\u000a\u000a  _proto.initTable = function initTable() {\u000a    var sBox = this.sBox;\u000a    var invSBox = this.invSBox;\u000a    var subMix = this.subMix;\u000a    var subMix0 = subMix[0];\u000a    var subMix1 = subMix[1];\u000a    var subMix2 = subMix[2];\u000a    var subMix3 = subMix[3];\u000a    var invSubMix = this.invSubMix;\u000a    var invSubMix0 = invSubMix[0];\u000a    var invSubMix1 = invSubMix[1];\u000a    var invSubMix2 = invSubMix[2];\u000a    var invSubMix3 = invSubMix[3];\u000a    var d = new Uint32Array(256);\u000a    var x = 0;\u000a    var xi = 0;\u000a    var i = 0;\u000a\u000a    for (i = 0; i < 256; i++) {\u000a      if (i < 128) {\u000a        d[i] = i << 1;\u000a      } else {\u000a        d[i] = i << 1 ^ 0x11b;\u000a      }\u000a    }\u000a\u000a    for (i = 0; i < 256; i++) {\u000a      var sx = xi ^ xi << 1 ^ xi << 2 ^ xi << 3 ^ xi << 4;\u000a      sx = sx >>> 8 ^ sx & 0xff ^ 0x63;\u000a      sBox[x] = sx;\u000a      invSBox[sx] = x; // Compute multiplication\u000a\u000a      var x2 = d[x];\u000a      var x4 = d[x2];\u000a      var x8 = d[x4]; // Compute sub/invSub bytes, mix columns tables\u000a\u000a      var t = d[sx] * 0x101 ^ sx * 0x1010100;\u000a      subMix0[x] = t << 24 | t >>> 8;\u000a      subMix1[x] = t << 16 | t >>> 16;\u000a      subMix2[x] = t << 8 | t >>> 24;\u000a      subMix3[x] = t; // Compute inv sub bytes, inv mix columns tables\u000a\u000a      t = x8 * 0x1010101 ^ x4 * 0x10001 ^ x2 * 0x101 ^ x * 0x1010100;\u000a      invSubMix0[sx] = t << 24 | t >>> 8;\u000a      invSubMix1[sx] = t << 16 | t >>> 16;\u000a      invSubMix2[sx] = t << 8 | t >>> 24;\u000a      invSubMix3[sx] = t; // Compute next counter\u000a\u000a      if (!x) {\u000a        x = xi = 1;\u000a      } else {\u000a        x = x2 ^ d[d[d[x8 ^ x2]]];\u000a        xi ^= d[d[xi]];\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.expandKey = function expandKey(keyBuffer) {\u000a    // convert keyBuffer to Uint32Array\u000a    var key = this.uint8ArrayToUint32Array_(keyBuffer);\u000a    var sameKey = true;\u000a    var offset = 0;\u000a\u000a    while (offset < key.length && sameKey) {\u000a      sameKey = key[offset] === this.key[offset];\u000a      offset++;\u000a    }\u000a\u000a    if (sameKey) {\u000a      return;\u000a    }\u000a\u000a    this.key = key;\u000a    var keySize = this.keySize = key.length;\u000a\u000a    if (keySize !== 4 && keySize !== 6 && keySize !== 8) {\u000a      throw new Error('Invalid aes key size=' + keySize);\u000a    }\u000a\u000a    var ksRows = this.ksRows = (keySize + 6 + 1) * 4;\u000a    var ksRow;\u000a    var invKsRow;\u000a    var keySchedule = this.keySchedule = new Uint32Array(ksRows);\u000a    var invKeySchedule = this.invKeySchedule = new Uint32Array(ksRows);\u000a    var sbox = this.sBox;\u000a    var rcon = this.rcon;\u000a    var invSubMix = this.invSubMix;\u000a    var invSubMix0 = invSubMix[0];\u000a    var invSubMix1 = invSubMix[1];\u000a    var invSubMix2 = invSubMix[2];\u000a    var invSubMix3 = invSubMix[3];\u000a    var prev;\u000a    var t;\u000a\u000a    for (ksRow = 0; ksRow < ksRows; ksRow++) {\u000a      if (ksRow < keySize) {\u000a        prev = keySchedule[ksRow] = key[ksRow];\u000a        continue;\u000a      }\u000a\u000a      t = prev;\u000a\u000a      if (ksRow % keySize === 0) {\u000a        // Rot word\u000a        t = t << 8 | t >>> 24; // Sub word\u000a\u000a        t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff]; // Mix Rcon\u000a\u000a        t ^= rcon[ksRow / keySize | 0] << 24;\u000a      } else if (keySize > 6 && ksRow % keySize === 4) {\u000a        // Sub word\u000a        t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];\u000a      }\u000a\u000a      keySchedule[ksRow] = prev = (keySchedule[ksRow - keySize] ^ t) >>> 0;\u000a    }\u000a\u000a    for (invKsRow = 0; invKsRow < ksRows; invKsRow++) {\u000a      ksRow = ksRows - invKsRow;\u000a\u000a      if (invKsRow & 3) {\u000a        t = keySchedule[ksRow];\u000a      } else {\u000a        t = keySchedule[ksRow - 4];\u000a      }\u000a\u000a      if (invKsRow < 4 || ksRow <= 4) {\u000a        invKeySchedule[invKsRow] = t;\u000a      } else {\u000a        invKeySchedule[invKsRow] = invSubMix0[sbox[t >>> 24]] ^ invSubMix1[sbox[t >>> 16 & 0xff]] ^ invSubMix2[sbox[t >>> 8 & 0xff]] ^ invSubMix3[sbox[t & 0xff]];\u000a      }\u000a\u000a      invKeySchedule[invKsRow] = invKeySchedule[invKsRow] >>> 0;\u000a    }\u000a  } // Adding this as a method greatly improves performance.\u000a  ;\u000a\u000a  _proto.networkToHostOrderSwap = function networkToHostOrderSwap(word) {\u000a    return word << 24 | (word & 0xff00) << 8 | (word & 0xff0000) >> 8 | word >>> 24;\u000a  };\u000a\u000a  _proto.decrypt = function decrypt(inputArrayBuffer, offset, aesIV, removePKCS7Padding) {\u000a    var nRounds = this.keySize + 6;\u000a    var invKeySchedule = this.invKeySchedule;\u000a    var invSBOX = this.invSBox;\u000a    var invSubMix = this.invSubMix;\u000a    var invSubMix0 = invSubMix[0];\u000a    var invSubMix1 = invSubMix[1];\u000a    var invSubMix2 = invSubMix[2];\u000a    var invSubMix3 = invSubMix[3];\u000a    var initVector = this.uint8ArrayToUint32Array_(aesIV);\u000a    var initVector0 = initVector[0];\u000a    var initVector1 = initVector[1];\u000a    var initVector2 = initVector[2];\u000a    var initVector3 = initVector[3];\u000a    var inputInt32 = new Int32Array(inputArrayBuffer);\u000a    var outputInt32 = new Int32Array(inputInt32.length);\u000a    var t0, t1, t2, t3;\u000a    var s0, s1, s2, s3;\u000a    var inputWords0, inputWords1, inputWords2, inputWords3;\u000a    var ksRow, i;\u000a    var swapWord = this.networkToHostOrderSwap;\u000a\u000a    while (offset < inputInt32.length) {\u000a      inputWords0 = swapWord(inputInt32[offset]);\u000a      inputWords1 = swapWord(inputInt32[offset + 1]);\u000a      inputWords2 = swapWord(inputInt32[offset + 2]);\u000a      inputWords3 = swapWord(inputInt32[offset + 3]);\u000a      s0 = inputWords0 ^ invKeySchedule[0];\u000a      s1 = inputWords3 ^ invKeySchedule[1];\u000a      s2 = inputWords2 ^ invKeySchedule[2];\u000a      s3 = inputWords1 ^ invKeySchedule[3];\u000a      ksRow = 4; // Iterate through the rounds of decryption\u000a\u000a      for (i = 1; i < nRounds; i++) {\u000a        t0 = invSubMix0[s0 >>> 24] ^ invSubMix1[s1 >> 16 & 0xff] ^ invSubMix2[s2 >> 8 & 0xff] ^ invSubMix3[s3 & 0xff] ^ invKeySchedule[ksRow];\u000a        t1 = invSubMix0[s1 >>> 24] ^ invSubMix1[s2 >> 16 & 0xff] ^ invSubMix2[s3 >> 8 & 0xff] ^ invSubMix3[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\u000a        t2 = invSubMix0[s2 >>> 24] ^ invSubMix1[s3 >> 16 & 0xff] ^ invSubMix2[s0 >> 8 & 0xff] ^ invSubMix3[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\u000a        t3 = invSubMix0[s3 >>> 24] ^ invSubMix1[s0 >> 16 & 0xff] ^ invSubMix2[s1 >> 8 & 0xff] ^ invSubMix3[s2 & 0xff] ^ invKeySchedule[ksRow + 3]; // Update state\u000a\u000a        s0 = t0;\u000a        s1 = t1;\u000a        s2 = t2;\u000a        s3 = t3;\u000a        ksRow = ksRow + 4;\u000a      } // Shift rows, sub bytes, add round key\u000a\u000a\u000a      t0 = invSBOX[s0 >>> 24] << 24 ^ invSBOX[s1 >> 16 & 0xff] << 16 ^ invSBOX[s2 >> 8 & 0xff] << 8 ^ invSBOX[s3 & 0xff] ^ invKeySchedule[ksRow];\u000a      t1 = invSBOX[s1 >>> 24] << 24 ^ invSBOX[s2 >> 16 & 0xff] << 16 ^ invSBOX[s3 >> 8 & 0xff] << 8 ^ invSBOX[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\u000a      t2 = invSBOX[s2 >>> 24] << 24 ^ invSBOX[s3 >> 16 & 0xff] << 16 ^ invSBOX[s0 >> 8 & 0xff] << 8 ^ invSBOX[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\u000a      t3 = invSBOX[s3 >>> 24] << 24 ^ invSBOX[s0 >> 16 & 0xff] << 16 ^ invSBOX[s1 >> 8 & 0xff] << 8 ^ invSBOX[s2 & 0xff] ^ invKeySchedule[ksRow + 3];\u000a      ksRow = ksRow + 3; // Write\u000a\u000a      outputInt32[offset] = swapWord(t0 ^ initVector0);\u000a      outputInt32[offset + 1] = swapWord(t3 ^ initVector1);\u000a      outputInt32[offset + 2] = swapWord(t2 ^ initVector2);\u000a      outputInt32[offset + 3] = swapWord(t1 ^ initVector3); // reset initVector to last 4 unsigned int\u000a\u000a      initVector0 = inputWords0;\u000a      initVector1 = inputWords1;\u000a      initVector2 = inputWords2;\u000a      initVector3 = inputWords3;\u000a      offset = offset + 4;\u000a    }\u000a\u000a    return removePKCS7Padding ? removePadding(outputInt32.buffer) : outputInt32.buffer;\u000a  };\u000a\u000a  _proto.destroy = function destroy() {\u000a    this.key = undefined;\u000a    this.keySize = undefined;\u000a    this.ksRows = undefined;\u000a    this.sBox = undefined;\u000a    this.invSBox = undefined;\u000a    this.subMix = undefined;\u000a    this.invSubMix = undefined;\u000a    this.keySchedule = undefined;\u000a    this.invKeySchedule = undefined;\u000a    this.rcon = undefined;\u000a  };\u000a\u000a  return AESDecryptor;\u000a}();\u000a\u000a/* harmony default export */ var aes_decryptor = (AESDecryptor);\u000a// EXTERNAL MODULE: ./src/errors.ts\u000avar errors = __webpack_require__("./src/errors.ts");\u000a\u000a// EXTERNAL MODULE: ./src/utils/logger.js\u000avar logger = __webpack_require__("./src/utils/logger.js");\u000a\u000a// EXTERNAL MODULE: ./src/events.js\u000avar events = __webpack_require__("./src/events.js");\u000a\u000a// EXTERNAL MODULE: ./src/utils/get-self-scope.js\u000avar get_self_scope = __webpack_require__("./src/utils/get-self-scope.js");\u000a\u000a// CONCATENATED MODULE: ./src/crypt/decrypter.js\u000a\u000a\u000a\u000a\u000a\u000a\u000a // see https://stackoverflow.com/a/11237259/589493\u000a\u000avar global = Object(get_self_scope["getSelfScope"])(); // safeguard for code that might run both on worker and main thread\u000a\u000avar decrypter_Decrypter = /*#__PURE__*/function () {\u000a  function Decrypter(observer, config, _temp) {\u000a    var _ref = _temp === void 0 ? {} : _temp,\u000a        _ref$removePKCS7Paddi = _ref.removePKCS7Padding,\u000a        removePKCS7Padding = _ref$removePKCS7Paddi === void 0 ? true : _ref$removePKCS7Paddi;\u000a\u000a    this.logEnabled = true;\u000a    this.observer = observer;\u000a    this.config = config;\u000a    this.removePKCS7Padding = removePKCS7Padding; // built in decryptor expects PKCS7 padding\u000a\u000a    if (removePKCS7Padding) {\u000a      try {\u000a        var browserCrypto = global.crypto;\u000a\u000a        if (browserCrypto) {\u000a          this.subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;\u000a        }\u000a      } catch (e) {}\u000a    }\u000a\u000a    this.disableWebCrypto = !this.subtle;\u000a  }\u000a\u000a  var _proto = Decrypter.prototype;\u000a\u000a  _proto.isSync = function isSync() {\u000a    return this.disableWebCrypto && this.config.enableSoftwareAES;\u000a  };\u000a\u000a  _proto.decrypt = function decrypt(data, key, iv, callback) {\u000a    var _this = this;\u000a\u000a    if (this.disableWebCrypto && this.config.enableSoftwareAES) {\u000a      if (this.logEnabled) {\u000a        logger["logger"].log('JS AES decrypt');\u000a        this.logEnabled = false;\u000a      }\u000a\u000a      var decryptor = this.decryptor;\u000a\u000a      if (!decryptor) {\u000a        this.decryptor = decryptor = new aes_decryptor();\u000a      }\u000a\u000a      decryptor.expandKey(key);\u000a      callback(decryptor.decrypt(data, 0, iv, this.removePKCS7Padding));\u000a    } else {\u000a      if (this.logEnabled) {\u000a        logger["logger"].log('WebCrypto AES decrypt');\u000a        this.logEnabled = false;\u000a      }\u000a\u000a      var subtle = this.subtle;\u000a\u000a      if (this.key !== key) {\u000a        this.key = key;\u000a        this.fastAesKey = new fast_aes_key(subtle, key);\u000a      }\u000a\u000a      this.fastAesKey.expandKey().then(function (aesKey) {\u000a        // decrypt using web crypto\u000a        var crypto = new AESCrypto(subtle, iv);\u000a        crypto.decrypt(data, aesKey).catch(function (err) {\u000a          _this.onWebCryptoError(err, data, key, iv, callback);\u000a        }).then(function (result) {\u000a          callback(result);\u000a        });\u000a      }).catch(function (err) {\u000a        _this.onWebCryptoError(err, data, key, iv, callback);\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.onWebCryptoError = function onWebCryptoError(err, data, key, iv, callback) {\u000a    if (this.config.enableSoftwareAES) {\u000a      logger["logger"].log('WebCrypto Error, disable WebCrypto API');\u000a      this.disableWebCrypto = true;\u000a      this.logEnabled = true;\u000a      this.decrypt(data, key, iv, callback);\u000a    } else {\u000a      logger["logger"].error("decrypting error : " + err.message);\u000a      this.observer.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        details: errors["ErrorDetails"].FRAG_DECRYPT_ERROR,\u000a        fatal: true,\u000a        reason: err.message\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.destroy = function destroy() {\u000a    var decryptor = this.decryptor;\u000a\u000a    if (decryptor) {\u000a      decryptor.destroy();\u000a      this.decryptor = undefined;\u000a    }\u000a  };\u000a\u000a  return Decrypter;\u000a}();\u000a\u000a/* harmony default export */ var decrypter = __webpack_exports__["default"] = (decrypter_Decrypter);\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/demux/demuxer-inline.js":\u000a/*!**************************************************!*\u005c\u000a  !*** ./src/demux/demuxer-inline.js + 12 modules ***!\u000a  \u005c**************************************************/\u000a/*! exports provided: default */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/crypt/decrypter.js because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/demux/id3.js because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/demux/mp4demuxer.js because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/errors.ts because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/events.js because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/polyfills/number.js because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/utils/get-self-scope.js because of ./src/hls.ts */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/utils/logger.js because of ./src/hls.ts */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a// ESM COMPAT FLAG\u000a__webpack_require__.r(__webpack_exports__);\u000a\u000a// EXTERNAL MODULE: ./src/events.js\u000avar events = __webpack_require__("./src/events.js");\u000a\u000a// EXTERNAL MODULE: ./src/errors.ts\u000avar errors = __webpack_require__("./src/errors.ts");\u000a\u000a// EXTERNAL MODULE: ./src/crypt/decrypter.js + 3 modules\u000avar crypt_decrypter = __webpack_require__("./src/crypt/decrypter.js");\u000a\u000a// EXTERNAL MODULE: ./src/polyfills/number.js\u000avar number = __webpack_require__("./src/polyfills/number.js");\u000a\u000a// EXTERNAL MODULE: ./src/utils/logger.js\u000avar logger = __webpack_require__("./src/utils/logger.js");\u000a\u000a// EXTERNAL MODULE: ./src/utils/get-self-scope.js\u000avar get_self_scope = __webpack_require__("./src/utils/get-self-scope.js");\u000a\u000a// CONCATENATED MODULE: ./src/demux/adts.js\u000a/**\u000a * ADTS parser helper\u000a * @link https://wiki.multimedia.cx/index.php?title=ADTS\u000a */\u000a\u000a\u000a\u000a\u000afunction getAudioConfig(observer, data, offset, audioCodec) {\u000a  var adtsObjectType,\u000a      // :int\u000a  adtsSampleingIndex,\u000a      // :int\u000a  adtsExtensionSampleingIndex,\u000a      // :int\u000a  adtsChanelConfig,\u000a      // :int\u000a  config,\u000a      userAgent = navigator.userAgent.toLowerCase(),\u000a      manifestCodec = audioCodec,\u000a      adtsSampleingRates = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350]; // byte 2\u000a\u000a  adtsObjectType = ((data[offset + 2] & 0xC0) >>> 6) + 1;\u000a  adtsSampleingIndex = (data[offset + 2] & 0x3C) >>> 2;\u000a\u000a  if (adtsSampleingIndex > adtsSampleingRates.length - 1) {\u000a    observer.trigger(events["default"].ERROR, {\u000a      type: errors["ErrorTypes"].MEDIA_ERROR,\u000a      details: errors["ErrorDetails"].FRAG_PARSING_ERROR,\u000a      fatal: true,\u000a      reason: "invalid ADTS sampling index:" + adtsSampleingIndex\u000a    });\u000a    return;\u000a  }\u000a\u000a  adtsChanelConfig = (data[offset + 2] & 0x01) << 2; // byte 3\u000a\u000a  adtsChanelConfig |= (data[offset + 3] & 0xC0) >>> 6;\u000a  logger["logger"].log("manifest codec:" + audioCodec + ",ADTS data:type:" + adtsObjectType + ",sampleingIndex:" + adtsSampleingIndex + "[" + adtsSampleingRates[adtsSampleingIndex] + "Hz],channelConfig:" + adtsChanelConfig); // firefox: freq less than 24kHz = AAC SBR (HE-AAC)\u000a\u000a  if (/firefox/i.test(userAgent)) {\u000a    if (adtsSampleingIndex >= 6) {\u000a      adtsObjectType = 5;\u000a      config = new Array(4); // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies\u000a      // there is a factor 2 between frame sample rate and output sample rate\u000a      // multiply frequency by 2 (see table below, equivalent to substract 3)\u000a\u000a      adtsExtensionSampleingIndex = adtsSampleingIndex - 3;\u000a    } else {\u000a      adtsObjectType = 2;\u000a      config = new Array(2);\u000a      adtsExtensionSampleingIndex = adtsSampleingIndex;\u000a    } // Android : always use AAC\u000a\u000a  } else if (userAgent.indexOf('android') !== -1) {\u000a    adtsObjectType = 2;\u000a    config = new Array(2);\u000a    adtsExtensionSampleingIndex = adtsSampleingIndex;\u000a  } else {\u000a    /*  for other browsers (Chrome/Vivaldi/Opera ...)\u000a        always force audio type to be HE-AAC SBR, as some browsers do not support audio codec switch properly (like Chrome ...)\u000a    */\u000a    adtsObjectType = 5;\u000a    config = new Array(4); // if (manifest codec is HE-AAC or HE-AACv2) OR (manifest codec not specified AND frequency less than 24kHz)\u000a\u000a    if (audioCodec && (audioCodec.indexOf('mp4a.40.29') !== -1 || audioCodec.indexOf('mp4a.40.5') !== -1) || !audioCodec && adtsSampleingIndex >= 6) {\u000a      // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies\u000a      // there is a factor 2 between frame sample rate and output sample rate\u000a      // multiply frequency by 2 (see table below, equivalent to substract 3)\u000a      adtsExtensionSampleingIndex = adtsSampleingIndex - 3;\u000a    } else {\u000a      // if (manifest codec is AAC) AND (frequency less than 24kHz AND nb channel is 1) OR (manifest codec not specified and mono audio)\u000a      // Chrome fails to play back with low frequency AAC LC mono when initialized with HE-AAC.  This is not a problem with stereo.\u000a      if (audioCodec && audioCodec.indexOf('mp4a.40.2') !== -1 && (adtsSampleingIndex >= 6 && adtsChanelConfig === 1 || /vivaldi/i.test(userAgent)) || !audioCodec && adtsChanelConfig === 1) {\u000a        adtsObjectType = 2;\u000a        config = new Array(2);\u000a      }\u000a\u000a      adtsExtensionSampleingIndex = adtsSampleingIndex;\u000a    }\u000a  }\u000a  /* refer to http://wiki.multimedia.cx/index.php?title=MPEG-4_Audio#Audio_Specific_Config\u000a      ISO 14496-3 (AAC).pdf - Table 1.13 \u2014 Syntax of AudioSpecificConfig()\u000a    Audio Profile / Audio Object Type\u000a    0: Null\u000a    1: AAC Main\u000a    2: AAC LC (Low Complexity)\u000a    3: AAC SSR (Scalable Sample Rate)\u000a    4: AAC LTP (Long Term Prediction)\u000a    5: SBR (Spectral Band Replication)\u000a    6: AAC Scalable\u000a   sampling freq\u000a    0: 96000 Hz\u000a    1: 88200 Hz\u000a    2: 64000 Hz\u000a    3: 48000 Hz\u000a    4: 44100 Hz\u000a    5: 32000 Hz\u000a    6: 24000 Hz\u000a    7: 22050 Hz\u000a    8: 16000 Hz\u000a    9: 12000 Hz\u000a    10: 11025 Hz\u000a    11: 8000 Hz\u000a    12: 7350 Hz\u000a    13: Reserved\u000a    14: Reserved\u000a    15: frequency is written explictly\u000a    Channel Configurations\u000a    These are the channel configurations:\u000a    0: Defined in AOT Specifc Config\u000a    1: 1 channel: front-center\u000a    2: 2 channels: front-left, front-right\u000a  */\u000a  // audioObjectType = profile => profile, the MPEG-4 Audio Object Type minus 1\u000a\u000a\u000a  config[0] = adtsObjectType << 3; // samplingFrequencyIndex\u000a\u000a  config[0] |= (adtsSampleingIndex & 0x0E) >> 1;\u000a  config[1] |= (adtsSampleingIndex & 0x01) << 7; // channelConfiguration\u000a\u000a  config[1] |= adtsChanelConfig << 3;\u000a\u000a  if (adtsObjectType === 5) {\u000a    // adtsExtensionSampleingIndex\u000a    config[1] |= (adtsExtensionSampleingIndex & 0x0E) >> 1;\u000a    config[2] = (adtsExtensionSampleingIndex & 0x01) << 7; // adtsObjectType (force to 2, chrome is checking that object type is less than 5 ???\u000a    //    https://chromium.googlesource.com/chromium/src.git/+/master/media/formats/mp4/aac.cc\u000a\u000a    config[2] |= 2 << 2;\u000a    config[3] = 0;\u000a  }\u000a\u000a  return {\u000a    config: config,\u000a    samplerate: adtsSampleingRates[adtsSampleingIndex],\u000a    channelCount: adtsChanelConfig,\u000a    codec: 'mp4a.40.' + adtsObjectType,\u000a    manifestCodec: manifestCodec\u000a  };\u000a}\u000afunction isHeaderPattern(data, offset) {\u000a  return data[offset] === 0xff && (data[offset + 1] & 0xf6) === 0xf0;\u000a}\u000afunction getHeaderLength(data, offset) {\u000a  return data[offset + 1] & 0x01 ? 7 : 9;\u000a}\u000afunction getFullFrameLength(data, offset) {\u000a  return (data[offset + 3] & 0x03) << 11 | data[offset + 4] << 3 | (data[offset + 5] & 0xE0) >>> 5;\u000a}\u000afunction isHeader(data, offset) {\u000a  // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\u000a  // Layer bits (position 14 and 15) in header should be always 0 for ADTS\u000a  // More info https://wiki.multimedia.cx/index.php?title=ADTS\u000a  if (offset + 1 < data.length && isHeaderPattern(data, offset)) {\u000a    return true;\u000a  }\u000a\u000a  return false;\u000a}\u000afunction adts_probe(data, offset) {\u000a  // same as isHeader but we also check that ADTS frame follows last ADTS frame\u000a  // or end of data is reached\u000a  if (isHeader(data, offset)) {\u000a    // ADTS header Length\u000a    var headerLength = getHeaderLength(data, offset);\u000a\u000a    if (offset + headerLength >= data.length) {\u000a      return false;\u000a    } // ADTS frame Length\u000a\u000a\u000a    var frameLength = getFullFrameLength(data, offset);\u000a\u000a    if (frameLength <= headerLength) {\u000a      return false;\u000a    }\u000a\u000a    var newOffset = offset + frameLength;\u000a\u000a    if (newOffset === data.length || newOffset + 1 < data.length && isHeaderPattern(data, newOffset)) {\u000a      return true;\u000a    }\u000a  }\u000a\u000a  return false;\u000a}\u000afunction initTrackConfig(track, observer, data, offset, audioCodec) {\u000a  if (!track.samplerate) {\u000a    var config = getAudioConfig(observer, data, offset, audioCodec);\u000a    track.config = config.config;\u000a    track.samplerate = config.samplerate;\u000a    track.channelCount = config.channelCount;\u000a    track.codec = config.codec;\u000a    track.manifestCodec = config.manifestCodec;\u000a    logger["logger"].log("parsed codec:" + track.codec + ",rate:" + config.samplerate + ",nb channel:" + config.channelCount);\u000a  }\u000a}\u000afunction getFrameDuration(samplerate) {\u000a  return 1024 * 90000 / samplerate;\u000a}\u000afunction parseFrameHeader(data, offset, pts, frameIndex, frameDuration) {\u000a  var headerLength, frameLength, stamp;\u000a  var length = data.length; // The protection skip bit tells us if we have 2 bytes of CRC data at the end of the ADTS header\u000a\u000a  headerLength = getHeaderLength(data, offset); // retrieve frame size\u000a\u000a  frameLength = getFullFrameLength(data, offset);\u000a  frameLength -= headerLength;\u000a\u000a  if (frameLength > 0 && offset + headerLength + frameLength <= length) {\u000a    stamp = pts + frameIndex * frameDuration; // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}/${(stamp/90).toFixed(0)}`);\u000a\u000a    return {\u000a      headerLength: headerLength,\u000a      frameLength: frameLength,\u000a      stamp: stamp\u000a    };\u000a  }\u000a\u000a  return undefined;\u000a}\u000afunction appendFrame(track, data, offset, pts, frameIndex) {\u000a  var frameDuration = getFrameDuration(track.samplerate);\u000a  var header = parseFrameHeader(data, offset, pts, frameIndex, frameDuration);\u000a\u000a  if (header) {\u000a    var stamp = header.stamp;\u000a    var headerLength = header.headerLength;\u000a    var frameLength = header.frameLength; // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}/${(stamp/90).toFixed(0)}`);\u000a\u000a    var aacSample = {\u000a      unit: data.subarray(offset + headerLength, offset + headerLength + frameLength),\u000a      pts: stamp,\u000a      dts: stamp\u000a    };\u000a    track.samples.push(aacSample);\u000a    return {\u000a      sample: aacSample,\u000a      length: frameLength + headerLength\u000a    };\u000a  }\u000a\u000a  return undefined;\u000a}\u000a// EXTERNAL MODULE: ./src/demux/id3.js\u000avar id3 = __webpack_require__("./src/demux/id3.js");\u000a\u000a// CONCATENATED MODULE: ./src/demux/aacdemuxer.js\u000a\u000a\u000a/**\u000a * AAC demuxer\u000a */\u000a\u000a\u000a\u000a\u000avar aacdemuxer_AACDemuxer = /*#__PURE__*/function () {\u000a  function AACDemuxer(observer, remuxer, config) {\u000a    this.observer = observer;\u000a    this.config = config;\u000a    this.remuxer = remuxer;\u000a  }\u000a\u000a  var _proto = AACDemuxer.prototype;\u000a\u000a  _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, duration) {\u000a    this._audioTrack = {\u000a      container: 'audio/adts',\u000a      type: 'audio',\u000a      id: 0,\u000a      sequenceNumber: 0,\u000a      isAAC: true,\u000a      samples: [],\u000a      len: 0,\u000a      manifestCodec: audioCodec,\u000a      duration: duration,\u000a      inputTimeScale: 90000\u000a    };\u000a  };\u000a\u000a  _proto.resetTimeStamp = function resetTimeStamp() {};\u000a\u000a  AACDemuxer.probe = function probe(data) {\u000a    if (!data) {\u000a      return false;\u000a    } // Check for the ADTS sync word\u000a    // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\u000a    // Layer bits (position 14 and 15) in header should be always 0 for ADTS\u000a    // More info https://wiki.multimedia.cx/index.php?title=ADTS\u000a\u000a\u000a    var id3Data = id3["default"].getID3Data(data, 0) || [];\u000a    var offset = id3Data.length;\u000a\u000a    for (var length = data.length; offset < length; offset++) {\u000a      if (adts_probe(data, offset)) {\u000a        logger["logger"].log('ADTS sync word found !');\u000a        return true;\u000a      }\u000a    }\u000a\u000a    return false;\u000a  } // feed incoming data to the front of the parsing pipeline\u000a  ;\u000a\u000a  _proto.append = function append(data, timeOffset, contiguous, accurateTimeOffset) {\u000a    var track = this._audioTrack;\u000a    var id3Data = id3["default"].getID3Data(data, 0) || [];\u000a    var timestamp = id3["default"].getTimeStamp(id3Data);\u000a    var pts = Object(number["isFiniteNumber"])(timestamp) ? timestamp * 90 : timeOffset * 90000;\u000a    var frameIndex = 0;\u000a    var stamp = pts;\u000a    var length = data.length;\u000a    var offset = id3Data.length;\u000a    var id3Samples = [{\u000a      pts: stamp,\u000a      dts: stamp,\u000a      data: id3Data\u000a    }];\u000a\u000a    while (offset < length - 1) {\u000a      if (isHeader(data, offset) && offset + 5 < length) {\u000a        initTrackConfig(track, this.observer, data, offset, track.manifestCodec);\u000a        var frame = appendFrame(track, data, offset, pts, frameIndex);\u000a\u000a        if (frame) {\u000a          offset += frame.length;\u000a          stamp = frame.sample.pts;\u000a          frameIndex++;\u000a        } else {\u000a          logger["logger"].log('Unable to parse AAC frame');\u000a          break;\u000a        }\u000a      } else if (id3["default"].isHeader(data, offset)) {\u000a        id3Data = id3["default"].getID3Data(data, offset);\u000a        id3Samples.push({\u000a          pts: stamp,\u000a          dts: stamp,\u000a          data: id3Data\u000a        });\u000a        offset += id3Data.length;\u000a      } else {\u000a        // nothing found, keep looking\u000a        offset++;\u000a      }\u000a    }\u000a\u000a    this.remuxer.remux(track, {\u000a      samples: []\u000a    }, {\u000a      samples: id3Samples,\u000a      inputTimeScale: 90000\u000a    }, {\u000a      samples: []\u000a    }, timeOffset, contiguous, accurateTimeOffset);\u000a  };\u000a\u000a  _proto.destroy = function destroy() {};\u000a\u000a  return AACDemuxer;\u000a}();\u000a\u000a/* harmony default export */ var aacdemuxer = (aacdemuxer_AACDemuxer);\u000a// EXTERNAL MODULE: ./src/demux/mp4demuxer.js\u000avar mp4demuxer = __webpack_require__("./src/demux/mp4demuxer.js");\u000a\u000a// CONCATENATED MODULE: ./src/demux/mpegaudio.js\u000a/**\u000a *  MPEG parser helper\u000a */\u000avar MpegAudio = {\u000a  BitratesMap: [32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 32, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 384, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 32, 48, 56, 64, 80, 96, 112, 128, 144, 160, 176, 192, 224, 256, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160],\u000a  SamplingRateMap: [44100, 48000, 32000, 22050, 24000, 16000, 11025, 12000, 8000],\u000a  SamplesCoefficients: [// MPEG 2.5\u000a  [0, // Reserved\u000a  72, // Layer3\u000a  144, // Layer2\u000a  12 // Layer1\u000a  ], // Reserved\u000a  [0, // Reserved\u000a  0, // Layer3\u000a  0, // Layer2\u000a  0 // Layer1\u000a  ], // MPEG 2\u000a  [0, // Reserved\u000a  72, // Layer3\u000a  144, // Layer2\u000a  12 // Layer1\u000a  ], // MPEG 1\u000a  [0, // Reserved\u000a  144, // Layer3\u000a  144, // Layer2\u000a  12 // Layer1\u000a  ]],\u000a  BytesInSlot: [0, // Reserved\u000a  1, // Layer3\u000a  1, // Layer2\u000a  4 // Layer1\u000a  ],\u000a  appendFrame: function appendFrame(track, data, offset, pts, frameIndex) {\u000a    // Using http://www.datavoyage.com/mpgscript/mpeghdr.htm as a reference\u000a    if (offset + 24 > data.length) {\u000a      return undefined;\u000a    }\u000a\u000a    var header = this.parseHeader(data, offset);\u000a\u000a    if (header && offset + header.frameLength <= data.length) {\u000a      var frameDuration = header.samplesPerFrame * 90000 / header.sampleRate;\u000a      var stamp = pts + frameIndex * frameDuration;\u000a      var sample = {\u000a        unit: data.subarray(offset, offset + header.frameLength),\u000a        pts: stamp,\u000a        dts: stamp\u000a      };\u000a      track.config = [];\u000a      track.channelCount = header.channelCount;\u000a      track.samplerate = header.sampleRate;\u000a      track.samples.push(sample);\u000a      return {\u000a        sample: sample,\u000a        length: header.frameLength\u000a      };\u000a    }\u000a\u000a    return undefined;\u000a  },\u000a  parseHeader: function parseHeader(data, offset) {\u000a    var headerB = data[offset + 1] >> 3 & 3;\u000a    var headerC = data[offset + 1] >> 1 & 3;\u000a    var headerE = data[offset + 2] >> 4 & 15;\u000a    var headerF = data[offset + 2] >> 2 & 3;\u000a    var headerG = data[offset + 2] >> 1 & 1;\u000a\u000a    if (headerB !== 1 && headerE !== 0 && headerE !== 15 && headerF !== 3) {\u000a      var columnInBitrates = headerB === 3 ? 3 - headerC : headerC === 3 ? 3 : 4;\u000a      var bitRate = MpegAudio.BitratesMap[columnInBitrates * 14 + headerE - 1] * 1000;\u000a      var columnInSampleRates = headerB === 3 ? 0 : headerB === 2 ? 1 : 2;\u000a      var sampleRate = MpegAudio.SamplingRateMap[columnInSampleRates * 3 + headerF];\u000a      var channelCount = data[offset + 3] >> 6 === 3 ? 1 : 2; // If bits of channel mode are `11` then it is a single channel (Mono)\u000a\u000a      var sampleCoefficient = MpegAudio.SamplesCoefficients[headerB][headerC];\u000a      var bytesInSlot = MpegAudio.BytesInSlot[headerC];\u000a      var samplesPerFrame = sampleCoefficient * 8 * bytesInSlot;\u000a      var frameLength = parseInt(sampleCoefficient * bitRate / sampleRate + headerG, 10) * bytesInSlot;\u000a      return {\u000a        sampleRate: sampleRate,\u000a        channelCount: channelCount,\u000a        frameLength: frameLength,\u000a        samplesPerFrame: samplesPerFrame\u000a      };\u000a    }\u000a\u000a    return undefined;\u000a  },\u000a  isHeaderPattern: function isHeaderPattern(data, offset) {\u000a    return data[offset] === 0xff && (data[offset + 1] & 0xe0) === 0xe0 && (data[offset + 1] & 0x06) !== 0x00;\u000a  },\u000a  isHeader: function isHeader(data, offset) {\u000a    // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\u000a    // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\u000a    // More info http://www.mp3-tech.org/programmer/frame_header.html\u000a    if (offset + 1 < data.length && this.isHeaderPattern(data, offset)) {\u000a      return true;\u000a    }\u000a\u000a    return false;\u000a  },\u000a  probe: function probe(data, offset) {\u000a    // same as isHeader but we also check that MPEG frame follows last MPEG frame\u000a    // or end of data is reached\u000a    if (offset + 1 < data.length && this.isHeaderPattern(data, offset)) {\u000a      // MPEG header Length\u000a      var headerLength = 4; // MPEG frame Length\u000a\u000a      var header = this.parseHeader(data, offset);\u000a      var frameLength = headerLength;\u000a\u000a      if (header && header.frameLength) {\u000a        frameLength = header.frameLength;\u000a      }\u000a\u000a      var newOffset = offset + frameLength;\u000a\u000a      if (newOffset === data.length || newOffset + 1 < data.length && this.isHeaderPattern(data, newOffset)) {\u000a        return true;\u000a      }\u000a    }\u000a\u000a    return false;\u000a  }\u000a};\u000a/* harmony default export */ var mpegaudio = (MpegAudio);\u000a// CONCATENATED MODULE: ./src/demux/exp-golomb.js\u000a/**\u000a * Parser for exponential Golomb codes, a variable-bitwidth number encoding scheme used by h264.\u000a*/\u000a\u000a\u000avar exp_golomb_ExpGolomb = /*#__PURE__*/function () {\u000a  function ExpGolomb(data) {\u000a    this.data = data; // the number of bytes left to examine in this.data\u000a\u000a    this.bytesAvailable = data.byteLength; // the current word being examined\u000a\u000a    this.word = 0; // :uint\u000a    // the number of bits left to examine in the current word\u000a\u000a    this.bitsAvailable = 0; // :uint\u000a  } // ():void\u000a\u000a\u000a  var _proto = ExpGolomb.prototype;\u000a\u000a  _proto.loadWord = function loadWord() {\u000a    var data = this.data,\u000a        bytesAvailable = this.bytesAvailable,\u000a        position = data.byteLength - bytesAvailable,\u000a        workingBytes = new Uint8Array(4),\u000a        availableBytes = Math.min(4, bytesAvailable);\u000a\u000a    if (availableBytes === 0) {\u000a      throw new Error('no bytes available');\u000a    }\u000a\u000a    workingBytes.set(data.subarray(position, position + availableBytes));\u000a    this.word = new DataView(workingBytes.buffer).getUint32(0); // track the amount of this.data that has been processed\u000a\u000a    this.bitsAvailable = availableBytes * 8;\u000a    this.bytesAvailable -= availableBytes;\u000a  } // (count:int):void\u000a  ;\u000a\u000a  _proto.skipBits = function skipBits(count) {\u000a    var skipBytes; // :int\u000a\u000a    if (this.bitsAvailable > count) {\u000a      this.word <<= count;\u000a      this.bitsAvailable -= count;\u000a    } else {\u000a      count -= this.bitsAvailable;\u000a      skipBytes = count >> 3;\u000a      count -= skipBytes >> 3;\u000a      this.bytesAvailable -= skipBytes;\u000a      this.loadWord();\u000a      this.word <<= count;\u000a      this.bitsAvailable -= count;\u000a    }\u000a  } // (size:int):uint\u000a  ;\u000a\u000a  _proto.readBits = function readBits(size) {\u000a    var bits = Math.min(this.bitsAvailable, size),\u000a        // :uint\u000a    valu = this.word >>> 32 - bits; // :uint\u000a\u000a    if (size > 32) {\u000a      logger["logger"].error('Cannot read more than 32 bits at a time');\u000a    }\u000a\u000a    this.bitsAvailable -= bits;\u000a\u000a    if (this.bitsAvailable > 0) {\u000a      this.word <<= bits;\u000a    } else if (this.bytesAvailable > 0) {\u000a      this.loadWord();\u000a    }\u000a\u000a    bits = size - bits;\u000a\u000a    if (bits > 0 && this.bitsAvailable) {\u000a      return valu << bits | this.readBits(bits);\u000a    } else {\u000a      return valu;\u000a    }\u000a  } // ():uint\u000a  ;\u000a\u000a  _proto.skipLZ = function skipLZ() {\u000a    var leadingZeroCount; // :uint\u000a\u000a    for (leadingZeroCount = 0; leadingZeroCount < this.bitsAvailable; ++leadingZeroCount) {\u000a      if ((this.word & 0x80000000 >>> leadingZeroCount) !== 0) {\u000a        // the first bit of working word is 1\u000a        this.word <<= leadingZeroCount;\u000a        this.bitsAvailable -= leadingZeroCount;\u000a        return leadingZeroCount;\u000a      }\u000a    } // we exhausted word and still have not found a 1\u000a\u000a\u000a    this.loadWord();\u000a    return leadingZeroCount + this.skipLZ();\u000a  } // ():void\u000a  ;\u000a\u000a  _proto.skipUEG = function skipUEG() {\u000a    this.skipBits(1 + this.skipLZ());\u000a  } // ():void\u000a  ;\u000a\u000a  _proto.skipEG = function skipEG() {\u000a    this.skipBits(1 + this.skipLZ());\u000a  } // ():uint\u000a  ;\u000a\u000a  _proto.readUEG = function readUEG() {\u000a    var clz = this.skipLZ(); // :uint\u000a\u000a    return this.readBits(clz + 1) - 1;\u000a  } // ():int\u000a  ;\u000a\u000a  _proto.readEG = function readEG() {\u000a    var valu = this.readUEG(); // :int\u000a\u000a    if (0x01 & valu) {\u000a      // the number is odd if the low order bit is set\u000a      return 1 + valu >>> 1; // add 1 to make it even, and divide by 2\u000a    } else {\u000a      return -1 * (valu >>> 1); // divide by two then make it negative\u000a    }\u000a  } // Some convenience functions\u000a  // :Boolean\u000a  ;\u000a\u000a  _proto.readBoolean = function readBoolean() {\u000a    return this.readBits(1) === 1;\u000a  } // ():int\u000a  ;\u000a\u000a  _proto.readUByte = function readUByte() {\u000a    return this.readBits(8);\u000a  } // ():int\u000a  ;\u000a\u000a  _proto.readUShort = function readUShort() {\u000a    return this.readBits(16);\u000a  } // ():int\u000a  ;\u000a\u000a  _proto.readUInt = function readUInt() {\u000a    return this.readBits(32);\u000a  }\u000a  /**\u000a   * Advance the ExpGolomb decoder past a scaling list. The scaling\u000a   * list is optionally transmitted as part of a sequence parameter\u000a   * set and is not relevant to transmuxing.\u000a   * @param count {number} the number of entries in this scaling list\u000a   * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1\u000a   */\u000a  ;\u000a\u000a  _proto.skipScalingList = function skipScalingList(count) {\u000a    var lastScale = 8,\u000a        nextScale = 8,\u000a        j,\u000a        deltaScale;\u000a\u000a    for (j = 0; j < count; j++) {\u000a      if (nextScale !== 0) {\u000a        deltaScale = this.readEG();\u000a        nextScale = (lastScale + deltaScale + 256) % 256;\u000a      }\u000a\u000a      lastScale = nextScale === 0 ? lastScale : nextScale;\u000a    }\u000a  }\u000a  /**\u000a   * Read a sequence parameter set and return some interesting video\u000a   * properties. A sequence parameter set is the H264 metadata that\u000a   * describes the properties of upcoming video frames.\u000a   * @param data {Uint8Array} the bytes of a sequence parameter set\u000a   * @return {object} an object with configuration parsed from the\u000a   * sequence parameter set, including the dimensions of the\u000a   * associated video frames.\u000a   */\u000a  ;\u000a\u000a  _proto.readSPS = function readSPS() {\u000a    var frameCropLeftOffset = 0,\u000a        frameCropRightOffset = 0,\u000a        frameCropTopOffset = 0,\u000a        frameCropBottomOffset = 0,\u000a        profileIdc,\u000a        profileCompat,\u000a        levelIdc,\u000a        numRefFramesInPicOrderCntCycle,\u000a        picWidthInMbsMinus1,\u000a        picHeightInMapUnitsMinus1,\u000a        frameMbsOnlyFlag,\u000a        scalingListCount,\u000a        i,\u000a        readUByte = this.readUByte.bind(this),\u000a        readBits = this.readBits.bind(this),\u000a        readUEG = this.readUEG.bind(this),\u000a        readBoolean = this.readBoolean.bind(this),\u000a        skipBits = this.skipBits.bind(this),\u000a        skipEG = this.skipEG.bind(this),\u000a        skipUEG = this.skipUEG.bind(this),\u000a        skipScalingList = this.skipScalingList.bind(this);\u000a    readUByte();\u000a    profileIdc = readUByte(); // profile_idc\u000a\u000a    profileCompat = readBits(5); // constraint_set[0-4]_flag, u(5)\u000a\u000a    skipBits(3); // reserved_zero_3bits u(3),\u000a\u000a    levelIdc = readUByte(); // level_idc u(8)\u000a\u000a    skipUEG(); // seq_parameter_set_id\u000a    // some profiles have more optional data we don't need\u000a\u000a    if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {\u000a      var chromaFormatIdc = readUEG();\u000a\u000a      if (chromaFormatIdc === 3) {\u000a        skipBits(1);\u000a      } // separate_colour_plane_flag\u000a\u000a\u000a      skipUEG(); // bit_depth_luma_minus8\u000a\u000a      skipUEG(); // bit_depth_chroma_minus8\u000a\u000a      skipBits(1); // qpprime_y_zero_transform_bypass_flag\u000a\u000a      if (readBoolean()) {\u000a        // seq_scaling_matrix_present_flag\u000a        scalingListCount = chromaFormatIdc !== 3 ? 8 : 12;\u000a\u000a        for (i = 0; i < scalingListCount; i++) {\u000a          if (readBoolean()) {\u000a            // seq_scaling_list_present_flag[ i ]\u000a            if (i < 6) {\u000a              skipScalingList(16);\u000a            } else {\u000a              skipScalingList(64);\u000a            }\u000a          }\u000a        }\u000a      }\u000a    }\u000a\u000a    skipUEG(); // log2_max_frame_num_minus4\u000a\u000a    var picOrderCntType = readUEG();\u000a\u000a    if (picOrderCntType === 0) {\u000a      readUEG(); // log2_max_pic_order_cnt_lsb_minus4\u000a    } else if (picOrderCntType === 1) {\u000a      skipBits(1); // delta_pic_order_always_zero_flag\u000a\u000a      skipEG(); // offset_for_non_ref_pic\u000a\u000a      skipEG(); // offset_for_top_to_bottom_field\u000a\u000a      numRefFramesInPicOrderCntCycle = readUEG();\u000a\u000a      for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {\u000a        skipEG();\u000a      } // offset_for_ref_frame[ i ]\u000a\u000a    }\u000a\u000a    skipUEG(); // max_num_ref_frames\u000a\u000a    skipBits(1); // gaps_in_frame_num_value_allowed_flag\u000a\u000a    picWidthInMbsMinus1 = readUEG();\u000a    picHeightInMapUnitsMinus1 = readUEG();\u000a    frameMbsOnlyFlag = readBits(1);\u000a\u000a    if (frameMbsOnlyFlag === 0) {\u000a      skipBits(1);\u000a    } // mb_adaptive_frame_field_flag\u000a\u000a\u000a    skipBits(1); // direct_8x8_inference_flag\u000a\u000a    if (readBoolean()) {\u000a      // frame_cropping_flag\u000a      frameCropLeftOffset = readUEG();\u000a      frameCropRightOffset = readUEG();\u000a      frameCropTopOffset = readUEG();\u000a      frameCropBottomOffset = readUEG();\u000a    }\u000a\u000a    var pixelRatio = [1, 1];\u000a\u000a    if (readBoolean()) {\u000a      // vui_parameters_present_flag\u000a      if (readBoolean()) {\u000a        // aspect_ratio_info_present_flag\u000a        var aspectRatioIdc = readUByte();\u000a\u000a        switch (aspectRatioIdc) {\u000a          case 1:\u000a            pixelRatio = [1, 1];\u000a            break;\u000a\u000a          case 2:\u000a            pixelRatio = [12, 11];\u000a            break;\u000a\u000a          case 3:\u000a            pixelRatio = [10, 11];\u000a            break;\u000a\u000a          case 4:\u000a            pixelRatio = [16, 11];\u000a            break;\u000a\u000a          case 5:\u000a            pixelRatio = [40, 33];\u000a            break;\u000a\u000a          case 6:\u000a            pixelRatio = [24, 11];\u000a            break;\u000a\u000a          case 7:\u000a            pixelRatio = [20, 11];\u000a            break;\u000a\u000a          case 8:\u000a            pixelRatio = [32, 11];\u000a            break;\u000a\u000a          case 9:\u000a            pixelRatio = [80, 33];\u000a            break;\u000a\u000a          case 10:\u000a            pixelRatio = [18, 11];\u000a            break;\u000a\u000a          case 11:\u000a            pixelRatio = [15, 11];\u000a            break;\u000a\u000a          case 12:\u000a            pixelRatio = [64, 33];\u000a            break;\u000a\u000a          case 13:\u000a            pixelRatio = [160, 99];\u000a            break;\u000a\u000a          case 14:\u000a            pixelRatio = [4, 3];\u000a            break;\u000a\u000a          case 15:\u000a            pixelRatio = [3, 2];\u000a            break;\u000a\u000a          case 16:\u000a            pixelRatio = [2, 1];\u000a            break;\u000a\u000a          case 255:\u000a            {\u000a              pixelRatio = [readUByte() << 8 | readUByte(), readUByte() << 8 | readUByte()];\u000a              break;\u000a            }\u000a        }\u000a      }\u000a    }\u000a\u000a    return {\u000a      width: Math.ceil((picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2),\u000a      height: (2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - (frameMbsOnlyFlag ? 2 : 4) * (frameCropTopOffset + frameCropBottomOffset),\u000a      pixelRatio: pixelRatio\u000a    };\u000a  };\u000a\u000a  _proto.readSliceType = function readSliceType() {\u000a    // skip NALu type\u000a    this.readUByte(); // discard first_mb_in_slice\u000a\u000a    this.readUEG(); // return slice_type\u000a\u000a    return this.readUEG();\u000a  };\u000a\u000a  return ExpGolomb;\u000a}();\u000a\u000a/* harmony default export */ var exp_golomb = (exp_golomb_ExpGolomb);\u000a// CONCATENATED MODULE: ./src/demux/sample-aes.js\u000a/**\u000a * SAMPLE-AES decrypter\u000a*/\u000a\u000a\u000avar sample_aes_SampleAesDecrypter = /*#__PURE__*/function () {\u000a  function SampleAesDecrypter(observer, config, decryptdata, discardEPB) {\u000a    this.decryptdata = decryptdata;\u000a    this.discardEPB = discardEPB;\u000a    this.decrypter = new crypt_decrypter["default"](observer, config, {\u000a      removePKCS7Padding: false\u000a    });\u000a  }\u000a\u000a  var _proto = SampleAesDecrypter.prototype;\u000a\u000a  _proto.decryptBuffer = function decryptBuffer(encryptedData, callback) {\u000a    this.decrypter.decrypt(encryptedData, this.decryptdata.key.buffer, this.decryptdata.iv.buffer, callback);\u000a  } // AAC - encrypt all full 16 bytes blocks starting from offset 16\u000a  ;\u000a\u000a  _proto.decryptAacSample = function decryptAacSample(samples, sampleIndex, callback, sync) {\u000a    var curUnit = samples[sampleIndex].unit;\u000a    var encryptedData = curUnit.subarray(16, curUnit.length - curUnit.length % 16);\u000a    var encryptedBuffer = encryptedData.buffer.slice(encryptedData.byteOffset, encryptedData.byteOffset + encryptedData.length);\u000a    var localthis = this;\u000a    this.decryptBuffer(encryptedBuffer, function (decryptedData) {\u000a      decryptedData = new Uint8Array(decryptedData);\u000a      curUnit.set(decryptedData, 16);\u000a\u000a      if (!sync) {\u000a        localthis.decryptAacSamples(samples, sampleIndex + 1, callback);\u000a      }\u000a    });\u000a  };\u000a\u000a  _proto.decryptAacSamples = function decryptAacSamples(samples, sampleIndex, callback) {\u000a    for (;; sampleIndex++) {\u000a      if (sampleIndex >= samples.length) {\u000a        callback();\u000a        return;\u000a      }\u000a\u000a      if (samples[sampleIndex].unit.length < 32) {\u000a        continue;\u000a      }\u000a\u000a      var sync = this.decrypter.isSync();\u000a      this.decryptAacSample(samples, sampleIndex, callback, sync);\u000a\u000a      if (!sync) {\u000a        return;\u000a      }\u000a    }\u000a  } // AVC - encrypt one 16 bytes block out of ten, starting from offset 32\u000a  ;\u000a\u000a  _proto.getAvcEncryptedData = function getAvcEncryptedData(decodedData) {\u000a    var encryptedDataLen = Math.floor((decodedData.length - 48) / 160) * 16 + 16;\u000a    var encryptedData = new Int8Array(encryptedDataLen);\u000a    var outputPos = 0;\u000a\u000a    for (var inputPos = 32; inputPos <= decodedData.length - 16; inputPos += 160, outputPos += 16) {\u000a      encryptedData.set(decodedData.subarray(inputPos, inputPos + 16), outputPos);\u000a    }\u000a\u000a    return encryptedData;\u000a  };\u000a\u000a  _proto.getAvcDecryptedUnit = function getAvcDecryptedUnit(decodedData, decryptedData) {\u000a    decryptedData = new Uint8Array(decryptedData);\u000a    var inputPos = 0;\u000a\u000a    for (var outputPos = 32; outputPos <= decodedData.length - 16; outputPos += 160, inputPos += 16) {\u000a      decodedData.set(decryptedData.subarray(inputPos, inputPos + 16), outputPos);\u000a    }\u000a\u000a    return decodedData;\u000a  };\u000a\u000a  _proto.decryptAvcSample = function decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit, sync) {\u000a    var decodedData = this.discardEPB(curUnit.data);\u000a    var encryptedData = this.getAvcEncryptedData(decodedData);\u000a    var localthis = this;\u000a    this.decryptBuffer(encryptedData.buffer, function (decryptedData) {\u000a      curUnit.data = localthis.getAvcDecryptedUnit(decodedData, decryptedData);\u000a\u000a      if (!sync) {\u000a        localthis.decryptAvcSamples(samples, sampleIndex, unitIndex + 1, callback);\u000a      }\u000a    });\u000a  };\u000a\u000a  _proto.decryptAvcSamples = function decryptAvcSamples(samples, sampleIndex, unitIndex, callback) {\u000a    for (;; sampleIndex++, unitIndex = 0) {\u000a      if (sampleIndex >= samples.length) {\u000a        callback();\u000a        return;\u000a      }\u000a\u000a      var curUnits = samples[sampleIndex].units;\u000a\u000a      for (;; unitIndex++) {\u000a        if (unitIndex >= curUnits.length) {\u000a          break;\u000a        }\u000a\u000a        var curUnit = curUnits[unitIndex];\u000a\u000a        if (curUnit.length <= 48 || curUnit.type !== 1 && curUnit.type !== 5) {\u000a          continue;\u000a        }\u000a\u000a        var sync = this.decrypter.isSync();\u000a        this.decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit, sync);\u000a\u000a        if (!sync) {\u000a          return;\u000a        }\u000a      }\u000a    }\u000a  };\u000a\u000a  return SampleAesDecrypter;\u000a}();\u000a\u000a/* harmony default export */ var sample_aes = (sample_aes_SampleAesDecrypter);\u000a// CONCATENATED MODULE: ./src/demux/tsdemuxer.js\u000a/**\u000a * highly optimized TS demuxer:\u000a * parse PAT, PMT\u000a * extract PES packet from audio and video PIDs\u000a * extract AVC/H264 NAL units and AAC/ADTS samples from PES packet\u000a * trigger the remuxer upon parsing completion\u000a * it also tries to workaround as best as it can audio codec switch (HE-AAC to AAC and vice versa), without having to restart the MediaSource.\u000a * it also controls the remuxing process :\u000a * upon discontinuity or level switch detection, it will also notifies the remuxer so that it can reset its state.\u000a*/\u000a\u000a\u000a\u000a\u000a // import Hex from '../utils/hex';\u000a\u000a\u000a\u000a // We are using fixed track IDs for driving the MP4 remuxer\u000a// instead of following the TS PIDs.\u000a// There is no reason not to do this and some browsers/SourceBuffer-demuxers\u000a// may not like if there are TrackID "switches"\u000a// See https://github.com/video-dev/hls.js/issues/1331\u000a// Here we are mapping our internal track types to constant MP4 track IDs\u000a// With MSE currently one can only have one track of each, and we are muxing\u000a// whatever video/audio rendition in them.\u000a\u000avar RemuxerTrackIdConfig = {\u000a  video: 1,\u000a  audio: 2,\u000a  id3: 3,\u000a  text: 4\u000a};\u000a\u000avar tsdemuxer_TSDemuxer = /*#__PURE__*/function () {\u000a  function TSDemuxer(observer, remuxer, config, typeSupported) {\u000a    this.observer = observer;\u000a    this.config = config;\u000a    this.typeSupported = typeSupported;\u000a    this.remuxer = remuxer;\u000a    this.sampleAes = null;\u000a    this.pmtUnknownTypes = {};\u000a  }\u000a\u000a  var _proto = TSDemuxer.prototype;\u000a\u000a  _proto.setDecryptData = function setDecryptData(decryptdata) {\u000a    if (decryptdata != null && decryptdata.key != null && decryptdata.method === 'SAMPLE-AES') {\u000a      this.sampleAes = new sample_aes(this.observer, this.config, decryptdata, this.discardEPB);\u000a    } else {\u000a      this.sampleAes = null;\u000a    }\u000a  };\u000a\u000a  TSDemuxer.probe = function probe(data) {\u000a    var syncOffset = TSDemuxer._syncOffset(data);\u000a\u000a    if (syncOffset < 0) {\u000a      return false;\u000a    } else {\u000a      if (syncOffset) {\u000a        logger["logger"].warn("MPEG2-TS detected but first sync word found @ offset " + syncOffset + ", junk ahead ?");\u000a      }\u000a\u000a      return true;\u000a    }\u000a  };\u000a\u000a  TSDemuxer._syncOffset = function _syncOffset(data) {\u000a    // scan 1000 first bytes\u000a    var scanwindow = Math.min(1000, data.length - 3 * 188);\u000a    var i = 0;\u000a\u000a    while (i < scanwindow) {\u000a      // a TS fragment should contain at least 3 TS packets, a PAT, a PMT, and one PID, each starting with 0x47\u000a      if (data[i] === 0x47 && data[i + 188] === 0x47 && data[i + 2 * 188] === 0x47) {\u000a        return i;\u000a      } else {\u000a        i++;\u000a      }\u000a    }\u000a\u000a    return -1;\u000a  }\u000a  /**\u000a   * Creates a track model internal to demuxer used to drive remuxing input\u000a   *\u000a   * @param {string} type 'audio' | 'video' | 'id3' | 'text'\u000a   * @param {number} duration\u000a   * @return {object} TSDemuxer's internal track model\u000a   */\u000a  ;\u000a\u000a  TSDemuxer.createTrack = function createTrack(type, duration) {\u000a    return {\u000a      container: type === 'video' || type === 'audio' ? 'video/mp2t' : undefined,\u000a      type: type,\u000a      id: RemuxerTrackIdConfig[type],\u000a      pid: -1,\u000a      inputTimeScale: 90000,\u000a      sequenceNumber: 0,\u000a      samples: [],\u000a      dropped: type === 'video' ? 0 : undefined,\u000a      isAAC: type === 'audio' ? true : undefined,\u000a      duration: type === 'audio' ? duration : undefined\u000a    };\u000a  }\u000a  /**\u000a   * Initializes a new init segment on the demuxer/remuxer interface. Needed for discontinuities/track-switches (or at stream start)\u000a   * Resets all internal track instances of the demuxer.\u000a   *\u000a   * @override Implements generic demuxing/remuxing interface (see DemuxerInline)\u000a   * @param {object} initSegment\u000a   * @param {string} audioCodec\u000a   * @param {string} videoCodec\u000a   * @param {number} duration (in TS timescale = 90kHz)\u000a   */\u000a  ;\u000a\u000a  _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, duration) {\u000a    this.pmtParsed = false;\u000a    this._pmtId = -1;\u000a    this.pmtUnknownTypes = {};\u000a    this._avcTrack = TSDemuxer.createTrack('video', duration);\u000a    this._audioTrack = TSDemuxer.createTrack('audio', duration);\u000a    this._id3Track = TSDemuxer.createTrack('id3', duration);\u000a    this._txtTrack = TSDemuxer.createTrack('text', duration); // flush any partial content\u000a\u000a    this.aacOverFlow = null;\u000a    this.aacLastPTS = null;\u000a    this.avcSample = null;\u000a    this.audioCodec = audioCodec;\u000a    this.videoCodec = videoCodec;\u000a    this._duration = duration;\u000a  }\u000a  /**\u000a   *\u000a   * @override\u000a   */\u000a  ;\u000a\u000a  _proto.resetTimeStamp = function resetTimeStamp() {} // feed incoming data to the front of the parsing pipeline\u000a  ;\u000a\u000a  _proto.append = function append(data, timeOffset, contiguous, accurateTimeOffset) {\u000a    var start,\u000a        len = data.length,\u000a        stt,\u000a        pid,\u000a        atf,\u000a        offset,\u000a        pes,\u000a        unknownPIDs = false;\u000a    this.pmtUnknownTypes = {};\u000a    this.contiguous = contiguous;\u000a\u000a    var pmtParsed = this.pmtParsed,\u000a        avcTrack = this._avcTrack,\u000a        audioTrack = this._audioTrack,\u000a        id3Track = this._id3Track,\u000a        avcId = avcTrack.pid,\u000a        audioId = audioTrack.pid,\u000a        id3Id = id3Track.pid,\u000a        pmtId = this._pmtId,\u000a        avcData = avcTrack.pesData,\u000a        audioData = audioTrack.pesData,\u000a        id3Data = id3Track.pesData,\u000a        parsePAT = this._parsePAT,\u000a        parsePMT = this._parsePMT.bind(this),\u000a        parsePES = this._parsePES,\u000a        parseAVCPES = this._parseAVCPES.bind(this),\u000a        parseAACPES = this._parseAACPES.bind(this),\u000a        parseMPEGPES = this._parseMPEGPES.bind(this),\u000a        parseID3PES = this._parseID3PES.bind(this);\u000a\u000a    var syncOffset = TSDemuxer._syncOffset(data); // don't parse last TS packet if incomplete\u000a\u000a\u000a    len -= (len + syncOffset) % 188; // loop through TS packets\u000a\u000a    for (start = syncOffset; start < len; start += 188) {\u000a      if (data[start] === 0x47) {\u000a        stt = !!(data[start + 1] & 0x40); // pid is a 13-bit field starting at the last bit of TS[1]\u000a\u000a        pid = ((data[start + 1] & 0x1f) << 8) + data[start + 2];\u000a        atf = (data[start + 3] & 0x30) >> 4; // if an adaption field is present, its length is specified by the fifth byte of the TS packet header.\u000a\u000a        if (atf > 1) {\u000a          offset = start + 5 + data[start + 4]; // continue if there is only adaptation field\u000a\u000a          if (offset === start + 188) {\u000a            continue;\u000a          }\u000a        } else {\u000a          offset = start + 4;\u000a        }\u000a\u000a        switch (pid) {\u000a          case avcId:\u000a            if (stt) {\u000a              if (avcData && (pes = parsePES(avcData))) {\u000a                parseAVCPES(pes, false);\u000a              }\u000a\u000a              avcData = {\u000a                data: [],\u000a                size: 0\u000a              };\u000a            }\u000a\u000a            if (avcData) {\u000a              avcData.data.push(data.subarray(offset, start + 188));\u000a              avcData.size += start + 188 - offset;\u000a            }\u000a\u000a            break;\u000a\u000a          case audioId:\u000a            if (stt) {\u000a              if (audioData && (pes = parsePES(audioData))) {\u000a                if (audioTrack.isAAC) {\u000a                  parseAACPES(pes);\u000a                } else {\u000a                  parseMPEGPES(pes);\u000a                }\u000a              }\u000a\u000a              audioData = {\u000a                data: [],\u000a                size: 0\u000a              };\u000a            }\u000a\u000a            if (audioData) {\u000a              audioData.data.push(data.subarray(offset, start + 188));\u000a              audioData.size += start + 188 - offset;\u000a            }\u000a\u000a            break;\u000a\u000a          case id3Id:\u000a            if (stt) {\u000a              if (id3Data && (pes = parsePES(id3Data))) {\u000a                parseID3PES(pes);\u000a              }\u000a\u000a              id3Data = {\u000a                data: [],\u000a                size: 0\u000a              };\u000a            }\u000a\u000a            if (id3Data) {\u000a              id3Data.data.push(data.subarray(offset, start + 188));\u000a              id3Data.size += start + 188 - offset;\u000a            }\u000a\u000a            break;\u000a\u000a          case 0:\u000a            if (stt) {\u000a              offset += data[offset] + 1;\u000a            }\u000a\u000a            pmtId = this._pmtId = parsePAT(data, offset);\u000a            break;\u000a\u000a          case pmtId:\u000a            if (stt) {\u000a              offset += data[offset] + 1;\u000a            }\u000a\u000a            var parsedPIDs = parsePMT(data, offset, this.typeSupported.mpeg === true || this.typeSupported.mp3 === true, this.sampleAes != null); // only update track id if track PID found while parsing PMT\u000a            // this is to avoid resetting the PID to -1 in case\u000a            // track PID transiently disappears from the stream\u000a            // this could happen in case of transient missing audio samples for example\u000a            // NOTE this is only the PID of the track as found in TS,\u000a            // but we are not using this for MP4 track IDs.\u000a\u000a            avcId = parsedPIDs.avc;\u000a\u000a            if (avcId > 0) {\u000a              avcTrack.pid = avcId;\u000a            }\u000a\u000a            audioId = parsedPIDs.audio;\u000a\u000a            if (audioId > 0) {\u000a              audioTrack.pid = audioId;\u000a              audioTrack.isAAC = parsedPIDs.isAAC;\u000a            }\u000a\u000a            id3Id = parsedPIDs.id3;\u000a\u000a            if (id3Id > 0) {\u000a              id3Track.pid = id3Id;\u000a            }\u000a\u000a            if (unknownPIDs && !pmtParsed) {\u000a              logger["logger"].log('reparse from beginning');\u000a              unknownPIDs = false; // we set it to -188, the += 188 in the for loop will reset start to 0\u000a\u000a              start = syncOffset - 188;\u000a            }\u000a\u000a            pmtParsed = this.pmtParsed = true;\u000a            break;\u000a\u000a          case 17:\u000a          case 0x1fff:\u000a            break;\u000a\u000a          default:\u000a            unknownPIDs = true;\u000a            break;\u000a        }\u000a      } else {\u000a        this.observer.trigger(events["default"].ERROR, {\u000a          type: errors["ErrorTypes"].MEDIA_ERROR,\u000a          details: errors["ErrorDetails"].FRAG_PARSING_ERROR,\u000a          fatal: false,\u000a          reason: 'TS packet did not start with 0x47'\u000a        });\u000a      }\u000a    } // try to parse last PES packets\u000a\u000a\u000a    if (avcData && (pes = parsePES(avcData))) {\u000a      parseAVCPES(pes, true);\u000a      avcTrack.pesData = null;\u000a    } else {\u000a      // either avcData null or PES truncated, keep it for next frag parsing\u000a      avcTrack.pesData = avcData;\u000a    }\u000a\u000a    if (audioData && (pes = parsePES(audioData))) {\u000a      if (audioTrack.isAAC) {\u000a        parseAACPES(pes);\u000a      } else {\u000a        parseMPEGPES(pes);\u000a      }\u000a\u000a      audioTrack.pesData = null;\u000a    } else {\u000a      if (audioData && audioData.size) {\u000a        logger["logger"].log('last AAC PES packet truncated,might overlap between fragments');\u000a      } // either audioData null or PES truncated, keep it for next frag parsing\u000a\u000a\u000a      audioTrack.pesData = audioData;\u000a    }\u000a\u000a    if (id3Data && (pes = parsePES(id3Data))) {\u000a      parseID3PES(pes);\u000a      id3Track.pesData = null;\u000a    } else {\u000a      // either id3Data null or PES truncated, keep it for next frag parsing\u000a      id3Track.pesData = id3Data;\u000a    }\u000a\u000a    if (this.sampleAes == null) {\u000a      this.remuxer.remux(audioTrack, avcTrack, id3Track, this._txtTrack, timeOffset, contiguous, accurateTimeOffset);\u000a    } else {\u000a      this.decryptAndRemux(audioTrack, avcTrack, id3Track, this._txtTrack, timeOffset, contiguous, accurateTimeOffset);\u000a    }\u000a  };\u000a\u000a  _proto.decryptAndRemux = function decryptAndRemux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset) {\u000a    if (audioTrack.samples && audioTrack.isAAC) {\u000a      var localthis = this;\u000a      this.sampleAes.decryptAacSamples(audioTrack.samples, 0, function () {\u000a        localthis.decryptAndRemuxAvc(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset);\u000a      });\u000a    } else {\u000a      this.decryptAndRemuxAvc(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset);\u000a    }\u000a  };\u000a\u000a  _proto.decryptAndRemuxAvc = function decryptAndRemuxAvc(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset) {\u000a    if (videoTrack.samples) {\u000a      var localthis = this;\u000a      this.sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, function () {\u000a        localthis.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset);\u000a      });\u000a    } else {\u000a      this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset);\u000a    }\u000a  };\u000a\u000a  _proto.destroy = function destroy() {\u000a    this._initPTS = this._initDTS = undefined;\u000a    this._duration = 0;\u000a  };\u000a\u000a  _proto._parsePAT = function _parsePAT(data, offset) {\u000a    // skip the PSI header and parse the first PMT entry\u000a    return (data[offset + 10] & 0x1F) << 8 | data[offset + 11]; // logger.log('PMT PID:'  + this._pmtId);\u000a  };\u000a\u000a  _proto._trackUnknownPmt = function _trackUnknownPmt(type, logLevel, message) {\u000a    // Only log unknown and unsupported stream types once per append or stream (by resetting this.pmtUnknownTypes)\u000a    // For more information on elementary stream types see:\u000a    // https://en.wikipedia.org/wiki/Program-specific_information#Elementary_stream_types\u000a    var result = this.pmtUnknownTypes[type] || 0;\u000a\u000a    if (result === 0) {\u000a      this.pmtUnknownTypes[type] = 0;\u000a      logLevel.call(logger["logger"], message);\u000a    }\u000a\u000a    this.pmtUnknownTypes[type]++;\u000a    return result;\u000a  };\u000a\u000a  _proto._parsePMT = function _parsePMT(data, offset, mpegSupported, isSampleAes) {\u000a    var sectionLength,\u000a        tableEnd,\u000a        programInfoLength,\u000a        pid,\u000a        result = {\u000a      audio: -1,\u000a      avc: -1,\u000a      id3: -1,\u000a      isAAC: true\u000a    };\u000a    sectionLength = (data[offset + 1] & 0x0f) << 8 | data[offset + 2];\u000a    tableEnd = offset + 3 + sectionLength - 4; // to determine where the table is, we have to figure out how\u000a    // long the program info descriptors are\u000a\u000a    programInfoLength = (data[offset + 10] & 0x0f) << 8 | data[offset + 11]; // advance the offset to the first entry in the mapping table\u000a\u000a    offset += 12 + programInfoLength;\u000a\u000a    while (offset < tableEnd) {\u000a      pid = (data[offset + 1] & 0x1F) << 8 | data[offset + 2];\u000a\u000a      switch (data[offset]) {\u000a        case 0xcf:\u000a          // SAMPLE-AES AAC\u000a          if (!isSampleAes) {\u000a            this._trackUnknownPmt(data[offset], logger["logger"].warn, 'ADTS AAC with AES-128-CBC frame encryption found in unencrypted stream');\u000a\u000a            break;\u000a          }\u000a\u000a        /* falls through */\u000a        // ISO/IEC 13818-7 ADTS AAC (MPEG-2 lower bit-rate audio)\u000a\u000a        case 0x0f:\u000a          // logger.log('AAC PID:'  + pid);\u000a          if (result.audio === -1) {\u000a            result.audio = pid;\u000a          }\u000a\u000a          break;\u000a        // Packetized metadata (ID3)\u000a\u000a        case 0x15:\u000a          // logger.log('ID3 PID:'  + pid);\u000a          if (result.id3 === -1) {\u000a            result.id3 = pid;\u000a          }\u000a\u000a          break;\u000a\u000a        case 0xdb:\u000a          // SAMPLE-AES AVC\u000a          if (!isSampleAes) {\u000a            this._trackUnknownPmt(data[offset], logger["logger"].warn, 'H.264 with AES-128-CBC slice encryption found in unencrypted stream');\u000a\u000a            break;\u000a          }\u000a\u000a        /* falls through */\u000a        // ITU-T Rec. H.264 and ISO/IEC 14496-10 (lower bit-rate video)\u000a\u000a        case 0x1b:\u000a          // logger.log('AVC PID:'  + pid);\u000a          if (result.avc === -1) {\u000a            result.avc = pid;\u000a          }\u000a\u000a          break;\u000a        // ISO/IEC 11172-3 (MPEG-1 audio)\u000a        // or ISO/IEC 13818-3 (MPEG-2 halved sample rate audio)\u000a\u000a        case 0x03:\u000a        case 0x04:\u000a          // logger.log('MPEG PID:'  + pid);\u000a          if (!mpegSupported) {\u000a            this._trackUnknownPmt(data[offset], logger["logger"].warn, 'MPEG audio found, not supported in this browser');\u000a          } else if (result.audio === -1) {\u000a            result.audio = pid;\u000a            result.isAAC = false;\u000a          }\u000a\u000a          break;\u000a\u000a        case 0x24:\u000a          this._trackUnknownPmt(data[offset], logger["logger"].warn, 'Unsupported HEVC stream type found');\u000a\u000a          break;\u000a\u000a        default:\u000a          this._trackUnknownPmt(data[offset], logger["logger"].log, 'Unknown stream type:' + data[offset]);\u000a\u000a          break;\u000a      } // move to the next table entry\u000a      // skip past the elementary stream descriptors, if present\u000a\u000a\u000a      offset += ((data[offset + 3] & 0x0F) << 8 | data[offset + 4]) + 5;\u000a    }\u000a\u000a    return result;\u000a  };\u000a\u000a  _proto._parsePES = function _parsePES(stream) {\u000a    var i = 0,\u000a        frag,\u000a        pesFlags,\u000a        pesPrefix,\u000a        pesLen,\u000a        pesHdrLen,\u000a        pesData,\u000a        pesPts,\u000a        pesDts,\u000a        payloadStartOffset,\u000a        data = stream.data; // safety check\u000a\u000a    if (!stream || stream.size === 0) {\u000a      return null;\u000a    } // we might need up to 19 bytes to read PES header\u000a    // if first chunk of data is less than 19 bytes, let's merge it with following ones until we get 19 bytes\u000a    // usually only one merge is needed (and this is rare ...)\u000a\u000a\u000a    while (data[0].length < 19 && data.length > 1) {\u000a      var newData = new Uint8Array(data[0].length + data[1].length);\u000a      newData.set(data[0]);\u000a      newData.set(data[1], data[0].length);\u000a      data[0] = newData;\u000a      data.splice(1, 1);\u000a    } // retrieve PTS/DTS from first fragment\u000a\u000a\u000a    frag = data[0];\u000a    pesPrefix = (frag[0] << 16) + (frag[1] << 8) + frag[2];\u000a\u000a    if (pesPrefix === 1) {\u000a      pesLen = (frag[4] << 8) + frag[5]; // if PES parsed length is not zero and greater than total received length, stop parsing. PES might be truncated\u000a      // minus 6 : PES header size\u000a\u000a      if (pesLen && pesLen > stream.size - 6) {\u000a        return null;\u000a      }\u000a\u000a      pesFlags = frag[7];\u000a\u000a      if (pesFlags & 0xC0) {\u000a        /* PES header described here : http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\u000a            as PTS / DTS is 33 bit we cannot use bitwise operator in JS,\u000a            as Bitwise operators treat their operands as a sequence of 32 bits */\u000a        pesPts = (frag[9] & 0x0E) * 536870912 + // 1 << 29\u000a        (frag[10] & 0xFF) * 4194304 + // 1 << 22\u000a        (frag[11] & 0xFE) * 16384 + // 1 << 14\u000a        (frag[12] & 0xFF) * 128 + // 1 << 7\u000a        (frag[13] & 0xFE) / 2; // check if greater than 2^32 -1\u000a\u000a        if (pesPts > 4294967295) {\u000a          // decrement 2^33\u000a          pesPts -= 8589934592;\u000a        }\u000a\u000a        if (pesFlags & 0x40) {\u000a          pesDts = (frag[14] & 0x0E) * 536870912 + // 1 << 29\u000a          (frag[15] & 0xFF) * 4194304 + // 1 << 22\u000a          (frag[16] & 0xFE) * 16384 + // 1 << 14\u000a          (frag[17] & 0xFF) * 128 + // 1 << 7\u000a          (frag[18] & 0xFE) / 2; // check if greater than 2^32 -1\u000a\u000a          if (pesDts > 4294967295) {\u000a            // decrement 2^33\u000a            pesDts -= 8589934592;\u000a          }\u000a\u000a          if (pesPts - pesDts > 60 * 90000) {\u000a            logger["logger"].warn(Math.round((pesPts - pesDts) / 90000) + "s delta between PTS and DTS, align them");\u000a            pesPts = pesDts;\u000a          }\u000a        } else {\u000a          pesDts = pesPts;\u000a        }\u000a      }\u000a\u000a      pesHdrLen = frag[8]; // 9 bytes : 6 bytes for PES header + 3 bytes for PES extension\u000a\u000a      payloadStartOffset = pesHdrLen + 9;\u000a\u000a      if (stream.size <= payloadStartOffset) {\u000a        return null;\u000a      }\u000a\u000a      stream.size -= payloadStartOffset; // reassemble PES packet\u000a\u000a      pesData = new Uint8Array(stream.size);\u000a\u000a      for (var j = 0, dataLen = data.length; j < dataLen; j++) {\u000a        frag = data[j];\u000a        var len = frag.byteLength;\u000a\u000a        if (payloadStartOffset) {\u000a          if (payloadStartOffset > len) {\u000a            // trim full frag if PES header bigger than frag\u000a            payloadStartOffset -= len;\u000a            continue;\u000a          } else {\u000a            // trim partial frag if PES header smaller than frag\u000a            frag = frag.subarray(payloadStartOffset);\u000a            len -= payloadStartOffset;\u000a            payloadStartOffset = 0;\u000a          }\u000a        }\u000a\u000a        pesData.set(frag, i);\u000a        i += len;\u000a      }\u000a\u000a      if (pesLen) {\u000a        // payload size : remove PES header + PES extension\u000a        pesLen -= pesHdrLen + 3;\u000a      }\u000a\u000a      return {\u000a        data: pesData,\u000a        pts: pesPts,\u000a        dts: pesDts,\u000a        len: pesLen\u000a      };\u000a    } else {\u000a      return null;\u000a    }\u000a  };\u000a\u000a  _proto.pushAccesUnit = function pushAccesUnit(avcSample, avcTrack) {\u000a    if (avcSample.units.length && avcSample.frame) {\u000a      var samples = avcTrack.samples;\u000a      var nbSamples = samples.length; // if sample does not have PTS/DTS, patch with last sample PTS/DTS\u000a\u000a      if (isNaN(avcSample.pts)) {\u000a        if (nbSamples) {\u000a          var lastSample = samples[nbSamples - 1];\u000a          avcSample.pts = lastSample.pts;\u000a          avcSample.dts = lastSample.dts;\u000a        } else {\u000a          // dropping samples, no timestamp found\u000a          avcTrack.dropped++;\u000a          return;\u000a        }\u000a      } // only push AVC sample if starting with a keyframe is not mandatory OR\u000a      //    if keyframe already found in this fragment OR\u000a      //       keyframe found in last fragment (track.sps) AND\u000a      //          samples already appended (we already found a keyframe in this fragment) OR fragment is contiguous\u000a\u000a\u000a      if (!this.config.forceKeyFrameOnDiscontinuity || avcSample.key === true || avcTrack.sps && (nbSamples || this.contiguous)) {\u000a        avcSample.id = nbSamples;\u000a        samples.push(avcSample);\u000a      } else {\u000a        // dropped samples, track it\u000a        avcTrack.dropped++;\u000a      }\u000a    }\u000a\u000a    if (avcSample.debug.length) {\u000a      logger["logger"].log(avcSample.pts + '/' + avcSample.dts + ':' + avcSample.debug);\u000a    }\u000a  };\u000a\u000a  _proto._parseAVCPES = function _parseAVCPES(pes, last) {\u000a    var _this = this;\u000a\u000a    // logger.log('parse new PES');\u000a    var track = this._avcTrack,\u000a        units = this._parseAVCNALu(pes.data),\u000a        debug = false,\u000a        expGolombDecoder,\u000a        avcSample = this.avcSample,\u000a        push,\u000a        spsfound = false,\u000a        i,\u000a        pushAccesUnit = this.pushAccesUnit.bind(this),\u000a        createAVCSample = function createAVCSample(key, pts, dts, debug) {\u000a      return {\u000a        key: key,\u000a        pts: pts,\u000a        dts: dts,\u000a        units: [],\u000a        debug: debug\u000a      };\u000a    }; // free pes.data to save up some memory\u000a\u000a\u000a    pes.data = null; // if new NAL units found and last sample still there, let's push ...\u000a    // this helps parsing streams with missing AUD (only do this if AUD never found)\u000a\u000a    if (avcSample && units.length && !track.audFound) {\u000a      pushAccesUnit(avcSample, track);\u000a      avcSample = this.avcSample = createAVCSample(false, pes.pts, pes.dts, '');\u000a    }\u000a\u000a    units.forEach(function (unit) {\u000a      switch (unit.type) {\u000a        // NDR\u000a        case 1:\u000a          push = true;\u000a\u000a          if (!avcSample) {\u000a            avcSample = _this.avcSample = createAVCSample(true, pes.pts, pes.dts, '');\u000a          }\u000a\u000a          if (debug) {\u000a            avcSample.debug += 'NDR ';\u000a          }\u000a\u000a          avcSample.frame = true;\u000a          var data = unit.data; // only check slice type to detect KF in case SPS found in same packet (any keyframe is preceded by SPS ...)\u000a\u000a          if (spsfound && data.length > 4) {\u000a            // retrieve slice type by parsing beginning of NAL unit (follow H264 spec, slice_header definition) to detect keyframe embedded in NDR\u000a            var sliceType = new exp_golomb(data).readSliceType(); // 2 : I slice, 4 : SI slice, 7 : I slice, 9: SI slice\u000a            // SI slice : A slice that is coded using intra prediction only and using quantisation of the prediction samples.\u000a            // An SI slice can be coded such that its decoded samples can be constructed identically to an SP slice.\u000a            // I slice: A slice that is not an SI slice that is decoded using intra prediction only.\u000a            // if (sliceType === 2 || sliceType === 7) {\u000a\u000a            if (sliceType === 2 || sliceType === 4 || sliceType === 7 || sliceType === 9) {\u000a              avcSample.key = true;\u000a            }\u000a          }\u000a\u000a          break;\u000a        // IDR\u000a\u000a        case 5:\u000a          push = true; // handle PES not starting with AUD\u000a\u000a          if (!avcSample) {\u000a            avcSample = _this.avcSample = createAVCSample(true, pes.pts, pes.dts, '');\u000a          }\u000a\u000a          if (debug) {\u000a            avcSample.debug += 'IDR ';\u000a          }\u000a\u000a          avcSample.key = true;\u000a          avcSample.frame = true;\u000a          break;\u000a        // SEI\u000a\u000a        case 6:\u000a          push = true;\u000a\u000a          if (debug && avcSample) {\u000a            avcSample.debug += 'SEI ';\u000a          }\u000a\u000a          expGolombDecoder = new exp_golomb(_this.discardEPB(unit.data)); // skip frameType\u000a\u000a          expGolombDecoder.readUByte();\u000a          var payloadType = 0;\u000a          var payloadSize = 0;\u000a          var endOfCaptions = false;\u000a          var b = 0;\u000a\u000a          while (!endOfCaptions && expGolombDecoder.bytesAvailable > 1) {\u000a            payloadType = 0;\u000a\u000a            do {\u000a              b = expGolombDecoder.readUByte();\u000a              payloadType += b;\u000a            } while (b === 0xFF); // Parse payload size.\u000a\u000a\u000a            payloadSize = 0;\u000a\u000a            do {\u000a              b = expGolombDecoder.readUByte();\u000a              payloadSize += b;\u000a            } while (b === 0xFF); // TODO: there can be more than one payload in an SEI packet...\u000a            // TODO: need to read type and size in a while loop to get them all\u000a\u000a\u000a            if (payloadType === 4 && expGolombDecoder.bytesAvailable !== 0) {\u000a              endOfCaptions = true;\u000a              var countryCode = expGolombDecoder.readUByte();\u000a\u000a              if (countryCode === 181) {\u000a                var providerCode = expGolombDecoder.readUShort();\u000a\u000a                if (providerCode === 49) {\u000a                  var userStructure = expGolombDecoder.readUInt();\u000a\u000a                  if (userStructure === 0x47413934) {\u000a                    var userDataType = expGolombDecoder.readUByte(); // Raw CEA-608 bytes wrapped in CEA-708 packet\u000a\u000a                    if (userDataType === 3) {\u000a                      var firstByte = expGolombDecoder.readUByte();\u000a                      var secondByte = expGolombDecoder.readUByte();\u000a                      var totalCCs = 31 & firstByte;\u000a                      var byteArray = [firstByte, secondByte];\u000a\u000a                      for (i = 0; i < totalCCs; i++) {\u000a                        // 3 bytes per CC\u000a                        byteArray.push(expGolombDecoder.readUByte());\u000a                        byteArray.push(expGolombDecoder.readUByte());\u000a                        byteArray.push(expGolombDecoder.readUByte());\u000a                      }\u000a\u000a                      _this._insertSampleInOrder(_this._txtTrack.samples, {\u000a                        type: 3,\u000a                        pts: pes.pts,\u000a                        bytes: byteArray\u000a                      });\u000a                    }\u000a                  }\u000a                }\u000a              }\u000a            } else if (payloadType === 5 && expGolombDecoder.bytesAvailable !== 0) {\u000a              endOfCaptions = true;\u000a\u000a              if (payloadSize > 16) {\u000a                var uuidStrArray = [];\u000a\u000a                for (i = 0; i < 16; i++) {\u000a                  uuidStrArray.push(expGolombDecoder.readUByte().toString(16));\u000a\u000a                  if (i === 3 || i === 5 || i === 7 || i === 9) {\u000a                    uuidStrArray.push('-');\u000a                  }\u000a                }\u000a\u000a                var length = payloadSize - 16;\u000a                var userDataPayloadBytes = new Uint8Array(length);\u000a\u000a                for (i = 0; i < length; i++) {\u000a                  userDataPayloadBytes[i] = expGolombDecoder.readUByte();\u000a                }\u000a\u000a                _this._insertSampleInOrder(_this._txtTrack.samples, {\u000a                  pts: pes.pts,\u000a                  payloadType: payloadType,\u000a                  uuid: uuidStrArray.join(''),\u000a                  userDataBytes: userDataPayloadBytes,\u000a                  userData: Object(id3["utf8ArrayToStr"])(userDataPayloadBytes.buffer)\u000a                });\u000a              }\u000a            } else if (payloadSize < expGolombDecoder.bytesAvailable) {\u000a              for (i = 0; i < payloadSize; i++) {\u000a                expGolombDecoder.readUByte();\u000a              }\u000a            }\u000a          }\u000a\u000a          break;\u000a        // SPS\u000a\u000a        case 7:\u000a          push = true;\u000a          spsfound = true;\u000a\u000a          if (debug && avcSample) {\u000a            avcSample.debug += 'SPS ';\u000a          }\u000a\u000a          if (!track.sps) {\u000a            expGolombDecoder = new exp_golomb(unit.data);\u000a            var config = expGolombDecoder.readSPS();\u000a            track.width = config.width;\u000a            track.height = config.height;\u000a            track.pixelRatio = config.pixelRatio;\u000a            track.sps = [unit.data];\u000a            track.duration = _this._duration;\u000a            var codecarray = unit.data.subarray(1, 4);\u000a            var codecstring = 'avc1.';\u000a\u000a            for (i = 0; i < 3; i++) {\u000a              var h = codecarray[i].toString(16);\u000a\u000a              if (h.length < 2) {\u000a                h = '0' + h;\u000a              }\u000a\u000a              codecstring += h;\u000a            }\u000a\u000a            track.codec = codecstring;\u000a          }\u000a\u000a          break;\u000a        // PPS\u000a\u000a        case 8:\u000a          push = true;\u000a\u000a          if (debug && avcSample) {\u000a            avcSample.debug += 'PPS ';\u000a          }\u000a\u000a          if (!track.pps) {\u000a            track.pps = [unit.data];\u000a          }\u000a\u000a          break;\u000a        // AUD\u000a\u000a        case 9:\u000a          push = false;\u000a          track.audFound = true;\u000a\u000a          if (avcSample) {\u000a            pushAccesUnit(avcSample, track);\u000a          }\u000a\u000a          avcSample = _this.avcSample = createAVCSample(false, pes.pts, pes.dts, debug ? 'AUD ' : '');\u000a          break;\u000a        // Filler Data\u000a\u000a        case 12:\u000a          push = false;\u000a          break;\u000a\u000a        default:\u000a          push = false;\u000a\u000a          if (avcSample) {\u000a            avcSample.debug += 'unknown NAL ' + unit.type + ' ';\u000a          }\u000a\u000a          break;\u000a      }\u000a\u000a      if (avcSample && push) {\u000a        var _units = avcSample.units;\u000a\u000a        _units.push(unit);\u000a      }\u000a    }); // if last PES packet, push samples\u000a\u000a    if (last && avcSample) {\u000a      pushAccesUnit(avcSample, track);\u000a      this.avcSample = null;\u000a    }\u000a  };\u000a\u000a  _proto._insertSampleInOrder = function _insertSampleInOrder(arr, data) {\u000a    var len = arr.length;\u000a\u000a    if (len > 0) {\u000a      if (data.pts >= arr[len - 1].pts) {\u000a        arr.push(data);\u000a      } else {\u000a        for (var pos = len - 1; pos >= 0; pos--) {\u000a          if (data.pts < arr[pos].pts) {\u000a            arr.splice(pos, 0, data);\u000a            break;\u000a          }\u000a        }\u000a      }\u000a    } else {\u000a      arr.push(data);\u000a    }\u000a  };\u000a\u000a  _proto._getLastNalUnit = function _getLastNalUnit() {\u000a    var avcSample = this.avcSample,\u000a        lastUnit; // try to fallback to previous sample if current one is empty\u000a\u000a    if (!avcSample || avcSample.units.length === 0) {\u000a      var track = this._avcTrack,\u000a          samples = track.samples;\u000a      avcSample = samples[samples.length - 1];\u000a    }\u000a\u000a    if (avcSample) {\u000a      var units = avcSample.units;\u000a      lastUnit = units[units.length - 1];\u000a    }\u000a\u000a    return lastUnit;\u000a  };\u000a\u000a  _proto._parseAVCNALu = function _parseAVCNALu(array) {\u000a    var i = 0,\u000a        len = array.byteLength,\u000a        value,\u000a        overflow,\u000a        track = this._avcTrack,\u000a        state = track.naluState || 0,\u000a        lastState = state;\u000a    var units = [],\u000a        unit,\u000a        unitType,\u000a        lastUnitStart = -1,\u000a        lastUnitType; // logger.log('PES:' + Hex.hexDump(array));\u000a\u000a    if (state === -1) {\u000a      // special use case where we found 3 or 4-byte start codes exactly at the end of previous PES packet\u000a      lastUnitStart = 0; // NALu type is value read from offset 0\u000a\u000a      lastUnitType = array[0] & 0x1f;\u000a      state = 0;\u000a      i = 1;\u000a    }\u000a\u000a    while (i < len) {\u000a      value = array[i++]; // optimization. state 0 and 1 are the predominant case. let's handle them outside of the switch/case\u000a\u000a      if (!state) {\u000a        state = value ? 0 : 1;\u000a        continue;\u000a      }\u000a\u000a      if (state === 1) {\u000a        state = value ? 0 : 2;\u000a        continue;\u000a      } // here we have state either equal to 2 or 3\u000a\u000a\u000a      if (!value) {\u000a        state = 3;\u000a      } else if (value === 1) {\u000a        if (lastUnitStart >= 0) {\u000a          unit = {\u000a            data: array.subarray(lastUnitStart, i - state - 1),\u000a            type: lastUnitType\u000a          }; // logger.log('pushing NALU, type/size:' + unit.type + '/' + unit.data.byteLength);\u000a\u000a          units.push(unit);\u000a        } else {\u000a          // lastUnitStart is undefined => this is the first start code found in this PES packet\u000a          // first check if start code delimiter is overlapping between 2 PES packets,\u000a          // ie it started in last packet (lastState not zero)\u000a          // and ended at the beginning of this PES packet (i <= 4 - lastState)\u000a          var lastUnit = this._getLastNalUnit();\u000a\u000a          if (lastUnit) {\u000a            if (lastState && i <= 4 - lastState) {\u000a              // start delimiter overlapping between PES packets\u000a              // strip start delimiter bytes from the end of last NAL unit\u000a              // check if lastUnit had a state different from zero\u000a              if (lastUnit.state) {\u000a                // strip last bytes\u000a                lastUnit.data = lastUnit.data.subarray(0, lastUnit.data.byteLength - lastState);\u000a              }\u000a            } // If NAL units are not starting right at the beginning of the PES packet, push preceding data into previous NAL unit.\u000a\u000a\u000a            overflow = i - state - 1;\u000a\u000a            if (overflow > 0) {\u000a              // logger.log('first NALU found with overflow:' + overflow);\u000a              var tmp = new Uint8Array(lastUnit.data.byteLength + overflow);\u000a              tmp.set(lastUnit.data, 0);\u000a              tmp.set(array.subarray(0, overflow), lastUnit.data.byteLength);\u000a              lastUnit.data = tmp;\u000a            }\u000a          }\u000a        } // check if we can read unit type\u000a\u000a\u000a        if (i < len) {\u000a          unitType = array[i] & 0x1f; // logger.log('find NALU @ offset:' + i + ',type:' + unitType);\u000a\u000a          lastUnitStart = i;\u000a          lastUnitType = unitType;\u000a          state = 0;\u000a        } else {\u000a          // not enough byte to read unit type. let's read it on next PES parsing\u000a          state = -1;\u000a        }\u000a      } else {\u000a        state = 0;\u000a      }\u000a    }\u000a\u000a    if (lastUnitStart >= 0 && state >= 0) {\u000a      unit = {\u000a        data: array.subarray(lastUnitStart, len),\u000a        type: lastUnitType,\u000a        state: state\u000a      };\u000a      units.push(unit); // logger.log('pushing NALU, type/size/state:' + unit.type + '/' + unit.data.byteLength + '/' + state);\u000a    } // no NALu found\u000a\u000a\u000a    if (units.length === 0) {\u000a      // append pes.data to previous NAL unit\u000a      var _lastUnit = this._getLastNalUnit();\u000a\u000a      if (_lastUnit) {\u000a        var _tmp = new Uint8Array(_lastUnit.data.byteLength + array.byteLength);\u000a\u000a        _tmp.set(_lastUnit.data, 0);\u000a\u000a        _tmp.set(array, _lastUnit.data.byteLength);\u000a\u000a        _lastUnit.data = _tmp;\u000a      }\u000a    }\u000a\u000a    track.naluState = state;\u000a    return units;\u000a  }\u000a  /**\u000a   * remove Emulation Prevention bytes from a RBSP\u000a   */\u000a  ;\u000a\u000a  _proto.discardEPB = function discardEPB(data) {\u000a    var length = data.byteLength,\u000a        EPBPositions = [],\u000a        i = 1,\u000a        newLength,\u000a        newData; // Find all `Emulation Prevention Bytes`\u000a\u000a    while (i < length - 2) {\u000a      if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\u000a        EPBPositions.push(i + 2);\u000a        i += 2;\u000a      } else {\u000a        i++;\u000a      }\u000a    } // If no Emulation Prevention Bytes were found just return the original\u000a    // array\u000a\u000a\u000a    if (EPBPositions.length === 0) {\u000a      return data;\u000a    } // Create a new array to hold the NAL unit data\u000a\u000a\u000a    newLength = length - EPBPositions.length;\u000a    newData = new Uint8Array(newLength);\u000a    var sourceIndex = 0;\u000a\u000a    for (i = 0; i < newLength; sourceIndex++, i++) {\u000a      if (sourceIndex === EPBPositions[0]) {\u000a        // Skip this byte\u000a        sourceIndex++; // Remove this position index\u000a\u000a        EPBPositions.shift();\u000a      }\u000a\u000a      newData[i] = data[sourceIndex];\u000a    }\u000a\u000a    return newData;\u000a  };\u000a\u000a  _proto._parseAACPES = function _parseAACPES(pes) {\u000a    var track = this._audioTrack,\u000a        data = pes.data,\u000a        pts = pes.pts,\u000a        startOffset = 0,\u000a        aacOverFlow = this.aacOverFlow,\u000a        aacLastPTS = this.aacLastPTS,\u000a        frameDuration,\u000a        frameIndex,\u000a        offset,\u000a        stamp,\u000a        len;\u000a\u000a    if (aacOverFlow) {\u000a      var tmp = new Uint8Array(aacOverFlow.byteLength + data.byteLength);\u000a      tmp.set(aacOverFlow, 0);\u000a      tmp.set(data, aacOverFlow.byteLength); // logger.log(`AAC: append overflowing ${aacOverFlow.byteLength} bytes to beginning of new PES`);\u000a\u000a      data = tmp;\u000a    } // look for ADTS header (0xFFFx)\u000a\u000a\u000a    for (offset = startOffset, len = data.length; offset < len - 1; offset++) {\u000a      if (isHeader(data, offset)) {\u000a        break;\u000a      }\u000a    } // if ADTS header does not start straight from the beginning of the PES payload, raise an error\u000a\u000a\u000a    if (offset) {\u000a      var reason, fatal;\u000a\u000a      if (offset < len - 1) {\u000a        reason = "AAC PES did not start with ADTS header,offset:" + offset;\u000a        fatal = false;\u000a      } else {\u000a        reason = 'no ADTS header found in AAC PES';\u000a        fatal = true;\u000a      }\u000a\u000a      logger["logger"].warn("parsing error:" + reason);\u000a      this.observer.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        details: errors["ErrorDetails"].FRAG_PARSING_ERROR,\u000a        fatal: fatal,\u000a        reason: reason\u000a      });\u000a\u000a      if (fatal) {\u000a        return;\u000a      }\u000a    }\u000a\u000a    initTrackConfig(track, this.observer, data, offset, this.audioCodec);\u000a    frameIndex = 0;\u000a    frameDuration = getFrameDuration(track.samplerate); // if last AAC frame is overflowing, we should ensure timestamps are contiguous:\u000a    // first sample PTS should be equal to last sample PTS + frameDuration\u000a\u000a    if (aacOverFlow && aacLastPTS) {\u000a      var newPTS = aacLastPTS + frameDuration;\u000a\u000a      if (Math.abs(newPTS - pts) > 1) {\u000a        logger["logger"].log("AAC: align PTS for overlapping frames by " + Math.round((newPTS - pts) / 90));\u000a        pts = newPTS;\u000a      }\u000a    } // scan for aac samples\u000a\u000a\u000a    while (offset < len) {\u000a      if (isHeader(data, offset)) {\u000a        if (offset + 5 < len) {\u000a          var frame = appendFrame(track, data, offset, pts, frameIndex);\u000a\u000a          if (frame) {\u000a            offset += frame.length;\u000a            stamp = frame.sample.pts;\u000a            frameIndex++;\u000a            continue;\u000a          }\u000a        } // We are at an ADTS header, but do not have enough data for a frame\u000a        // Remaining data will be added to aacOverFlow\u000a\u000a\u000a        break;\u000a      } else {\u000a        // nothing found, keep looking\u000a        offset++;\u000a      }\u000a    }\u000a\u000a    if (offset < len) {\u000a      aacOverFlow = data.subarray(offset, len); // logger.log(`AAC: overflow detected:${len-offset}`);\u000a    } else {\u000a      aacOverFlow = null;\u000a    }\u000a\u000a    this.aacOverFlow = aacOverFlow;\u000a    this.aacLastPTS = stamp;\u000a  };\u000a\u000a  _proto._parseMPEGPES = function _parseMPEGPES(pes) {\u000a    var data = pes.data;\u000a    var length = data.length;\u000a    var frameIndex = 0;\u000a    var offset = 0;\u000a    var pts = pes.pts;\u000a\u000a    while (offset < length) {\u000a      if (mpegaudio.isHeader(data, offset)) {\u000a        var frame = mpegaudio.appendFrame(this._audioTrack, data, offset, pts, frameIndex);\u000a\u000a        if (frame) {\u000a          offset += frame.length;\u000a          frameIndex++;\u000a        } else {\u000a          // logger.log('Unable to parse Mpeg audio frame');\u000a          break;\u000a        }\u000a      } else {\u000a        // nothing found, keep looking\u000a        offset++;\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto._parseID3PES = function _parseID3PES(pes) {\u000a    this._id3Track.samples.push(pes);\u000a  };\u000a\u000a  return TSDemuxer;\u000a}();\u000a\u000a/* harmony default export */ var tsdemuxer = (tsdemuxer_TSDemuxer);\u000a// CONCATENATED MODULE: ./src/demux/mp3demuxer.js\u000a/**\u000a * MP3 demuxer\u000a */\u000a\u000a\u000a\u000a\u000avar mp3demuxer_MP3Demuxer = /*#__PURE__*/function () {\u000a  function MP3Demuxer(observer, remuxer, config) {\u000a    this.observer = observer;\u000a    this.config = config;\u000a    this.remuxer = remuxer;\u000a  }\u000a\u000a  var _proto = MP3Demuxer.prototype;\u000a\u000a  _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, duration) {\u000a    this._audioTrack = {\u000a      container: 'audio/mpeg',\u000a      type: 'audio',\u000a      id: -1,\u000a      sequenceNumber: 0,\u000a      isAAC: false,\u000a      samples: [],\u000a      len: 0,\u000a      manifestCodec: audioCodec,\u000a      duration: duration,\u000a      inputTimeScale: 90000\u000a    };\u000a  };\u000a\u000a  _proto.resetTimeStamp = function resetTimeStamp() {};\u000a\u000a  MP3Demuxer.probe = function probe(data) {\u000a    // check if data contains ID3 timestamp and MPEG sync word\u000a    var offset, length;\u000a    var id3Data = id3["default"].getID3Data(data, 0);\u000a\u000a    if (id3Data && id3["default"].getTimeStamp(id3Data) !== undefined) {\u000a      // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\u000a      // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\u000a      // More info http://www.mp3-tech.org/programmer/frame_header.html\u000a      for (offset = id3Data.length, length = Math.min(data.length - 1, offset + 100); offset < length; offset++) {\u000a        if (mpegaudio.probe(data, offset)) {\u000a          logger["logger"].log('MPEG Audio sync word found !');\u000a          return true;\u000a        }\u000a      }\u000a    }\u000a\u000a    return false;\u000a  } // feed incoming data to the front of the parsing pipeline\u000a  ;\u000a\u000a  _proto.append = function append(data, timeOffset, contiguous, accurateTimeOffset) {\u000a    var id3Data = id3["default"].getID3Data(data, 0);\u000a    var timestamp = id3["default"].getTimeStamp(id3Data);\u000a    var pts = timestamp !== undefined ? 90 * timestamp : timeOffset * 90000;\u000a    var offset = id3Data.length;\u000a    var length = data.length;\u000a    var frameIndex = 0,\u000a        stamp = 0;\u000a    var track = this._audioTrack;\u000a    var id3Samples = [{\u000a      pts: pts,\u000a      dts: pts,\u000a      data: id3Data\u000a    }];\u000a\u000a    while (offset < length) {\u000a      if (mpegaudio.isHeader(data, offset)) {\u000a        var frame = mpegaudio.appendFrame(track, data, offset, pts, frameIndex);\u000a\u000a        if (frame) {\u000a          offset += frame.length;\u000a          stamp = frame.sample.pts;\u000a          frameIndex++;\u000a        } else {\u000a          // logger.log('Unable to parse Mpeg audio frame');\u000a          break;\u000a        }\u000a      } else if (id3["default"].isHeader(data, offset)) {\u000a        id3Data = id3["default"].getID3Data(data, offset);\u000a        id3Samples.push({\u000a          pts: stamp,\u000a          dts: stamp,\u000a          data: id3Data\u000a        });\u000a        offset += id3Data.length;\u000a      } else {\u000a        // nothing found, keep looking\u000a        offset++;\u000a      }\u000a    }\u000a\u000a    this.remuxer.remux(track, {\u000a      samples: []\u000a    }, {\u000a      samples: id3Samples,\u000a      inputTimeScale: 90000\u000a    }, {\u000a      samples: []\u000a    }, timeOffset, contiguous, accurateTimeOffset);\u000a  };\u000a\u000a  _proto.destroy = function destroy() {};\u000a\u000a  return MP3Demuxer;\u000a}();\u000a\u000a/* harmony default export */ var mp3demuxer = (mp3demuxer_MP3Demuxer);\u000a// CONCATENATED MODULE: ./src/remux/aac-helper.js\u000a/**\u000a *  AAC helper\u000a */\u000avar AAC = /*#__PURE__*/function () {\u000a  function AAC() {}\u000a\u000a  AAC.getSilentFrame = function getSilentFrame(codec, channelCount) {\u000a    switch (codec) {\u000a      case 'mp4a.40.2':\u000a        if (channelCount === 1) {\u000a          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);\u000a        } else if (channelCount === 2) {\u000a          return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);\u000a        } else if (channelCount === 3) {\u000a          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);\u000a        } else if (channelCount === 4) {\u000a          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);\u000a        } else if (channelCount === 5) {\u000a          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);\u000a        } else if (channelCount === 6) {\u000a          return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);\u000a        }\u000a\u000a        break;\u000a      // handle HE-AAC below (mp4a.40.5 / mp4a.40.29)\u000a\u000a      default:\u000a        if (channelCount === 1) {\u000a          // ffmpeg -y -f lavfi -i "aevalsrc=0:d=0.05" -c:a libfdk_aac -profile:a aac_he -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\u005cn"' -v output.aac\u000a          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x4e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x1c, 0x6, 0xf1, 0xc1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\u000a        } else if (channelCount === 2) {\u000a          // ffmpeg -y -f lavfi -i "aevalsrc=0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\u005cn"' -v output.aac\u000a          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\u000a        } else if (channelCount === 3) {\u000a          // ffmpeg -y -f lavfi -i "aevalsrc=0|0|0:d=0.05" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 "0x%x," "\u005cn"' -v output.aac\u000a          return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\u000a        }\u000a\u000a        break;\u000a    }\u000a\u000a    return null;\u000a  };\u000a\u000a  return AAC;\u000a}();\u000a\u000a/* harmony default export */ var aac_helper = (AAC);\u000a// CONCATENATED MODULE: ./src/remux/mp4-generator.js\u000a/**\u000a * Generate MP4 Box\u000a*/\u000avar UINT32_MAX = Math.pow(2, 32) - 1;\u000a\u000avar MP4 = /*#__PURE__*/function () {\u000a  function MP4() {}\u000a\u000a  MP4.init = function init() {\u000a    MP4.types = {\u000a      avc1: [],\u000a      // codingname\u000a      avcC: [],\u000a      btrt: [],\u000a      dinf: [],\u000a      dref: [],\u000a      esds: [],\u000a      ftyp: [],\u000a      hdlr: [],\u000a      mdat: [],\u000a      mdhd: [],\u000a      mdia: [],\u000a      mfhd: [],\u000a      minf: [],\u000a      moof: [],\u000a      moov: [],\u000a      mp4a: [],\u000a      '.mp3': [],\u000a      mvex: [],\u000a      mvhd: [],\u000a      pasp: [],\u000a      sdtp: [],\u000a      stbl: [],\u000a      stco: [],\u000a      stsc: [],\u000a      stsd: [],\u000a      stsz: [],\u000a      stts: [],\u000a      tfdt: [],\u000a      tfhd: [],\u000a      traf: [],\u000a      trak: [],\u000a      trun: [],\u000a      trex: [],\u000a      tkhd: [],\u000a      vmhd: [],\u000a      smhd: []\u000a    };\u000a    var i;\u000a\u000a    for (i in MP4.types) {\u000a      if (MP4.types.hasOwnProperty(i)) {\u000a        MP4.types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];\u000a      }\u000a    }\u000a\u000a    var videoHdlr = new Uint8Array([0x00, // version 0\u000a    0x00, 0x00, 0x00, // flags\u000a    0x00, 0x00, 0x00, 0x00, // pre_defined\u000a    0x76, 0x69, 0x64, 0x65, // handler_type: 'vide'\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\u000a    ]);\u000a    var audioHdlr = new Uint8Array([0x00, // version 0\u000a    0x00, 0x00, 0x00, // flags\u000a    0x00, 0x00, 0x00, 0x00, // pre_defined\u000a    0x73, 0x6f, 0x75, 0x6e, // handler_type: 'soun'\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'\u000a    ]);\u000a    MP4.HDLR_TYPES = {\u000a      'video': videoHdlr,\u000a      'audio': audioHdlr\u000a    };\u000a    var dref = new Uint8Array([0x00, // version 0\u000a    0x00, 0x00, 0x00, // flags\u000a    0x00, 0x00, 0x00, 0x01, // entry_count\u000a    0x00, 0x00, 0x00, 0x0c, // entry_size\u000a    0x75, 0x72, 0x6c, 0x20, // 'url' type\u000a    0x00, // version 0\u000a    0x00, 0x00, 0x01 // entry_flags\u000a    ]);\u000a    var stco = new Uint8Array([0x00, // version\u000a    0x00, 0x00, 0x00, // flags\u000a    0x00, 0x00, 0x00, 0x00 // entry_count\u000a    ]);\u000a    MP4.STTS = MP4.STSC = MP4.STCO = stco;\u000a    MP4.STSZ = new Uint8Array([0x00, // version\u000a    0x00, 0x00, 0x00, // flags\u000a    0x00, 0x00, 0x00, 0x00, // sample_size\u000a    0x00, 0x00, 0x00, 0x00 // sample_count\u000a    ]);\u000a    MP4.VMHD = new Uint8Array([0x00, // version\u000a    0x00, 0x00, 0x01, // flags\u000a    0x00, 0x00, // graphicsmode\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor\u000a    ]);\u000a    MP4.SMHD = new Uint8Array([0x00, // version\u000a    0x00, 0x00, 0x00, // flags\u000a    0x00, 0x00, // balance\u000a    0x00, 0x00 // reserved\u000a    ]);\u000a    MP4.STSD = new Uint8Array([0x00, // version 0\u000a    0x00, 0x00, 0x00, // flags\u000a    0x00, 0x00, 0x00, 0x01]); // entry_count\u000a\u000a    var majorBrand = new Uint8Array([105, 115, 111, 109]); // isom\u000a\u000a    var avc1Brand = new Uint8Array([97, 118, 99, 49]); // avc1\u000a\u000a    var minorVersion = new Uint8Array([0, 0, 0, 1]);\u000a    MP4.FTYP = MP4.box(MP4.types.ftyp, majorBrand, minorVersion, majorBrand, avc1Brand);\u000a    MP4.DINF = MP4.box(MP4.types.dinf, MP4.box(MP4.types.dref, dref));\u000a  };\u000a\u000a  MP4.box = function box(type) {\u000a    var payload = Array.prototype.slice.call(arguments, 1),\u000a        size = 8,\u000a        i = payload.length,\u000a        len = i,\u000a        result; // calculate the total size we need to allocate\u000a\u000a    while (i--) {\u000a      size += payload[i].byteLength;\u000a    }\u000a\u000a    result = new Uint8Array(size);\u000a    result[0] = size >> 24 & 0xff;\u000a    result[1] = size >> 16 & 0xff;\u000a    result[2] = size >> 8 & 0xff;\u000a    result[3] = size & 0xff;\u000a    result.set(type, 4); // copy the payload into the result\u000a\u000a    for (i = 0, size = 8; i < len; i++) {\u000a      // copy payload[i] array @ offset size\u000a      result.set(payload[i], size);\u000a      size += payload[i].byteLength;\u000a    }\u000a\u000a    return result;\u000a  };\u000a\u000a  MP4.hdlr = function hdlr(type) {\u000a    return MP4.box(MP4.types.hdlr, MP4.HDLR_TYPES[type]);\u000a  };\u000a\u000a  MP4.mdat = function mdat(data) {\u000a    return MP4.box(MP4.types.mdat, data);\u000a  };\u000a\u000a  MP4.mdhd = function mdhd(timescale, duration) {\u000a    duration *= timescale;\u000a    var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\u000a    var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\u000a    return MP4.box(MP4.types.mdhd, new Uint8Array([0x01, // version 1\u000a    0x00, 0x00, 0x00, // flags\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, // creation_time\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, // modification_time\u000a    timescale >> 24 & 0xFF, timescale >> 16 & 0xFF, timescale >> 8 & 0xFF, timescale & 0xFF, // timescale\u000a    upperWordDuration >> 24, upperWordDuration >> 16 & 0xFF, upperWordDuration >> 8 & 0xFF, upperWordDuration & 0xFF, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xFF, lowerWordDuration >> 8 & 0xFF, lowerWordDuration & 0xFF, 0x55, 0xc4, // 'und' language (undetermined)\u000a    0x00, 0x00]));\u000a  };\u000a\u000a  MP4.mdia = function mdia(track) {\u000a    return MP4.box(MP4.types.mdia, MP4.mdhd(track.timescale, track.duration), MP4.hdlr(track.type), MP4.minf(track));\u000a  };\u000a\u000a  MP4.mfhd = function mfhd(sequenceNumber) {\u000a    return MP4.box(MP4.types.mfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00, // flags\u000a    sequenceNumber >> 24, sequenceNumber >> 16 & 0xFF, sequenceNumber >> 8 & 0xFF, sequenceNumber & 0xFF // sequence_number\u000a    ]));\u000a  };\u000a\u000a  MP4.minf = function minf(track) {\u000a    if (track.type === 'audio') {\u000a      return MP4.box(MP4.types.minf, MP4.box(MP4.types.smhd, MP4.SMHD), MP4.DINF, MP4.stbl(track));\u000a    } else {\u000a      return MP4.box(MP4.types.minf, MP4.box(MP4.types.vmhd, MP4.VMHD), MP4.DINF, MP4.stbl(track));\u000a    }\u000a  };\u000a\u000a  MP4.moof = function moof(sn, baseMediaDecodeTime, track) {\u000a    return MP4.box(MP4.types.moof, MP4.mfhd(sn), MP4.traf(track, baseMediaDecodeTime));\u000a  }\u000a  /**\u000a  * @param tracks... (optional) {array} the tracks associated with this movie\u000a  */\u000a  ;\u000a\u000a  MP4.moov = function moov(tracks) {\u000a    var i = tracks.length,\u000a        boxes = [];\u000a\u000a    while (i--) {\u000a      boxes[i] = MP4.trak(tracks[i]);\u000a    }\u000a\u000a    return MP4.box.apply(null, [MP4.types.moov, MP4.mvhd(tracks[0].timescale, tracks[0].duration)].concat(boxes).concat(MP4.mvex(tracks)));\u000a  };\u000a\u000a  MP4.mvex = function mvex(tracks) {\u000a    var i = tracks.length,\u000a        boxes = [];\u000a\u000a    while (i--) {\u000a      boxes[i] = MP4.trex(tracks[i]);\u000a    }\u000a\u000a    return MP4.box.apply(null, [MP4.types.mvex].concat(boxes));\u000a  };\u000a\u000a  MP4.mvhd = function mvhd(timescale, duration) {\u000a    duration *= timescale;\u000a    var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\u000a    var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\u000a    var bytes = new Uint8Array([0x01, // version 1\u000a    0x00, 0x00, 0x00, // flags\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, // creation_time\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, // modification_time\u000a    timescale >> 24 & 0xFF, timescale >> 16 & 0xFF, timescale >> 8 & 0xFF, timescale & 0xFF, // timescale\u000a    upperWordDuration >> 24, upperWordDuration >> 16 & 0xFF, upperWordDuration >> 8 & 0xFF, upperWordDuration & 0xFF, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xFF, lowerWordDuration >> 8 & 0xFF, lowerWordDuration & 0xFF, 0x00, 0x01, 0x00, 0x00, // 1.0 rate\u000a    0x01, 0x00, // 1.0 volume\u000a    0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined\u000a    0xff, 0xff, 0xff, 0xff // next_track_ID\u000a    ]);\u000a    return MP4.box(MP4.types.mvhd, bytes);\u000a  };\u000a\u000a  MP4.sdtp = function sdtp(track) {\u000a    var samples = track.samples || [],\u000a        bytes = new Uint8Array(4 + samples.length),\u000a        flags,\u000a        i; // leave the full box header (4 bytes) all zero\u000a    // write the sample table\u000a\u000a    for (i = 0; i < samples.length; i++) {\u000a      flags = samples[i].flags;\u000a      bytes[i + 4] = flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;\u000a    }\u000a\u000a    return MP4.box(MP4.types.sdtp, bytes);\u000a  };\u000a\u000a  MP4.stbl = function stbl(track) {\u000a    return MP4.box(MP4.types.stbl, MP4.stsd(track), MP4.box(MP4.types.stts, MP4.STTS), MP4.box(MP4.types.stsc, MP4.STSC), MP4.box(MP4.types.stsz, MP4.STSZ), MP4.box(MP4.types.stco, MP4.STCO));\u000a  };\u000a\u000a  MP4.avc1 = function avc1(track) {\u000a    var sps = [],\u000a        pps = [],\u000a        i,\u000a        data,\u000a        len; // assemble the SPSs\u000a\u000a    for (i = 0; i < track.sps.length; i++) {\u000a      data = track.sps[i];\u000a      len = data.byteLength;\u000a      sps.push(len >>> 8 & 0xFF);\u000a      sps.push(len & 0xFF); // SPS\u000a\u000a      sps = sps.concat(Array.prototype.slice.call(data));\u000a    } // assemble the PPSs\u000a\u000a\u000a    for (i = 0; i < track.pps.length; i++) {\u000a      data = track.pps[i];\u000a      len = data.byteLength;\u000a      pps.push(len >>> 8 & 0xFF);\u000a      pps.push(len & 0xFF);\u000a      pps = pps.concat(Array.prototype.slice.call(data));\u000a    }\u000a\u000a    var avcc = MP4.box(MP4.types.avcC, new Uint8Array([0x01, // version\u000a    sps[3], // profile\u000a    sps[4], // profile compat\u000a    sps[5], // level\u000a    0xfc | 3, // lengthSizeMinusOne, hard-coded to 4 bytes\u000a    0xE0 | track.sps.length // 3bit reserved (111) + numOfSequenceParameterSets\u000a    ].concat(sps).concat([track.pps.length // numOfPictureParameterSets\u000a    ]).concat(pps))),\u000a        // "PPS"\u000a    width = track.width,\u000a        height = track.height,\u000a        hSpacing = track.pixelRatio[0],\u000a        vSpacing = track.pixelRatio[1];\u000a    return MP4.box(MP4.types.avc1, new Uint8Array([0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x01, // data_reference_index\u000a    0x00, 0x00, // pre_defined\u000a    0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // pre_defined\u000a    width >> 8 & 0xFF, width & 0xff, // width\u000a    height >> 8 & 0xFF, height & 0xff, // height\u000a    0x00, 0x48, 0x00, 0x00, // horizresolution\u000a    0x00, 0x48, 0x00, 0x00, // vertresolution\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x01, // frame_count\u000a    0x12, 0x64, 0x61, 0x69, 0x6C, // dailymotion/hls.js\u000a    0x79, 0x6D, 0x6F, 0x74, 0x69, 0x6F, 0x6E, 0x2F, 0x68, 0x6C, 0x73, 0x2E, 0x6A, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // compressorname\u000a    0x00, 0x18, // depth = 24\u000a    0x11, 0x11]), // pre_defined = -1\u000a    avcc, MP4.box(MP4.types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80, // bufferSizeDB\u000a    0x00, 0x2d, 0xc6, 0xc0, // maxBitrate\u000a    0x00, 0x2d, 0xc6, 0xc0])), // avgBitrate\u000a    MP4.box(MP4.types.pasp, new Uint8Array([hSpacing >> 24, // hSpacing\u000a    hSpacing >> 16 & 0xFF, hSpacing >> 8 & 0xFF, hSpacing & 0xFF, vSpacing >> 24, // vSpacing\u000a    vSpacing >> 16 & 0xFF, vSpacing >> 8 & 0xFF, vSpacing & 0xFF])));\u000a  };\u000a\u000a  MP4.esds = function esds(track) {\u000a    var configlen = track.config.length;\u000a    return new Uint8Array([0x00, // version 0\u000a    0x00, 0x00, 0x00, // flags\u000a    0x03, // descriptor_type\u000a    0x17 + configlen, // length\u000a    0x00, 0x01, // es_id\u000a    0x00, // stream_priority\u000a    0x04, // descriptor_type\u000a    0x0f + configlen, // length\u000a    0x40, // codec : mpeg4_audio\u000a    0x15, // stream_type\u000a    0x00, 0x00, 0x00, // buffer_size\u000a    0x00, 0x00, 0x00, 0x00, // maxBitrate\u000a    0x00, 0x00, 0x00, 0x00, // avgBitrate\u000a    0x05 // descriptor_type\u000a    ].concat([configlen]).concat(track.config).concat([0x06, 0x01, 0x02])); // GASpecificConfig)); // length + audio config descriptor\u000a  };\u000a\u000a  MP4.mp4a = function mp4a(track) {\u000a    var samplerate = track.samplerate;\u000a    return MP4.box(MP4.types.mp4a, new Uint8Array([0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x01, // data_reference_index\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, track.channelCount, // channelcount\u000a    0x00, 0x10, // sampleSize:16bits\u000a    0x00, 0x00, 0x00, 0x00, // reserved2\u000a    samplerate >> 8 & 0xFF, samplerate & 0xff, //\u000a    0x00, 0x00]), MP4.box(MP4.types.esds, MP4.esds(track)));\u000a  };\u000a\u000a  MP4.mp3 = function mp3(track) {\u000a    var samplerate = track.samplerate;\u000a    return MP4.box(MP4.types['.mp3'], new Uint8Array([0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x01, // data_reference_index\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, track.channelCount, // channelcount\u000a    0x00, 0x10, // sampleSize:16bits\u000a    0x00, 0x00, 0x00, 0x00, // reserved2\u000a    samplerate >> 8 & 0xFF, samplerate & 0xff, //\u000a    0x00, 0x00]));\u000a  };\u000a\u000a  MP4.stsd = function stsd(track) {\u000a    if (track.type === 'audio') {\u000a      if (!track.isAAC && track.codec === 'mp3') {\u000a        return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp3(track));\u000a      }\u000a\u000a      return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp4a(track));\u000a    } else {\u000a      return MP4.box(MP4.types.stsd, MP4.STSD, MP4.avc1(track));\u000a    }\u000a  };\u000a\u000a  MP4.tkhd = function tkhd(track) {\u000a    var id = track.id,\u000a        duration = track.duration * track.timescale,\u000a        width = track.width,\u000a        height = track.height,\u000a        upperWordDuration = Math.floor(duration / (UINT32_MAX + 1)),\u000a        lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\u000a    return MP4.box(MP4.types.tkhd, new Uint8Array([0x01, // version 1\u000a    0x00, 0x00, 0x07, // flags\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, // creation_time\u000a    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03, // modification_time\u000a    id >> 24 & 0xFF, id >> 16 & 0xFF, id >> 8 & 0xFF, id & 0xFF, // track_ID\u000a    0x00, 0x00, 0x00, 0x00, // reserved\u000a    upperWordDuration >> 24, upperWordDuration >> 16 & 0xFF, upperWordDuration >> 8 & 0xFF, upperWordDuration & 0xFF, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xFF, lowerWordDuration >> 8 & 0xFF, lowerWordDuration & 0xFF, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // reserved\u000a    0x00, 0x00, // layer\u000a    0x00, 0x00, // alternate_group\u000a    0x00, 0x00, // non-audio track volume\u000a    0x00, 0x00, // reserved\u000a    0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, // transformation: unity matrix\u000a    width >> 8 & 0xFF, width & 0xFF, 0x00, 0x00, // width\u000a    height >> 8 & 0xFF, height & 0xFF, 0x00, 0x00 // height\u000a    ]));\u000a  };\u000a\u000a  MP4.traf = function traf(track, baseMediaDecodeTime) {\u000a    var sampleDependencyTable = MP4.sdtp(track),\u000a        id = track.id,\u000a        upperWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1)),\u000a        lowerWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));\u000a    return MP4.box(MP4.types.traf, MP4.box(MP4.types.tfhd, new Uint8Array([0x00, // version 0\u000a    0x00, 0x00, 0x00, // flags\u000a    id >> 24, id >> 16 & 0XFF, id >> 8 & 0XFF, id & 0xFF // track_ID\u000a    ])), MP4.box(MP4.types.tfdt, new Uint8Array([0x01, // version 1\u000a    0x00, 0x00, 0x00, // flags\u000a    upperWordBaseMediaDecodeTime >> 24, upperWordBaseMediaDecodeTime >> 16 & 0XFF, upperWordBaseMediaDecodeTime >> 8 & 0XFF, upperWordBaseMediaDecodeTime & 0xFF, lowerWordBaseMediaDecodeTime >> 24, lowerWordBaseMediaDecodeTime >> 16 & 0XFF, lowerWordBaseMediaDecodeTime >> 8 & 0XFF, lowerWordBaseMediaDecodeTime & 0xFF])), MP4.trun(track, sampleDependencyTable.length + 16 + // tfhd\u000a    20 + // tfdt\u000a    8 + // traf header\u000a    16 + // mfhd\u000a    8 + // moof header\u000a    8), // mdat header\u000a    sampleDependencyTable);\u000a  }\u000a  /**\u000a   * Generate a track box.\u000a   * @param track {object} a track definition\u000a   * @return {Uint8Array} the track box\u000a   */\u000a  ;\u000a\u000a  MP4.trak = function trak(track) {\u000a    track.duration = track.duration || 0xffffffff;\u000a    return MP4.box(MP4.types.trak, MP4.tkhd(track), MP4.mdia(track));\u000a  };\u000a\u000a  MP4.trex = function trex(track) {\u000a    var id = track.id;\u000a    return MP4.box(MP4.types.trex, new Uint8Array([0x00, // version 0\u000a    0x00, 0x00, 0x00, // flags\u000a    id >> 24, id >> 16 & 0XFF, id >> 8 & 0XFF, id & 0xFF, // track_ID\u000a    0x00, 0x00, 0x00, 0x01, // default_sample_description_index\u000a    0x00, 0x00, 0x00, 0x00, // default_sample_duration\u000a    0x00, 0x00, 0x00, 0x00, // default_sample_size\u000a    0x00, 0x01, 0x00, 0x01 // default_sample_flags\u000a    ]));\u000a  };\u000a\u000a  MP4.trun = function trun(track, offset) {\u000a    var samples = track.samples || [],\u000a        len = samples.length,\u000a        arraylen = 12 + 16 * len,\u000a        array = new Uint8Array(arraylen),\u000a        i,\u000a        sample,\u000a        duration,\u000a        size,\u000a        flags,\u000a        cts;\u000a    offset += 8 + arraylen;\u000a    array.set([0x00, // version 0\u000a    0x00, 0x0f, 0x01, // flags\u000a    len >>> 24 & 0xFF, len >>> 16 & 0xFF, len >>> 8 & 0xFF, len & 0xFF, // sample_count\u000a    offset >>> 24 & 0xFF, offset >>> 16 & 0xFF, offset >>> 8 & 0xFF, offset & 0xFF // data_offset\u000a    ], 0);\u000a\u000a    for (i = 0; i < len; i++) {\u000a      sample = samples[i];\u000a      duration = sample.duration;\u000a      size = sample.size;\u000a      flags = sample.flags;\u000a      cts = sample.cts;\u000a      array.set([duration >>> 24 & 0xFF, duration >>> 16 & 0xFF, duration >>> 8 & 0xFF, duration & 0xFF, // sample_duration\u000a      size >>> 24 & 0xFF, size >>> 16 & 0xFF, size >>> 8 & 0xFF, size & 0xFF, // sample_size\u000a      flags.isLeading << 2 | flags.dependsOn, flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.paddingValue << 1 | flags.isNonSync, flags.degradPrio & 0xF0 << 8, flags.degradPrio & 0x0F, // sample_flags\u000a      cts >>> 24 & 0xFF, cts >>> 16 & 0xFF, cts >>> 8 & 0xFF, cts & 0xFF // sample_composition_time_offset\u000a      ], 12 + 16 * i);\u000a    }\u000a\u000a    return MP4.box(MP4.types.trun, array);\u000a  };\u000a\u000a  MP4.initSegment = function initSegment(tracks) {\u000a    if (!MP4.types) {\u000a      MP4.init();\u000a    }\u000a\u000a    var movie = MP4.moov(tracks),\u000a        result;\u000a    result = new Uint8Array(MP4.FTYP.byteLength + movie.byteLength);\u000a    result.set(MP4.FTYP);\u000a    result.set(movie, MP4.FTYP.byteLength);\u000a    return result;\u000a  };\u000a\u000a  return MP4;\u000a}();\u000a\u000a/* harmony default export */ var mp4_generator = (MP4);\u000a// CONCATENATED MODULE: ./src/utils/timescale-conversion.ts\u000avar MPEG_TS_CLOCK_FREQ_HZ = 90000;\u000afunction toTimescaleFromScale(value, destScale, srcScale, round) {\u000a  if (srcScale === void 0) {\u000a    srcScale = 1;\u000a  }\u000a\u000a  if (round === void 0) {\u000a    round = false;\u000a  }\u000a\u000a  return toTimescaleFromBase(value, destScale, 1 / srcScale);\u000a}\u000afunction toTimescaleFromBase(value, destScale, srcBase, round) {\u000a  if (srcBase === void 0) {\u000a    srcBase = 1;\u000a  }\u000a\u000a  if (round === void 0) {\u000a    round = false;\u000a  }\u000a\u000a  var result = value * destScale * srcBase; // equivalent to `(value * scale) / (1 / base)`\u000a\u000a  return round ? Math.round(result) : result;\u000a}\u000afunction toMsFromMpegTsClock(value, round) {\u000a  if (round === void 0) {\u000a    round = false;\u000a  }\u000a\u000a  return toTimescaleFromBase(value, 1000, 1 / MPEG_TS_CLOCK_FREQ_HZ, round);\u000a}\u000afunction toMpegTsClockFromTimescale(value, srcScale) {\u000a  if (srcScale === void 0) {\u000a    srcScale = 1;\u000a  }\u000a\u000a  return toTimescaleFromBase(value, MPEG_TS_CLOCK_FREQ_HZ, 1 / srcScale);\u000a}\u000a// CONCATENATED MODULE: ./src/remux/mp4-remuxer.js\u000a/**\u000a * fMP4 remuxer\u000a*/\u000a\u000a\u000a\u000a\u000a\u000a\u000avar MAX_SILENT_FRAME_DURATION_90KHZ = toMpegTsClockFromTimescale(10);\u000avar PTS_DTS_SHIFT_TOLERANCE_90KHZ = toMpegTsClockFromTimescale(0.2);\u000a\u000avar mp4_remuxer_MP4Remuxer = /*#__PURE__*/function () {\u000a  function MP4Remuxer(observer, config, typeSupported, vendor) {\u000a    this.observer = observer;\u000a    this.config = config;\u000a    this.typeSupported = typeSupported;\u000a    var userAgent = navigator.userAgent;\u000a    this.isSafari = vendor && vendor.indexOf('Apple') > -1 && userAgent && !userAgent.match('CriOS');\u000a    this.ISGenerated = false;\u000a  }\u000a\u000a  var _proto = MP4Remuxer.prototype;\u000a\u000a  _proto.destroy = function destroy() {};\u000a\u000a  _proto.resetTimeStamp = function resetTimeStamp(defaultTimeStamp) {\u000a    this._initPTS = this._initDTS = defaultTimeStamp;\u000a  };\u000a\u000a  _proto.resetInitSegment = function resetInitSegment() {\u000a    this.ISGenerated = false;\u000a  };\u000a\u000a  _proto.remux = function remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset) {\u000a    // generate Init Segment if needed\u000a    if (!this.ISGenerated) {\u000a      this.generateIS(audioTrack, videoTrack, timeOffset);\u000a    }\u000a\u000a    if (this.ISGenerated) {\u000a      var nbAudioSamples = audioTrack.samples.length;\u000a      var nbVideoSamples = videoTrack.samples.length;\u000a      var audioTimeOffset = timeOffset;\u000a      var videoTimeOffset = timeOffset;\u000a\u000a      if (nbAudioSamples && nbVideoSamples) {\u000a        // timeOffset is expected to be the offset of the first timestamp of this fragment (first DTS)\u000a        // if first audio DTS is not aligned with first video DTS then we need to take that into account\u000a        // when providing timeOffset to remuxAudio / remuxVideo. if we don't do that, there might be a permanent / small\u000a        // drift between audio and video streams\u000a        // Use pts at timeOffset 0 so that VOD streams begin at 0\u000a        var tsDelta = timeOffset > 0 ? audioTrack.samples[0].dts - videoTrack.samples[0].dts : audioTrack.samples[0].pts - videoTrack.samples[0].pts;\u000a        var audiovideoTimestampDelta = tsDelta / videoTrack.inputTimeScale;\u000a        audioTimeOffset += Math.max(0, audiovideoTimestampDelta);\u000a        videoTimeOffset += Math.max(0, -audiovideoTimestampDelta);\u000a      } // Purposefully remuxing audio before video, so that remuxVideo can use nextAudioPts, which is\u000a      // calculated in remuxAudio.\u000a      // logger.log('nb AAC samples:' + audioTrack.samples.length);\u000a\u000a\u000a      if (nbAudioSamples) {\u000a        // if initSegment was generated without video samples, regenerate it again\u000a        if (!audioTrack.timescale) {\u000a          logger["logger"].warn('regenerate InitSegment as audio detected');\u000a          this.generateIS(audioTrack, videoTrack, timeOffset);\u000a        }\u000a\u000a        var audioData = this.remuxAudio(audioTrack, audioTimeOffset, contiguous, accurateTimeOffset); // logger.log('nb AVC samples:' + videoTrack.samples.length);\u000a\u000a        if (nbVideoSamples) {\u000a          var audioTrackLength;\u000a\u000a          if (audioData) {\u000a            audioTrackLength = audioData.endPTS - audioData.startPTS;\u000a          } // if initSegment was generated without video samples, regenerate it again\u000a\u000a\u000a          if (!videoTrack.timescale) {\u000a            logger["logger"].warn('regenerate InitSegment as video detected');\u000a            this.generateIS(audioTrack, videoTrack, timeOffset);\u000a          }\u000a\u000a          this.remuxVideo(videoTrack, videoTimeOffset, contiguous, audioTrackLength, accurateTimeOffset);\u000a        }\u000a      } else {\u000a        // logger.log('nb AVC samples:' + videoTrack.samples.length);\u000a        if (nbVideoSamples) {\u000a          var videoData = this.remuxVideo(videoTrack, videoTimeOffset, contiguous, 0, accurateTimeOffset);\u000a\u000a          if (videoData && audioTrack.codec) {\u000a            this.remuxEmptyAudio(audioTrack, audioTimeOffset, contiguous, videoData);\u000a          }\u000a        }\u000a      }\u000a    } // logger.log('nb ID3 samples:' + audioTrack.samples.length);\u000a\u000a\u000a    if (id3Track.samples.length) {\u000a      this.remuxID3(id3Track, timeOffset);\u000a    } // logger.log('nb ID3 samples:' + audioTrack.samples.length);\u000a\u000a\u000a    if (textTrack.samples.length) {\u000a      this.remuxText(textTrack, timeOffset);\u000a    } // notify end of parsing\u000a\u000a\u000a    this.observer.trigger(events["default"].FRAG_PARSED);\u000a  };\u000a\u000a  _proto.generateIS = function generateIS(audioTrack, videoTrack, timeOffset) {\u000a    var observer = this.observer,\u000a        audioSamples = audioTrack.samples,\u000a        videoSamples = videoTrack.samples,\u000a        typeSupported = this.typeSupported,\u000a        container = 'audio/mp4',\u000a        tracks = {},\u000a        data = {\u000a      tracks: tracks\u000a    },\u000a        computePTSDTS = this._initPTS === undefined,\u000a        initPTS,\u000a        initDTS;\u000a\u000a    if (computePTSDTS) {\u000a      initPTS = initDTS = Infinity;\u000a    }\u000a\u000a    if (audioTrack.config && audioSamples.length) {\u000a      // let's use audio sampling rate as MP4 time scale.\u000a      // rationale is that there is a integer nb of audio frames per audio sample (1024 for AAC)\u000a      // using audio sampling rate here helps having an integer MP4 frame duration\u000a      // this avoids potential rounding issue and AV sync issue\u000a      audioTrack.timescale = audioTrack.samplerate;\u000a      logger["logger"].log("audio sampling rate : " + audioTrack.samplerate);\u000a\u000a      if (!audioTrack.isAAC) {\u000a        if (typeSupported.mpeg) {\u000a          // Chrome and Safari\u000a          container = 'audio/mpeg';\u000a          audioTrack.codec = '';\u000a        } else if (typeSupported.mp3) {\u000a          // Firefox\u000a          audioTrack.codec = 'mp3';\u000a        }\u000a      }\u000a\u000a      tracks.audio = {\u000a        container: container,\u000a        codec: audioTrack.codec,\u000a        initSegment: !audioTrack.isAAC && typeSupported.mpeg ? new Uint8Array() : mp4_generator.initSegment([audioTrack]),\u000a        metadata: {\u000a          channelCount: audioTrack.channelCount\u000a        }\u000a      };\u000a\u000a      if (computePTSDTS) {\u000a        // remember first PTS of this demuxing context. for audio, PTS = DTS\u000a        initPTS = initDTS = audioSamples[0].pts - Math.round(audioTrack.inputTimeScale * timeOffset);\u000a      }\u000a    }\u000a\u000a    if (videoTrack.sps && videoTrack.pps && videoSamples.length) {\u000a      // let's use input time scale as MP4 video timescale\u000a      // we use input time scale straight away to avoid rounding issues on frame duration / cts computation\u000a      var inputTimeScale = videoTrack.inputTimeScale;\u000a      videoTrack.timescale = inputTimeScale;\u000a      tracks.video = {\u000a        container: 'video/mp4',\u000a        codec: videoTrack.codec,\u000a        initSegment: mp4_generator.initSegment([videoTrack]),\u000a        metadata: {\u000a          width: videoTrack.width,\u000a          height: videoTrack.height\u000a        }\u000a      };\u000a\u000a      if (computePTSDTS) {\u000a        var startPTS = Math.round(inputTimeScale * timeOffset);\u000a        initPTS = Math.min(initPTS, videoSamples[0].pts - startPTS);\u000a        initDTS = Math.min(initDTS, videoSamples[0].dts - startPTS);\u000a        this.observer.trigger(events["default"].INIT_PTS_FOUND, {\u000a          initPTS: initPTS\u000a        });\u000a      }\u000a    } else if (computePTSDTS && tracks.audio) {\u000a      // initPTS found for audio-only stream with main and alt audio\u000a      this.observer.trigger(events["default"].INIT_PTS_FOUND, {\u000a        initPTS: initPTS\u000a      });\u000a    }\u000a\u000a    if (Object.keys(tracks).length) {\u000a      observer.trigger(events["default"].FRAG_PARSING_INIT_SEGMENT, data);\u000a      this.ISGenerated = true;\u000a\u000a      if (computePTSDTS) {\u000a        this._initPTS = initPTS;\u000a        this._initDTS = initDTS;\u000a      }\u000a    } else {\u000a      observer.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        details: errors["ErrorDetails"].FRAG_PARSING_ERROR,\u000a        fatal: false,\u000a        reason: 'no audio/video samples found'\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.remuxVideo = function remuxVideo(track, timeOffset, contiguous, audioTrackLength, accurateTimeOffset) {\u000a    var offset = 8;\u000a    var mp4SampleDuration;\u000a    var mdat;\u000a    var moof;\u000a    var firstDTS;\u000a    var lastDTS;\u000a    var minPTS = Number.POSITIVE_INFINITY;\u000a    var maxPTS = Number.NEGATIVE_INFINITY;\u000a    var timeScale = track.timescale;\u000a    var inputSamples = track.samples;\u000a    var outputSamples = [];\u000a    var nbSamples = inputSamples.length;\u000a    var ptsNormalize = this._PTSNormalize;\u000a    var initPTS = this._initPTS; // if parsed fragment is contiguous with last one, let's use last DTS value as reference\u000a\u000a    var nextAvcDts = this.nextAvcDts;\u000a    var isSafari = this.isSafari;\u000a\u000a    if (nbSamples === 0) {\u000a      return;\u000a    } // Safari does not like overlapping DTS on consecutive fragments. let's use nextAvcDts to overcome this if fragments are consecutive\u000a\u000a\u000a    if (isSafari) {\u000a      // also consider consecutive fragments as being contiguous (even if a level switch occurs),\u000a      // for sake of clarity:\u000a      // consecutive fragments are frags with\u000a      //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR\u000a      //  - less than 200 ms PTS gaps (timeScale/5)\u000a      contiguous |= nbSamples && nextAvcDts && (accurateTimeOffset && Math.abs(timeOffset - nextAvcDts / timeScale) < 0.1 || Math.abs(inputSamples[0].pts - nextAvcDts - initPTS) < timeScale / 5);\u000a    }\u000a\u000a    if (!contiguous) {\u000a      // if not contiguous, let's use target timeOffset\u000a      nextAvcDts = timeOffset * timeScale;\u000a    } // PTS is coded on 33bits, and can loop from -2^32 to 2^32\u000a    // ptsNormalize will make PTS/DTS value monotonic, we use last known DTS value as reference value\u000a\u000a\u000a    inputSamples.forEach(function (sample) {\u000a      sample.pts = ptsNormalize(sample.pts - initPTS, nextAvcDts);\u000a      sample.dts = ptsNormalize(sample.dts - initPTS, nextAvcDts);\u000a      minPTS = Math.min(sample.pts, minPTS);\u000a      maxPTS = Math.max(sample.pts, maxPTS);\u000a    }); // sort video samples by DTS then PTS then demux id order\u000a\u000a    inputSamples.sort(function (a, b) {\u000a      var deltadts = a.dts - b.dts;\u000a      var deltapts = a.pts - b.pts;\u000a      return deltadts || deltapts || a.id - b.id;\u000a    }); // handle broken streams with PTS < DTS, tolerance up 0.2 seconds\u000a\u000a    var PTSDTSshift = inputSamples.reduce(function (prev, curr) {\u000a      return Math.max(Math.min(prev, curr.pts - curr.dts), -1 * PTS_DTS_SHIFT_TOLERANCE_90KHZ);\u000a    }, 0);\u000a\u000a    if (PTSDTSshift < 0) {\u000a      logger["logger"].warn("PTS < DTS detected in video samples, shifting DTS by " + toMsFromMpegTsClock(PTSDTSshift, true) + " ms to overcome this issue");\u000a\u000a      for (var i = 0; i < nbSamples; i++) {\u000a        inputSamples[i].dts = Math.max(0, inputSamples[i].dts + PTSDTSshift);\u000a      }\u000a    } // Get first/last DTS\u000a\u000a\u000a    firstDTS = inputSamples[0].dts;\u000a    lastDTS = inputSamples[nbSamples - 1].dts; // on Safari let's signal the same sample duration for all samples\u000a    // sample duration (as expected by trun MP4 boxes), should be the delta between sample DTS\u000a    // set this constant duration as being the avg delta between consecutive DTS.\u000a\u000a    var averageSampleDuration = Math.round((lastDTS - firstDTS) / (nbSamples - 1)); // check timestamp continuity across consecutive fragments (this is to remove inter-fragment gap/hole)\u000a\u000a    var delta = firstDTS - nextAvcDts; // if fragment are contiguous, detect hole/overlapping between fragments\u000a\u000a    if (contiguous) {\u000a      var foundHole = delta > averageSampleDuration;\u000a      var foundOverlap = delta < -1;\u000a\u000a      if (foundHole || foundOverlap) {\u000a        if (foundHole) {\u000a          logger["logger"].warn("AVC: " + toMsFromMpegTsClock(delta, true) + "ms (" + delta + "dts) hole between fragments detected, filling it");\u000a        } else {\u000a          logger["logger"].warn("AVC: " + toMsFromMpegTsClock(-delta, true) + "ms (" + delta + "dts) overlapping between fragments detected");\u000a        }\u000a\u000a        firstDTS = nextAvcDts;\u000a        minPTS -= delta;\u000a        inputSamples[0].dts = firstDTS;\u000a        inputSamples[0].pts = minPTS;\u000a        logger["logger"].log("Video: First PTS/DTS adjusted: " + toMsFromMpegTsClock(minPTS, true) + "/" + toMsFromMpegTsClock(firstDTS, true) + ", delta: " + toMsFromMpegTsClock(delta, true) + " ms");\u000a      }\u000a    } // Clamp first DTS to 0 so that we're still aligning on initPTS,\u000a    // and not passing negative values to MP4.traf. This will change initial frame compositionTimeOffset!\u000a\u000a\u000a    firstDTS = Math.max(firstDTS, 0);\u000a    var nbNalu = 0,\u000a        naluLen = 0;\u000a\u000a    for (var _i = 0; _i < nbSamples; _i++) {\u000a      // compute total/avc sample length and nb of NAL units\u000a      var sample = inputSamples[_i],\u000a          units = sample.units,\u000a          nbUnits = units.length,\u000a          sampleLen = 0;\u000a\u000a      for (var j = 0; j < nbUnits; j++) {\u000a        sampleLen += units[j].data.length;\u000a      }\u000a\u000a      naluLen += sampleLen;\u000a      nbNalu += nbUnits;\u000a      sample.length = sampleLen; // normalize PTS/DTS\u000a\u000a      if (isSafari) {\u000a        // sample DTS is computed using a constant decoding offset (mp4SampleDuration) between samples\u000a        sample.dts = firstDTS + _i * averageSampleDuration;\u000a      } else {\u000a        // ensure sample monotonic DTS\u000a        sample.dts = Math.max(sample.dts, firstDTS);\u000a      } // ensure that computed value is greater or equal than sample DTS\u000a\u000a\u000a      sample.pts = Math.max(sample.pts, sample.dts);\u000a    }\u000a    /* concatenate the video data and construct the mdat in place\u000a      (need 8 more bytes to fill length and mpdat type) */\u000a\u000a\u000a    var mdatSize = naluLen + 4 * nbNalu + 8;\u000a\u000a    try {\u000a      mdat = new Uint8Array(mdatSize);\u000a    } catch (err) {\u000a      this.observer.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MUX_ERROR,\u000a        details: errors["ErrorDetails"].REMUX_ALLOC_ERROR,\u000a        fatal: false,\u000a        bytes: mdatSize,\u000a        reason: "fail allocating video mdat " + mdatSize\u000a      });\u000a      return;\u000a    }\u000a\u000a    var view = new DataView(mdat.buffer);\u000a    view.setUint32(0, mdatSize);\u000a    mdat.set(mp4_generator.types.mdat, 4);\u000a\u000a    for (var _i2 = 0; _i2 < nbSamples; _i2++) {\u000a      var avcSample = inputSamples[_i2],\u000a          avcSampleUnits = avcSample.units,\u000a          mp4SampleLength = 0,\u000a          compositionTimeOffset = void 0; // convert NALU bitstream to MP4 format (prepend NALU with size field)\u000a\u000a      for (var _j = 0, _nbUnits = avcSampleUnits.length; _j < _nbUnits; _j++) {\u000a        var unit = avcSampleUnits[_j],\u000a            unitData = unit.data,\u000a            unitDataLen = unit.data.byteLength;\u000a        view.setUint32(offset, unitDataLen);\u000a        offset += 4;\u000a        mdat.set(unitData, offset);\u000a        offset += unitDataLen;\u000a        mp4SampleLength += 4 + unitDataLen;\u000a      }\u000a\u000a      if (!isSafari) {\u000a        // expected sample duration is the Decoding Timestamp diff of consecutive samples\u000a        if (_i2 < nbSamples - 1) {\u000a          mp4SampleDuration = inputSamples[_i2 + 1].dts - avcSample.dts;\u000a        } else {\u000a          var config = this.config,\u000a              lastFrameDuration = avcSample.dts - inputSamples[_i2 > 0 ? _i2 - 1 : _i2].dts;\u000a\u000a          if (config.stretchShortVideoTrack) {\u000a            // In some cases, a segment's audio track duration may exceed the video track duration.\u000a            // Since we've already remuxed audio, and we know how long the audio track is, we look to\u000a            // see if the delta to the next segment is longer than maxBufferHole.\u000a            // If so, playback would potentially get stuck, so we artificially inflate\u000a            // the duration of the last frame to minimize any potential gap between segments.\u000a            var maxBufferHole = config.maxBufferHole,\u000a                gapTolerance = Math.floor(maxBufferHole * timeScale),\u000a                deltaToFrameEnd = (audioTrackLength ? minPTS + audioTrackLength * timeScale : this.nextAudioPts) - avcSample.pts;\u000a\u000a            if (deltaToFrameEnd > gapTolerance) {\u000a              // We subtract lastFrameDuration from deltaToFrameEnd to try to prevent any video\u000a              // frame overlap. maxBufferHole should be >> lastFrameDuration anyway.\u000a              mp4SampleDuration = deltaToFrameEnd - lastFrameDuration;\u000a\u000a              if (mp4SampleDuration < 0) {\u000a                mp4SampleDuration = lastFrameDuration;\u000a              }\u000a\u000a              logger["logger"].log("It is approximately " + toMsFromMpegTsClock(deltaToFrameEnd, false) + " ms to the next segment; using duration " + toMsFromMpegTsClock(mp4SampleDuration, false) + " ms for the last video frame.");\u000a            } else {\u000a              mp4SampleDuration = lastFrameDuration;\u000a            }\u000a          } else {\u000a            mp4SampleDuration = lastFrameDuration;\u000a          }\u000a        }\u000a\u000a        compositionTimeOffset = Math.round(avcSample.pts - avcSample.dts);\u000a      } else {\u000a        compositionTimeOffset = Math.max(0, mp4SampleDuration * Math.round((avcSample.pts - avcSample.dts) / mp4SampleDuration));\u000a      } // console.log('PTS/DTS/initDTS/normPTS/normDTS/relative PTS : ${avcSample.pts}/${avcSample.dts}/${initDTS}/${ptsnorm}/${dtsnorm}/${(avcSample.pts/4294967296).toFixed(3)}');\u000a\u000a\u000a      outputSamples.push({\u000a        size: mp4SampleLength,\u000a        // constant duration\u000a        duration: mp4SampleDuration,\u000a        cts: compositionTimeOffset,\u000a        flags: {\u000a          isLeading: 0,\u000a          isDependedOn: 0,\u000a          hasRedundancy: 0,\u000a          degradPrio: 0,\u000a          dependsOn: avcSample.key ? 2 : 1,\u000a          isNonSync: avcSample.key ? 0 : 1\u000a        }\u000a      });\u000a    } // next AVC sample DTS should be equal to last sample DTS + last sample duration (in PES timescale)\u000a\u000a\u000a    this.nextAvcDts = lastDTS + mp4SampleDuration;\u000a    var dropped = track.dropped;\u000a    track.nbNalu = 0;\u000a    track.dropped = 0;\u000a\u000a    if (outputSamples.length && navigator.userAgent.toLowerCase().indexOf('chrome') > -1) {\u000a      var flags = outputSamples[0].flags; // chrome workaround, mark first sample as being a Random Access Point to avoid sourcebuffer append issue\u000a      // https://code.google.com/p/chromium/issues/detail?id=229412\u000a\u000a      flags.dependsOn = 2;\u000a      flags.isNonSync = 0;\u000a    }\u000a\u000a    track.samples = outputSamples;\u000a    moof = mp4_generator.moof(track.sequenceNumber++, firstDTS, track);\u000a    track.samples = [];\u000a    var data = {\u000a      data1: moof,\u000a      data2: mdat,\u000a      startPTS: minPTS / timeScale,\u000a      endPTS: (maxPTS + mp4SampleDuration) / timeScale,\u000a      startDTS: firstDTS / timeScale,\u000a      endDTS: this.nextAvcDts / timeScale,\u000a      type: 'video',\u000a      hasAudio: false,\u000a      hasVideo: true,\u000a      nb: outputSamples.length,\u000a      dropped: dropped\u000a    };\u000a    this.observer.trigger(events["default"].FRAG_PARSING_DATA, data);\u000a    return data;\u000a  };\u000a\u000a  _proto.remuxAudio = function remuxAudio(track, timeOffset, contiguous, accurateTimeOffset) {\u000a    var inputTimeScale = track.inputTimeScale;\u000a    var mp4timeScale = track.timescale;\u000a    var scaleFactor = inputTimeScale / mp4timeScale;\u000a    var mp4SampleDuration = track.isAAC ? 1024 : 1152;\u000a    var inputSampleDuration = mp4SampleDuration * scaleFactor;\u000a    var ptsNormalize = this._PTSNormalize;\u000a    var initPTS = this._initPTS;\u000a    var rawMPEG = !track.isAAC && this.typeSupported.mpeg;\u000a    var mp4Sample;\u000a    var fillFrame;\u000a    var mdat;\u000a    var moof;\u000a    var firstPTS;\u000a    var lastPTS;\u000a    var offset = rawMPEG ? 0 : 8;\u000a    var inputSamples = track.samples;\u000a    var outputSamples = [];\u000a    var nextAudioPts = this.nextAudioPts; // for audio samples, also consider consecutive fragments as being contiguous (even if a level switch occurs),\u000a    // for sake of clarity:\u000a    // consecutive fragments are frags with\u000a    //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR\u000a    //  - less than 20 audio frames distance\u000a    // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)\u000a    // this helps ensuring audio continuity\u000a    // and this also avoids audio glitches/cut when switching quality, or reporting wrong duration on first audio frame\u000a\u000a    contiguous |= inputSamples.length && nextAudioPts && (accurateTimeOffset && Math.abs(timeOffset - nextAudioPts / inputTimeScale) < 0.1 || Math.abs(inputSamples[0].pts - nextAudioPts - initPTS) < 20 * inputSampleDuration); // compute normalized PTS\u000a\u000a    inputSamples.forEach(function (sample) {\u000a      sample.pts = sample.dts = ptsNormalize(sample.pts - initPTS, timeOffset * inputTimeScale);\u000a    }); // filter out sample with negative PTS that are not playable anyway\u000a    // if we don't remove these negative samples, they will shift all audio samples forward.\u000a    // leading to audio overlap between current / next fragment\u000a\u000a    inputSamples = inputSamples.filter(function (sample) {\u000a      return sample.pts >= 0;\u000a    }); // in case all samples have negative PTS, and have been filtered out, return now\u000a\u000a    if (inputSamples.length === 0) {\u000a      return;\u000a    }\u000a\u000a    if (!contiguous) {\u000a      if (!accurateTimeOffset) {\u000a        // if frag are mot contiguous and if we cant trust time offset, let's use first sample PTS as next audio PTS\u000a        nextAudioPts = inputSamples[0].pts;\u000a      } else {\u000a        // if timeOffset is accurate, let's use it as predicted next audio PTS\u000a        nextAudioPts = timeOffset * inputTimeScale;\u000a      }\u000a    } // If the audio track is missing samples, the frames seem to get "left-shifted" within the\u000a    // resulting mp4 segment, causing sync issues and leaving gaps at the end of the audio segment.\u000a    // In an effort to prevent this from happening, we inject frames here where there are gaps.\u000a    // When possible, we inject a silent frame; when that's not possible, we duplicate the last\u000a    // frame.\u000a\u000a\u000a    if (track.isAAC) {\u000a      var maxAudioFramesDrift = this.config.maxAudioFramesDrift;\u000a\u000a      for (var i = 0, nextPts = nextAudioPts; i < inputSamples.length;) {\u000a        // First, let's see how far off this frame is from where we expect it to be\u000a        var sample = inputSamples[i],\u000a            delta;\u000a        var pts = sample.pts;\u000a        delta = pts - nextPts; // If we're overlapping by more than a duration, drop this sample\u000a\u000a        if (delta <= -maxAudioFramesDrift * inputSampleDuration) {\u000a          if (contiguous) {\u000a            logger["logger"].warn("Dropping 1 audio frame @ " + toMsFromMpegTsClock(nextPts, true) / 1000 + "s due to " + toMsFromMpegTsClock(delta, true) + " ms overlap.");\u000a            inputSamples.splice(i, 1); // Don't touch nextPtsNorm or i\u000a          } else {\u000a            // When changing qualities we can't trust that audio has been appended up to nextAudioPts\u000a            // Warn about the overlap but do not drop samples as that can introduce buffer gaps\u000a            logger["logger"].warn("Audio frame @ " + toMsFromMpegTsClock(pts, true) / 1000 + "s overlaps nextAudioPts by " + toMsFromMpegTsClock(delta, true) + " ms.");\u000a            nextPts = pts + inputSampleDuration;\u000a            i++;\u000a          }\u000a        } // eslint-disable-line brace-style\u000a        // Insert missing frames if:\u000a        // 1: We're more than maxAudioFramesDrift frame away\u000a        // 2: Not more than MAX_SILENT_FRAME_DURATION away\u000a        // 3: currentTime (aka nextPtsNorm) is not 0\u000a        else if (delta >= maxAudioFramesDrift * inputSampleDuration && delta < MAX_SILENT_FRAME_DURATION_90KHZ && nextPts) {\u000a            var missing = Math.round(delta / inputSampleDuration);\u000a            logger["logger"].warn("Injecting " + missing + " audio frames @ " + toMsFromMpegTsClock(nextPts, true) / 1000 + "s due to " + toMsFromMpegTsClock(delta, true) + " ms gap.");\u000a\u000a            for (var j = 0; j < missing; j++) {\u000a              var newStamp = Math.max(nextPts, 0);\u000a              fillFrame = aac_helper.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\u000a\u000a              if (!fillFrame) {\u000a                logger["logger"].log('Unable to get silent frame for given audio codec; duplicating last frame instead.');\u000a                fillFrame = sample.unit.subarray();\u000a              }\u000a\u000a              inputSamples.splice(i, 0, {\u000a                unit: fillFrame,\u000a                pts: newStamp,\u000a                dts: newStamp\u000a              });\u000a              nextPts += inputSampleDuration;\u000a              i++;\u000a            } // Adjust sample to next expected pts\u000a\u000a\u000a            sample.pts = sample.dts = nextPts;\u000a            nextPts += inputSampleDuration;\u000a            i++;\u000a          } else {\u000a            // Otherwise, just adjust pts\u000a            if (Math.abs(delta) > 0.1 * inputSampleDuration) {// logger.log(`Invalid frame delta ${Math.round(delta + inputSampleDuration)} at PTS ${Math.round(pts / 90)} (should be ${Math.round(inputSampleDuration)}).`);\u000a            }\u000a\u000a            sample.pts = sample.dts = nextPts;\u000a            nextPts += inputSampleDuration;\u000a            i++;\u000a          }\u000a      }\u000a    } // compute mdat size, as we eventually filtered/added some samples\u000a\u000a\u000a    var nbSamples = inputSamples.length;\u000a    var mdatSize = 0;\u000a\u000a    while (nbSamples--) {\u000a      mdatSize += inputSamples[nbSamples].unit.byteLength;\u000a    }\u000a\u000a    for (var _j2 = 0, _nbSamples = inputSamples.length; _j2 < _nbSamples; _j2++) {\u000a      var audioSample = inputSamples[_j2];\u000a      var unit = audioSample.unit;\u000a      var _pts = audioSample.pts; // logger.log(`Audio/PTS:${toMsFromMpegTsClock(pts, true)}`);\u000a      // if not first sample\u000a\u000a      if (lastPTS !== undefined && mp4Sample) {\u000a        mp4Sample.duration = Math.round((_pts - lastPTS) / scaleFactor);\u000a      } else {\u000a        var _delta = _pts - nextAudioPts;\u000a\u000a        var numMissingFrames = 0; // if fragment are contiguous, detect hole/overlapping between fragments\u000a        // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)\u000a\u000a        if (contiguous && track.isAAC) {\u000a          // log delta\u000a          if (_delta) {\u000a            if (_delta > 0 && _delta < MAX_SILENT_FRAME_DURATION_90KHZ) {\u000a              // Q: why do we have to round here, shouldn't this always result in an integer if timestamps are correct,\u000a              // and if not, shouldn't we actually Math.ceil() instead?\u000a              numMissingFrames = Math.round((_pts - nextAudioPts) / inputSampleDuration);\u000a              logger["logger"].log(toMsFromMpegTsClock(_delta, true) + " ms hole between AAC samples detected,filling it");\u000a\u000a              if (numMissingFrames > 0) {\u000a                fillFrame = aac_helper.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\u000a\u000a                if (!fillFrame) {\u000a                  fillFrame = unit.subarray();\u000a                }\u000a\u000a                mdatSize += numMissingFrames * fillFrame.length;\u000a              } // if we have frame overlap, overlapping for more than half a frame duraion\u000a\u000a            } else if (_delta < -12) {\u000a              // drop overlapping audio frames... browser will deal with it\u000a              logger["logger"].log("drop overlapping AAC sample, expected/parsed/delta: " + toMsFromMpegTsClock(nextAudioPts, true) + " ms / " + toMsFromMpegTsClock(_pts, true) + " ms / " + toMsFromMpegTsClock(-_delta, true) + " ms");\u000a              mdatSize -= unit.byteLength;\u000a              continue;\u000a            } // set PTS/DTS to expected PTS/DTS\u000a\u000a\u000a            _pts = nextAudioPts;\u000a          }\u000a        } // remember first PTS of our audioSamples\u000a\u000a\u000a        firstPTS = _pts;\u000a\u000a        if (mdatSize > 0) {\u000a          mdatSize += offset;\u000a\u000a          try {\u000a            mdat = new Uint8Array(mdatSize);\u000a          } catch (err) {\u000a            this.observer.trigger(events["default"].ERROR, {\u000a              type: errors["ErrorTypes"].MUX_ERROR,\u000a              details: errors["ErrorDetails"].REMUX_ALLOC_ERROR,\u000a              fatal: false,\u000a              bytes: mdatSize,\u000a              reason: "fail allocating audio mdat " + mdatSize\u000a            });\u000a            return;\u000a          }\u000a\u000a          if (!rawMPEG) {\u000a            var view = new DataView(mdat.buffer);\u000a            view.setUint32(0, mdatSize);\u000a            mdat.set(mp4_generator.types.mdat, 4);\u000a          }\u000a        } else {\u000a          // no audio samples\u000a          return;\u000a        }\u000a\u000a        for (var _i3 = 0; _i3 < numMissingFrames; _i3++) {\u000a          fillFrame = aac_helper.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\u000a\u000a          if (!fillFrame) {\u000a            logger["logger"].log('Unable to get silent frame for given audio codec; duplicating this frame instead.');\u000a            fillFrame = unit.subarray();\u000a          }\u000a\u000a          mdat.set(fillFrame, offset);\u000a          offset += fillFrame.byteLength;\u000a          mp4Sample = {\u000a            size: fillFrame.byteLength,\u000a            cts: 0,\u000a            duration: 1024,\u000a            flags: {\u000a              isLeading: 0,\u000a              isDependedOn: 0,\u000a              hasRedundancy: 0,\u000a              degradPrio: 0,\u000a              dependsOn: 1\u000a            }\u000a          };\u000a          outputSamples.push(mp4Sample);\u000a        }\u000a      }\u000a\u000a      mdat.set(unit, offset);\u000a      var unitLen = unit.byteLength;\u000a      offset += unitLen; // console.log('PTS/DTS/initDTS/normPTS/normDTS/relative PTS : ${audioSample.pts}/${audioSample.dts}/${initDTS}/${ptsnorm}/${dtsnorm}/${(audioSample.pts/4294967296).toFixed(3)}');\u000a\u000a      mp4Sample = {\u000a        size: unitLen,\u000a        cts: 0,\u000a        duration: 0,\u000a        flags: {\u000a          isLeading: 0,\u000a          isDependedOn: 0,\u000a          hasRedundancy: 0,\u000a          degradPrio: 0,\u000a          dependsOn: 1\u000a        }\u000a      };\u000a      outputSamples.push(mp4Sample);\u000a      lastPTS = _pts;\u000a    }\u000a\u000a    var lastSampleDuration = 0;\u000a    nbSamples = outputSamples.length; // set last sample duration as being identical to previous sample\u000a\u000a    if (nbSamples >= 2) {\u000a      lastSampleDuration = outputSamples[nbSamples - 2].duration;\u000a      mp4Sample.duration = lastSampleDuration;\u000a    }\u000a\u000a    if (nbSamples) {\u000a      // next audio sample PTS should be equal to last sample PTS + duration\u000a      this.nextAudioPts = nextAudioPts = lastPTS + scaleFactor * lastSampleDuration; // logger.log('Audio/PTS/PTSend:' + audioSample.pts.toFixed(0) + '/' + this.nextAacDts.toFixed(0));\u000a\u000a      track.samples = outputSamples;\u000a\u000a      if (rawMPEG) {\u000a        moof = new Uint8Array();\u000a      } else {\u000a        moof = mp4_generator.moof(track.sequenceNumber++, firstPTS / scaleFactor, track);\u000a      }\u000a\u000a      track.samples = [];\u000a      var start = firstPTS / inputTimeScale;\u000a      var end = nextAudioPts / inputTimeScale;\u000a      var audioData = {\u000a        data1: moof,\u000a        data2: mdat,\u000a        startPTS: start,\u000a        endPTS: end,\u000a        startDTS: start,\u000a        endDTS: end,\u000a        type: 'audio',\u000a        hasAudio: true,\u000a        hasVideo: false,\u000a        nb: nbSamples\u000a      };\u000a      this.observer.trigger(events["default"].FRAG_PARSING_DATA, audioData);\u000a      return audioData;\u000a    }\u000a\u000a    return null;\u000a  };\u000a\u000a  _proto.remuxEmptyAudio = function remuxEmptyAudio(track, timeOffset, contiguous, videoData) {\u000a    var inputTimeScale = track.inputTimeScale;\u000a    var mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;\u000a    var scaleFactor = inputTimeScale / mp4timeScale;\u000a    var nextAudioPts = this.nextAudioPts; // sync with video's timestamp\u000a\u000a    var startDTS = (nextAudioPts !== undefined ? nextAudioPts : videoData.startDTS * inputTimeScale) + this._initDTS;\u000a    var endDTS = videoData.endDTS * inputTimeScale + this._initDTS; // one sample's duration value\u000a\u000a    var sampleDuration = 1024;\u000a    var frameDuration = scaleFactor * sampleDuration; // samples count of this segment's duration\u000a\u000a    var nbSamples = Math.ceil((endDTS - startDTS) / frameDuration); // silent frame\u000a\u000a    var silentFrame = aac_helper.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\u000a    logger["logger"].warn('remux empty Audio'); // Can't remux if we can't generate a silent frame...\u000a\u000a    if (!silentFrame) {\u000a      logger["logger"].trace('Unable to remuxEmptyAudio since we were unable to get a silent frame for given audio codec!');\u000a      return;\u000a    }\u000a\u000a    var samples = [];\u000a\u000a    for (var i = 0; i < nbSamples; i++) {\u000a      var stamp = startDTS + i * frameDuration;\u000a      samples.push({\u000a        unit: silentFrame,\u000a        pts: stamp,\u000a        dts: stamp\u000a      });\u000a    }\u000a\u000a    track.samples = samples;\u000a    this.remuxAudio(track, timeOffset, contiguous);\u000a  };\u000a\u000a  _proto.remuxID3 = function remuxID3(track) {\u000a    var length = track.samples.length;\u000a\u000a    if (!length) {\u000a      return;\u000a    }\u000a\u000a    var inputTimeScale = track.inputTimeScale;\u000a    var initPTS = this._initPTS;\u000a    var initDTS = this._initDTS; // consume samples\u000a\u000a    for (var index = 0; index < length; index++) {\u000a      var sample = track.samples[index]; // setting id3 pts, dts to relative time\u000a      // using this._initPTS and this._initDTS to calculate relative time\u000a\u000a      sample.pts = (sample.pts - initPTS) / inputTimeScale;\u000a      sample.dts = (sample.dts - initDTS) / inputTimeScale;\u000a    }\u000a\u000a    this.observer.trigger(events["default"].FRAG_PARSING_METADATA, {\u000a      samples: track.samples\u000a    });\u000a    track.samples = [];\u000a  };\u000a\u000a  _proto.remuxText = function remuxText(track) {\u000a    track.samples.sort(function (a, b) {\u000a      return a.pts - b.pts;\u000a    });\u000a    var length = track.samples.length,\u000a        sample;\u000a    var inputTimeScale = track.inputTimeScale;\u000a    var initPTS = this._initPTS; // consume samples\u000a\u000a    if (length) {\u000a      for (var index = 0; index < length; index++) {\u000a        sample = track.samples[index]; // setting text pts, dts to relative time\u000a        // using this._initPTS and this._initDTS to calculate relative time\u000a\u000a        sample.pts = (sample.pts - initPTS) / inputTimeScale;\u000a      }\u000a\u000a      this.observer.trigger(events["default"].FRAG_PARSING_USERDATA, {\u000a        samples: track.samples\u000a      });\u000a    }\u000a\u000a    track.samples = [];\u000a  };\u000a\u000a  _proto._PTSNormalize = function _PTSNormalize(value, reference) {\u000a    var offset;\u000a\u000a    if (reference === undefined) {\u000a      return value;\u000a    }\u000a\u000a    if (reference < value) {\u000a      // - 2^33\u000a      offset = -8589934592;\u000a    } else {\u000a      // + 2^33\u000a      offset = 8589934592;\u000a    }\u000a    /* PTS is 33bit (from 0 to 2^33 -1)\u000a      if diff between value and reference is bigger than half of the amplitude (2^32) then it means that\u000a      PTS looping occured. fill the gap */\u000a\u000a\u000a    while (Math.abs(value - reference) > 4294967296) {\u000a      value += offset;\u000a    }\u000a\u000a    return value;\u000a  };\u000a\u000a  return MP4Remuxer;\u000a}();\u000a\u000a/* harmony default export */ var mp4_remuxer = (mp4_remuxer_MP4Remuxer);\u000a// CONCATENATED MODULE: ./src/remux/passthrough-remuxer.js\u000a/**\u000a * passthrough remuxer\u000a*/\u000a\u000a\u000avar passthrough_remuxer_PassThroughRemuxer = /*#__PURE__*/function () {\u000a  function PassThroughRemuxer(observer) {\u000a    this.observer = observer;\u000a  }\u000a\u000a  var _proto = PassThroughRemuxer.prototype;\u000a\u000a  _proto.destroy = function destroy() {};\u000a\u000a  _proto.resetTimeStamp = function resetTimeStamp() {};\u000a\u000a  _proto.resetInitSegment = function resetInitSegment() {};\u000a\u000a  _proto.remux = function remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, contiguous, accurateTimeOffset, rawData) {\u000a    var observer = this.observer;\u000a    var streamType = '';\u000a\u000a    if (audioTrack) {\u000a      streamType += 'audio';\u000a    }\u000a\u000a    if (videoTrack) {\u000a      streamType += 'video';\u000a    }\u000a\u000a    observer.trigger(events["default"].FRAG_PARSING_DATA, {\u000a      data1: rawData,\u000a      startPTS: timeOffset,\u000a      startDTS: timeOffset,\u000a      type: streamType,\u000a      hasAudio: !!audioTrack,\u000a      hasVideo: !!videoTrack,\u000a      nb: 1,\u000a      dropped: 0\u000a    }); // notify end of parsing\u000a\u000a    observer.trigger(events["default"].FRAG_PARSED);\u000a  };\u000a\u000a  return PassThroughRemuxer;\u000a}();\u000a\u000a/* harmony default export */ var passthrough_remuxer = (passthrough_remuxer_PassThroughRemuxer);\u000a// CONCATENATED MODULE: ./src/demux/demuxer-inline.js\u000a/**\u000a *\u000a * inline demuxer: probe fragments and instantiate\u000a * appropriate demuxer depending on content type (TSDemuxer, AACDemuxer, ...)\u000a *\u000a */\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a // see https://stackoverflow.com/a/11237259/589493\u000a\u000avar global = Object(get_self_scope["getSelfScope"])(); // safeguard for code that might run both on worker and main thread\u000a\u000avar now; // performance.now() not available on WebWorker, at least on Safari Desktop\u000a\u000atry {\u000a  now = global.performance.now.bind(global.performance);\u000a} catch (err) {\u000a  logger["logger"].debug('Unable to use Performance API on this environment');\u000a  now = global.Date.now;\u000a}\u000a\u000avar demuxer_inline_DemuxerInline = /*#__PURE__*/function () {\u000a  function DemuxerInline(observer, typeSupported, config, vendor) {\u000a    this.observer = observer;\u000a    this.typeSupported = typeSupported;\u000a    this.config = config;\u000a    this.vendor = vendor;\u000a  }\u000a\u000a  var _proto = DemuxerInline.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    var demuxer = this.demuxer;\u000a\u000a    if (demuxer) {\u000a      demuxer.destroy();\u000a    }\u000a  };\u000a\u000a  _proto.push = function push(data, decryptdata, initSegment, audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS) {\u000a    var _this = this;\u000a\u000a    if (data.byteLength > 0 && decryptdata != null && decryptdata.key != null && decryptdata.method === 'AES-128') {\u000a      var decrypter = this.decrypter;\u000a\u000a      if (decrypter == null) {\u000a        decrypter = this.decrypter = new crypt_decrypter["default"](this.observer, this.config);\u000a      }\u000a\u000a      var startTime = now();\u000a      decrypter.decrypt(data, decryptdata.key.buffer, decryptdata.iv.buffer, function (decryptedData) {\u000a        var endTime = now();\u000a\u000a        _this.observer.trigger(events["default"].FRAG_DECRYPTED, {\u000a          stats: {\u000a            tstart: startTime,\u000a            tdecrypt: endTime\u000a          }\u000a        });\u000a\u000a        _this.pushDecrypted(new Uint8Array(decryptedData), decryptdata, new Uint8Array(initSegment), audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS);\u000a      });\u000a    } else {\u000a      this.pushDecrypted(new Uint8Array(data), decryptdata, new Uint8Array(initSegment), audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS);\u000a    }\u000a  };\u000a\u000a  _proto.pushDecrypted = function pushDecrypted(data, decryptdata, initSegment, audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS) {\u000a    var demuxer = this.demuxer;\u000a\u000a    if (!demuxer || // in case of continuity change, or track switch\u000a    // we might switch from content type (AAC container to TS container, or TS to fmp4 for example)\u000a    // so let's check that current demuxer is still valid\u000a    (discontinuity || trackSwitch) && !this.probe(data)) {\u000a      var observer = this.observer;\u000a      var typeSupported = this.typeSupported;\u000a      var config = this.config; // probing order is TS/MP4/AAC/MP3\u000a\u000a      var muxConfig = [{\u000a        demux: tsdemuxer,\u000a        remux: mp4_remuxer\u000a      }, {\u000a        demux: mp4demuxer["default"],\u000a        remux: passthrough_remuxer\u000a      }, {\u000a        demux: aacdemuxer,\u000a        remux: mp4_remuxer\u000a      }, {\u000a        demux: mp3demuxer,\u000a        remux: mp4_remuxer\u000a      }]; // probe for content type\u000a\u000a      for (var i = 0, len = muxConfig.length; i < len; i++) {\u000a        var mux = muxConfig[i];\u000a        var probe = mux.demux.probe;\u000a\u000a        if (probe(data)) {\u000a          var _remuxer = this.remuxer = new mux.remux(observer, config, typeSupported, this.vendor);\u000a\u000a          demuxer = new mux.demux(observer, _remuxer, config, typeSupported);\u000a          this.probe = probe;\u000a          break;\u000a        }\u000a      }\u000a\u000a      if (!demuxer) {\u000a        observer.trigger(events["default"].ERROR, {\u000a          type: errors["ErrorTypes"].MEDIA_ERROR,\u000a          details: errors["ErrorDetails"].FRAG_PARSING_ERROR,\u000a          fatal: true,\u000a          reason: 'no demux matching with content found'\u000a        });\u000a        return;\u000a      }\u000a\u000a      this.demuxer = demuxer;\u000a    }\u000a\u000a    var remuxer = this.remuxer;\u000a\u000a    if (discontinuity || trackSwitch) {\u000a      demuxer.resetInitSegment(initSegment, audioCodec, videoCodec, duration);\u000a      remuxer.resetInitSegment();\u000a    }\u000a\u000a    if (discontinuity) {\u000a      demuxer.resetTimeStamp(defaultInitPTS);\u000a      remuxer.resetTimeStamp(defaultInitPTS);\u000a    }\u000a\u000a    if (typeof demuxer.setDecryptData === 'function') {\u000a      demuxer.setDecryptData(decryptdata);\u000a    }\u000a\u000a    demuxer.append(data, timeOffset, contiguous, accurateTimeOffset);\u000a  };\u000a\u000a  return DemuxerInline;\u000a}();\u000a\u000a/* harmony default export */ var demuxer_inline = __webpack_exports__["default"] = (demuxer_inline_DemuxerInline);\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/demux/demuxer-worker.js":\u000a/*!*************************************!*\u005c\u000a  !*** ./src/demux/demuxer-worker.js ***!\u000a  \u005c*************************************/\u000a/*! exports provided: default */\u000a/*! ModuleConcatenation bailout: Module is referenced from these modules with unsupported syntax: ./src/demux/demuxer.js (referenced with require.resolve) */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a__webpack_require__.r(__webpack_exports__);\u000a/* harmony import */ var _demux_demuxer_inline__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../demux/demuxer-inline */ "./src/demux/demuxer-inline.js");\u000a/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.js");\u000a/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.js");\u000a/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! eventemitter3 */ "./node_modules/eventemitter3/index.js");\u000a/* harmony import */ var eventemitter3__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(eventemitter3__WEBPACK_IMPORTED_MODULE_3__);\u000a/* demuxer web worker.\u000a *  - listen to worker message, and trigger DemuxerInline upon reception of Fragments.\u000a *  - provides MP4 Boxes back to main thread using [transferable objects](https://developers.google.com/web/updates/2011/12/Transferable-Objects-Lightning-Fast) in order to minimize message passing overhead.\u000a */\u000a\u000a\u000a\u000a\u000a\u000avar DemuxerWorker = function DemuxerWorker(self) {\u000a  // observer setup\u000a  var observer = new eventemitter3__WEBPACK_IMPORTED_MODULE_3__["EventEmitter"]();\u000a\u000a  observer.trigger = function trigger(event) {\u000a    for (var _len = arguments.length, data = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\u000a      data[_key - 1] = arguments[_key];\u000a    }\u000a\u000a    observer.emit.apply(observer, [event, event].concat(data));\u000a  };\u000a\u000a  observer.off = function off(event) {\u000a    for (var _len2 = arguments.length, data = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\u000a      data[_key2 - 1] = arguments[_key2];\u000a    }\u000a\u000a    observer.removeListener.apply(observer, [event].concat(data));\u000a  };\u000a\u000a  var forwardMessage = function forwardMessage(ev, data) {\u000a    self.postMessage({\u000a      event: ev,\u000a      data: data\u000a    });\u000a  };\u000a\u000a  self.addEventListener('message', function (ev) {\u000a    var data = ev.data; // console.log('demuxer cmd:' + data.cmd);\u000a\u000a    switch (data.cmd) {\u000a      case 'init':\u000a        var config = JSON.parse(data.config);\u000a        self.demuxer = new _demux_demuxer_inline__WEBPACK_IMPORTED_MODULE_0__["default"](observer, data.typeSupported, config, data.vendor);\u000a        Object(_utils_logger__WEBPACK_IMPORTED_MODULE_2__["enableLogs"])(config.debug); // signal end of worker init\u000a\u000a        forwardMessage('init', null);\u000a        break;\u000a\u000a      case 'demux':\u000a        self.demuxer.push(data.data, data.decryptdata, data.initSegment, data.audioCodec, data.videoCodec, data.timeOffset, data.discontinuity, data.trackSwitch, data.contiguous, data.duration, data.accurateTimeOffset, data.defaultInitPTS);\u000a        break;\u000a\u000a      default:\u000a        break;\u000a    }\u000a  }); // forward events to main thread\u000a\u000a  observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["default"].FRAG_DECRYPTED, forwardMessage);\u000a  observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["default"].FRAG_PARSING_INIT_SEGMENT, forwardMessage);\u000a  observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["default"].FRAG_PARSED, forwardMessage);\u000a  observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["default"].ERROR, forwardMessage);\u000a  observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["default"].FRAG_PARSING_METADATA, forwardMessage);\u000a  observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["default"].FRAG_PARSING_USERDATA, forwardMessage);\u000a  observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["default"].INIT_PTS_FOUND, forwardMessage); // special case for FRAG_PARSING_DATA: pass data1/data2 as transferable object (no copy)\u000a\u000a  observer.on(_events__WEBPACK_IMPORTED_MODULE_1__["default"].FRAG_PARSING_DATA, function (ev, data) {\u000a    var transferable = [];\u000a    var message = {\u000a      event: ev,\u000a      data: data\u000a    };\u000a\u000a    if (data.data1) {\u000a      message.data1 = data.data1.buffer;\u000a      transferable.push(data.data1.buffer);\u000a      delete data.data1;\u000a    }\u000a\u000a    if (data.data2) {\u000a      message.data2 = data.data2.buffer;\u000a      transferable.push(data.data2.buffer);\u000a      delete data.data2;\u000a    }\u000a\u000a    self.postMessage(message, transferable);\u000a  });\u000a};\u000a\u000a/* harmony default export */ __webpack_exports__["default"] = (DemuxerWorker);\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/demux/id3.js":\u000a/*!**************************!*\u005c\u000a  !*** ./src/demux/id3.js ***!\u000a  \u005c**************************/\u000a/*! exports provided: default, utf8ArrayToStr */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a__webpack_require__.r(__webpack_exports__);\u000a/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "utf8ArrayToStr", function() { return utf8ArrayToStr; });\u000a/* harmony import */ var _utils_get_self_scope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/get-self-scope */ "./src/utils/get-self-scope.js");\u000a\u000a/**\u000a * ID3 parser\u000a */\u000a\u000avar ID3 = /*#__PURE__*/function () {\u000a  function ID3() {}\u000a\u000a  /**\u000a   * Returns true if an ID3 header can be found at offset in data\u000a   * @param {Uint8Array} data - The data to search in\u000a   * @param {number} offset - The offset at which to start searching\u000a   * @return {boolean} - True if an ID3 header is found\u000a   */\u000a  ID3.isHeader = function isHeader(data, offset) {\u000a    /*\u000a    * http://id3.org/id3v2.3.0\u000a    * [0]     = 'I'\u000a    * [1]     = 'D'\u000a    * [2]     = '3'\u000a    * [3,4]   = {Version}\u000a    * [5]     = {Flags}\u000a    * [6-9]   = {ID3 Size}\u000a    *\u000a    * An ID3v2 tag can be detected with the following pattern:\u000a    *  $49 44 33 yy yy xx zz zz zz zz\u000a    * Where yy is less than $FF, xx is the 'flags' byte and zz is less than $80\u000a    */\u000a    if (offset + 10 <= data.length) {\u000a      // look for 'ID3' identifier\u000a      if (data[offset] === 0x49 && data[offset + 1] === 0x44 && data[offset + 2] === 0x33) {\u000a        // check version is within range\u000a        if (data[offset + 3] < 0xFF && data[offset + 4] < 0xFF) {\u000a          // check size is within range\u000a          if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {\u000a            return true;\u000a          }\u000a        }\u000a      }\u000a    }\u000a\u000a    return false;\u000a  }\u000a  /**\u000a   * Returns true if an ID3 footer can be found at offset in data\u000a   * @param {Uint8Array} data - The data to search in\u000a   * @param {number} offset - The offset at which to start searching\u000a   * @return {boolean} - True if an ID3 footer is found\u000a   */\u000a  ;\u000a\u000a  ID3.isFooter = function isFooter(data, offset) {\u000a    /*\u000a    * The footer is a copy of the header, but with a different identifier\u000a    */\u000a    if (offset + 10 <= data.length) {\u000a      // look for '3DI' identifier\u000a      if (data[offset] === 0x33 && data[offset + 1] === 0x44 && data[offset + 2] === 0x49) {\u000a        // check version is within range\u000a        if (data[offset + 3] < 0xFF && data[offset + 4] < 0xFF) {\u000a          // check size is within range\u000a          if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {\u000a            return true;\u000a          }\u000a        }\u000a      }\u000a    }\u000a\u000a    return false;\u000a  }\u000a  /**\u000a   * Returns any adjacent ID3 tags found in data starting at offset, as one block of data\u000a   * @param {Uint8Array} data - The data to search in\u000a   * @param {number} offset - The offset at which to start searching\u000a   * @return {Uint8Array} - The block of data containing any ID3 tags found\u000a   */\u000a  ;\u000a\u000a  ID3.getID3Data = function getID3Data(data, offset) {\u000a    var front = offset;\u000a    var length = 0;\u000a\u000a    while (ID3.isHeader(data, offset)) {\u000a      // ID3 header is 10 bytes\u000a      length += 10;\u000a\u000a      var size = ID3._readSize(data, offset + 6);\u000a\u000a      length += size;\u000a\u000a      if (ID3.isFooter(data, offset + 10)) {\u000a        // ID3 footer is 10 bytes\u000a        length += 10;\u000a      }\u000a\u000a      offset += length;\u000a    }\u000a\u000a    if (length > 0) {\u000a      return data.subarray(front, front + length);\u000a    }\u000a\u000a    return undefined;\u000a  };\u000a\u000a  ID3._readSize = function _readSize(data, offset) {\u000a    var size = 0;\u000a    size = (data[offset] & 0x7f) << 21;\u000a    size |= (data[offset + 1] & 0x7f) << 14;\u000a    size |= (data[offset + 2] & 0x7f) << 7;\u000a    size |= data[offset + 3] & 0x7f;\u000a    return size;\u000a  }\u000a  /**\u000a   * Searches for the Elementary Stream timestamp found in the ID3 data chunk\u000a   * @param {Uint8Array} data - Block of data containing one or more ID3 tags\u000a   * @return {number} - The timestamp\u000a   */\u000a  ;\u000a\u000a  ID3.getTimeStamp = function getTimeStamp(data) {\u000a    var frames = ID3.getID3Frames(data);\u000a\u000a    for (var i = 0; i < frames.length; i++) {\u000a      var frame = frames[i];\u000a\u000a      if (ID3.isTimeStampFrame(frame)) {\u000a        return ID3._readTimeStamp(frame);\u000a      }\u000a    }\u000a\u000a    return undefined;\u000a  }\u000a  /**\u000a   * Returns true if the ID3 frame is an Elementary Stream timestamp frame\u000a   * @param {ID3 frame} frame\u000a   */\u000a  ;\u000a\u000a  ID3.isTimeStampFrame = function isTimeStampFrame(frame) {\u000a    return frame && frame.key === 'PRIV' && frame.info === 'com.apple.streaming.transportStreamTimestamp';\u000a  };\u000a\u000a  ID3._getFrameData = function _getFrameData(data) {\u000a    /*\u000a    Frame ID       $xx xx xx xx (four characters)\u000a    Size           $xx xx xx xx\u000a    Flags          $xx xx\u000a    */\u000a    var type = String.fromCharCode(data[0], data[1], data[2], data[3]);\u000a\u000a    var size = ID3._readSize(data, 4); // skip frame id, size, and flags\u000a\u000a\u000a    var offset = 10;\u000a    return {\u000a      type: type,\u000a      size: size,\u000a      data: data.subarray(offset, offset + size)\u000a    };\u000a  }\u000a  /**\u000a   * Returns an array of ID3 frames found in all the ID3 tags in the id3Data\u000a   * @param {Uint8Array} id3Data - The ID3 data containing one or more ID3 tags\u000a   * @return {ID3 frame[]} - Array of ID3 frame objects\u000a   */\u000a  ;\u000a\u000a  ID3.getID3Frames = function getID3Frames(id3Data) {\u000a    var offset = 0;\u000a    var frames = [];\u000a\u000a    while (ID3.isHeader(id3Data, offset)) {\u000a      var size = ID3._readSize(id3Data, offset + 6); // skip past ID3 header\u000a\u000a\u000a      offset += 10;\u000a      var end = offset + size; // loop through frames in the ID3 tag\u000a\u000a      while (offset + 8 < end) {\u000a        var frameData = ID3._getFrameData(id3Data.subarray(offset));\u000a\u000a        var frame = ID3._decodeFrame(frameData);\u000a\u000a        if (frame) {\u000a          frames.push(frame);\u000a        } // skip frame header and frame data\u000a\u000a\u000a        offset += frameData.size + 10;\u000a      }\u000a\u000a      if (ID3.isFooter(id3Data, offset)) {\u000a        offset += 10;\u000a      }\u000a    }\u000a\u000a    return frames;\u000a  };\u000a\u000a  ID3._decodeFrame = function _decodeFrame(frame) {\u000a    if (frame.type === 'PRIV') {\u000a      return ID3._decodePrivFrame(frame);\u000a    } else if (frame.type[0] === 'T') {\u000a      return ID3._decodeTextFrame(frame);\u000a    } else if (frame.type[0] === 'W') {\u000a      return ID3._decodeURLFrame(frame);\u000a    }\u000a\u000a    return undefined;\u000a  };\u000a\u000a  ID3._readTimeStamp = function _readTimeStamp(timeStampFrame) {\u000a    if (timeStampFrame.data.byteLength === 8) {\u000a      var data = new Uint8Array(timeStampFrame.data); // timestamp is 33 bit expressed as a big-endian eight-octet number,\u000a      // with the upper 31 bits set to zero.\u000a\u000a      var pts33Bit = data[3] & 0x1;\u000a      var timestamp = (data[4] << 23) + (data[5] << 15) + (data[6] << 7) + data[7];\u000a      timestamp /= 45;\u000a\u000a      if (pts33Bit) {\u000a        timestamp += 47721858.84;\u000a      } // 2^32 / 90\u000a\u000a\u000a      return Math.round(timestamp);\u000a    }\u000a\u000a    return undefined;\u000a  };\u000a\u000a  ID3._decodePrivFrame = function _decodePrivFrame(frame) {\u000a    /*\u000a    Format: <text string>\u005c0<binary data>\u000a    */\u000a    if (frame.size < 2) {\u000a      return undefined;\u000a    }\u000a\u000a    var owner = ID3._utf8ArrayToStr(frame.data, true);\u000a\u000a    var privateData = new Uint8Array(frame.data.subarray(owner.length + 1));\u000a    return {\u000a      key: frame.type,\u000a      info: owner,\u000a      data: privateData.buffer\u000a    };\u000a  };\u000a\u000a  ID3._decodeTextFrame = function _decodeTextFrame(frame) {\u000a    if (frame.size < 2) {\u000a      return undefined;\u000a    }\u000a\u000a    if (frame.type === 'TXXX') {\u000a      /*\u000a      Format:\u000a      [0]   = {Text Encoding}\u000a      [1-?] = {Description}\u005c0{Value}\u000a      */\u000a      var index = 1;\u000a\u000a      var description = ID3._utf8ArrayToStr(frame.data.subarray(index), true);\u000a\u000a      index += description.length + 1;\u000a\u000a      var value = ID3._utf8ArrayToStr(frame.data.subarray(index));\u000a\u000a      return {\u000a        key: frame.type,\u000a        info: description,\u000a        data: value\u000a      };\u000a    } else {\u000a      /*\u000a      Format:\u000a      [0]   = {Text Encoding}\u000a      [1-?] = {Value}\u000a      */\u000a      var text = ID3._utf8ArrayToStr(frame.data.subarray(1));\u000a\u000a      return {\u000a        key: frame.type,\u000a        data: text\u000a      };\u000a    }\u000a  };\u000a\u000a  ID3._decodeURLFrame = function _decodeURLFrame(frame) {\u000a    if (frame.type === 'WXXX') {\u000a      /*\u000a      Format:\u000a      [0]   = {Text Encoding}\u000a      [1-?] = {Description}\u005c0{URL}\u000a      */\u000a      if (frame.size < 2) {\u000a        return undefined;\u000a      }\u000a\u000a      var index = 1;\u000a\u000a      var description = ID3._utf8ArrayToStr(frame.data.subarray(index));\u000a\u000a      index += description.length + 1;\u000a\u000a      var value = ID3._utf8ArrayToStr(frame.data.subarray(index));\u000a\u000a      return {\u000a        key: frame.type,\u000a        info: description,\u000a        data: value\u000a      };\u000a    } else {\u000a      /*\u000a      Format:\u000a      [0-?] = {URL}\u000a      */\u000a      var url = ID3._utf8ArrayToStr(frame.data);\u000a\u000a      return {\u000a        key: frame.type,\u000a        data: url\u000a      };\u000a    }\u000a  } // http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197\u000a  // http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt\u000a\u000a  /* utf.js - UTF-8 <=> UTF-16 convertion\u000a   *\u000a   * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\u000a   * Version: 1.0\u000a   * LastModified: Dec 25 1999\u000a   * This library is free.  You can redistribute it and/or modify it.\u000a   */\u000a  ;\u000a\u000a  ID3._utf8ArrayToStr = function _utf8ArrayToStr(array, exitOnNull) {\u000a    if (exitOnNull === void 0) {\u000a      exitOnNull = false;\u000a    }\u000a\u000a    var decoder = getTextDecoder();\u000a\u000a    if (decoder) {\u000a      var decoded = decoder.decode(array);\u000a\u000a      if (exitOnNull) {\u000a        // grab up to the first null\u000a        var idx = decoded.indexOf('\u005c0');\u000a        return idx !== -1 ? decoded.substring(0, idx) : decoded;\u000a      } // remove any null characters\u000a\u000a\u000a      return decoded.replace(/\u005c0/g, '');\u000a    }\u000a\u000a    var len = array.length;\u000a    var c;\u000a    var char2;\u000a    var char3;\u000a    var out = '';\u000a    var i = 0;\u000a\u000a    while (i < len) {\u000a      c = array[i++];\u000a\u000a      if (c === 0x00 && exitOnNull) {\u000a        return out;\u000a      } else if (c === 0x00 || c === 0x03) {\u000a        // If the character is 3 (END_OF_TEXT) or 0 (NULL) then skip it\u000a        continue;\u000a      }\u000a\u000a      switch (c >> 4) {\u000a        case 0:\u000a        case 1:\u000a        case 2:\u000a        case 3:\u000a        case 4:\u000a        case 5:\u000a        case 6:\u000a        case 7:\u000a          // 0xxxxxxx\u000a          out += String.fromCharCode(c);\u000a          break;\u000a\u000a        case 12:\u000a        case 13:\u000a          // 110x xxxx   10xx xxxx\u000a          char2 = array[i++];\u000a          out += String.fromCharCode((c & 0x1F) << 6 | char2 & 0x3F);\u000a          break;\u000a\u000a        case 14:\u000a          // 1110 xxxx  10xx xxxx  10xx xxxx\u000a          char2 = array[i++];\u000a          char3 = array[i++];\u000a          out += String.fromCharCode((c & 0x0F) << 12 | (char2 & 0x3F) << 6 | (char3 & 0x3F) << 0);\u000a          break;\u000a\u000a        default:\u000a      }\u000a    }\u000a\u000a    return out;\u000a  };\u000a\u000a  return ID3;\u000a}();\u000a\u000avar decoder;\u000a\u000afunction getTextDecoder() {\u000a  var global = Object(_utils_get_self_scope__WEBPACK_IMPORTED_MODULE_0__["getSelfScope"])(); // safeguard for code that might run both on worker and main thread\u000a\u000a  if (!decoder && typeof global.TextDecoder !== 'undefined') {\u000a    decoder = new global.TextDecoder('utf-8');\u000a  }\u000a\u000a  return decoder;\u000a}\u000a\u000avar utf8ArrayToStr = ID3._utf8ArrayToStr;\u000a/* harmony default export */ __webpack_exports__["default"] = (ID3);\u000a\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/demux/mp4demuxer.js":\u000a/*!*********************************!*\u005c\u000a  !*** ./src/demux/mp4demuxer.js ***!\u000a  \u005c*********************************/\u000a/*! exports provided: default */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a__webpack_require__.r(__webpack_exports__);\u000a/* harmony import */ var _utils_logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/logger */ "./src/utils/logger.js");\u000a/* harmony import */ var _events__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../events */ "./src/events.js");\u000a/**\u000a * MP4 demuxer\u000a */\u000a\u000a\u000avar UINT32_MAX = Math.pow(2, 32) - 1;\u000a\u000avar MP4Demuxer = /*#__PURE__*/function () {\u000a  function MP4Demuxer(observer, remuxer) {\u000a    this.observer = observer;\u000a    this.remuxer = remuxer;\u000a  }\u000a\u000a  var _proto = MP4Demuxer.prototype;\u000a\u000a  _proto.resetTimeStamp = function resetTimeStamp(initPTS) {\u000a    this.initPTS = initPTS;\u000a  };\u000a\u000a  _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, duration) {\u000a    // jshint unused:false\u000a    if (initSegment && initSegment.byteLength) {\u000a      var initData = this.initData = MP4Demuxer.parseInitSegment(initSegment); // default audio codec if nothing specified\u000a      // TODO : extract that from initsegment\u000a\u000a      if (audioCodec == null) {\u000a        audioCodec = 'mp4a.40.5';\u000a      }\u000a\u000a      if (videoCodec == null) {\u000a        videoCodec = 'avc1.42e01e';\u000a      }\u000a\u000a      var tracks = {};\u000a\u000a      if (initData.audio && initData.video) {\u000a        tracks.audiovideo = {\u000a          container: 'video/mp4',\u000a          codec: audioCodec + ',' + videoCodec,\u000a          initSegment: duration ? initSegment : null\u000a        };\u000a      } else {\u000a        if (initData.audio) {\u000a          tracks.audio = {\u000a            container: 'audio/mp4',\u000a            codec: audioCodec,\u000a            initSegment: duration ? initSegment : null\u000a          };\u000a        }\u000a\u000a        if (initData.video) {\u000a          tracks.video = {\u000a            container: 'video/mp4',\u000a            codec: videoCodec,\u000a            initSegment: duration ? initSegment : null\u000a          };\u000a        }\u000a      }\u000a\u000a      this.observer.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["default"].FRAG_PARSING_INIT_SEGMENT, {\u000a        tracks: tracks\u000a      });\u000a    } else {\u000a      if (audioCodec) {\u000a        this.audioCodec = audioCodec;\u000a      }\u000a\u000a      if (videoCodec) {\u000a        this.videoCodec = videoCodec;\u000a      }\u000a    }\u000a  };\u000a\u000a  MP4Demuxer.probe = function probe(data) {\u000a    // ensure we find a moof box in the first 16 kB\u000a    return MP4Demuxer.findBox({\u000a      data: data,\u000a      start: 0,\u000a      end: Math.min(data.length, 16384)\u000a    }, ['moof']).length > 0;\u000a  };\u000a\u000a  MP4Demuxer.bin2str = function bin2str(buffer) {\u000a    return String.fromCharCode.apply(null, buffer);\u000a  };\u000a\u000a  MP4Demuxer.readUint16 = function readUint16(buffer, offset) {\u000a    if (buffer.data) {\u000a      offset += buffer.start;\u000a      buffer = buffer.data;\u000a    }\u000a\u000a    var val = buffer[offset] << 8 | buffer[offset + 1];\u000a    return val < 0 ? 65536 + val : val;\u000a  };\u000a\u000a  MP4Demuxer.readUint32 = function readUint32(buffer, offset) {\u000a    if (buffer.data) {\u000a      offset += buffer.start;\u000a      buffer = buffer.data;\u000a    }\u000a\u000a    var val = buffer[offset] << 24 | buffer[offset + 1] << 16 | buffer[offset + 2] << 8 | buffer[offset + 3];\u000a    return val < 0 ? 4294967296 + val : val;\u000a  };\u000a\u000a  MP4Demuxer.writeUint32 = function writeUint32(buffer, offset, value) {\u000a    if (buffer.data) {\u000a      offset += buffer.start;\u000a      buffer = buffer.data;\u000a    }\u000a\u000a    buffer[offset] = value >> 24;\u000a    buffer[offset + 1] = value >> 16 & 0xff;\u000a    buffer[offset + 2] = value >> 8 & 0xff;\u000a    buffer[offset + 3] = value & 0xff;\u000a  } // Find the data for a box specified by its path\u000a  ;\u000a\u000a  MP4Demuxer.findBox = function findBox(data, path) {\u000a    var results = [],\u000a        i,\u000a        size,\u000a        type,\u000a        end,\u000a        subresults,\u000a        start,\u000a        endbox;\u000a\u000a    if (data.data) {\u000a      start = data.start;\u000a      end = data.end;\u000a      data = data.data;\u000a    } else {\u000a      start = 0;\u000a      end = data.byteLength;\u000a    }\u000a\u000a    if (!path.length) {\u000a      // short-circuit the search for empty paths\u000a      return null;\u000a    }\u000a\u000a    for (i = start; i < end;) {\u000a      size = MP4Demuxer.readUint32(data, i);\u000a      type = MP4Demuxer.bin2str(data.subarray(i + 4, i + 8));\u000a      endbox = size > 1 ? i + size : end;\u000a\u000a      if (type === path[0]) {\u000a        if (path.length === 1) {\u000a          // this is the end of the path and we've found the box we were\u000a          // looking for\u000a          results.push({\u000a            data: data,\u000a            start: i + 8,\u000a            end: endbox\u000a          });\u000a        } else {\u000a          // recursively search for the next box along the path\u000a          subresults = MP4Demuxer.findBox({\u000a            data: data,\u000a            start: i + 8,\u000a            end: endbox\u000a          }, path.slice(1));\u000a\u000a          if (subresults.length) {\u000a            results = results.concat(subresults);\u000a          }\u000a        }\u000a      }\u000a\u000a      i = endbox;\u000a    } // we've finished searching all of data\u000a\u000a\u000a    return results;\u000a  };\u000a\u000a  MP4Demuxer.parseSegmentIndex = function parseSegmentIndex(initSegment) {\u000a    var moov = MP4Demuxer.findBox(initSegment, ['moov'])[0];\u000a    var moovEndOffset = moov ? moov.end : null; // we need this in case we need to chop of garbage of the end of current data\u000a\u000a    var index = 0;\u000a    var sidx = MP4Demuxer.findBox(initSegment, ['sidx']);\u000a    var references;\u000a\u000a    if (!sidx || !sidx[0]) {\u000a      return null;\u000a    }\u000a\u000a    references = [];\u000a    sidx = sidx[0];\u000a    var version = sidx.data[0]; // set initial offset, we skip the reference ID (not needed)\u000a\u000a    index = version === 0 ? 8 : 16;\u000a    var timescale = MP4Demuxer.readUint32(sidx, index);\u000a    index += 4; // TODO: parse earliestPresentationTime and firstOffset\u000a    // usually zero in our case\u000a\u000a    var earliestPresentationTime = 0;\u000a    var firstOffset = 0;\u000a\u000a    if (version === 0) {\u000a      index += 8;\u000a    } else {\u000a      index += 16;\u000a    } // skip reserved\u000a\u000a\u000a    index += 2;\u000a    var startByte = sidx.end + firstOffset;\u000a    var referencesCount = MP4Demuxer.readUint16(sidx, index);\u000a    index += 2;\u000a\u000a    for (var i = 0; i < referencesCount; i++) {\u000a      var referenceIndex = index;\u000a      var referenceInfo = MP4Demuxer.readUint32(sidx, referenceIndex);\u000a      referenceIndex += 4;\u000a      var referenceSize = referenceInfo & 0x7FFFFFFF;\u000a      var referenceType = (referenceInfo & 0x80000000) >>> 31;\u000a\u000a      if (referenceType === 1) {\u000a        console.warn('SIDX has hierarchical references (not supported)');\u000a        return;\u000a      }\u000a\u000a      var subsegmentDuration = MP4Demuxer.readUint32(sidx, referenceIndex);\u000a      referenceIndex += 4;\u000a      references.push({\u000a        referenceSize: referenceSize,\u000a        subsegmentDuration: subsegmentDuration,\u000a        // unscaled\u000a        info: {\u000a          duration: subsegmentDuration / timescale,\u000a          start: startByte,\u000a          end: startByte + referenceSize - 1\u000a        }\u000a      });\u000a      startByte += referenceSize; // Skipping 1 bit for |startsWithSap|, 3 bits for |sapType|, and 28 bits\u000a      // for |sapDelta|.\u000a\u000a      referenceIndex += 4; // skip to next ref\u000a\u000a      index = referenceIndex;\u000a    }\u000a\u000a    return {\u000a      earliestPresentationTime: earliestPresentationTime,\u000a      timescale: timescale,\u000a      version: version,\u000a      referencesCount: referencesCount,\u000a      references: references,\u000a      moovEndOffset: moovEndOffset\u000a    };\u000a  }\u000a  /**\u000a   * Parses an MP4 initialization segment and extracts stream type and\u000a   * timescale values for any declared tracks. Timescale values indicate the\u000a   * number of clock ticks per second to assume for time-based values\u000a   * elsewhere in the MP4.\u000a   *\u000a   * To determine the start time of an MP4, you need two pieces of\u000a   * information: the timescale unit and the earliest base media decode\u000a   * time. Multiple timescales can be specified within an MP4 but the\u000a   * base media decode time is always expressed in the timescale from\u000a   * the media header box for the track:\u000a   * ```\u000a   * moov > trak > mdia > mdhd.timescale\u000a   * moov > trak > mdia > hdlr\u000a   * ```\u000a   * @param init {Uint8Array} the bytes of the init segment\u000a   * @return {object} a hash of track type to timescale values or null if\u000a   * the init segment is malformed.\u000a   */\u000a  ;\u000a\u000a  MP4Demuxer.parseInitSegment = function parseInitSegment(initSegment) {\u000a    var result = [];\u000a    var traks = MP4Demuxer.findBox(initSegment, ['moov', 'trak']);\u000a    traks.forEach(function (trak) {\u000a      var tkhd = MP4Demuxer.findBox(trak, ['tkhd'])[0];\u000a\u000a      if (tkhd) {\u000a        var version = tkhd.data[tkhd.start];\u000a        var index = version === 0 ? 12 : 20;\u000a        var trackId = MP4Demuxer.readUint32(tkhd, index);\u000a        var mdhd = MP4Demuxer.findBox(trak, ['mdia', 'mdhd'])[0];\u000a\u000a        if (mdhd) {\u000a          version = mdhd.data[mdhd.start];\u000a          index = version === 0 ? 12 : 20;\u000a          var timescale = MP4Demuxer.readUint32(mdhd, index);\u000a          var hdlr = MP4Demuxer.findBox(trak, ['mdia', 'hdlr'])[0];\u000a\u000a          if (hdlr) {\u000a            var hdlrType = MP4Demuxer.bin2str(hdlr.data.subarray(hdlr.start + 8, hdlr.start + 12));\u000a            var type = {\u000a              'soun': 'audio',\u000a              'vide': 'video'\u000a            }[hdlrType];\u000a\u000a            if (type) {\u000a              // extract codec info. TODO : parse codec details to be able to build MIME type\u000a              var codecBox = MP4Demuxer.findBox(trak, ['mdia', 'minf', 'stbl', 'stsd']);\u000a\u000a              if (codecBox.length) {\u000a                codecBox = codecBox[0];\u000a                var codecType = MP4Demuxer.bin2str(codecBox.data.subarray(codecBox.start + 12, codecBox.start + 16));\u000a                _utils_logger__WEBPACK_IMPORTED_MODULE_0__["logger"].log("MP4Demuxer:" + type + ":" + codecType + " found");\u000a              }\u000a\u000a              result[trackId] = {\u000a                timescale: timescale,\u000a                type: type\u000a              };\u000a              result[type] = {\u000a                timescale: timescale,\u000a                id: trackId\u000a              };\u000a            }\u000a          }\u000a        }\u000a      }\u000a    });\u000a    return result;\u000a  }\u000a  /**\u000a  * Determine the base media decode start time, in seconds, for an MP4\u000a  * fragment. If multiple fragments are specified, the earliest time is\u000a  * returned.\u000a  *\u000a  * The base media decode time can be parsed from track fragment\u000a  * metadata:\u000a  * ```\u000a  * moof > traf > tfdt.baseMediaDecodeTime\u000a  * ```\u000a  * It requires the timescale value from the mdhd to interpret.\u000a  *\u000a  * @param timescale {object} a hash of track ids to timescale values.\u000a  * @return {number} the earliest base media decode start time for the\u000a  * fragment, in seconds\u000a  */\u000a  ;\u000a\u000a  MP4Demuxer.getStartDTS = function getStartDTS(initData, fragment) {\u000a    var trafs, baseTimes, result; // we need info from two childrend of each track fragment box\u000a\u000a    trafs = MP4Demuxer.findBox(fragment, ['moof', 'traf']); // determine the start times for each track\u000a\u000a    baseTimes = [].concat.apply([], trafs.map(function (traf) {\u000a      return MP4Demuxer.findBox(traf, ['tfhd']).map(function (tfhd) {\u000a        var id, scale, baseTime; // get the track id from the tfhd\u000a\u000a        id = MP4Demuxer.readUint32(tfhd, 4); // assume a 90kHz clock if no timescale was specified\u000a\u000a        scale = initData[id].timescale || 90e3; // get the base media decode time from the tfdt\u000a\u000a        baseTime = MP4Demuxer.findBox(traf, ['tfdt']).map(function (tfdt) {\u000a          var version, result;\u000a          version = tfdt.data[tfdt.start];\u000a          result = MP4Demuxer.readUint32(tfdt, 4);\u000a\u000a          if (version === 1) {\u000a            result *= Math.pow(2, 32);\u000a            result += MP4Demuxer.readUint32(tfdt, 8);\u000a          }\u000a\u000a          return result;\u000a        })[0]; // convert base time to seconds\u000a\u000a        return baseTime / scale;\u000a      });\u000a    })); // return the minimum\u000a\u000a    result = Math.min.apply(null, baseTimes);\u000a    return isFinite(result) ? result : 0;\u000a  };\u000a\u000a  MP4Demuxer.offsetStartDTS = function offsetStartDTS(initData, fragment, timeOffset) {\u000a    MP4Demuxer.findBox(fragment, ['moof', 'traf']).map(function (traf) {\u000a      return MP4Demuxer.findBox(traf, ['tfhd']).map(function (tfhd) {\u000a        // get the track id from the tfhd\u000a        var id = MP4Demuxer.readUint32(tfhd, 4); // assume a 90kHz clock if no timescale was specified\u000a\u000a        var timescale = initData[id].timescale || 90e3; // get the base media decode time from the tfdt\u000a\u000a        MP4Demuxer.findBox(traf, ['tfdt']).map(function (tfdt) {\u000a          var version = tfdt.data[tfdt.start];\u000a          var baseMediaDecodeTime = MP4Demuxer.readUint32(tfdt, 4);\u000a\u000a          if (version === 0) {\u000a            MP4Demuxer.writeUint32(tfdt, 4, baseMediaDecodeTime - timeOffset * timescale);\u000a          } else {\u000a            baseMediaDecodeTime *= Math.pow(2, 32);\u000a            baseMediaDecodeTime += MP4Demuxer.readUint32(tfdt, 8);\u000a            baseMediaDecodeTime -= timeOffset * timescale;\u000a            baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);\u000a            var upper = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));\u000a            var lower = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));\u000a            MP4Demuxer.writeUint32(tfdt, 4, upper);\u000a            MP4Demuxer.writeUint32(tfdt, 8, lower);\u000a          }\u000a        });\u000a      });\u000a    });\u000a  } // feed incoming data to the front of the parsing pipeline\u000a  ;\u000a\u000a  _proto.append = function append(data, timeOffset, contiguous, accurateTimeOffset) {\u000a    var initData = this.initData;\u000a\u000a    if (!initData) {\u000a      this.resetInitSegment(data, this.audioCodec, this.videoCodec, false);\u000a      initData = this.initData;\u000a    }\u000a\u000a    var startDTS,\u000a        initPTS = this.initPTS;\u000a\u000a    if (initPTS === undefined) {\u000a      var _startDTS = MP4Demuxer.getStartDTS(initData, data);\u000a\u000a      this.initPTS = initPTS = _startDTS - timeOffset;\u000a      this.observer.trigger(_events__WEBPACK_IMPORTED_MODULE_1__["default"].INIT_PTS_FOUND, {\u000a        initPTS: initPTS\u000a      });\u000a    }\u000a\u000a    MP4Demuxer.offsetStartDTS(initData, data, initPTS);\u000a    startDTS = MP4Demuxer.getStartDTS(initData, data);\u000a    this.remuxer.remux(initData.audio, initData.video, null, null, startDTS, contiguous, accurateTimeOffset, data);\u000a  };\u000a\u000a  _proto.destroy = function destroy() {};\u000a\u000a  return MP4Demuxer;\u000a}();\u000a\u000a/* harmony default export */ __webpack_exports__["default"] = (MP4Demuxer);\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/errors.ts":\u000a/*!***********************!*\u005c\u000a  !*** ./src/errors.ts ***!\u000a  \u005c***********************/\u000a/*! exports provided: ErrorTypes, ErrorDetails */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a__webpack_require__.r(__webpack_exports__);\u000a/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ErrorTypes", function() { return ErrorTypes; });\u000a/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ErrorDetails", function() { return ErrorDetails; });\u000avar ErrorTypes;\u000a/**\u000a * @enum {ErrorDetails}\u000a * @typedef {string} ErrorDetail\u000a */\u000a\u000a(function (ErrorTypes) {\u000a  ErrorTypes["NETWORK_ERROR"] = "networkError";\u000a  ErrorTypes["MEDIA_ERROR"] = "mediaError";\u000a  ErrorTypes["KEY_SYSTEM_ERROR"] = "keySystemError";\u000a  ErrorTypes["MUX_ERROR"] = "muxError";\u000a  ErrorTypes["OTHER_ERROR"] = "otherError";\u000a})(ErrorTypes || (ErrorTypes = {}));\u000a\u000avar ErrorDetails;\u000a\u000a(function (ErrorDetails) {\u000a  ErrorDetails["KEY_SYSTEM_NO_KEYS"] = "keySystemNoKeys";\u000a  ErrorDetails["KEY_SYSTEM_NO_ACCESS"] = "keySystemNoAccess";\u000a  ErrorDetails["KEY_SYSTEM_NO_SESSION"] = "keySystemNoSession";\u000a  ErrorDetails["KEY_SYSTEM_LICENSE_REQUEST_FAILED"] = "keySystemLicenseRequestFailed";\u000a  ErrorDetails["KEY_SYSTEM_NO_INIT_DATA"] = "keySystemNoInitData";\u000a  ErrorDetails["MANIFEST_LOAD_ERROR"] = "manifestLoadError";\u000a  ErrorDetails["MANIFEST_LOAD_TIMEOUT"] = "manifestLoadTimeOut";\u000a  ErrorDetails["MANIFEST_PARSING_ERROR"] = "manifestParsingError";\u000a  ErrorDetails["MANIFEST_INCOMPATIBLE_CODECS_ERROR"] = "manifestIncompatibleCodecsError";\u000a  ErrorDetails["LEVEL_EMPTY_ERROR"] = "levelEmptyError";\u000a  ErrorDetails["LEVEL_LOAD_ERROR"] = "levelLoadError";\u000a  ErrorDetails["LEVEL_LOAD_TIMEOUT"] = "levelLoadTimeOut";\u000a  ErrorDetails["LEVEL_SWITCH_ERROR"] = "levelSwitchError";\u000a  ErrorDetails["AUDIO_TRACK_LOAD_ERROR"] = "audioTrackLoadError";\u000a  ErrorDetails["AUDIO_TRACK_LOAD_TIMEOUT"] = "audioTrackLoadTimeOut";\u000a  ErrorDetails["FRAG_LOAD_ERROR"] = "fragLoadError";\u000a  ErrorDetails["FRAG_LOAD_TIMEOUT"] = "fragLoadTimeOut";\u000a  ErrorDetails["FRAG_DECRYPT_ERROR"] = "fragDecryptError";\u000a  ErrorDetails["FRAG_PARSING_ERROR"] = "fragParsingError";\u000a  ErrorDetails["REMUX_ALLOC_ERROR"] = "remuxAllocError";\u000a  ErrorDetails["KEY_LOAD_ERROR"] = "keyLoadError";\u000a  ErrorDetails["KEY_LOAD_TIMEOUT"] = "keyLoadTimeOut";\u000a  ErrorDetails["BUFFER_ADD_CODEC_ERROR"] = "bufferAddCodecError";\u000a  ErrorDetails["BUFFER_APPEND_ERROR"] = "bufferAppendError";\u000a  ErrorDetails["BUFFER_APPENDING_ERROR"] = "bufferAppendingError";\u000a  ErrorDetails["BUFFER_STALLED_ERROR"] = "bufferStalledError";\u000a  ErrorDetails["BUFFER_FULL_ERROR"] = "bufferFullError";\u000a  ErrorDetails["BUFFER_SEEK_OVER_HOLE"] = "bufferSeekOverHole";\u000a  ErrorDetails["BUFFER_NUDGE_ON_STALL"] = "bufferNudgeOnStall";\u000a  ErrorDetails["INTERNAL_EXCEPTION"] = "internalException";\u000a})(ErrorDetails || (ErrorDetails = {}));\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/events.js":\u000a/*!***********************!*\u005c\u000a  !*** ./src/events.js ***!\u000a  \u005c***********************/\u000a/*! exports provided: default */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a__webpack_require__.r(__webpack_exports__);\u000a/**\u000a * @readonly\u000a * @enum {string}\u000a */\u000avar HlsEvents = {\u000a  // fired before MediaSource is attaching to media element - data: { media }\u000a  MEDIA_ATTACHING: 'hlsMediaAttaching',\u000a  // fired when MediaSource has been succesfully attached to media element - data: { }\u000a  MEDIA_ATTACHED: 'hlsMediaAttached',\u000a  // fired before detaching MediaSource from media element - data: { }\u000a  MEDIA_DETACHING: 'hlsMediaDetaching',\u000a  // fired when MediaSource has been detached from media element - data: { }\u000a  MEDIA_DETACHED: 'hlsMediaDetached',\u000a  // fired when we buffer is going to be reset - data: { }\u000a  BUFFER_RESET: 'hlsBufferReset',\u000a  // fired when we know about the codecs that we need buffers for to push into - data: {tracks : { container, codec, levelCodec, initSegment, metadata }}\u000a  BUFFER_CODECS: 'hlsBufferCodecs',\u000a  // fired when sourcebuffers have been created - data: { tracks : tracks }\u000a  BUFFER_CREATED: 'hlsBufferCreated',\u000a  // fired when we append a segment to the buffer - data: { segment: segment object }\u000a  BUFFER_APPENDING: 'hlsBufferAppending',\u000a  // fired when we are done with appending a media segment to the buffer - data : { parent : segment parent that triggered BUFFER_APPENDING, pending : nb of segments waiting for appending for this segment parent}\u000a  BUFFER_APPENDED: 'hlsBufferAppended',\u000a  // fired when the stream is finished and we want to notify the media buffer that there will be no more data - data: { }\u000a  BUFFER_EOS: 'hlsBufferEos',\u000a  // fired when the media buffer should be flushed - data { startOffset, endOffset }\u000a  BUFFER_FLUSHING: 'hlsBufferFlushing',\u000a  // fired when the media buffer has been flushed - data: { }\u000a  BUFFER_FLUSHED: 'hlsBufferFlushed',\u000a  // fired to signal that a manifest loading starts - data: { url : manifestURL}\u000a  MANIFEST_LOADING: 'hlsManifestLoading',\u000a  // fired after manifest has been loaded - data: { levels : [available quality levels], audioTracks : [ available audio tracks], url : manifestURL, stats : { trequest, tfirst, tload, mtime}}\u000a  MANIFEST_LOADED: 'hlsManifestLoaded',\u000a  // fired after manifest has been parsed - data: { levels : [available quality levels], firstLevel : index of first quality level appearing in Manifest}\u000a  MANIFEST_PARSED: 'hlsManifestParsed',\u000a  // fired when a level switch is requested - data: { level : id of new level }\u000a  LEVEL_SWITCHING: 'hlsLevelSwitching',\u000a  // fired when a level switch is effective - data: { level : id of new level }\u000a  LEVEL_SWITCHED: 'hlsLevelSwitched',\u000a  // fired when a level playlist loading starts - data: { url : level URL, level : id of level being loaded}\u000a  LEVEL_LOADING: 'hlsLevelLoading',\u000a  // fired when a level playlist loading finishes - data: { details : levelDetails object, level : id of loaded level, stats : { trequest, tfirst, tload, mtime} }\u000a  LEVEL_LOADED: 'hlsLevelLoaded',\u000a  // fired when a level's details have been updated based on previous details, after it has been loaded - data: { details : levelDetails object, level : id of updated level }\u000a  LEVEL_UPDATED: 'hlsLevelUpdated',\u000a  // fired when a level's PTS information has been updated after parsing a fragment - data: { details : levelDetails object, level : id of updated level, drift: PTS drift observed when parsing last fragment }\u000a  LEVEL_PTS_UPDATED: 'hlsLevelPtsUpdated',\u000a  // fired to notify that levels have changed after removing a level - data: { levels : [available quality levels] }\u000a  LEVELS_UPDATED: 'hlsLevelsUpdated',\u000a  // fired to notify that audio track lists has been updated - data: { audioTracks : audioTracks }\u000a  AUDIO_TRACKS_UPDATED: 'hlsAudioTracksUpdated',\u000a  // fired when an audio track switching is requested - data: { id : audio track id }\u000a  AUDIO_TRACK_SWITCHING: 'hlsAudioTrackSwitching',\u000a  // fired when an audio track switch actually occurs - data: { id : audio track id }\u000a  AUDIO_TRACK_SWITCHED: 'hlsAudioTrackSwitched',\u000a  // fired when an audio track loading starts - data: { url : audio track URL, id : audio track id }\u000a  AUDIO_TRACK_LOADING: 'hlsAudioTrackLoading',\u000a  // fired when an audio track loading finishes - data: { details : levelDetails object, id : audio track id, stats : { trequest, tfirst, tload, mtime } }\u000a  AUDIO_TRACK_LOADED: 'hlsAudioTrackLoaded',\u000a  // fired to notify that subtitle track lists has been updated - data: { subtitleTracks : subtitleTracks }\u000a  SUBTITLE_TRACKS_UPDATED: 'hlsSubtitleTracksUpdated',\u000a  // fired when an subtitle track switch occurs - data: { id : subtitle track id }\u000a  SUBTITLE_TRACK_SWITCH: 'hlsSubtitleTrackSwitch',\u000a  // fired when a subtitle track loading starts - data: { url : subtitle track URL, id : subtitle track id }\u000a  SUBTITLE_TRACK_LOADING: 'hlsSubtitleTrackLoading',\u000a  // fired when a subtitle track loading finishes - data: { details : levelDetails object, id : subtitle track id, stats : { trequest, tfirst, tload, mtime } }\u000a  SUBTITLE_TRACK_LOADED: 'hlsSubtitleTrackLoaded',\u000a  // fired when a subtitle fragment has been processed - data: { success : boolean, frag : the processed frag }\u000a  SUBTITLE_FRAG_PROCESSED: 'hlsSubtitleFragProcessed',\u000a  // fired when a set of VTTCues to be managed externally has been parsed - data: { type: string, track: string, cues: [ VTTCue ] }\u000a  CUES_PARSED: 'hlsCuesParsed',\u000a  // fired when a text track to be managed externally is found - data: { tracks: [ { label: string, kind: string, default: boolean } ] }\u000a  NON_NATIVE_TEXT_TRACKS_FOUND: 'hlsNonNativeTextTracksFound',\u000a  // fired when the first timestamp is found - data: { id : demuxer id, initPTS: initPTS, frag : fragment object }\u000a  INIT_PTS_FOUND: 'hlsInitPtsFound',\u000a  // fired when a fragment loading starts - data: { frag : fragment object }\u000a  FRAG_LOADING: 'hlsFragLoading',\u000a  // fired when a fragment loading is progressing - data: { frag : fragment object, { trequest, tfirst, loaded } }\u000a  FRAG_LOAD_PROGRESS: 'hlsFragLoadProgress',\u000a  // Identifier for fragment load aborting for emergency switch down - data: { frag : fragment object }\u000a  FRAG_LOAD_EMERGENCY_ABORTED: 'hlsFragLoadEmergencyAborted',\u000a  // fired when a fragment loading is completed - data: { frag : fragment object, payload : fragment payload, stats : { trequest, tfirst, tload, length } }\u000a  FRAG_LOADED: 'hlsFragLoaded',\u000a  // fired when a fragment has finished decrypting - data: { id : demuxer id, frag: fragment object, payload : fragment payload, stats : { tstart, tdecrypt } }\u000a  FRAG_DECRYPTED: 'hlsFragDecrypted',\u000a  // fired when Init Segment has been extracted from fragment - data: { id : demuxer id, frag: fragment object, moov : moov MP4 box, codecs : codecs found while parsing fragment }\u000a  FRAG_PARSING_INIT_SEGMENT: 'hlsFragParsingInitSegment',\u000a  // fired when parsing sei text is completed - data: { id : demuxer id, frag: fragment object, samples : [ sei samples pes ] }\u000a  FRAG_PARSING_USERDATA: 'hlsFragParsingUserdata',\u000a  // fired when parsing id3 is completed - data: { id : demuxer id, frag: fragment object, samples : [ id3 samples pes ] }\u000a  FRAG_PARSING_METADATA: 'hlsFragParsingMetadata',\u000a  // fired when data have been extracted from fragment - data: { id : demuxer id, frag: fragment object, data1 : moof MP4 box or TS fragments, data2 : mdat MP4 box or null}\u000a  FRAG_PARSING_DATA: 'hlsFragParsingData',\u000a  // fired when fragment parsing is completed - data: { id : demuxer id, frag: fragment object }\u000a  FRAG_PARSED: 'hlsFragParsed',\u000a  // fired when fragment remuxed MP4 boxes have all been appended into SourceBuffer - data: { id : demuxer id, frag : fragment object, stats : { trequest, tfirst, tload, tparsed, tbuffered, length, bwEstimate } }\u000a  FRAG_BUFFERED: 'hlsFragBuffered',\u000a  // fired when fragment matching with current media position is changing - data : { id : demuxer id, frag : fragment object }\u000a  FRAG_CHANGED: 'hlsFragChanged',\u000a  // Identifier for a FPS drop event - data: { curentDropped, currentDecoded, totalDroppedFrames }\u000a  FPS_DROP: 'hlsFpsDrop',\u000a  // triggered when FPS drop triggers auto level capping - data: { level, droppedlevel }\u000a  FPS_DROP_LEVEL_CAPPING: 'hlsFpsDropLevelCapping',\u000a  // Identifier for an error event - data: { type : error type, details : error details, fatal : if true, hls.js cannot/will not try to recover, if false, hls.js will try to recover,other error specific data }\u000a  ERROR: 'hlsError',\u000a  // fired when hls.js instance starts destroying. Different from MEDIA_DETACHED as one could want to detach and reattach a media to the instance of hls.js to handle mid-rolls for example - data: { }\u000a  DESTROYING: 'hlsDestroying',\u000a  // fired when a decrypt key loading starts - data: { frag : fragment object }\u000a  KEY_LOADING: 'hlsKeyLoading',\u000a  // fired when a decrypt key loading is completed - data: { frag : fragment object, payload : key payload, stats : { trequest, tfirst, tload, length } }\u000a  KEY_LOADED: 'hlsKeyLoaded',\u000a  // fired upon stream controller state transitions - data: { previousState, nextState }\u000a  STREAM_STATE_TRANSITION: 'hlsStreamStateTransition',\u000a  // fired when the live back buffer is reached defined by the liveBackBufferLength config option - data : { bufferEnd: number }\u000a  LIVE_BACK_BUFFER_REACHED: 'hlsLiveBackBufferReached'\u000a};\u000a/* harmony default export */ __webpack_exports__["default"] = (HlsEvents);\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/hls.ts":\u000a/*!*********************************!*\u005c\u000a  !*** ./src/hls.ts + 50 modules ***!\u000a  \u005c*********************************/\u000a/*! exports provided: default */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/crypt/decrypter.js because of ./src/demux/demuxer-worker.js */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/demux/demuxer-inline.js because of ./src/demux/demuxer-worker.js */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/demux/id3.js because of ./src/demux/demuxer-worker.js */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/demux/mp4demuxer.js because of ./src/demux/demuxer-worker.js */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/errors.ts because of ./src/demux/demuxer-worker.js */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/events.js because of ./src/demux/demuxer-worker.js */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/polyfills/number.js because of ./src/demux/demuxer-worker.js */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/utils/get-self-scope.js because of ./src/demux/demuxer-worker.js */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./src/utils/logger.js because of ./src/demux/demuxer-worker.js */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./node_modules/eventemitter3/index.js (<- Module is not an ECMAScript module) */\u000a/*! ModuleConcatenation bailout: Cannot concat with ./node_modules/url-toolkit/src/url-toolkit.js (<- Module is not an ECMAScript module) */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a// ESM COMPAT FLAG\u000a__webpack_require__.r(__webpack_exports__);\u000a\u000a// EXPORTS\u000a__webpack_require__.d(__webpack_exports__, "default", function() { return /* binding */ hls_Hls; });\u000a\u000a// NAMESPACE OBJECT: ./src/utils/cues.ts\u000avar cues_namespaceObject = {};\u000a__webpack_require__.r(cues_namespaceObject);\u000a__webpack_require__.d(cues_namespaceObject, "newCue", function() { return newCue; });\u000a\u000a// EXTERNAL MODULE: ./node_modules/url-toolkit/src/url-toolkit.js\u000avar url_toolkit = __webpack_require__("./node_modules/url-toolkit/src/url-toolkit.js");\u000a\u000a// EXTERNAL MODULE: ./src/errors.ts\u000avar errors = __webpack_require__("./src/errors.ts");\u000a\u000a// EXTERNAL MODULE: ./src/polyfills/number.js\u000avar number = __webpack_require__("./src/polyfills/number.js");\u000a\u000a// EXTERNAL MODULE: ./src/events.js\u000avar events = __webpack_require__("./src/events.js");\u000a\u000a// EXTERNAL MODULE: ./src/utils/logger.js\u000avar logger = __webpack_require__("./src/utils/logger.js");\u000a\u000a// CONCATENATED MODULE: ./src/event-handler.ts\u000a/*\u000a*\u000a* All objects in the event handling chain should inherit from this class\u000a*\u000a*/\u000a\u000a\u000a\u000avar FORBIDDEN_EVENT_NAMES = {\u000a  'hlsEventGeneric': true,\u000a  'hlsHandlerDestroying': true,\u000a  'hlsHandlerDestroyed': true\u000a};\u000a\u000avar event_handler_EventHandler = /*#__PURE__*/function () {\u000a  function EventHandler(hls) {\u000a    this.hls = void 0;\u000a    this.handledEvents = void 0;\u000a    this.useGenericHandler = void 0;\u000a    this.hls = hls;\u000a    this.onEvent = this.onEvent.bind(this);\u000a\u000a    for (var _len = arguments.length, events = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\u000a      events[_key - 1] = arguments[_key];\u000a    }\u000a\u000a    this.handledEvents = events;\u000a    this.useGenericHandler = true;\u000a    this.registerListeners();\u000a  }\u000a\u000a  var _proto = EventHandler.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    this.onHandlerDestroying();\u000a    this.unregisterListeners();\u000a    this.onHandlerDestroyed();\u000a  };\u000a\u000a  _proto.onHandlerDestroying = function onHandlerDestroying() {};\u000a\u000a  _proto.onHandlerDestroyed = function onHandlerDestroyed() {};\u000a\u000a  _proto.isEventHandler = function isEventHandler() {\u000a    return typeof this.handledEvents === 'object' && this.handledEvents.length && typeof this.onEvent === 'function';\u000a  };\u000a\u000a  _proto.registerListeners = function registerListeners() {\u000a    if (this.isEventHandler()) {\u000a      this.handledEvents.forEach(function (event) {\u000a        if (FORBIDDEN_EVENT_NAMES[event]) {\u000a          throw new Error('Forbidden event-name: ' + event);\u000a        }\u000a\u000a        this.hls.on(event, this.onEvent);\u000a      }, this);\u000a    }\u000a  };\u000a\u000a  _proto.unregisterListeners = function unregisterListeners() {\u000a    if (this.isEventHandler()) {\u000a      this.handledEvents.forEach(function (event) {\u000a        this.hls.off(event, this.onEvent);\u000a      }, this);\u000a    }\u000a  }\u000a  /**\u000a   * arguments: event (string), data (any)\u000a   */\u000a  ;\u000a\u000a  _proto.onEvent = function onEvent(event, data) {\u000a    this.onEventGeneric(event, data);\u000a  };\u000a\u000a  _proto.onEventGeneric = function onEventGeneric(event, data) {\u000a    var eventToFunction = function eventToFunction(event, data) {\u000a      var funcName = 'on' + event.replace('hls', '');\u000a\u000a      if (typeof this[funcName] !== 'function') {\u000a        throw new Error("Event " + event + " has no generic handler in this " + this.constructor.name + " class (tried " + funcName + ")");\u000a      }\u000a\u000a      return this[funcName].bind(this, data);\u000a    };\u000a\u000a    try {\u000a      eventToFunction.call(this, event, data).call();\u000a    } catch (err) {\u000a      logger["logger"].error("An internal error happened while handling event " + event + ". Error message: \u005c"" + err.message + "\u005c". Here is a stacktrace:", err);\u000a      this.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].OTHER_ERROR,\u000a        details: errors["ErrorDetails"].INTERNAL_EXCEPTION,\u000a        fatal: false,\u000a        event: event,\u000a        err: err\u000a      });\u000a    }\u000a  };\u000a\u000a  return EventHandler;\u000a}();\u000a\u000a/* harmony default export */ var event_handler = (event_handler_EventHandler);\u000a// CONCATENATED MODULE: ./src/types/loader.ts\u000a/**\u000a * `type` property values for this loaders' context object\u000a * @enum\u000a *\u000a */\u000avar PlaylistContextType;\u000a/**\u000a * @enum {string}\u000a */\u000a\u000a(function (PlaylistContextType) {\u000a  PlaylistContextType["MANIFEST"] = "manifest";\u000a  PlaylistContextType["LEVEL"] = "level";\u000a  PlaylistContextType["AUDIO_TRACK"] = "audioTrack";\u000a  PlaylistContextType["SUBTITLE_TRACK"] = "subtitleTrack";\u000a})(PlaylistContextType || (PlaylistContextType = {}));\u000a\u000avar PlaylistLevelType;\u000a\u000a(function (PlaylistLevelType) {\u000a  PlaylistLevelType["MAIN"] = "main";\u000a  PlaylistLevelType["AUDIO"] = "audio";\u000a  PlaylistLevelType["SUBTITLE"] = "subtitle";\u000a})(PlaylistLevelType || (PlaylistLevelType = {}));\u000a// EXTERNAL MODULE: ./src/demux/mp4demuxer.js\u000avar mp4demuxer = __webpack_require__("./src/demux/mp4demuxer.js");\u000a\u000a// CONCATENATED MODULE: ./src/loader/level-key.ts\u000afunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000a\u000a\u000avar level_key_LevelKey = /*#__PURE__*/function () {\u000a  function LevelKey(baseURI, relativeURI) {\u000a    this._uri = null;\u000a    this.baseuri = void 0;\u000a    this.reluri = void 0;\u000a    this.method = null;\u000a    this.key = null;\u000a    this.iv = null;\u000a    this.baseuri = baseURI;\u000a    this.reluri = relativeURI;\u000a  }\u000a\u000a  _createClass(LevelKey, [{\u000a    key: "uri",\u000a    get: function get() {\u000a      if (!this._uri && this.reluri) {\u000a        this._uri = Object(url_toolkit["buildAbsoluteURL"])(this.baseuri, this.reluri, {\u000a          alwaysNormalize: true\u000a        });\u000a      }\u000a\u000a      return this._uri;\u000a    }\u000a  }]);\u000a\u000a  return LevelKey;\u000a}();\u000a\u000a\u000a// CONCATENATED MODULE: ./src/loader/fragment.ts\u000a\u000a\u000a\u000afunction fragment_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction fragment_createClass(Constructor, protoProps, staticProps) { if (protoProps) fragment_defineProperties(Constructor.prototype, protoProps); if (staticProps) fragment_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000a\u000a\u000a\u000avar ElementaryStreamTypes;\u000a\u000a(function (ElementaryStreamTypes) {\u000a  ElementaryStreamTypes["AUDIO"] = "audio";\u000a  ElementaryStreamTypes["VIDEO"] = "video";\u000a})(ElementaryStreamTypes || (ElementaryStreamTypes = {}));\u000a\u000avar fragment_Fragment = /*#__PURE__*/function () {\u000a  function Fragment() {\u000a    var _this$_elementaryStre;\u000a\u000a    this._url = null;\u000a    this._byteRange = null;\u000a    this._decryptdata = null;\u000a    this._elementaryStreams = (_this$_elementaryStre = {}, _this$_elementaryStre[ElementaryStreamTypes.AUDIO] = false, _this$_elementaryStre[ElementaryStreamTypes.VIDEO] = false, _this$_elementaryStre);\u000a    this.deltaPTS = 0;\u000a    this.rawProgramDateTime = null;\u000a    this.programDateTime = null;\u000a    this.title = null;\u000a    this.tagList = [];\u000a    this.cc = void 0;\u000a    this.type = void 0;\u000a    this.relurl = void 0;\u000a    this.baseurl = void 0;\u000a    this.duration = void 0;\u000a    this.start = void 0;\u000a    this.sn = 0;\u000a    this.urlId = 0;\u000a    this.level = 0;\u000a    this.levelkey = void 0;\u000a    this.loader = void 0;\u000a  }\u000a\u000a  var _proto = Fragment.prototype;\u000a\u000a  // setByteRange converts a EXT-X-BYTERANGE attribute into a two element array\u000a  _proto.setByteRange = function setByteRange(value, previousFrag) {\u000a    var params = value.split('@', 2);\u000a    var byteRange = [];\u000a\u000a    if (params.length === 1) {\u000a      byteRange[0] = previousFrag ? previousFrag.byteRangeEndOffset : 0;\u000a    } else {\u000a      byteRange[0] = parseInt(params[1]);\u000a    }\u000a\u000a    byteRange[1] = parseInt(params[0]) + byteRange[0];\u000a    this._byteRange = byteRange;\u000a  };\u000a\u000a  /**\u000a   * @param {ElementaryStreamTypes} type\u000a   */\u000a  _proto.addElementaryStream = function addElementaryStream(type) {\u000a    this._elementaryStreams[type] = true;\u000a  }\u000a  /**\u000a   * @param {ElementaryStreamTypes} type\u000a   */\u000a  ;\u000a\u000a  _proto.hasElementaryStream = function hasElementaryStream(type) {\u000a    return this._elementaryStreams[type] === true;\u000a  }\u000a  /**\u000a   * Utility method for parseLevelPlaylist to create an initialization vector for a given segment\u000a   * @param {number} segmentNumber - segment number to generate IV with\u000a   * @returns {Uint8Array}\u000a   */\u000a  ;\u000a\u000a  _proto.createInitializationVector = function createInitializationVector(segmentNumber) {\u000a    var uint8View = new Uint8Array(16);\u000a\u000a    for (var i = 12; i < 16; i++) {\u000a      uint8View[i] = segmentNumber >> 8 * (15 - i) & 0xff;\u000a    }\u000a\u000a    return uint8View;\u000a  }\u000a  /**\u000a   * Utility method for parseLevelPlaylist to get a fragment's decryption data from the currently parsed encryption key data\u000a   * @param levelkey - a playlist's encryption info\u000a   * @param segmentNumber - the fragment's segment number\u000a   * @returns {LevelKey} - an object to be applied as a fragment's decryptdata\u000a   */\u000a  ;\u000a\u000a  _proto.setDecryptDataFromLevelKey = function setDecryptDataFromLevelKey(levelkey, segmentNumber) {\u000a    var decryptdata = levelkey;\u000a\u000a    if ((levelkey === null || levelkey === void 0 ? void 0 : levelkey.method) && levelkey.uri && !levelkey.iv) {\u000a      decryptdata = new level_key_LevelKey(levelkey.baseuri, levelkey.reluri);\u000a      decryptdata.method = levelkey.method;\u000a      decryptdata.iv = this.createInitializationVector(segmentNumber);\u000a    }\u000a\u000a    return decryptdata;\u000a  };\u000a\u000a  fragment_createClass(Fragment, [{\u000a    key: "url",\u000a    get: function get() {\u000a      if (!this._url && this.relurl) {\u000a        this._url = Object(url_toolkit["buildAbsoluteURL"])(this.baseurl, this.relurl, {\u000a          alwaysNormalize: true\u000a        });\u000a      }\u000a\u000a      return this._url;\u000a    },\u000a    set: function set(value) {\u000a      this._url = value;\u000a    }\u000a  }, {\u000a    key: "byteRange",\u000a    get: function get() {\u000a      if (!this._byteRange) {\u000a        return [];\u000a      }\u000a\u000a      return this._byteRange;\u000a    }\u000a    /**\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "byteRangeStartOffset",\u000a    get: function get() {\u000a      return this.byteRange[0];\u000a    }\u000a  }, {\u000a    key: "byteRangeEndOffset",\u000a    get: function get() {\u000a      return this.byteRange[1];\u000a    }\u000a  }, {\u000a    key: "decryptdata",\u000a    get: function get() {\u000a      if (!this.levelkey && !this._decryptdata) {\u000a        return null;\u000a      }\u000a\u000a      if (!this._decryptdata && this.levelkey) {\u000a        var sn = this.sn;\u000a\u000a        if (typeof sn !== 'number') {\u000a          // We are fetching decryption data for a initialization segment\u000a          // If the segment was encrypted with AES-128\u000a          // It must have an IV defined. We cannot substitute the Segment Number in.\u000a          if (this.levelkey && this.levelkey.method === 'AES-128' && !this.levelkey.iv) {\u000a            logger["logger"].warn("missing IV for initialization segment with method=\u005c"" + this.levelkey.method + "\u005c" - compliance issue");\u000a          }\u000a          /*\u000a          Be converted to a Number.\u000a          'initSegment' will become NaN.\u000a          NaN, which when converted through ToInt32() -> +0.\u000a          ---\u000a          Explicitly set sn to resulting value from implicit conversions 'initSegment' values for IV generation.\u000a          */\u000a\u000a\u000a          sn = 0;\u000a        }\u000a\u000a        this._decryptdata = this.setDecryptDataFromLevelKey(this.levelkey, sn);\u000a      }\u000a\u000a      return this._decryptdata;\u000a    }\u000a  }, {\u000a    key: "endProgramDateTime",\u000a    get: function get() {\u000a      if (this.programDateTime === null) {\u000a        return null;\u000a      }\u000a\u000a      if (!Object(number["isFiniteNumber"])(this.programDateTime)) {\u000a        return null;\u000a      }\u000a\u000a      var duration = !Object(number["isFiniteNumber"])(this.duration) ? 0 : this.duration;\u000a      return this.programDateTime + duration * 1000;\u000a    }\u000a  }, {\u000a    key: "encrypted",\u000a    get: function get() {\u000a      return !!(this.decryptdata && this.decryptdata.uri !== null && this.decryptdata.key === null);\u000a    }\u000a  }]);\u000a\u000a  return Fragment;\u000a}();\u000a\u000a\u000a// CONCATENATED MODULE: ./src/loader/level.js\u000a\u000a\u000afunction level_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction level_createClass(Constructor, protoProps, staticProps) { if (protoProps) level_defineProperties(Constructor.prototype, protoProps); if (staticProps) level_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000avar level_Level = /*#__PURE__*/function () {\u000a  function Level(baseUrl) {\u000a    // Please keep properties in alphabetical order\u000a    this.endCC = 0;\u000a    this.endSN = 0;\u000a    this.fragments = [];\u000a    this.initSegment = null;\u000a    this.live = true;\u000a    this.needSidxRanges = false;\u000a    this.startCC = 0;\u000a    this.startSN = 0;\u000a    this.startTimeOffset = null;\u000a    this.targetduration = 0;\u000a    this.totalduration = 0;\u000a    this.type = null;\u000a    this.url = baseUrl;\u000a    this.version = null;\u000a  }\u000a\u000a  level_createClass(Level, [{\u000a    key: "hasProgramDateTime",\u000a    get: function get() {\u000a      return !!(this.fragments[0] && Object(number["isFiniteNumber"])(this.fragments[0].programDateTime));\u000a    }\u000a  }]);\u000a\u000a  return Level;\u000a}();\u000a\u000a\u000a// CONCATENATED MODULE: ./src/utils/attr-list.js\u000avar DECIMAL_RESOLUTION_REGEX = /^(\u005cd+)x(\u005cd+)$/; // eslint-disable-line no-useless-escape\u000a\u000avar ATTR_LIST_REGEX = /\u005cs*(.+?)\u005cs*=((?:\u005c".*?\u005c")|.*?)(?:,|$)/g; // eslint-disable-line no-useless-escape\u000a// adapted from https://github.com/kanongil/node-m3u8parse/blob/master/attrlist.js\u000a\u000avar AttrList = /*#__PURE__*/function () {\u000a  function AttrList(attrs) {\u000a    if (typeof attrs === 'string') {\u000a      attrs = AttrList.parseAttrList(attrs);\u000a    }\u000a\u000a    for (var attr in attrs) {\u000a      if (attrs.hasOwnProperty(attr)) {\u000a        this[attr] = attrs[attr];\u000a      }\u000a    }\u000a  }\u000a\u000a  var _proto = AttrList.prototype;\u000a\u000a  _proto.decimalInteger = function decimalInteger(attrName) {\u000a    var intValue = parseInt(this[attrName], 10);\u000a\u000a    if (intValue > Number.MAX_SAFE_INTEGER) {\u000a      return Infinity;\u000a    }\u000a\u000a    return intValue;\u000a  };\u000a\u000a  _proto.hexadecimalInteger = function hexadecimalInteger(attrName) {\u000a    if (this[attrName]) {\u000a      var stringValue = (this[attrName] || '0x').slice(2);\u000a      stringValue = (stringValue.length & 1 ? '0' : '') + stringValue;\u000a      var value = new Uint8Array(stringValue.length / 2);\u000a\u000a      for (var i = 0; i < stringValue.length / 2; i++) {\u000a        value[i] = parseInt(stringValue.slice(i * 2, i * 2 + 2), 16);\u000a      }\u000a\u000a      return value;\u000a    } else {\u000a      return null;\u000a    }\u000a  };\u000a\u000a  _proto.hexadecimalIntegerAsNumber = function hexadecimalIntegerAsNumber(attrName) {\u000a    var intValue = parseInt(this[attrName], 16);\u000a\u000a    if (intValue > Number.MAX_SAFE_INTEGER) {\u000a      return Infinity;\u000a    }\u000a\u000a    return intValue;\u000a  };\u000a\u000a  _proto.decimalFloatingPoint = function decimalFloatingPoint(attrName) {\u000a    return parseFloat(this[attrName]);\u000a  };\u000a\u000a  _proto.enumeratedString = function enumeratedString(attrName) {\u000a    return this[attrName];\u000a  };\u000a\u000a  _proto.decimalResolution = function decimalResolution(attrName) {\u000a    var res = DECIMAL_RESOLUTION_REGEX.exec(this[attrName]);\u000a\u000a    if (res === null) {\u000a      return undefined;\u000a    }\u000a\u000a    return {\u000a      width: parseInt(res[1], 10),\u000a      height: parseInt(res[2], 10)\u000a    };\u000a  };\u000a\u000a  AttrList.parseAttrList = function parseAttrList(input) {\u000a    var match,\u000a        attrs = {};\u000a    ATTR_LIST_REGEX.lastIndex = 0;\u000a\u000a    while ((match = ATTR_LIST_REGEX.exec(input)) !== null) {\u000a      var value = match[2],\u000a          quote = '"';\u000a\u000a      if (value.indexOf(quote) === 0 && value.lastIndexOf(quote) === value.length - 1) {\u000a        value = value.slice(1, -1);\u000a      }\u000a\u000a      attrs[match[1]] = value;\u000a    }\u000a\u000a    return attrs;\u000a  };\u000a\u000a  return AttrList;\u000a}();\u000a\u000a/* harmony default export */ var attr_list = (AttrList);\u000a// CONCATENATED MODULE: ./src/utils/codecs.ts\u000a// from http://mp4ra.org/codecs.html\u000avar sampleEntryCodesISO = {\u000a  audio: {\u000a    'a3ds': true,\u000a    'ac-3': true,\u000a    'ac-4': true,\u000a    'alac': true,\u000a    'alaw': true,\u000a    'dra1': true,\u000a    'dts+': true,\u000a    'dts-': true,\u000a    'dtsc': true,\u000a    'dtse': true,\u000a    'dtsh': true,\u000a    'ec-3': true,\u000a    'enca': true,\u000a    'g719': true,\u000a    'g726': true,\u000a    'm4ae': true,\u000a    'mha1': true,\u000a    'mha2': true,\u000a    'mhm1': true,\u000a    'mhm2': true,\u000a    'mlpa': true,\u000a    'mp4a': true,\u000a    'raw ': true,\u000a    'Opus': true,\u000a    'samr': true,\u000a    'sawb': true,\u000a    'sawp': true,\u000a    'sevc': true,\u000a    'sqcp': true,\u000a    'ssmv': true,\u000a    'twos': true,\u000a    'ulaw': true\u000a  },\u000a  video: {\u000a    'avc1': true,\u000a    'avc2': true,\u000a    'avc3': true,\u000a    'avc4': true,\u000a    'avcp': true,\u000a    'drac': true,\u000a    'dvav': true,\u000a    'dvhe': true,\u000a    'encv': true,\u000a    'hev1': true,\u000a    'hvc1': true,\u000a    'mjp2': true,\u000a    'mp4v': true,\u000a    'mvc1': true,\u000a    'mvc2': true,\u000a    'mvc3': true,\u000a    'mvc4': true,\u000a    'resv': true,\u000a    'rv60': true,\u000a    's263': true,\u000a    'svc1': true,\u000a    'svc2': true,\u000a    'vc-1': true,\u000a    'vp08': true,\u000a    'vp09': true\u000a  }\u000a};\u000a\u000afunction isCodecType(codec, type) {\u000a  var typeCodes = sampleEntryCodesISO[type];\u000a  return !!typeCodes && typeCodes[codec.slice(0, 4)] === true;\u000a}\u000a\u000afunction isCodecSupportedInMp4(codec, type) {\u000a  return MediaSource.isTypeSupported((type || 'video') + "/mp4;codecs=\u005c"" + codec + "\u005c"");\u000a}\u000a\u000a\u000a// CONCATENATED MODULE: ./src/loader/m3u8-parser.ts\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a/**\u000a * M3U8 parser\u000a * @module\u000a */\u000a// https://regex101.com is your friend\u000avar MASTER_PLAYLIST_REGEX = /(?:#EXT-X-STREAM-INF:([^\u005cn\u005cr]*)[\u005cr\u005cn]+([^\u005cr\u005cn]+)|#EXT-X-SESSION-DATA:([^\u005cn\u005cr]*)[\u005cr\u005cn]+)/g;\u000avar MASTER_PLAYLIST_MEDIA_REGEX = /#EXT-X-MEDIA:(.*)/g;\u000avar LEVEL_PLAYLIST_REGEX_FAST = new RegExp([/#EXTINF:\u005cs*(\u005cd*(?:\u005c.\u005cd+)?)(?:,(.*)\u005cs+)?/.source, // duration (#EXTINF:<duration>,<title>), group 1 => duration, group 2 => title\u000a/|(?!#)([\u005cS+ ?]+)/.source, // segment URI, group 3 => the URI (note newline is not eaten)\u000a/|#EXT-X-BYTERANGE:*(.+)/.source, // next segment's byterange, group 4 => range spec (x@y)\u000a/|#EXT-X-PROGRAM-DATE-TIME:(.+)/.source, // next segment's program date/time group 5 => the datetime spec\u000a/|#.*/.source // All other non-segment oriented tags will match with all groups empty\u000a].join(''), 'g');\u000avar LEVEL_PLAYLIST_REGEX_SLOW = /(?:(?:#(EXTM3U))|(?:#EXT-X-(PLAYLIST-TYPE):(.+))|(?:#EXT-X-(MEDIA-SEQUENCE): *(\u005cd+))|(?:#EXT-X-(TARGETDURATION): *(\u005cd+))|(?:#EXT-X-(KEY):(.+))|(?:#EXT-X-(START):(.+))|(?:#EXT-X-(ENDLIST))|(?:#EXT-X-(DISCONTINUITY-SEQ)UENCE:(\u005cd+))|(?:#EXT-X-(DIS)CONTINUITY))|(?:#EXT-X-(VERSION):(\u005cd+))|(?:#EXT-X-(MAP):(.+))|(?:(#)([^:]*):(.*))|(?:(#)(.*))(?:.*)\u005cr?\u005cn?/;\u000avar MP4_REGEX_SUFFIX = /\u005c.(mp4|m4s|m4v|m4a)$/i;\u000a\u000avar m3u8_parser_M3U8Parser = /*#__PURE__*/function () {\u000a  function M3U8Parser() {}\u000a\u000a  M3U8Parser.findGroup = function findGroup(groups, mediaGroupId) {\u000a    for (var i = 0; i < groups.length; i++) {\u000a      var group = groups[i];\u000a\u000a      if (group.id === mediaGroupId) {\u000a        return group;\u000a      }\u000a    }\u000a  };\u000a\u000a  M3U8Parser.convertAVC1ToAVCOTI = function convertAVC1ToAVCOTI(codec) {\u000a    var avcdata = codec.split('.');\u000a    var result;\u000a\u000a    if (avcdata.length > 2) {\u000a      result = avcdata.shift() + '.';\u000a      result += parseInt(avcdata.shift()).toString(16);\u000a      result += ('000' + parseInt(avcdata.shift()).toString(16)).substr(-4);\u000a    } else {\u000a      result = codec;\u000a    }\u000a\u000a    return result;\u000a  };\u000a\u000a  M3U8Parser.resolve = function resolve(url, baseUrl) {\u000a    return url_toolkit["buildAbsoluteURL"](baseUrl, url, {\u000a      alwaysNormalize: true\u000a    });\u000a  };\u000a\u000a  M3U8Parser.parseMasterPlaylist = function parseMasterPlaylist(string, baseurl) {\u000a    // TODO(typescript-level)\u000a    var levels = [];\u000a    var sessionData = {};\u000a    var hasSessionData = false;\u000a    MASTER_PLAYLIST_REGEX.lastIndex = 0; // TODO(typescript-level)\u000a\u000a    function setCodecs(codecs, level) {\u000a      ['video', 'audio'].forEach(function (type) {\u000a        var filtered = codecs.filter(function (codec) {\u000a          return isCodecType(codec, type);\u000a        });\u000a\u000a        if (filtered.length) {\u000a          var preferred = filtered.filter(function (codec) {\u000a            return codec.lastIndexOf('avc1', 0) === 0 || codec.lastIndexOf('mp4a', 0) === 0;\u000a          });\u000a          level[type + "Codec"] = preferred.length > 0 ? preferred[0] : filtered[0]; // remove from list\u000a\u000a          codecs = codecs.filter(function (codec) {\u000a            return filtered.indexOf(codec) === -1;\u000a          });\u000a        }\u000a      });\u000a      level.unknownCodecs = codecs;\u000a    }\u000a\u000a    var result;\u000a\u000a    while ((result = MASTER_PLAYLIST_REGEX.exec(string)) != null) {\u000a      if (result[1]) {\u000a        // '#EXT-X-STREAM-INF' is found, parse level tag  in group 1\u000a        // TODO(typescript-level)\u000a        var level = {};\u000a        var attrs = level.attrs = new attr_list(result[1]);\u000a        level.url = M3U8Parser.resolve(result[2], baseurl);\u000a        var resolution = attrs.decimalResolution('RESOLUTION');\u000a\u000a        if (resolution) {\u000a          level.width = resolution.width;\u000a          level.height = resolution.height;\u000a        }\u000a\u000a        level.bitrate = attrs.decimalInteger('AVERAGE-BANDWIDTH') || attrs.decimalInteger('BANDWIDTH');\u000a        level.name = attrs.NAME;\u000a        setCodecs([].concat((attrs.CODECS || '').split(/[ ,]+/)), level);\u000a\u000a        if (level.videoCodec && level.videoCodec.indexOf('avc1') !== -1) {\u000a          level.videoCodec = M3U8Parser.convertAVC1ToAVCOTI(level.videoCodec);\u000a        }\u000a\u000a        levels.push(level);\u000a      } else if (result[3]) {\u000a        // '#EXT-X-SESSION-DATA' is found, parse session data in group 3\u000a        var sessionAttrs = new attr_list(result[3]);\u000a\u000a        if (sessionAttrs['DATA-ID']) {\u000a          hasSessionData = true;\u000a          sessionData[sessionAttrs['DATA-ID']] = sessionAttrs;\u000a        }\u000a      }\u000a    }\u000a\u000a    return {\u000a      levels: levels,\u000a      sessionData: hasSessionData ? sessionData : null\u000a    };\u000a  };\u000a\u000a  M3U8Parser.parseMasterPlaylistMedia = function parseMasterPlaylistMedia(string, baseurl, type, audioGroups) {\u000a    if (audioGroups === void 0) {\u000a      audioGroups = [];\u000a    }\u000a\u000a    var result;\u000a    var medias = [];\u000a    var id = 0;\u000a    MASTER_PLAYLIST_MEDIA_REGEX.lastIndex = 0;\u000a\u000a    while ((result = MASTER_PLAYLIST_MEDIA_REGEX.exec(string)) !== null) {\u000a      var attrs = new attr_list(result[1]);\u000a\u000a      if (attrs.TYPE === type) {\u000a        var media = {\u000a          attrs: attrs,\u000a          id: id++,\u000a          groupId: attrs['GROUP-ID'],\u000a          instreamId: attrs['INSTREAM-ID'],\u000a          name: attrs.NAME || attrs.LANGUAGE,\u000a          type: type,\u000a          default: attrs.DEFAULT === 'YES',\u000a          autoselect: attrs.AUTOSELECT === 'YES',\u000a          forced: attrs.FORCED === 'YES',\u000a          lang: attrs.LANGUAGE\u000a        };\u000a\u000a        if (attrs.URI) {\u000a          media.url = M3U8Parser.resolve(attrs.URI, baseurl);\u000a        }\u000a\u000a        if (audioGroups.length) {\u000a          // If there are audio groups signalled in the manifest, let's look for a matching codec string for this track\u000a          var groupCodec = M3U8Parser.findGroup(audioGroups, media.groupId); // If we don't find the track signalled, lets use the first audio groups codec we have\u000a          // Acting as a best guess\u000a\u000a          media.audioCodec = groupCodec ? groupCodec.codec : audioGroups[0].codec;\u000a        }\u000a\u000a        medias.push(media);\u000a      }\u000a    }\u000a\u000a    return medias;\u000a  };\u000a\u000a  M3U8Parser.parseLevelPlaylist = function parseLevelPlaylist(string, baseurl, id, type, levelUrlId) {\u000a    var currentSN = 0;\u000a    var totalduration = 0;\u000a    var level = new level_Level(baseurl);\u000a    var discontinuityCounter = 0;\u000a    var prevFrag = null;\u000a    var frag = new fragment_Fragment();\u000a    var result;\u000a    var i;\u000a    var levelkey;\u000a    var firstPdtIndex = null;\u000a    LEVEL_PLAYLIST_REGEX_FAST.lastIndex = 0;\u000a\u000a    while ((result = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) !== null) {\u000a      var duration = result[1];\u000a\u000a      if (duration) {\u000a        // INF\u000a        frag.duration = parseFloat(duration); // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\u000a\u000a        var title = (' ' + result[2]).slice(1);\u000a        frag.title = title || null;\u000a        frag.tagList.push(title ? ['INF', duration, title] : ['INF', duration]);\u000a      } else if (result[3]) {\u000a        // url\u000a        if (Object(number["isFiniteNumber"])(frag.duration)) {\u000a          var sn = currentSN++;\u000a          frag.type = type;\u000a          frag.start = totalduration;\u000a\u000a          if (levelkey) {\u000a            frag.levelkey = levelkey;\u000a          }\u000a\u000a          frag.sn = sn;\u000a          frag.level = id;\u000a          frag.cc = discontinuityCounter;\u000a          frag.urlId = levelUrlId;\u000a          frag.baseurl = baseurl; // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\u000a\u000a          frag.relurl = (' ' + result[3]).slice(1);\u000a          assignProgramDateTime(frag, prevFrag);\u000a          level.fragments.push(frag);\u000a          prevFrag = frag;\u000a          totalduration += frag.duration;\u000a          frag = new fragment_Fragment();\u000a        }\u000a      } else if (result[4]) {\u000a        // X-BYTERANGE\u000a        var data = (' ' + result[4]).slice(1);\u000a\u000a        if (prevFrag) {\u000a          frag.setByteRange(data, prevFrag);\u000a        } else {\u000a          frag.setByteRange(data);\u000a        }\u000a      } else if (result[5]) {\u000a        // PROGRAM-DATE-TIME\u000a        // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\u000a        frag.rawProgramDateTime = (' ' + result[5]).slice(1);\u000a        frag.tagList.push(['PROGRAM-DATE-TIME', frag.rawProgramDateTime]);\u000a\u000a        if (firstPdtIndex === null) {\u000a          firstPdtIndex = level.fragments.length;\u000a        }\u000a      } else {\u000a        result = result[0].match(LEVEL_PLAYLIST_REGEX_SLOW);\u000a\u000a        if (!result) {\u000a          logger["logger"].warn('No matches on slow regex match for level playlist!');\u000a          continue;\u000a        }\u000a\u000a        for (i = 1; i < result.length; i++) {\u000a          if (typeof result[i] !== 'undefined') {\u000a            break;\u000a          }\u000a        } // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\u000a\u000a\u000a        var value1 = (' ' + result[i + 1]).slice(1);\u000a        var value2 = (' ' + result[i + 2]).slice(1);\u000a\u000a        switch (result[i]) {\u000a          case '#':\u000a            frag.tagList.push(value2 ? [value1, value2] : [value1]);\u000a            break;\u000a\u000a          case 'PLAYLIST-TYPE':\u000a            level.type = value1.toUpperCase();\u000a            break;\u000a\u000a          case 'MEDIA-SEQUENCE':\u000a            currentSN = level.startSN = parseInt(value1);\u000a            break;\u000a\u000a          case 'TARGETDURATION':\u000a            level.targetduration = parseFloat(value1);\u000a            break;\u000a\u000a          case 'VERSION':\u000a            level.version = parseInt(value1);\u000a            break;\u000a\u000a          case 'EXTM3U':\u000a            break;\u000a\u000a          case 'ENDLIST':\u000a            level.live = false;\u000a            break;\u000a\u000a          case 'DIS':\u000a            discontinuityCounter++;\u000a            frag.tagList.push(['DIS']);\u000a            break;\u000a\u000a          case 'DISCONTINUITY-SEQ':\u000a            discontinuityCounter = parseInt(value1);\u000a            break;\u000a\u000a          case 'KEY':\u000a            {\u000a              // https://tools.ietf.org/html/rfc8216#section-4.3.2.4\u000a              var decryptparams = value1;\u000a              var keyAttrs = new attr_list(decryptparams);\u000a              var decryptmethod = keyAttrs.enumeratedString('METHOD');\u000a              var decrypturi = keyAttrs.URI;\u000a              var decryptiv = keyAttrs.hexadecimalInteger('IV'); // From RFC: This attribute is OPTIONAL; its absence indicates an implicit value of "identity".\u000a\u000a              var decryptkeyformat = keyAttrs.KEYFORMAT || 'identity';\u000a\u000a              if (decryptkeyformat === 'com.apple.streamingkeydelivery') {\u000a                logger["logger"].warn('Keyformat com.apple.streamingkeydelivery is not supported');\u000a                continue;\u000a              }\u000a\u000a              if (decryptmethod) {\u000a                levelkey = new level_key_LevelKey(baseurl, decrypturi);\u000a\u000a                if (decrypturi && ['AES-128', 'SAMPLE-AES', 'SAMPLE-AES-CENC'].indexOf(decryptmethod) >= 0) {\u000a                  levelkey.method = decryptmethod;\u000a                  levelkey.key = null; // Initialization Vector (IV)\u000a\u000a                  levelkey.iv = decryptiv;\u000a                }\u000a              }\u000a\u000a              break;\u000a            }\u000a\u000a          case 'START':\u000a            {\u000a              var startAttrs = new attr_list(value1);\u000a              var startTimeOffset = startAttrs.decimalFloatingPoint('TIME-OFFSET'); // TIME-OFFSET can be 0\u000a\u000a              if (Object(number["isFiniteNumber"])(startTimeOffset)) {\u000a                level.startTimeOffset = startTimeOffset;\u000a              }\u000a\u000a              break;\u000a            }\u000a\u000a          case 'MAP':\u000a            {\u000a              var mapAttrs = new attr_list(value1);\u000a              frag.relurl = mapAttrs.URI;\u000a\u000a              if (mapAttrs.BYTERANGE) {\u000a                frag.setByteRange(mapAttrs.BYTERANGE);\u000a              }\u000a\u000a              frag.baseurl = baseurl;\u000a              frag.level = id;\u000a              frag.type = type;\u000a              frag.sn = 'initSegment';\u000a              level.initSegment = frag;\u000a              frag = new fragment_Fragment();\u000a              frag.rawProgramDateTime = level.initSegment.rawProgramDateTime;\u000a              break;\u000a            }\u000a\u000a          default:\u000a            logger["logger"].warn("line parsed but not handled: " + result);\u000a            break;\u000a        }\u000a      }\u000a    }\u000a\u000a    frag = prevFrag; // logger.log('found ' + level.fragments.length + ' fragments');\u000a\u000a    if (frag && !frag.relurl) {\u000a      level.fragments.pop();\u000a      totalduration -= frag.duration;\u000a    }\u000a\u000a    level.totalduration = totalduration;\u000a    level.averagetargetduration = totalduration / level.fragments.length;\u000a    level.endSN = currentSN - 1;\u000a    level.startCC = level.fragments[0] ? level.fragments[0].cc : 0;\u000a    level.endCC = discontinuityCounter;\u000a\u000a    if (!level.initSegment && level.fragments.length) {\u000a      // this is a bit lurky but HLS really has no other way to tell us\u000a      // if the fragments are TS or MP4, except if we download them :/\u000a      // but this is to be able to handle SIDX.\u000a      if (level.fragments.every(function (frag) {\u000a        return MP4_REGEX_SUFFIX.test(frag.relurl);\u000a      })) {\u000a        logger["logger"].warn('MP4 fragments found but no init segment (probably no MAP, incomplete M3U8), trying to fetch SIDX');\u000a        frag = new fragment_Fragment();\u000a        frag.relurl = level.fragments[0].relurl;\u000a        frag.baseurl = baseurl;\u000a        frag.level = id;\u000a        frag.type = type;\u000a        frag.sn = 'initSegment';\u000a        level.initSegment = frag;\u000a        level.needSidxRanges = true;\u000a      }\u000a    }\u000a    /**\u000a     * Backfill any missing PDT values\u000a       "If the first EXT-X-PROGRAM-DATE-TIME tag in a Playlist appears after\u000a       one or more Media Segment URIs, the client SHOULD extrapolate\u000a       backward from that tag (using EXTINF durations and/or media\u000a       timestamps) to associate dates with those segments."\u000a     * We have already extrapolated forward, but all fragments up to the first instance of PDT do not have their PDTs\u000a     * computed.\u000a     */\u000a\u000a\u000a    if (firstPdtIndex) {\u000a      backfillProgramDateTimes(level.fragments, firstPdtIndex);\u000a    }\u000a\u000a    return level;\u000a  };\u000a\u000a  return M3U8Parser;\u000a}();\u000a\u000a\u000a\u000afunction backfillProgramDateTimes(fragments, startIndex) {\u000a  var fragPrev = fragments[startIndex];\u000a\u000a  for (var i = startIndex - 1; i >= 0; i--) {\u000a    var frag = fragments[i];\u000a    frag.programDateTime = fragPrev.programDateTime - frag.duration * 1000;\u000a    fragPrev = frag;\u000a  }\u000a}\u000a\u000afunction assignProgramDateTime(frag, prevFrag) {\u000a  if (frag.rawProgramDateTime) {\u000a    frag.programDateTime = Date.parse(frag.rawProgramDateTime);\u000a  } else if (prevFrag === null || prevFrag === void 0 ? void 0 : prevFrag.programDateTime) {\u000a    frag.programDateTime = prevFrag.endProgramDateTime;\u000a  }\u000a\u000a  if (!Object(number["isFiniteNumber"])(frag.programDateTime)) {\u000a    frag.programDateTime = null;\u000a    frag.rawProgramDateTime = null;\u000a  }\u000a}\u000a// CONCATENATED MODULE: ./src/loader/playlist-loader.ts\u000a\u000a\u000a\u000afunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/**\u000a * PlaylistLoader - delegate for media manifest/playlist loading tasks. Takes care of parsing media to internal data-models.\u000a *\u000a * Once loaded, dispatches events with parsed data-models of manifest/levels/audio/subtitle tracks.\u000a *\u000a * Uses loader(s) set in config to do actual internal loading of resource tasks.\u000a *\u000a * @module\u000a *\u000a */\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000avar _window = window,\u000a    performance = _window.performance;\u000a/**\u000a * @constructor\u000a */\u000a\u000avar playlist_loader_PlaylistLoader = /*#__PURE__*/function (_EventHandler) {\u000a  _inheritsLoose(PlaylistLoader, _EventHandler);\u000a\u000a  /**\u000a   * @constructs\u000a   * @param {Hls} hls\u000a   */\u000a  function PlaylistLoader(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].MANIFEST_LOADING, events["default"].LEVEL_LOADING, events["default"].AUDIO_TRACK_LOADING, events["default"].SUBTITLE_TRACK_LOADING) || this;\u000a    _this.loaders = {};\u000a    return _this;\u000a  }\u000a  /**\u000a   * @param {PlaylistContextType} type\u000a   * @returns {boolean}\u000a   */\u000a\u000a\u000a  PlaylistLoader.canHaveQualityLevels = function canHaveQualityLevels(type) {\u000a    return type !== PlaylistContextType.AUDIO_TRACK && type !== PlaylistContextType.SUBTITLE_TRACK;\u000a  }\u000a  /**\u000a   * Map context.type to LevelType\u000a   * @param {PlaylistLoaderContext} context\u000a   * @returns {LevelType}\u000a   */\u000a  ;\u000a\u000a  PlaylistLoader.mapContextToLevelType = function mapContextToLevelType(context) {\u000a    var type = context.type;\u000a\u000a    switch (type) {\u000a      case PlaylistContextType.AUDIO_TRACK:\u000a        return PlaylistLevelType.AUDIO;\u000a\u000a      case PlaylistContextType.SUBTITLE_TRACK:\u000a        return PlaylistLevelType.SUBTITLE;\u000a\u000a      default:\u000a        return PlaylistLevelType.MAIN;\u000a    }\u000a  };\u000a\u000a  PlaylistLoader.getResponseUrl = function getResponseUrl(response, context) {\u000a    var url = response.url; // responseURL not supported on some browsers (it is used to detect URL redirection)\u000a    // data-uri mode also not supported (but no need to detect redirection)\u000a\u000a    if (url === undefined || url.indexOf('data:') === 0) {\u000a      // fallback to initial URL\u000a      url = context.url;\u000a    }\u000a\u000a    return url;\u000a  }\u000a  /**\u000a   * Returns defaults or configured loader-type overloads (pLoader and loader config params)\u000a   * Default loader is XHRLoader (see utils)\u000a   * @param {PlaylistLoaderContext} context\u000a   * @returns {Loader} or other compatible configured overload\u000a   */\u000a  ;\u000a\u000a  var _proto = PlaylistLoader.prototype;\u000a\u000a  _proto.createInternalLoader = function createInternalLoader(context) {\u000a    var config = this.hls.config;\u000a    var PLoader = config.pLoader;\u000a    var Loader = config.loader; // TODO(typescript-config): Verify once config is typed that InternalLoader always returns a Loader\u000a\u000a    var InternalLoader = PLoader || Loader;\u000a    var loader = new InternalLoader(config); // TODO - Do we really need to assign the instance or if the dep has been lost\u000a\u000a    context.loader = loader;\u000a    this.loaders[context.type] = loader;\u000a    return loader;\u000a  };\u000a\u000a  _proto.getInternalLoader = function getInternalLoader(context) {\u000a    return this.loaders[context.type];\u000a  };\u000a\u000a  _proto.resetInternalLoader = function resetInternalLoader(contextType) {\u000a    if (this.loaders[contextType]) {\u000a      delete this.loaders[contextType];\u000a    }\u000a  }\u000a  /**\u000a   * Call `destroy` on all internal loader instances mapped (one per context type)\u000a   */\u000a  ;\u000a\u000a  _proto.destroyInternalLoaders = function destroyInternalLoaders() {\u000a    for (var contextType in this.loaders) {\u000a      var loader = this.loaders[contextType];\u000a\u000a      if (loader) {\u000a        loader.destroy();\u000a      }\u000a\u000a      this.resetInternalLoader(contextType);\u000a    }\u000a  };\u000a\u000a  _proto.destroy = function destroy() {\u000a    this.destroyInternalLoaders();\u000a\u000a    _EventHandler.prototype.destroy.call(this);\u000a  };\u000a\u000a  _proto.onManifestLoading = function onManifestLoading(data) {\u000a    this.load({\u000a      url: data.url,\u000a      type: PlaylistContextType.MANIFEST,\u000a      level: 0,\u000a      id: null,\u000a      responseType: 'text'\u000a    });\u000a  };\u000a\u000a  _proto.onLevelLoading = function onLevelLoading(data) {\u000a    this.load({\u000a      url: data.url,\u000a      type: PlaylistContextType.LEVEL,\u000a      level: data.level,\u000a      id: data.id,\u000a      responseType: 'text'\u000a    });\u000a  };\u000a\u000a  _proto.onAudioTrackLoading = function onAudioTrackLoading(data) {\u000a    this.load({\u000a      url: data.url,\u000a      type: PlaylistContextType.AUDIO_TRACK,\u000a      level: null,\u000a      id: data.id,\u000a      responseType: 'text'\u000a    });\u000a  };\u000a\u000a  _proto.onSubtitleTrackLoading = function onSubtitleTrackLoading(data) {\u000a    this.load({\u000a      url: data.url,\u000a      type: PlaylistContextType.SUBTITLE_TRACK,\u000a      level: null,\u000a      id: data.id,\u000a      responseType: 'text'\u000a    });\u000a  };\u000a\u000a  _proto.load = function load(context) {\u000a    var config = this.hls.config;\u000a    logger["logger"].debug("Loading playlist of type " + context.type + ", level: " + context.level + ", id: " + context.id); // Check if a loader for this context already exists\u000a\u000a    var loader = this.getInternalLoader(context);\u000a\u000a    if (loader) {\u000a      var loaderContext = loader.context;\u000a\u000a      if (loaderContext && loaderContext.url === context.url) {\u000a        // same URL can't overlap\u000a        logger["logger"].trace('playlist request ongoing');\u000a        return false;\u000a      } else {\u000a        logger["logger"].warn("aborting previous loader for type: " + context.type);\u000a        loader.abort();\u000a      }\u000a    }\u000a\u000a    var maxRetry;\u000a    var timeout;\u000a    var retryDelay;\u000a    var maxRetryDelay; // apply different configs for retries depending on\u000a    // context (manifest, level, audio/subs playlist)\u000a\u000a    switch (context.type) {\u000a      case PlaylistContextType.MANIFEST:\u000a        maxRetry = config.manifestLoadingMaxRetry;\u000a        timeout = config.manifestLoadingTimeOut;\u000a        retryDelay = config.manifestLoadingRetryDelay;\u000a        maxRetryDelay = config.manifestLoadingMaxRetryTimeout;\u000a        break;\u000a\u000a      case PlaylistContextType.LEVEL:\u000a        // Disable internal loader retry logic, since we are managing retries in Level Controller\u000a        maxRetry = 0;\u000a        maxRetryDelay = 0;\u000a        retryDelay = 0;\u000a        timeout = config.levelLoadingTimeOut; // TODO Introduce retry settings for audio-track and subtitle-track, it should not use level retry config\u000a\u000a        break;\u000a\u000a      default:\u000a        maxRetry = config.levelLoadingMaxRetry;\u000a        timeout = config.levelLoadingTimeOut;\u000a        retryDelay = config.levelLoadingRetryDelay;\u000a        maxRetryDelay = config.levelLoadingMaxRetryTimeout;\u000a        break;\u000a    }\u000a\u000a    loader = this.createInternalLoader(context);\u000a    var loaderConfig = {\u000a      timeout: timeout,\u000a      maxRetry: maxRetry,\u000a      retryDelay: retryDelay,\u000a      maxRetryDelay: maxRetryDelay\u000a    };\u000a    var loaderCallbacks = {\u000a      onSuccess: this.loadsuccess.bind(this),\u000a      onError: this.loaderror.bind(this),\u000a      onTimeout: this.loadtimeout.bind(this)\u000a    };\u000a    logger["logger"].debug("Calling internal loader delegate for URL: " + context.url);\u000a    loader.load(context, loaderConfig, loaderCallbacks);\u000a    return true;\u000a  };\u000a\u000a  _proto.loadsuccess = function loadsuccess(response, stats, context, networkDetails) {\u000a    if (networkDetails === void 0) {\u000a      networkDetails = null;\u000a    }\u000a\u000a    if (context.isSidxRequest) {\u000a      this._handleSidxRequest(response, context);\u000a\u000a      this._handlePlaylistLoaded(response, stats, context, networkDetails);\u000a\u000a      return;\u000a    }\u000a\u000a    this.resetInternalLoader(context.type);\u000a\u000a    if (typeof response.data !== 'string') {\u000a      throw new Error('expected responseType of "text" for PlaylistLoader');\u000a    }\u000a\u000a    var string = response.data;\u000a    stats.tload = performance.now(); // stats.mtime = new Date(target.getResponseHeader('Last-Modified'));\u000a    // Validate if it is an M3U8 at all\u000a\u000a    if (string.indexOf('#EXTM3U') !== 0) {\u000a      this._handleManifestParsingError(response, context, 'no EXTM3U delimiter', networkDetails);\u000a\u000a      return;\u000a    } // Check if chunk-list or master. handle empty chunk list case (first EXTINF not signaled, but TARGETDURATION present)\u000a\u000a\u000a    if (string.indexOf('#EXTINF:') > 0 || string.indexOf('#EXT-X-TARGETDURATION:') > 0) {\u000a      this._handleTrackOrLevelPlaylist(response, stats, context, networkDetails);\u000a    } else {\u000a      this._handleMasterPlaylist(response, stats, context, networkDetails);\u000a    }\u000a  };\u000a\u000a  _proto.loaderror = function loaderror(response, context, networkDetails) {\u000a    if (networkDetails === void 0) {\u000a      networkDetails = null;\u000a    }\u000a\u000a    this._handleNetworkError(context, networkDetails, false, response);\u000a  };\u000a\u000a  _proto.loadtimeout = function loadtimeout(stats, context, networkDetails) {\u000a    if (networkDetails === void 0) {\u000a      networkDetails = null;\u000a    }\u000a\u000a    this._handleNetworkError(context, networkDetails, true);\u000a  } // TODO(typescript-config): networkDetails can currently be a XHR or Fetch impl,\u000a  // but with custom loaders it could be generic investigate this further when config is typed\u000a  ;\u000a\u000a  _proto._handleMasterPlaylist = function _handleMasterPlaylist(response, stats, context, networkDetails) {\u000a    var hls = this.hls;\u000a    var string = response.data;\u000a    var url = PlaylistLoader.getResponseUrl(response, context);\u000a\u000a    var _M3U8Parser$parseMast = m3u8_parser_M3U8Parser.parseMasterPlaylist(string, url),\u000a        levels = _M3U8Parser$parseMast.levels,\u000a        sessionData = _M3U8Parser$parseMast.sessionData;\u000a\u000a    if (!levels.length) {\u000a      this._handleManifestParsingError(response, context, 'no level found in manifest', networkDetails);\u000a\u000a      return;\u000a    } // multi level playlist, parse level info\u000a\u000a\u000a    var audioGroups = levels.map(function (level) {\u000a      return {\u000a        id: level.attrs.AUDIO,\u000a        codec: level.audioCodec\u000a      };\u000a    });\u000a    var audioTracks = m3u8_parser_M3U8Parser.parseMasterPlaylistMedia(string, url, 'AUDIO', audioGroups);\u000a    var subtitles = m3u8_parser_M3U8Parser.parseMasterPlaylistMedia(string, url, 'SUBTITLES');\u000a    var captions = m3u8_parser_M3U8Parser.parseMasterPlaylistMedia(string, url, 'CLOSED-CAPTIONS');\u000a\u000a    if (audioTracks.length) {\u000a      // check if we have found an audio track embedded in main playlist (audio track without URI attribute)\u000a      var embeddedAudioFound = false;\u000a      audioTracks.forEach(function (audioTrack) {\u000a        if (!audioTrack.url) {\u000a          embeddedAudioFound = true;\u000a        }\u000a      }); // if no embedded audio track defined, but audio codec signaled in quality level,\u000a      // we need to signal this main audio track this could happen with playlists with\u000a      // alt audio rendition in which quality levels (main)\u000a      // contains both audio+video. but with mixed audio track not signaled\u000a\u000a      if (embeddedAudioFound === false && levels[0].audioCodec && !levels[0].attrs.AUDIO) {\u000a        logger["logger"].log('audio codec signaled in quality level, but no embedded audio track signaled, create one');\u000a        audioTracks.unshift({\u000a          type: 'main',\u000a          name: 'main',\u000a          default: false,\u000a          autoselect: false,\u000a          forced: false,\u000a          id: -1,\u000a          attrs: {},\u000a          url: ''\u000a        });\u000a      }\u000a    }\u000a\u000a    hls.trigger(events["default"].MANIFEST_LOADED, {\u000a      levels: levels,\u000a      audioTracks: audioTracks,\u000a      subtitles: subtitles,\u000a      captions: captions,\u000a      url: url,\u000a      stats: stats,\u000a      networkDetails: networkDetails,\u000a      sessionData: sessionData\u000a    });\u000a  };\u000a\u000a  _proto._handleTrackOrLevelPlaylist = function _handleTrackOrLevelPlaylist(response, stats, context, networkDetails) {\u000a    var hls = this.hls;\u000a    var id = context.id,\u000a        level = context.level,\u000a        type = context.type;\u000a    var url = PlaylistLoader.getResponseUrl(response, context); // if the values are null, they will result in the else conditional\u000a\u000a    var levelUrlId = Object(number["isFiniteNumber"])(id) ? id : 0;\u000a    var levelId = Object(number["isFiniteNumber"])(level) ? level : levelUrlId;\u000a    var levelType = PlaylistLoader.mapContextToLevelType(context);\u000a    var levelDetails = m3u8_parser_M3U8Parser.parseLevelPlaylist(response.data, url, levelId, levelType, levelUrlId); // set stats on level structure\u000a    // TODO(jstackhouse): why? mixing concerns, is it just treated as value bag?\u000a\u000a    levelDetails.tload = stats.tload;\u000a\u000a    if (!levelDetails.fragments.length) {\u000a      hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].NETWORK_ERROR,\u000a        details: errors["ErrorDetails"].LEVEL_EMPTY_ERROR,\u000a        fatal: false,\u000a        url: url,\u000a        reason: 'no fragments found in level',\u000a        level: typeof context.level === 'number' ? context.level : undefined\u000a      });\u000a      return;\u000a    } // We have done our first request (Manifest-type) and receive\u000a    // not a master playlist but a chunk-list (track/level)\u000a    // We fire the manifest-loaded event anyway with the parsed level-details\u000a    // by creating a single-level structure for it.\u000a\u000a\u000a    if (type === PlaylistContextType.MANIFEST) {\u000a      var singleLevel = {\u000a        url: url,\u000a        details: levelDetails\u000a      };\u000a      hls.trigger(events["default"].MANIFEST_LOADED, {\u000a        levels: [singleLevel],\u000a        audioTracks: [],\u000a        url: url,\u000a        stats: stats,\u000a        networkDetails: networkDetails,\u000a        sessionData: null\u000a      });\u000a    } // save parsing time\u000a\u000a\u000a    stats.tparsed = performance.now(); // in case we need SIDX ranges\u000a    // return early after calling load for\u000a    // the SIDX box.\u000a\u000a    if (levelDetails.needSidxRanges) {\u000a      var sidxUrl = levelDetails.initSegment.url;\u000a      this.load({\u000a        url: sidxUrl,\u000a        isSidxRequest: true,\u000a        type: type,\u000a        level: level,\u000a        levelDetails: levelDetails,\u000a        id: id,\u000a        rangeStart: 0,\u000a        rangeEnd: 2048,\u000a        responseType: 'arraybuffer'\u000a      });\u000a      return;\u000a    } // extend the context with the new levelDetails property\u000a\u000a\u000a    context.levelDetails = levelDetails;\u000a\u000a    this._handlePlaylistLoaded(response, stats, context, networkDetails);\u000a  };\u000a\u000a  _proto._handleSidxRequest = function _handleSidxRequest(response, context) {\u000a    if (typeof response.data === 'string') {\u000a      throw new Error('sidx request must be made with responseType of array buffer');\u000a    }\u000a\u000a    var sidxInfo = mp4demuxer["default"].parseSegmentIndex(new Uint8Array(response.data)); // if provided fragment does not contain sidx, early return\u000a\u000a    if (!sidxInfo) {\u000a      return;\u000a    }\u000a\u000a    var sidxReferences = sidxInfo.references;\u000a    var levelDetails = context.levelDetails;\u000a    sidxReferences.forEach(function (segmentRef, index) {\u000a      var segRefInfo = segmentRef.info;\u000a\u000a      if (!levelDetails) {\u000a        return;\u000a      }\u000a\u000a      var frag = levelDetails.fragments[index];\u000a\u000a      if (frag.byteRange.length === 0) {\u000a        frag.setByteRange(String(1 + segRefInfo.end - segRefInfo.start) + '@' + String(segRefInfo.start));\u000a      }\u000a    });\u000a\u000a    if (levelDetails) {\u000a      levelDetails.initSegment.setByteRange(String(sidxInfo.moovEndOffset) + '@0');\u000a    }\u000a  };\u000a\u000a  _proto._handleManifestParsingError = function _handleManifestParsingError(response, context, reason, networkDetails) {\u000a    this.hls.trigger(events["default"].ERROR, {\u000a      type: errors["ErrorTypes"].NETWORK_ERROR,\u000a      details: errors["ErrorDetails"].MANIFEST_PARSING_ERROR,\u000a      fatal: true,\u000a      url: response.url,\u000a      reason: reason,\u000a      networkDetails: networkDetails\u000a    });\u000a  };\u000a\u000a  _proto._handleNetworkError = function _handleNetworkError(context, networkDetails, timeout, response) {\u000a    if (timeout === void 0) {\u000a      timeout = false;\u000a    }\u000a\u000a    if (response === void 0) {\u000a      response = null;\u000a    }\u000a\u000a    logger["logger"].info("A network error occured while loading a " + context.type + "-type playlist");\u000a    var details;\u000a    var fatal;\u000a    var loader = this.getInternalLoader(context);\u000a\u000a    switch (context.type) {\u000a      case PlaylistContextType.MANIFEST:\u000a        details = timeout ? errors["ErrorDetails"].MANIFEST_LOAD_TIMEOUT : errors["ErrorDetails"].MANIFEST_LOAD_ERROR;\u000a        fatal = true;\u000a        break;\u000a\u000a      case PlaylistContextType.LEVEL:\u000a        details = timeout ? errors["ErrorDetails"].LEVEL_LOAD_TIMEOUT : errors["ErrorDetails"].LEVEL_LOAD_ERROR;\u000a        fatal = false;\u000a        break;\u000a\u000a      case PlaylistContextType.AUDIO_TRACK:\u000a        details = timeout ? errors["ErrorDetails"].AUDIO_TRACK_LOAD_TIMEOUT : errors["ErrorDetails"].AUDIO_TRACK_LOAD_ERROR;\u000a        fatal = false;\u000a        break;\u000a\u000a      default:\u000a        // details = ...?\u000a        fatal = false;\u000a    }\u000a\u000a    if (loader) {\u000a      loader.abort();\u000a      this.resetInternalLoader(context.type);\u000a    } // TODO(typescript-events): when error events are handled, type this\u000a\u000a\u000a    var errorData = {\u000a      type: errors["ErrorTypes"].NETWORK_ERROR,\u000a      details: details,\u000a      fatal: fatal,\u000a      url: context.url,\u000a      loader: loader,\u000a      context: context,\u000a      networkDetails: networkDetails\u000a    };\u000a\u000a    if (response) {\u000a      errorData.response = response;\u000a    }\u000a\u000a    this.hls.trigger(events["default"].ERROR, errorData);\u000a  };\u000a\u000a  _proto._handlePlaylistLoaded = function _handlePlaylistLoaded(response, stats, context, networkDetails) {\u000a    var type = context.type,\u000a        level = context.level,\u000a        id = context.id,\u000a        levelDetails = context.levelDetails;\u000a\u000a    if (!levelDetails || !levelDetails.targetduration) {\u000a      this._handleManifestParsingError(response, context, 'invalid target duration', networkDetails);\u000a\u000a      return;\u000a    }\u000a\u000a    var canHaveLevels = PlaylistLoader.canHaveQualityLevels(context.type);\u000a\u000a    if (canHaveLevels) {\u000a      this.hls.trigger(events["default"].LEVEL_LOADED, {\u000a        details: levelDetails,\u000a        level: level || 0,\u000a        id: id || 0,\u000a        stats: stats,\u000a        networkDetails: networkDetails\u000a      });\u000a    } else {\u000a      switch (type) {\u000a        case PlaylistContextType.AUDIO_TRACK:\u000a          this.hls.trigger(events["default"].AUDIO_TRACK_LOADED, {\u000a            details: levelDetails,\u000a            id: id,\u000a            stats: stats,\u000a            networkDetails: networkDetails\u000a          });\u000a          break;\u000a\u000a        case PlaylistContextType.SUBTITLE_TRACK:\u000a          this.hls.trigger(events["default"].SUBTITLE_TRACK_LOADED, {\u000a            details: levelDetails,\u000a            id: id,\u000a            stats: stats,\u000a            networkDetails: networkDetails\u000a          });\u000a          break;\u000a      }\u000a    }\u000a  };\u000a\u000a  return PlaylistLoader;\u000a}(event_handler);\u000a\u000a/* harmony default export */ var playlist_loader = (playlist_loader_PlaylistLoader);\u000a// CONCATENATED MODULE: ./src/loader/fragment-loader.js\u000a\u000a\u000a\u000afunction fragment_loader_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * Fragment Loader\u000a*/\u000a\u000a\u000a\u000a\u000a\u000avar fragment_loader_FragmentLoader = /*#__PURE__*/function (_EventHandler) {\u000a  fragment_loader_inheritsLoose(FragmentLoader, _EventHandler);\u000a\u000a  function FragmentLoader(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].FRAG_LOADING) || this;\u000a    _this.loaders = {};\u000a    return _this;\u000a  }\u000a\u000a  var _proto = FragmentLoader.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    var loaders = this.loaders;\u000a\u000a    for (var loaderName in loaders) {\u000a      var loader = loaders[loaderName];\u000a\u000a      if (loader) {\u000a        loader.destroy();\u000a      }\u000a    }\u000a\u000a    this.loaders = {};\u000a\u000a    _EventHandler.prototype.destroy.call(this);\u000a  };\u000a\u000a  _proto.onFragLoading = function onFragLoading(data) {\u000a    var frag = data.frag,\u000a        type = frag.type,\u000a        loaders = this.loaders,\u000a        config = this.hls.config,\u000a        FragmentILoader = config.fLoader,\u000a        DefaultILoader = config.loader; // reset fragment state\u000a\u000a    frag.loaded = 0;\u000a    var loader = loaders[type];\u000a\u000a    if (loader) {\u000a      logger["logger"].warn("abort previous fragment loader for type: " + type);\u000a      loader.abort();\u000a    }\u000a\u000a    loader = loaders[type] = frag.loader = config.fLoader ? new FragmentILoader(config) : new DefaultILoader(config);\u000a    var loaderContext, loaderConfig, loaderCallbacks;\u000a    loaderContext = {\u000a      url: frag.url,\u000a      frag: frag,\u000a      responseType: 'arraybuffer',\u000a      progressData: false\u000a    };\u000a    var start = frag.byteRangeStartOffset,\u000a        end = frag.byteRangeEndOffset;\u000a\u000a    if (Object(number["isFiniteNumber"])(start) && Object(number["isFiniteNumber"])(end)) {\u000a      loaderContext.rangeStart = start;\u000a      loaderContext.rangeEnd = end;\u000a    }\u000a\u000a    loaderConfig = {\u000a      timeout: config.fragLoadingTimeOut,\u000a      maxRetry: 0,\u000a      retryDelay: 0,\u000a      maxRetryDelay: config.fragLoadingMaxRetryTimeout\u000a    };\u000a    loaderCallbacks = {\u000a      onSuccess: this.loadsuccess.bind(this),\u000a      onError: this.loaderror.bind(this),\u000a      onTimeout: this.loadtimeout.bind(this),\u000a      onProgress: this.loadprogress.bind(this)\u000a    };\u000a    loader.load(loaderContext, loaderConfig, loaderCallbacks);\u000a  };\u000a\u000a  _proto.loadsuccess = function loadsuccess(response, stats, context, networkDetails) {\u000a    if (networkDetails === void 0) {\u000a      networkDetails = null;\u000a    }\u000a\u000a    var payload = response.data,\u000a        frag = context.frag; // detach fragment loader on load success\u000a\u000a    frag.loader = undefined;\u000a    this.loaders[frag.type] = undefined;\u000a    this.hls.trigger(events["default"].FRAG_LOADED, {\u000a      payload: payload,\u000a      frag: frag,\u000a      stats: stats,\u000a      networkDetails: networkDetails\u000a    });\u000a  };\u000a\u000a  _proto.loaderror = function loaderror(response, context, networkDetails) {\u000a    if (networkDetails === void 0) {\u000a      networkDetails = null;\u000a    }\u000a\u000a    var frag = context.frag;\u000a    var loader = frag.loader;\u000a\u000a    if (loader) {\u000a      loader.abort();\u000a    }\u000a\u000a    this.loaders[frag.type] = undefined;\u000a    this.hls.trigger(events["default"].ERROR, {\u000a      type: errors["ErrorTypes"].NETWORK_ERROR,\u000a      details: errors["ErrorDetails"].FRAG_LOAD_ERROR,\u000a      fatal: false,\u000a      frag: context.frag,\u000a      response: response,\u000a      networkDetails: networkDetails\u000a    });\u000a  };\u000a\u000a  _proto.loadtimeout = function loadtimeout(stats, context, networkDetails) {\u000a    if (networkDetails === void 0) {\u000a      networkDetails = null;\u000a    }\u000a\u000a    var frag = context.frag;\u000a    var loader = frag.loader;\u000a\u000a    if (loader) {\u000a      loader.abort();\u000a    }\u000a\u000a    this.loaders[frag.type] = undefined;\u000a    this.hls.trigger(events["default"].ERROR, {\u000a      type: errors["ErrorTypes"].NETWORK_ERROR,\u000a      details: errors["ErrorDetails"].FRAG_LOAD_TIMEOUT,\u000a      fatal: false,\u000a      frag: context.frag,\u000a      networkDetails: networkDetails\u000a    });\u000a  } // data will be used for progressive parsing\u000a  ;\u000a\u000a  _proto.loadprogress = function loadprogress(stats, context, data, networkDetails) {\u000a    if (networkDetails === void 0) {\u000a      networkDetails = null;\u000a    }\u000a\u000a    // jshint ignore:line\u000a    var frag = context.frag;\u000a    frag.loaded = stats.loaded;\u000a    this.hls.trigger(events["default"].FRAG_LOAD_PROGRESS, {\u000a      frag: frag,\u000a      stats: stats,\u000a      networkDetails: networkDetails\u000a    });\u000a  };\u000a\u000a  return FragmentLoader;\u000a}(event_handler);\u000a\u000a/* harmony default export */ var fragment_loader = (fragment_loader_FragmentLoader);\u000a// CONCATENATED MODULE: ./src/loader/key-loader.ts\u000afunction key_loader_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * Decrypt key Loader\u000a*/\u000a\u000a\u000a\u000a\u000a\u000avar key_loader_KeyLoader = /*#__PURE__*/function (_EventHandler) {\u000a  key_loader_inheritsLoose(KeyLoader, _EventHandler);\u000a\u000a  function KeyLoader(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].KEY_LOADING) || this;\u000a    _this.loaders = {};\u000a    _this.decryptkey = null;\u000a    _this.decrypturl = null;\u000a    return _this;\u000a  }\u000a\u000a  var _proto = KeyLoader.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    for (var loaderName in this.loaders) {\u000a      var loader = this.loaders[loaderName];\u000a\u000a      if (loader) {\u000a        loader.destroy();\u000a      }\u000a    }\u000a\u000a    this.loaders = {};\u000a\u000a    _EventHandler.prototype.destroy.call(this);\u000a  };\u000a\u000a  _proto.onKeyLoading = function onKeyLoading(data) {\u000a    var frag = data.frag;\u000a    var type = frag.type;\u000a    var loader = this.loaders[type];\u000a\u000a    if (!frag.decryptdata) {\u000a      logger["logger"].warn('Missing decryption data on fragment in onKeyLoading');\u000a      return;\u000a    } // Load the key if the uri is different from previous one, or if the decrypt key has not yet been retrieved\u000a\u000a\u000a    var uri = frag.decryptdata.uri;\u000a\u000a    if (uri !== this.decrypturl || this.decryptkey === null) {\u000a      var config = this.hls.config;\u000a\u000a      if (loader) {\u000a        logger["logger"].warn("abort previous key loader for type:" + type);\u000a        loader.abort();\u000a      }\u000a\u000a      if (!uri) {\u000a        logger["logger"].warn('key uri is falsy');\u000a        return;\u000a      }\u000a\u000a      frag.loader = this.loaders[type] = new config.loader(config);\u000a      this.decrypturl = uri;\u000a      this.decryptkey = null;\u000a      var loaderContext = {\u000a        url: uri,\u000a        frag: frag,\u000a        responseType: 'arraybuffer'\u000a      }; // maxRetry is 0 so that instead of retrying the same key on the same variant multiple times,\u000a      // key-loader will trigger an error and rely on stream-controller to handle retry logic.\u000a      // this will also align retry logic with fragment-loader\u000a\u000a      var loaderConfig = {\u000a        timeout: config.fragLoadingTimeOut,\u000a        maxRetry: 0,\u000a        retryDelay: config.fragLoadingRetryDelay,\u000a        maxRetryDelay: config.fragLoadingMaxRetryTimeout\u000a      };\u000a      var loaderCallbacks = {\u000a        onSuccess: this.loadsuccess.bind(this),\u000a        onError: this.loaderror.bind(this),\u000a        onTimeout: this.loadtimeout.bind(this)\u000a      };\u000a      frag.loader.load(loaderContext, loaderConfig, loaderCallbacks);\u000a    } else if (this.decryptkey) {\u000a      // Return the key if it's already been loaded\u000a      frag.decryptdata.key = this.decryptkey;\u000a      this.hls.trigger(events["default"].KEY_LOADED, {\u000a        frag: frag\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.loadsuccess = function loadsuccess(response, stats, context) {\u000a    var frag = context.frag;\u000a\u000a    if (!frag.decryptdata) {\u000a      logger["logger"].error('after key load, decryptdata unset');\u000a      return;\u000a    }\u000a\u000a    this.decryptkey = frag.decryptdata.key = new Uint8Array(response.data); // detach fragment loader on load success\u000a\u000a    frag.loader = undefined;\u000a    delete this.loaders[frag.type];\u000a    this.hls.trigger(events["default"].KEY_LOADED, {\u000a      frag: frag\u000a    });\u000a  };\u000a\u000a  _proto.loaderror = function loaderror(response, context) {\u000a    var frag = context.frag;\u000a    var loader = frag.loader;\u000a\u000a    if (loader) {\u000a      loader.abort();\u000a    }\u000a\u000a    delete this.loaders[frag.type];\u000a    this.hls.trigger(events["default"].ERROR, {\u000a      type: errors["ErrorTypes"].NETWORK_ERROR,\u000a      details: errors["ErrorDetails"].KEY_LOAD_ERROR,\u000a      fatal: false,\u000a      frag: frag,\u000a      response: response\u000a    });\u000a  };\u000a\u000a  _proto.loadtimeout = function loadtimeout(stats, context) {\u000a    var frag = context.frag;\u000a    var loader = frag.loader;\u000a\u000a    if (loader) {\u000a      loader.abort();\u000a    }\u000a\u000a    delete this.loaders[frag.type];\u000a    this.hls.trigger(events["default"].ERROR, {\u000a      type: errors["ErrorTypes"].NETWORK_ERROR,\u000a      details: errors["ErrorDetails"].KEY_LOAD_TIMEOUT,\u000a      fatal: false,\u000a      frag: frag\u000a    });\u000a  };\u000a\u000a  return KeyLoader;\u000a}(event_handler);\u000a\u000a/* harmony default export */ var key_loader = (key_loader_KeyLoader);\u000a// CONCATENATED MODULE: ./src/controller/fragment-tracker.js\u000a\u000a\u000afunction fragment_tracker_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a\u000a\u000avar FragmentState = {\u000a  NOT_LOADED: 'NOT_LOADED',\u000a  APPENDING: 'APPENDING',\u000a  PARTIAL: 'PARTIAL',\u000a  OK: 'OK'\u000a};\u000avar fragment_tracker_FragmentTracker = /*#__PURE__*/function (_EventHandler) {\u000a  fragment_tracker_inheritsLoose(FragmentTracker, _EventHandler);\u000a\u000a  function FragmentTracker(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].BUFFER_APPENDED, events["default"].FRAG_BUFFERED, events["default"].FRAG_LOADED) || this;\u000a    _this.bufferPadding = 0.2;\u000a    _this.fragments = Object.create(null);\u000a    _this.timeRanges = Object.create(null);\u000a    _this.config = hls.config;\u000a    return _this;\u000a  }\u000a\u000a  var _proto = FragmentTracker.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    this.fragments = Object.create(null);\u000a    this.timeRanges = Object.create(null);\u000a    this.config = null;\u000a    event_handler.prototype.destroy.call(this);\u000a\u000a    _EventHandler.prototype.destroy.call(this);\u000a  }\u000a  /**\u000a   * Return a Fragment that match the position and levelType.\u000a   * If not found any Fragment, return null\u000a   * @param {number} position\u000a   * @param {LevelType} levelType\u000a   * @returns {Fragment|null}\u000a   */\u000a  ;\u000a\u000a  _proto.getBufferedFrag = function getBufferedFrag(position, levelType) {\u000a    var fragments = this.fragments;\u000a    var bufferedFrags = Object.keys(fragments).filter(function (key) {\u000a      var fragmentEntity = fragments[key];\u000a\u000a      if (fragmentEntity.body.type !== levelType) {\u000a        return false;\u000a      }\u000a\u000a      if (!fragmentEntity.buffered) {\u000a        return false;\u000a      }\u000a\u000a      var frag = fragmentEntity.body;\u000a      return frag.startPTS <= position && position <= frag.endPTS;\u000a    });\u000a\u000a    if (bufferedFrags.length === 0) {\u000a      return null;\u000a    } else {\u000a      // https://github.com/video-dev/hls.js/pull/1545#discussion_r166229566\u000a      var bufferedFragKey = bufferedFrags.pop();\u000a      return fragments[bufferedFragKey].body;\u000a    }\u000a  }\u000a  /**\u000a   * Partial fragments effected by coded frame eviction will be removed\u000a   * The browser will unload parts of the buffer to free up memory for new buffer data\u000a   * Fragments will need to be reloaded when the buffer is freed up, removing partial fragments will allow them to reload(since there might be parts that are still playable)\u000a   * @param {String} elementaryStream The elementaryStream of media this is (eg. video/audio)\u000a   * @param {TimeRanges} timeRange TimeRange object from a sourceBuffer\u000a   */\u000a  ;\u000a\u000a  _proto.detectEvictedFragments = function detectEvictedFragments(elementaryStream, timeRange) {\u000a    var _this2 = this;\u000a\u000a    // Check if any flagged fragments have been unloaded\u000a    Object.keys(this.fragments).forEach(function (key) {\u000a      var fragmentEntity = _this2.fragments[key];\u000a\u000a      if (!fragmentEntity || !fragmentEntity.buffered) {\u000a        return;\u000a      }\u000a\u000a      var esData = fragmentEntity.range[elementaryStream];\u000a\u000a      if (!esData) {\u000a        return;\u000a      }\u000a\u000a      var fragmentTimes = esData.time;\u000a\u000a      for (var i = 0; i < fragmentTimes.length; i++) {\u000a        var time = fragmentTimes[i];\u000a\u000a        if (!_this2.isTimeBuffered(time.startPTS, time.endPTS, timeRange)) {\u000a          // Unregister partial fragment as it needs to load again to be reused\u000a          _this2.removeFragment(fragmentEntity.body);\u000a\u000a          break;\u000a        }\u000a      }\u000a    });\u000a  }\u000a  /**\u000a   * Checks if the fragment passed in is loaded in the buffer properly\u000a   * Partially loaded fragments will be registered as a partial fragment\u000a   * @param {Object} fragment Check the fragment against all sourceBuffers loaded\u000a   */\u000a  ;\u000a\u000a  _proto.detectPartialFragments = function detectPartialFragments(fragment) {\u000a    var _this3 = this;\u000a\u000a    var fragKey = this.getFragmentKey(fragment);\u000a    var fragmentEntity = this.fragments[fragKey];\u000a\u000a    if (fragmentEntity) {\u000a      fragmentEntity.buffered = true;\u000a      Object.keys(this.timeRanges).forEach(function (elementaryStream) {\u000a        if (fragment.hasElementaryStream(elementaryStream)) {\u000a          var timeRange = _this3.timeRanges[elementaryStream]; // Check for malformed fragments\u000a          // Gaps need to be calculated for each elementaryStream\u000a\u000a          fragmentEntity.range[elementaryStream] = _this3.getBufferedTimes(fragment.startPTS, fragment.endPTS, timeRange);\u000a        }\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.getBufferedTimes = function getBufferedTimes(startPTS, endPTS, timeRange) {\u000a    var fragmentTimes = [];\u000a    var startTime, endTime;\u000a    var fragmentPartial = false;\u000a\u000a    for (var i = 0; i < timeRange.length; i++) {\u000a      startTime = timeRange.start(i) - this.bufferPadding;\u000a      endTime = timeRange.end(i) + this.bufferPadding;\u000a\u000a      if (startPTS >= startTime && endPTS <= endTime) {\u000a        // Fragment is entirely contained in buffer\u000a        // No need to check the other timeRange times since it's completely playable\u000a        fragmentTimes.push({\u000a          startPTS: Math.max(startPTS, timeRange.start(i)),\u000a          endPTS: Math.min(endPTS, timeRange.end(i))\u000a        });\u000a        break;\u000a      } else if (startPTS < endTime && endPTS > startTime) {\u000a        // Check for intersection with buffer\u000a        // Get playable sections of the fragment\u000a        fragmentTimes.push({\u000a          startPTS: Math.max(startPTS, timeRange.start(i)),\u000a          endPTS: Math.min(endPTS, timeRange.end(i))\u000a        });\u000a        fragmentPartial = true;\u000a      } else if (endPTS <= startTime) {\u000a        // No need to check the rest of the timeRange as it is in order\u000a        break;\u000a      }\u000a    }\u000a\u000a    return {\u000a      time: fragmentTimes,\u000a      partial: fragmentPartial\u000a    };\u000a  };\u000a\u000a  _proto.getFragmentKey = function getFragmentKey(fragment) {\u000a    return fragment.type + "_" + fragment.level + "_" + fragment.urlId + "_" + fragment.sn;\u000a  }\u000a  /**\u000a   * Gets the partial fragment for a certain time\u000a   * @param {Number} time\u000a   * @returns {Object} fragment Returns a partial fragment at a time or null if there is no partial fragment\u000a   */\u000a  ;\u000a\u000a  _proto.getPartialFragment = function getPartialFragment(time) {\u000a    var _this4 = this;\u000a\u000a    var timePadding, startTime, endTime;\u000a    var bestFragment = null;\u000a    var bestOverlap = 0;\u000a    Object.keys(this.fragments).forEach(function (key) {\u000a      var fragmentEntity = _this4.fragments[key];\u000a\u000a      if (_this4.isPartial(fragmentEntity)) {\u000a        startTime = fragmentEntity.body.startPTS - _this4.bufferPadding;\u000a        endTime = fragmentEntity.body.endPTS + _this4.bufferPadding;\u000a\u000a        if (time >= startTime && time <= endTime) {\u000a          // Use the fragment that has the most padding from start and end time\u000a          timePadding = Math.min(time - startTime, endTime - time);\u000a\u000a          if (bestOverlap <= timePadding) {\u000a            bestFragment = fragmentEntity.body;\u000a            bestOverlap = timePadding;\u000a          }\u000a        }\u000a      }\u000a    });\u000a    return bestFragment;\u000a  }\u000a  /**\u000a   * @param {Object} fragment The fragment to check\u000a   * @returns {String} Returns the fragment state when a fragment never loaded or if it partially loaded\u000a   */\u000a  ;\u000a\u000a  _proto.getState = function getState(fragment) {\u000a    var fragKey = this.getFragmentKey(fragment);\u000a    var fragmentEntity = this.fragments[fragKey];\u000a    var state = FragmentState.NOT_LOADED;\u000a\u000a    if (fragmentEntity !== undefined) {\u000a      if (!fragmentEntity.buffered) {\u000a        state = FragmentState.APPENDING;\u000a      } else if (this.isPartial(fragmentEntity) === true) {\u000a        state = FragmentState.PARTIAL;\u000a      } else {\u000a        state = FragmentState.OK;\u000a      }\u000a    }\u000a\u000a    return state;\u000a  };\u000a\u000a  _proto.isPartial = function isPartial(fragmentEntity) {\u000a    return fragmentEntity.buffered === true && (fragmentEntity.range.video !== undefined && fragmentEntity.range.video.partial === true || fragmentEntity.range.audio !== undefined && fragmentEntity.range.audio.partial === true);\u000a  };\u000a\u000a  _proto.isTimeBuffered = function isTimeBuffered(startPTS, endPTS, timeRange) {\u000a    var startTime, endTime;\u000a\u000a    for (var i = 0; i < timeRange.length; i++) {\u000a      startTime = timeRange.start(i) - this.bufferPadding;\u000a      endTime = timeRange.end(i) + this.bufferPadding;\u000a\u000a      if (startPTS >= startTime && endPTS <= endTime) {\u000a        return true;\u000a      }\u000a\u000a      if (endPTS <= startTime) {\u000a        // No need to check the rest of the timeRange as it is in order\u000a        return false;\u000a      }\u000a    }\u000a\u000a    return false;\u000a  }\u000a  /**\u000a   * Fires when a fragment loading is completed\u000a   */\u000a  ;\u000a\u000a  _proto.onFragLoaded = function onFragLoaded(e) {\u000a    var fragment = e.frag; // don't track initsegment (for which sn is not a number)\u000a    // don't track frags used for bitrateTest, they're irrelevant.\u000a\u000a    if (!Object(number["isFiniteNumber"])(fragment.sn) || fragment.bitrateTest) {\u000a      return;\u000a    }\u000a\u000a    this.fragments[this.getFragmentKey(fragment)] = {\u000a      body: fragment,\u000a      range: Object.create(null),\u000a      buffered: false\u000a    };\u000a  }\u000a  /**\u000a   * Fires when the buffer is updated\u000a   */\u000a  ;\u000a\u000a  _proto.onBufferAppended = function onBufferAppended(e) {\u000a    var _this5 = this;\u000a\u000a    // Store the latest timeRanges loaded in the buffer\u000a    this.timeRanges = e.timeRanges;\u000a    Object.keys(this.timeRanges).forEach(function (elementaryStream) {\u000a      var timeRange = _this5.timeRanges[elementaryStream];\u000a\u000a      _this5.detectEvictedFragments(elementaryStream, timeRange);\u000a    });\u000a  }\u000a  /**\u000a   * Fires after a fragment has been loaded into the source buffer\u000a   */\u000a  ;\u000a\u000a  _proto.onFragBuffered = function onFragBuffered(e) {\u000a    this.detectPartialFragments(e.frag);\u000a  }\u000a  /**\u000a   * Return true if fragment tracker has the fragment.\u000a   * @param {Object} fragment\u000a   * @returns {boolean}\u000a   */\u000a  ;\u000a\u000a  _proto.hasFragment = function hasFragment(fragment) {\u000a    var fragKey = this.getFragmentKey(fragment);\u000a    return this.fragments[fragKey] !== undefined;\u000a  }\u000a  /**\u000a   * Remove a fragment from fragment tracker until it is loaded again\u000a   * @param {Object} fragment The fragment to remove\u000a   */\u000a  ;\u000a\u000a  _proto.removeFragment = function removeFragment(fragment) {\u000a    var fragKey = this.getFragmentKey(fragment);\u000a    delete this.fragments[fragKey];\u000a  }\u000a  /**\u000a   * Remove all fragments from fragment tracker.\u000a   */\u000a  ;\u000a\u000a  _proto.removeAllFragments = function removeAllFragments() {\u000a    this.fragments = Object.create(null);\u000a  };\u000a\u000a  return FragmentTracker;\u000a}(event_handler);\u000a// CONCATENATED MODULE: ./src/utils/binary-search.ts\u000avar BinarySearch = {\u000a  /**\u000a   * Searches for an item in an array which matches a certain condition.\u000a   * This requires the condition to only match one item in the array,\u000a   * and for the array to be ordered.\u000a   *\u000a   * @param {Array<T>} list The array to search.\u000a   * @param {BinarySearchComparison<T>} comparisonFn\u000a   *      Called and provided a candidate item as the first argument.\u000a   *      Should return:\u000a   *          > -1 if the item should be located at a lower index than the provided item.\u000a   *          > 1 if the item should be located at a higher index than the provided item.\u000a   *          > 0 if the item is the item you're looking for.\u000a   *\u000a   * @return {T | null} The object if it is found or null otherwise.\u000a   */\u000a  search: function search(list, comparisonFn) {\u000a    var minIndex = 0;\u000a    var maxIndex = list.length - 1;\u000a    var currentIndex = null;\u000a    var currentElement = null;\u000a\u000a    while (minIndex <= maxIndex) {\u000a      currentIndex = (minIndex + maxIndex) / 2 | 0;\u000a      currentElement = list[currentIndex];\u000a      var comparisonResult = comparisonFn(currentElement);\u000a\u000a      if (comparisonResult > 0) {\u000a        minIndex = currentIndex + 1;\u000a      } else if (comparisonResult < 0) {\u000a        maxIndex = currentIndex - 1;\u000a      } else {\u000a        return currentElement;\u000a      }\u000a    }\u000a\u000a    return null;\u000a  }\u000a};\u000a/* harmony default export */ var binary_search = (BinarySearch);\u000a// CONCATENATED MODULE: ./src/utils/buffer-helper.ts\u000a/**\u000a * @module BufferHelper\u000a *\u000a * Providing methods dealing with buffer length retrieval for example.\u000a *\u000a * In general, a helper around HTML5 MediaElement TimeRanges gathered from `buffered` property.\u000a *\u000a * Also @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/buffered\u000a*/\u000avar BufferHelper = /*#__PURE__*/function () {\u000a  function BufferHelper() {}\u000a\u000a  /**\u000a   * Return true if `media`'s buffered include `position`\u000a   * @param {Bufferable} media\u000a   * @param {number} position\u000a   * @returns {boolean}\u000a   */\u000a  BufferHelper.isBuffered = function isBuffered(media, position) {\u000a    try {\u000a      if (media) {\u000a        var buffered = media.buffered;\u000a\u000a        for (var i = 0; i < buffered.length; i++) {\u000a          if (position >= buffered.start(i) && position <= buffered.end(i)) {\u000a            return true;\u000a          }\u000a        }\u000a      }\u000a    } catch (error) {// this is to catch\u000a      // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':\u000a      // This SourceBuffer has been removed from the parent media source\u000a    }\u000a\u000a    return false;\u000a  };\u000a\u000a  BufferHelper.bufferInfo = function bufferInfo(media, pos, maxHoleDuration) {\u000a    try {\u000a      if (media) {\u000a        var vbuffered = media.buffered;\u000a        var buffered = [];\u000a        var i;\u000a\u000a        for (i = 0; i < vbuffered.length; i++) {\u000a          buffered.push({\u000a            start: vbuffered.start(i),\u000a            end: vbuffered.end(i)\u000a          });\u000a        }\u000a\u000a        return this.bufferedInfo(buffered, pos, maxHoleDuration);\u000a      }\u000a    } catch (error) {// this is to catch\u000a      // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':\u000a      // This SourceBuffer has been removed from the parent media source\u000a    }\u000a\u000a    return {\u000a      len: 0,\u000a      start: pos,\u000a      end: pos,\u000a      nextStart: undefined\u000a    };\u000a  };\u000a\u000a  BufferHelper.bufferedInfo = function bufferedInfo(buffered, pos, maxHoleDuration) {\u000a    // sort on buffer.start/smaller end (IE does not always return sorted buffered range)\u000a    buffered.sort(function (a, b) {\u000a      var diff = a.start - b.start;\u000a\u000a      if (diff) {\u000a        return diff;\u000a      } else {\u000a        return b.end - a.end;\u000a      }\u000a    });\u000a    var buffered2 = [];\u000a\u000a    if (maxHoleDuration) {\u000a      // there might be some small holes between buffer time range\u000a      // consider that holes smaller than maxHoleDuration are irrelevant and build another\u000a      // buffer time range representations that discards those holes\u000a      for (var i = 0; i < buffered.length; i++) {\u000a        var buf2len = buffered2.length;\u000a\u000a        if (buf2len) {\u000a          var buf2end = buffered2[buf2len - 1].end; // if small hole (value between 0 or maxHoleDuration ) or overlapping (negative)\u000a\u000a          if (buffered[i].start - buf2end < maxHoleDuration) {\u000a            // merge overlapping time ranges\u000a            // update lastRange.end only if smaller than item.end\u000a            // e.g.  [ 1, 15] with  [ 2,8] => [ 1,15] (no need to modify lastRange.end)\u000a            // whereas [ 1, 8] with  [ 2,15] => [ 1,15] ( lastRange should switch from [1,8] to [1,15])\u000a            if (buffered[i].end > buf2end) {\u000a              buffered2[buf2len - 1].end = buffered[i].end;\u000a            }\u000a          } else {\u000a            // big hole\u000a            buffered2.push(buffered[i]);\u000a          }\u000a        } else {\u000a          // first value\u000a          buffered2.push(buffered[i]);\u000a        }\u000a      }\u000a    } else {\u000a      buffered2 = buffered;\u000a    }\u000a\u000a    var bufferLen = 0; // bufferStartNext can possibly be undefined based on the conditional logic below\u000a\u000a    var bufferStartNext; // bufferStart and bufferEnd are buffer boundaries around current video position\u000a\u000a    var bufferStart = pos;\u000a    var bufferEnd = pos;\u000a\u000a    for (var _i = 0; _i < buffered2.length; _i++) {\u000a      var start = buffered2[_i].start,\u000a          end = buffered2[_i].end; // logger.log('buf start/end:' + buffered.start(i) + '/' + buffered.end(i));\u000a\u000a      if (pos + maxHoleDuration >= start && pos < end) {\u000a        // play position is inside this buffer TimeRange, retrieve end of buffer position and buffer length\u000a        bufferStart = start;\u000a        bufferEnd = end;\u000a        bufferLen = bufferEnd - pos;\u000a      } else if (pos + maxHoleDuration < start) {\u000a        bufferStartNext = start;\u000a        break;\u000a      }\u000a    }\u000a\u000a    return {\u000a      len: bufferLen,\u000a      start: bufferStart,\u000a      end: bufferEnd,\u000a      nextStart: bufferStartNext\u000a    };\u000a  };\u000a\u000a  return BufferHelper;\u000a}();\u000a// EXTERNAL MODULE: ./node_modules/eventemitter3/index.js\u000avar eventemitter3 = __webpack_require__("./node_modules/eventemitter3/index.js");\u000a\u000a// EXTERNAL MODULE: ./node_modules/webworkify-webpack/index.js\u000avar webworkify_webpack = __webpack_require__("./node_modules/webworkify-webpack/index.js");\u000a\u000a// EXTERNAL MODULE: ./src/demux/demuxer-inline.js + 12 modules\u000avar demuxer_inline = __webpack_require__("./src/demux/demuxer-inline.js");\u000a\u000a// CONCATENATED MODULE: ./src/utils/mediasource-helper.ts\u000a/**\u000a * MediaSource helper\u000a */\u000afunction getMediaSource() {\u000a  return window.MediaSource || window.WebKitMediaSource;\u000a}\u000a// EXTERNAL MODULE: ./src/utils/get-self-scope.js\u000avar get_self_scope = __webpack_require__("./src/utils/get-self-scope.js");\u000a\u000a// CONCATENATED MODULE: ./src/observer.ts\u000afunction observer_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a\u000a/**\u000a * Simple adapter sub-class of Nodejs-like EventEmitter.\u000a */\u000a\u000avar Observer = /*#__PURE__*/function (_EventEmitter) {\u000a  observer_inheritsLoose(Observer, _EventEmitter);\u000a\u000a  function Observer() {\u000a    return _EventEmitter.apply(this, arguments) || this;\u000a  }\u000a\u000a  var _proto = Observer.prototype;\u000a\u000a  /**\u000a   * We simply want to pass along the event-name itself\u000a   * in every call to a handler, which is the purpose of our `trigger` method\u000a   * extending the standard API.\u000a   */\u000a  _proto.trigger = function trigger(event) {\u000a    for (var _len = arguments.length, data = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\u000a      data[_key - 1] = arguments[_key];\u000a    }\u000a\u000a    this.emit.apply(this, [event, event].concat(data));\u000a  };\u000a\u000a  return Observer;\u000a}(eventemitter3["EventEmitter"]);\u000a// CONCATENATED MODULE: ./src/demux/demuxer.js\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a // see https://stackoverflow.com/a/11237259/589493\u000a\u000avar global = Object(get_self_scope["getSelfScope"])(); // safeguard for code that might run both on worker and main thread\u000a\u000avar demuxer_MediaSource = getMediaSource() || {\u000a  isTypeSupported: function isTypeSupported() {\u000a    return false;\u000a  }\u000a};\u000a\u000avar demuxer_Demuxer = /*#__PURE__*/function () {\u000a  function Demuxer(hls, id) {\u000a    var _this = this;\u000a\u000a    this.hls = hls;\u000a    this.id = id;\u000a    var observer = this.observer = new Observer();\u000a    var config = hls.config;\u000a\u000a    var forwardMessage = function forwardMessage(ev, data) {\u000a      data = data || {};\u000a      data.frag = _this.frag;\u000a      data.id = _this.id;\u000a      hls.trigger(ev, data);\u000a    }; // forward events to main thread\u000a\u000a\u000a    observer.on(events["default"].FRAG_DECRYPTED, forwardMessage);\u000a    observer.on(events["default"].FRAG_PARSING_INIT_SEGMENT, forwardMessage);\u000a    observer.on(events["default"].FRAG_PARSING_DATA, forwardMessage);\u000a    observer.on(events["default"].FRAG_PARSED, forwardMessage);\u000a    observer.on(events["default"].ERROR, forwardMessage);\u000a    observer.on(events["default"].FRAG_PARSING_METADATA, forwardMessage);\u000a    observer.on(events["default"].FRAG_PARSING_USERDATA, forwardMessage);\u000a    observer.on(events["default"].INIT_PTS_FOUND, forwardMessage);\u000a    var typeSupported = {\u000a      mp4: demuxer_MediaSource.isTypeSupported('video/mp4'),\u000a      mpeg: demuxer_MediaSource.isTypeSupported('audio/mpeg'),\u000a      mp3: demuxer_MediaSource.isTypeSupported('audio/mp4; codecs="mp3"')\u000a    }; // navigator.vendor is not always available in Web Worker\u000a    // refer to https://developer.mozilla.org/en-US/docs/Web/API/WorkerGlobalScope/navigator\u000a\u000a    var vendor = navigator.vendor;\u000a\u000a    if (config.enableWorker && typeof Worker !== 'undefined') {\u000a      logger["logger"].log('demuxing in webworker');\u000a      var w;\u000a\u000a      try {\u000a        w = this.w = webworkify_webpack(/*require.resolve*/(/*! ../demux/demuxer-worker.js */ "./src/demux/demuxer-worker.js"));\u000a        this.onwmsg = this.onWorkerMessage.bind(this);\u000a        w.addEventListener('message', this.onwmsg);\u000a\u000a        w.onerror = function (event) {\u000a          hls.trigger(events["default"].ERROR, {\u000a            type: errors["ErrorTypes"].OTHER_ERROR,\u000a            details: errors["ErrorDetails"].INTERNAL_EXCEPTION,\u000a            fatal: true,\u000a            event: 'demuxerWorker',\u000a            err: {\u000a              message: event.message + ' (' + event.filename + ':' + event.lineno + ')'\u000a            }\u000a          });\u000a        };\u000a\u000a        w.postMessage({\u000a          cmd: 'init',\u000a          typeSupported: typeSupported,\u000a          vendor: vendor,\u000a          id: id,\u000a          config: JSON.stringify(config)\u000a        });\u000a      } catch (err) {\u000a        logger["logger"].warn('Error in worker:', err);\u000a        logger["logger"].error('Error while initializing DemuxerWorker, fallback on DemuxerInline');\u000a\u000a        if (w) {\u000a          // revoke the Object URL that was used to create demuxer worker, so as not to leak it\u000a          global.URL.revokeObjectURL(w.objectURL);\u000a        }\u000a\u000a        this.demuxer = new demuxer_inline["default"](observer, typeSupported, config, vendor);\u000a        this.w = undefined;\u000a      }\u000a    } else {\u000a      this.demuxer = new demuxer_inline["default"](observer, typeSupported, config, vendor);\u000a    }\u000a  }\u000a\u000a  var _proto = Demuxer.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    var w = this.w;\u000a\u000a    if (w) {\u000a      w.removeEventListener('message', this.onwmsg);\u000a      w.terminate();\u000a      this.w = null;\u000a    } else {\u000a      var demuxer = this.demuxer;\u000a\u000a      if (demuxer) {\u000a        demuxer.destroy();\u000a        this.demuxer = null;\u000a      }\u000a    }\u000a\u000a    var observer = this.observer;\u000a\u000a    if (observer) {\u000a      observer.removeAllListeners();\u000a      this.observer = null;\u000a    }\u000a  };\u000a\u000a  _proto.push = function push(data, initSegment, audioCodec, videoCodec, frag, duration, accurateTimeOffset, defaultInitPTS) {\u000a    var w = this.w;\u000a    var timeOffset = Object(number["isFiniteNumber"])(frag.startPTS) ? frag.startPTS : frag.start;\u000a    var decryptdata = frag.decryptdata;\u000a    var lastFrag = this.frag;\u000a    var discontinuity = !(lastFrag && frag.cc === lastFrag.cc);\u000a    var trackSwitch = !(lastFrag && frag.level === lastFrag.level);\u000a    var nextSN = lastFrag && frag.sn === lastFrag.sn + 1;\u000a    var contiguous = !trackSwitch && nextSN;\u000a\u000a    if (discontinuity) {\u000a      logger["logger"].log(this.id + ":discontinuity detected");\u000a    }\u000a\u000a    if (trackSwitch) {\u000a      logger["logger"].log(this.id + ":switch detected");\u000a    }\u000a\u000a    this.frag = frag;\u000a\u000a    if (w) {\u000a      // post fragment payload as transferable objects for ArrayBuffer (no copy)\u000a      w.postMessage({\u000a        cmd: 'demux',\u000a        data: data,\u000a        decryptdata: decryptdata,\u000a        initSegment: initSegment,\u000a        audioCodec: audioCodec,\u000a        videoCodec: videoCodec,\u000a        timeOffset: timeOffset,\u000a        discontinuity: discontinuity,\u000a        trackSwitch: trackSwitch,\u000a        contiguous: contiguous,\u000a        duration: duration,\u000a        accurateTimeOffset: accurateTimeOffset,\u000a        defaultInitPTS: defaultInitPTS\u000a      }, data instanceof ArrayBuffer ? [data] : []);\u000a    } else {\u000a      var demuxer = this.demuxer;\u000a\u000a      if (demuxer) {\u000a        demuxer.push(data, decryptdata, initSegment, audioCodec, videoCodec, timeOffset, discontinuity, trackSwitch, contiguous, duration, accurateTimeOffset, defaultInitPTS);\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onWorkerMessage = function onWorkerMessage(ev) {\u000a    var data = ev.data,\u000a        hls = this.hls;\u000a\u000a    switch (data.event) {\u000a      case 'init':\u000a        // revoke the Object URL that was used to create demuxer worker, so as not to leak it\u000a        global.URL.revokeObjectURL(this.w.objectURL);\u000a        break;\u000a      // special case for FRAG_PARSING_DATA: data1 and data2 are transferable objects\u000a\u000a      case events["default"].FRAG_PARSING_DATA:\u000a        data.data.data1 = new Uint8Array(data.data1);\u000a\u000a        if (data.data2) {\u000a          data.data.data2 = new Uint8Array(data.data2);\u000a        }\u000a\u000a      /* falls through */\u000a\u000a      default:\u000a        data.data = data.data || {};\u000a        data.data.frag = this.frag;\u000a        data.data.id = this.id;\u000a        hls.trigger(data.event, data.data);\u000a        break;\u000a    }\u000a  };\u000a\u000a  return Demuxer;\u000a}();\u000a\u000a/* harmony default export */ var demux_demuxer = (demuxer_Demuxer);\u000a// CONCATENATED MODULE: ./src/controller/level-helper.js\u000a\u000a\u000a\u000a\u000a\u000a/**\u000a * @module LevelHelper\u000a *\u000a * Providing methods dealing with playlist sliding and drift\u000a *\u000a * TODO: Create an actual `Level` class/model that deals with all this logic in an object-oriented-manner.\u000a *\u000a * */\u000a\u000afunction addGroupId(level, type, id) {\u000a  switch (type) {\u000a    case 'audio':\u000a      if (!level.audioGroupIds) {\u000a        level.audioGroupIds = [];\u000a      }\u000a\u000a      level.audioGroupIds.push(id);\u000a      break;\u000a\u000a    case 'text':\u000a      if (!level.textGroupIds) {\u000a        level.textGroupIds = [];\u000a      }\u000a\u000a      level.textGroupIds.push(id);\u000a      break;\u000a  }\u000a}\u000afunction updatePTS(fragments, fromIdx, toIdx) {\u000a  var fragFrom = fragments[fromIdx],\u000a      fragTo = fragments[toIdx],\u000a      fragToPTS = fragTo.startPTS; // if we know startPTS[toIdx]\u000a\u000a  if (Object(number["isFiniteNumber"])(fragToPTS)) {\u000a    // update fragment duration.\u000a    // it helps to fix drifts between playlist reported duration and fragment real duration\u000a    if (toIdx > fromIdx) {\u000a      fragFrom.duration = fragToPTS - fragFrom.start;\u000a\u000a      if (fragFrom.duration < 0) {\u000a        logger["logger"].warn("negative duration computed for frag " + fragFrom.sn + ",level " + fragFrom.level + ", there should be some duration drift between playlist and fragment!");\u000a      }\u000a    } else {\u000a      fragTo.duration = fragFrom.start - fragToPTS;\u000a\u000a      if (fragTo.duration < 0) {\u000a        logger["logger"].warn("negative duration computed for frag " + fragTo.sn + ",level " + fragTo.level + ", there should be some duration drift between playlist and fragment!");\u000a      }\u000a    }\u000a  } else {\u000a    // we dont know startPTS[toIdx]\u000a    if (toIdx > fromIdx) {\u000a      fragTo.start = fragFrom.start + fragFrom.duration;\u000a    } else {\u000a      fragTo.start = Math.max(fragFrom.start - fragTo.duration, 0);\u000a    }\u000a  }\u000a}\u000afunction updateFragPTSDTS(details, frag, startPTS, endPTS, startDTS, endDTS) {\u000a  // update frag PTS/DTS\u000a  var maxStartPTS = startPTS;\u000a\u000a  if (Object(number["isFiniteNumber"])(frag.startPTS)) {\u000a    // delta PTS between audio and video\u000a    var deltaPTS = Math.abs(frag.startPTS - startPTS);\u000a\u000a    if (!Object(number["isFiniteNumber"])(frag.deltaPTS)) {\u000a      frag.deltaPTS = deltaPTS;\u000a    } else {\u000a      frag.deltaPTS = Math.max(deltaPTS, frag.deltaPTS);\u000a    }\u000a\u000a    maxStartPTS = Math.max(startPTS, frag.startPTS);\u000a    startPTS = Math.min(startPTS, frag.startPTS);\u000a    endPTS = Math.max(endPTS, frag.endPTS);\u000a    startDTS = Math.min(startDTS, frag.startDTS);\u000a    endDTS = Math.max(endDTS, frag.endDTS);\u000a  }\u000a\u000a  var drift = startPTS - frag.start;\u000a  frag.start = frag.startPTS = startPTS;\u000a  frag.maxStartPTS = maxStartPTS;\u000a  frag.endPTS = endPTS;\u000a  frag.startDTS = startDTS;\u000a  frag.endDTS = endDTS;\u000a  frag.duration = endPTS - startPTS;\u000a  var sn = frag.sn; // exit if sn out of range\u000a\u000a  if (!details || sn < details.startSN || sn > details.endSN) {\u000a    return 0;\u000a  }\u000a\u000a  var fragIdx, fragments, i;\u000a  fragIdx = sn - details.startSN;\u000a  fragments = details.fragments; // update frag reference in fragments array\u000a  // rationale is that fragments array might not contain this frag object.\u000a  // this will happen if playlist has been refreshed between frag loading and call to updateFragPTSDTS()\u000a  // if we don't update frag, we won't be able to propagate PTS info on the playlist\u000a  // resulting in invalid sliding computation\u000a\u000a  fragments[fragIdx] = frag; // adjust fragment PTS/duration from seqnum-1 to frag 0\u000a\u000a  for (i = fragIdx; i > 0; i--) {\u000a    updatePTS(fragments, i, i - 1);\u000a  } // adjust fragment PTS/duration from seqnum to last frag\u000a\u000a\u000a  for (i = fragIdx; i < fragments.length - 1; i++) {\u000a    updatePTS(fragments, i, i + 1);\u000a  }\u000a\u000a  details.PTSKnown = true;\u000a  return drift;\u000a}\u000afunction mergeDetails(oldDetails, newDetails) {\u000a  // potentially retrieve cached initsegment\u000a  if (newDetails.initSegment && oldDetails.initSegment) {\u000a    newDetails.initSegment = oldDetails.initSegment;\u000a  } // check if old/new playlists have fragments in common\u000a  // loop through overlapping SN and update startPTS , cc, and duration if any found\u000a\u000a\u000a  var ccOffset = 0;\u000a  var PTSFrag;\u000a  mapFragmentIntersection(oldDetails, newDetails, function (oldFrag, newFrag) {\u000a    ccOffset = oldFrag.cc - newFrag.cc;\u000a\u000a    if (Object(number["isFiniteNumber"])(oldFrag.startPTS)) {\u000a      newFrag.start = newFrag.startPTS = oldFrag.startPTS;\u000a      newFrag.endPTS = oldFrag.endPTS;\u000a      newFrag.duration = oldFrag.duration;\u000a      newFrag.backtracked = oldFrag.backtracked;\u000a      newFrag.dropped = oldFrag.dropped;\u000a      PTSFrag = newFrag;\u000a    } // PTS is known when there are overlapping segments\u000a\u000a\u000a    newDetails.PTSKnown = true;\u000a  });\u000a\u000a  if (!newDetails.PTSKnown) {\u000a    return;\u000a  }\u000a\u000a  if (ccOffset) {\u000a    logger["logger"].log('discontinuity sliding from playlist, take drift into account');\u000a    var newFragments = newDetails.fragments;\u000a\u000a    for (var i = 0; i < newFragments.length; i++) {\u000a      newFragments[i].cc += ccOffset;\u000a    }\u000a  } // if at least one fragment contains PTS info, recompute PTS information for all fragments\u000a\u000a\u000a  if (PTSFrag) {\u000a    updateFragPTSDTS(newDetails, PTSFrag, PTSFrag.startPTS, PTSFrag.endPTS, PTSFrag.startDTS, PTSFrag.endDTS);\u000a  } else {\u000a    // ensure that delta is within oldFragments range\u000a    // also adjust sliding in case delta is 0 (we could have old=[50-60] and new=old=[50-61])\u000a    // in that case we also need to adjust start offset of all fragments\u000a    adjustSliding(oldDetails, newDetails);\u000a  } // if we are here, it means we have fragments overlapping between\u000a  // old and new level. reliable PTS info is thus relying on old level\u000a\u000a\u000a  newDetails.PTSKnown = oldDetails.PTSKnown;\u000a}\u000afunction mergeSubtitlePlaylists(oldPlaylist, newPlaylist, referenceStart) {\u000a  if (referenceStart === void 0) {\u000a    referenceStart = 0;\u000a  }\u000a\u000a  var lastIndex = -1;\u000a  mapFragmentIntersection(oldPlaylist, newPlaylist, function (oldFrag, newFrag, index) {\u000a    newFrag.start = oldFrag.start;\u000a    lastIndex = index;\u000a  });\u000a  var frags = newPlaylist.fragments;\u000a\u000a  if (lastIndex < 0) {\u000a    frags.forEach(function (frag) {\u000a      frag.start += referenceStart;\u000a    });\u000a    return;\u000a  }\u000a\u000a  for (var i = lastIndex + 1; i < frags.length; i++) {\u000a    frags[i].start = frags[i - 1].start + frags[i - 1].duration;\u000a  }\u000a}\u000afunction mapFragmentIntersection(oldPlaylist, newPlaylist, intersectionFn) {\u000a  if (!oldPlaylist || !newPlaylist) {\u000a    return;\u000a  }\u000a\u000a  var start = Math.max(oldPlaylist.startSN, newPlaylist.startSN) - newPlaylist.startSN;\u000a  var end = Math.min(oldPlaylist.endSN, newPlaylist.endSN) - newPlaylist.startSN;\u000a  var delta = newPlaylist.startSN - oldPlaylist.startSN;\u000a\u000a  for (var i = start; i <= end; i++) {\u000a    var oldFrag = oldPlaylist.fragments[delta + i];\u000a    var newFrag = newPlaylist.fragments[i];\u000a\u000a    if (!oldFrag || !newFrag) {\u000a      break;\u000a    }\u000a\u000a    intersectionFn(oldFrag, newFrag, i);\u000a  }\u000a}\u000afunction adjustSliding(oldPlaylist, newPlaylist) {\u000a  var delta = newPlaylist.startSN - oldPlaylist.startSN;\u000a  var oldFragments = oldPlaylist.fragments;\u000a  var newFragments = newPlaylist.fragments;\u000a\u000a  if (delta < 0 || delta > oldFragments.length) {\u000a    return;\u000a  }\u000a\u000a  for (var i = 0; i < newFragments.length; i++) {\u000a    newFragments[i].start += oldFragments[delta].start;\u000a  }\u000a}\u000afunction computeReloadInterval(currentPlaylist, newPlaylist, lastRequestTime) {\u000a  var reloadInterval = 1000 * (newPlaylist.averagetargetduration ? newPlaylist.averagetargetduration : newPlaylist.targetduration);\u000a  var minReloadInterval = reloadInterval / 2;\u000a\u000a  if (currentPlaylist && newPlaylist.endSN === currentPlaylist.endSN) {\u000a    // follow HLS Spec, If the client reloads a Playlist file and finds that it has not\u000a    // changed then it MUST wait for a period of one-half the target\u000a    // duration before retrying.\u000a    reloadInterval = minReloadInterval;\u000a  }\u000a\u000a  if (lastRequestTime) {\u000a    reloadInterval = Math.max(minReloadInterval, reloadInterval - (window.performance.now() - lastRequestTime));\u000a  } // in any case, don't reload more than half of target duration\u000a\u000a\u000a  return Math.round(reloadInterval);\u000a}\u000a// CONCATENATED MODULE: ./src/utils/time-ranges.ts\u000a/**\u000a *  TimeRanges to string helper\u000a */\u000avar TimeRanges = {\u000a  toString: function toString(r) {\u000a    var log = '';\u000a    var len = r.length;\u000a\u000a    for (var i = 0; i < len; i++) {\u000a      log += '[' + r.start(i).toFixed(3) + ',' + r.end(i).toFixed(3) + ']';\u000a    }\u000a\u000a    return log;\u000a  }\u000a};\u000a/* harmony default export */ var time_ranges = (TimeRanges);\u000a// CONCATENATED MODULE: ./src/utils/discontinuities.js\u000a\u000a\u000a\u000afunction findFirstFragWithCC(fragments, cc) {\u000a  var firstFrag = null;\u000a\u000a  for (var i = 0; i < fragments.length; i += 1) {\u000a    var currentFrag = fragments[i];\u000a\u000a    if (currentFrag && currentFrag.cc === cc) {\u000a      firstFrag = currentFrag;\u000a      break;\u000a    }\u000a  }\u000a\u000a  return firstFrag;\u000a}\u000afunction findFragWithCC(fragments, CC) {\u000a  return binary_search.search(fragments, function (candidate) {\u000a    if (candidate.cc < CC) {\u000a      return 1;\u000a    } else if (candidate.cc > CC) {\u000a      return -1;\u000a    } else {\u000a      return 0;\u000a    }\u000a  });\u000a}\u000afunction shouldAlignOnDiscontinuities(lastFrag, lastLevel, details) {\u000a  var shouldAlign = false;\u000a\u000a  if (lastLevel && lastLevel.details && details) {\u000a    if (details.endCC > details.startCC || lastFrag && lastFrag.cc < details.startCC) {\u000a      shouldAlign = true;\u000a    }\u000a  }\u000a\u000a  return shouldAlign;\u000a} // Find the first frag in the previous level which matches the CC of the first frag of the new level\u000a\u000afunction findDiscontinuousReferenceFrag(prevDetails, curDetails) {\u000a  var prevFrags = prevDetails.fragments;\u000a  var curFrags = curDetails.fragments;\u000a\u000a  if (!curFrags.length || !prevFrags.length) {\u000a    logger["logger"].log('No fragments to align');\u000a    return;\u000a  }\u000a\u000a  var prevStartFrag = findFirstFragWithCC(prevFrags, curFrags[0].cc);\u000a\u000a  if (!prevStartFrag || prevStartFrag && !prevStartFrag.startPTS) {\u000a    logger["logger"].log('No frag in previous level to align on');\u000a    return;\u000a  }\u000a\u000a  return prevStartFrag;\u000a}\u000afunction adjustPts(sliding, details) {\u000a  details.fragments.forEach(function (frag) {\u000a    if (frag) {\u000a      var start = frag.start + sliding;\u000a      frag.start = frag.startPTS = start;\u000a      frag.endPTS = start + frag.duration;\u000a    }\u000a  });\u000a  details.PTSKnown = true;\u000a}\u000a/**\u000a * Using the parameters of the last level, this function computes PTS' of the new fragments so that they form a\u000a * contiguous stream with the last fragments.\u000a * The PTS of a fragment lets Hls.js know where it fits into a stream - by knowing every PTS, we know which fragment to\u000a * download at any given time. PTS is normally computed when the fragment is demuxed, so taking this step saves us time\u000a * and an extra download.\u000a * @param lastFrag\u000a * @param lastLevel\u000a * @param details\u000a */\u000a\u000afunction alignStream(lastFrag, lastLevel, details) {\u000a  alignDiscontinuities(lastFrag, details, lastLevel);\u000a\u000a  if (!details.PTSKnown && lastLevel) {\u000a    // If the PTS wasn't figured out via discontinuity sequence that means there was no CC increase within the level.\u000a    // Aligning via Program Date Time should therefore be reliable, since PDT should be the same within the same\u000a    // discontinuity sequence.\u000a    alignPDT(details, lastLevel.details);\u000a  }\u000a}\u000a/**\u000a * Computes the PTS if a new level's fragments using the PTS of a fragment in the last level which shares the same\u000a * discontinuity sequence.\u000a * @param lastLevel - The details of the last loaded level\u000a * @param details - The details of the new level\u000a */\u000a\u000afunction alignDiscontinuities(lastFrag, details, lastLevel) {\u000a  if (shouldAlignOnDiscontinuities(lastFrag, lastLevel, details)) {\u000a    var referenceFrag = findDiscontinuousReferenceFrag(lastLevel.details, details);\u000a\u000a    if (referenceFrag) {\u000a      logger["logger"].log('Adjusting PTS using last level due to CC increase within current level');\u000a      adjustPts(referenceFrag.start, details);\u000a    }\u000a  }\u000a}\u000a/**\u000a * Computes the PTS of a new level's fragments using the difference in Program Date Time from the last level.\u000a * @param details - The details of the new level\u000a * @param lastDetails - The details of the last loaded level\u000a */\u000a\u000afunction alignPDT(details, lastDetails) {\u000a  if (lastDetails && lastDetails.fragments.length) {\u000a    if (!details.hasProgramDateTime || !lastDetails.hasProgramDateTime) {\u000a      return;\u000a    } // if last level sliding is 1000 and its first frag PROGRAM-DATE-TIME is 2017-08-20 1:10:00 AM\u000a    // and if new details first frag PROGRAM DATE-TIME is 2017-08-20 1:10:08 AM\u000a    // then we can deduce that playlist B sliding is 1000+8 = 1008s\u000a\u000a\u000a    var lastPDT = lastDetails.fragments[0].programDateTime;\u000a    var newPDT = details.fragments[0].programDateTime; // date diff is in ms. frag.start is in seconds\u000a\u000a    var sliding = (newPDT - lastPDT) / 1000 + lastDetails.fragments[0].start;\u000a\u000a    if (Object(number["isFiniteNumber"])(sliding)) {\u000a      logger["logger"].log("adjusting PTS using programDateTime delta, sliding:" + sliding.toFixed(3));\u000a      adjustPts(sliding, details);\u000a    }\u000a  }\u000a}\u000a// CONCATENATED MODULE: ./src/controller/fragment-finders.ts\u000a\u000a\u000a\u000a/**\u000a * Returns first fragment whose endPdt value exceeds the given PDT.\u000a * @param {Array<Fragment>} fragments - The array of candidate fragments\u000a * @param {number|null} [PDTValue = null] - The PDT value which must be exceeded\u000a * @param {number} [maxFragLookUpTolerance = 0] - The amount of time that a fragment's start/end can be within in order to be considered contiguous\u000a * @returns {*|null} fragment - The best matching fragment\u000a */\u000afunction findFragmentByPDT(fragments, PDTValue, maxFragLookUpTolerance) {\u000a  if (PDTValue === null || !Array.isArray(fragments) || !fragments.length || !Object(number["isFiniteNumber"])(PDTValue)) {\u000a    return null;\u000a  } // if less than start\u000a\u000a\u000a  var startPDT = fragments[0].programDateTime;\u000a\u000a  if (PDTValue < (startPDT || 0)) {\u000a    return null;\u000a  }\u000a\u000a  var endPDT = fragments[fragments.length - 1].endProgramDateTime;\u000a\u000a  if (PDTValue >= (endPDT || 0)) {\u000a    return null;\u000a  }\u000a\u000a  maxFragLookUpTolerance = maxFragLookUpTolerance || 0;\u000a\u000a  for (var seg = 0; seg < fragments.length; ++seg) {\u000a    var frag = fragments[seg];\u000a\u000a    if (pdtWithinToleranceTest(PDTValue, maxFragLookUpTolerance, frag)) {\u000a      return frag;\u000a    }\u000a  }\u000a\u000a  return null;\u000a}\u000a/**\u000a * Finds a fragment based on the SN of the previous fragment; or based on the needs of the current buffer.\u000a * This method compensates for small buffer gaps by applying a tolerance to the start of any candidate fragment, thus\u000a * breaking any traps which would cause the same fragment to be continuously selected within a small range.\u000a * @param {*} fragPrevious - The last frag successfully appended\u000a * @param {Array<Fragment>} fragments - The array of candidate fragments\u000a * @param {number} [bufferEnd = 0] - The end of the contiguous buffered range the playhead is currently within\u000a * @param {number} maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous\u000a * @returns {*} foundFrag - The best matching fragment\u000a */\u000a\u000afunction findFragmentByPTS(fragPrevious, fragments, bufferEnd, maxFragLookUpTolerance) {\u000a  if (bufferEnd === void 0) {\u000a    bufferEnd = 0;\u000a  }\u000a\u000a  if (maxFragLookUpTolerance === void 0) {\u000a    maxFragLookUpTolerance = 0;\u000a  }\u000a\u000a  var fragNext = null;\u000a\u000a  if (fragPrevious) {\u000a    fragNext = fragments[fragPrevious.sn - fragments[0].sn + 1];\u000a  } else if (bufferEnd === 0 && fragments[0].start === 0) {\u000a    fragNext = fragments[0];\u000a  } // Prefer the next fragment if it's within tolerance\u000a\u000a\u000a  if (fragNext && fragment_finders_fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, fragNext) === 0) {\u000a    return fragNext;\u000a  } // We might be seeking past the tolerance so find the best match\u000a\u000a\u000a  var foundFragment = binary_search.search(fragments, fragment_finders_fragmentWithinToleranceTest.bind(null, bufferEnd, maxFragLookUpTolerance));\u000a\u000a  if (foundFragment) {\u000a    return foundFragment;\u000a  } // If no match was found return the next fragment after fragPrevious, or null\u000a\u000a\u000a  return fragNext;\u000a}\u000a/**\u000a * The test function used by the findFragmentBySn's BinarySearch to look for the best match to the current buffer conditions.\u000a * @param {*} candidate - The fragment to test\u000a * @param {number} [bufferEnd = 0] - The end of the current buffered range the playhead is currently within\u000a * @param {number} [maxFragLookUpTolerance = 0] - The amount of time that a fragment's start can be within in order to be considered contiguous\u000a * @returns {number} - 0 if it matches, 1 if too low, -1 if too high\u000a */\u000a\u000afunction fragment_finders_fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, candidate) {\u000a  if (bufferEnd === void 0) {\u000a    bufferEnd = 0;\u000a  }\u000a\u000a  if (maxFragLookUpTolerance === void 0) {\u000a    maxFragLookUpTolerance = 0;\u000a  }\u000a\u000a  // offset should be within fragment boundary - config.maxFragLookUpTolerance\u000a  // this is to cope with situations like\u000a  // bufferEnd = 9.991\u000a  // frag[] : [0,10]\u000a  // frag[1] : [10,20]\u000a  // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here\u000a  //              frag start               frag start+duration\u000a  //                  |-----------------------------|\u000a  //              <--->                         <--->\u000a  //  ...--------><-----------------------------><---------....\u000a  // previous frag         matching fragment         next frag\u000a  //  return -1             return 0                 return 1\u000a  // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);\u000a  // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments\u000a  var candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0));\u000a\u000a  if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) {\u000a    return 1;\u000a  } else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) {\u000a    // if maxFragLookUpTolerance will have negative value then don't return -1 for first element\u000a    return -1;\u000a  }\u000a\u000a  return 0;\u000a}\u000a/**\u000a * The test function used by the findFragmentByPdt's BinarySearch to look for the best match to the current buffer conditions.\u000a * This function tests the candidate's program date time values, as represented in Unix time\u000a * @param {*} candidate - The fragment to test\u000a * @param {number} [pdtBufferEnd = 0] - The Unix time representing the end of the current buffered range\u000a * @param {number} [maxFragLookUpTolerance = 0] - The amount of time that a fragment's start can be within in order to be considered contiguous\u000a * @returns {boolean} True if contiguous, false otherwise\u000a */\u000a\u000afunction pdtWithinToleranceTest(pdtBufferEnd, maxFragLookUpTolerance, candidate) {\u000a  var candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0)) * 1000; // endProgramDateTime can be null, default to zero\u000a\u000a  var endProgramDateTime = candidate.endProgramDateTime || 0;\u000a  return endProgramDateTime - candidateLookupTolerance > pdtBufferEnd;\u000a}\u000a// CONCATENATED MODULE: ./src/controller/gap-controller.js\u000a\u000a\u000a\u000a\u000avar STALL_MINIMUM_DURATION_MS = 250;\u000avar MAX_START_GAP_JUMP = 2.0;\u000avar SKIP_BUFFER_HOLE_STEP_SECONDS = 0.1;\u000avar SKIP_BUFFER_RANGE_START = 0.05;\u000a\u000avar gap_controller_GapController = /*#__PURE__*/function () {\u000a  function GapController(config, media, fragmentTracker, hls) {\u000a    this.config = config;\u000a    this.media = media;\u000a    this.fragmentTracker = fragmentTracker;\u000a    this.hls = hls;\u000a    this.nudgeRetry = 0;\u000a    this.stallReported = false;\u000a    this.stalled = null;\u000a    this.moved = false;\u000a    this.seeking = false;\u000a  }\u000a  /**\u000a   * Checks if the playhead is stuck within a gap, and if so, attempts to free it.\u000a   * A gap is an unbuffered range between two buffered ranges (or the start and the first buffered range).\u000a   *\u000a   * @param {number} lastCurrentTime Previously read playhead position\u000a   */\u000a\u000a\u000a  var _proto = GapController.prototype;\u000a\u000a  _proto.poll = function poll(lastCurrentTime) {\u000a    var config = this.config,\u000a        media = this.media,\u000a        stalled = this.stalled;\u000a    var currentTime = media.currentTime,\u000a        seeking = media.seeking;\u000a    var seeked = this.seeking && !seeking;\u000a    var beginSeek = !this.seeking && seeking;\u000a    this.seeking = seeking; // The playhead is moving, no-op\u000a\u000a    if (currentTime !== lastCurrentTime) {\u000a      this.moved = true;\u000a\u000a      if (stalled !== null) {\u000a        // The playhead is now moving, but was previously stalled\u000a        if (this.stallReported) {\u000a          var _stalledDuration = self.performance.now() - stalled;\u000a\u000a          logger["logger"].warn("playback not stuck anymore @" + currentTime + ", after " + Math.round(_stalledDuration) + "ms");\u000a          this.stallReported = false;\u000a        }\u000a\u000a        this.stalled = null;\u000a        this.nudgeRetry = 0;\u000a      }\u000a\u000a      return;\u000a    } // Clear stalled state when beginning or finishing seeking so that we don't report stalls coming out of a seek\u000a\u000a\u000a    if (beginSeek || seeked) {\u000a      this.stalled = null;\u000a    } // The playhead should not be moving\u000a\u000a\u000a    if (media.paused || media.ended || media.playbackRate === 0 || !media.buffered.length) {\u000a      return;\u000a    }\u000a\u000a    var bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\u000a    var isBuffered = bufferInfo.len > 0;\u000a    var nextStart = bufferInfo.nextStart || 0; // There is no playable buffer (waiting for buffer append)\u000a\u000a    if (!isBuffered && !nextStart) {\u000a      return;\u000a    }\u000a\u000a    if (seeking) {\u000a      // Waiting for seeking in a buffered range to complete\u000a      var hasEnoughBuffer = bufferInfo.len > MAX_START_GAP_JUMP; // Next buffered range is too far ahead to jump to while still seeking\u000a\u000a      var noBufferGap = !nextStart || nextStart - currentTime > MAX_START_GAP_JUMP && !this.fragmentTracker.getPartialFragment(currentTime);\u000a\u000a      if (hasEnoughBuffer || noBufferGap) {\u000a        return;\u000a      } // Reset moved state when seeking to a point in or before a gap\u000a\u000a\u000a      this.moved = false;\u000a    } // Skip start gaps if we haven't played, but the last poll detected the start of a stall\u000a    // The addition poll gives the browser a chance to jump the gap for us\u000a\u000a\u000a    if (!this.moved && this.stalled) {\u000a      // Jump start gaps within jump threshold\u000a      var startJump = Math.max(nextStart, bufferInfo.start || 0) - currentTime;\u000a\u000a      if (startJump > 0 && startJump <= MAX_START_GAP_JUMP) {\u000a        this._trySkipBufferHole(null);\u000a\u000a        return;\u000a      }\u000a    } // Start tracking stall time\u000a\u000a\u000a    var tnow = self.performance.now();\u000a\u000a    if (stalled === null) {\u000a      this.stalled = tnow;\u000a      return;\u000a    }\u000a\u000a    var stalledDuration = tnow - stalled;\u000a\u000a    if (!seeking && stalledDuration >= STALL_MINIMUM_DURATION_MS) {\u000a      // Report stalling after trying to fix\u000a      this._reportStall(bufferInfo.len);\u000a    }\u000a\u000a    var bufferedWithHoles = BufferHelper.bufferInfo(media, currentTime, config.maxBufferHole);\u000a\u000a    this._tryFixBufferStall(bufferedWithHoles, stalledDuration);\u000a  }\u000a  /**\u000a   * Detects and attempts to fix known buffer stalling issues.\u000a   * @param bufferInfo - The properties of the current buffer.\u000a   * @param stalledDurationMs - The amount of time Hls.js has been stalling for.\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._tryFixBufferStall = function _tryFixBufferStall(bufferInfo, stalledDurationMs) {\u000a    var config = this.config,\u000a        fragmentTracker = this.fragmentTracker,\u000a        media = this.media;\u000a    var currentTime = media.currentTime;\u000a    var partial = fragmentTracker.getPartialFragment(currentTime);\u000a\u000a    if (partial) {\u000a      // Try to skip over the buffer hole caused by a partial fragment\u000a      // This method isn't limited by the size of the gap between buffered ranges\u000a      var targetTime = this._trySkipBufferHole(partial); // we return here in this case, meaning\u000a      // the branch below only executes when we don't handle a partial fragment\u000a\u000a\u000a      if (targetTime) {\u000a        return;\u000a      }\u000a    } // if we haven't had to skip over a buffer hole of a partial fragment\u000a    // we may just have to "nudge" the playlist as the browser decoding/rendering engine\u000a    // needs to cross some sort of threshold covering all source-buffers content\u000a    // to start playing properly.\u000a\u000a\u000a    if (bufferInfo.len > config.maxBufferHole && stalledDurationMs > config.highBufferWatchdogPeriod * 1000) {\u000a      logger["logger"].warn('Trying to nudge playhead over buffer-hole'); // Try to nudge currentTime over a buffer hole if we've been stalling for the configured amount of seconds\u000a      // We only try to jump the hole if it's under the configured size\u000a      // Reset stalled so to rearm watchdog timer\u000a\u000a      this.stalled = null;\u000a\u000a      this._tryNudgeBuffer();\u000a    }\u000a  }\u000a  /**\u000a   * Triggers a BUFFER_STALLED_ERROR event, but only once per stall period.\u000a   * @param bufferLen - The playhead distance from the end of the current buffer segment.\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._reportStall = function _reportStall(bufferLen) {\u000a    var hls = this.hls,\u000a        media = this.media,\u000a        stallReported = this.stallReported;\u000a\u000a    if (!stallReported) {\u000a      // Report stalled error once\u000a      this.stallReported = true;\u000a      logger["logger"].warn("Playback stalling at @" + media.currentTime + " due to low buffer (buffer=" + bufferLen + ")");\u000a      hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        details: errors["ErrorDetails"].BUFFER_STALLED_ERROR,\u000a        fatal: false,\u000a        buffer: bufferLen\u000a      });\u000a    }\u000a  }\u000a  /**\u000a   * Attempts to fix buffer stalls by jumping over known gaps caused by partial fragments\u000a   * @param partial - The partial fragment found at the current time (where playback is stalling).\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._trySkipBufferHole = function _trySkipBufferHole(partial) {\u000a    var config = this.config,\u000a        hls = this.hls,\u000a        media = this.media;\u000a    var currentTime = media.currentTime;\u000a    var lastEndTime = 0; // Check if currentTime is between unbuffered regions of partial fragments\u000a\u000a    for (var i = 0; i < media.buffered.length; i++) {\u000a      var startTime = media.buffered.start(i);\u000a\u000a      if (currentTime + config.maxBufferHole >= lastEndTime && currentTime < startTime) {\u000a        var targetTime = Math.max(startTime + SKIP_BUFFER_RANGE_START, media.currentTime + SKIP_BUFFER_HOLE_STEP_SECONDS);\u000a        logger["logger"].warn("skipping hole, adjusting currentTime from " + currentTime + " to " + targetTime);\u000a        this.moved = true;\u000a        this.stalled = null;\u000a        media.currentTime = targetTime;\u000a\u000a        if (partial) {\u000a          hls.trigger(events["default"].ERROR, {\u000a            type: errors["ErrorTypes"].MEDIA_ERROR,\u000a            details: errors["ErrorDetails"].BUFFER_SEEK_OVER_HOLE,\u000a            fatal: false,\u000a            reason: "fragment loaded with buffer holes, seeking from " + currentTime + " to " + targetTime,\u000a            frag: partial\u000a          });\u000a        }\u000a\u000a        return targetTime;\u000a      }\u000a\u000a      lastEndTime = media.buffered.end(i);\u000a    }\u000a\u000a    return 0;\u000a  }\u000a  /**\u000a   * Attempts to fix buffer stalls by advancing the mediaElement's current time by a small amount.\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._tryNudgeBuffer = function _tryNudgeBuffer() {\u000a    var config = this.config,\u000a        hls = this.hls,\u000a        media = this.media;\u000a    var currentTime = media.currentTime;\u000a    var nudgeRetry = (this.nudgeRetry || 0) + 1;\u000a    this.nudgeRetry = nudgeRetry;\u000a\u000a    if (nudgeRetry < config.nudgeMaxRetry) {\u000a      var targetTime = currentTime + nudgeRetry * config.nudgeOffset; // playback stalled in buffered area ... let's nudge currentTime to try to overcome this\u000a\u000a      logger["logger"].warn("Nudging 'currentTime' from " + currentTime + " to " + targetTime);\u000a      media.currentTime = targetTime;\u000a      hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        details: errors["ErrorDetails"].BUFFER_NUDGE_ON_STALL,\u000a        fatal: false\u000a      });\u000a    } else {\u000a      logger["logger"].error("Playhead still not moving while enough data buffered @" + currentTime + " after " + config.nudgeMaxRetry + " nudges");\u000a      hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        details: errors["ErrorDetails"].BUFFER_STALLED_ERROR,\u000a        fatal: true\u000a      });\u000a    }\u000a  };\u000a\u000a  return GapController;\u000a}();\u000a\u000a\u000a// CONCATENATED MODULE: ./src/task-loop.ts\u000afunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return self; }\u000a\u000afunction task_loop_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a\u000a\u000a/**\u000a * Sub-class specialization of EventHandler base class.\u000a *\u000a * TaskLoop allows to schedule a task function being called (optionnaly repeatedly) on the main loop,\u000a * scheduled asynchroneously, avoiding recursive calls in the same tick.\u000a *\u000a * The task itself is implemented in `doTick`. It can be requested and called for single execution\u000a * using the `tick` method.\u000a *\u000a * It will be assured that the task execution method (`tick`) only gets called once per main loop "tick",\u000a * no matter how often it gets requested for execution. Execution in further ticks will be scheduled accordingly.\u000a *\u000a * If further execution requests have already been scheduled on the next tick, it can be checked with `hasNextTick`,\u000a * and cancelled with `clearNextTick`.\u000a *\u000a * The task can be scheduled as an interval repeatedly with a period as parameter (see `setInterval`, `clearInterval`).\u000a *\u000a * Sub-classes need to implement the `doTick` method which will effectively have the task execution routine.\u000a *\u000a * Further explanations:\u000a *\u000a * The baseclass has a `tick` method that will schedule the doTick call. It may be called synchroneously\u000a * only for a stack-depth of one. On re-entrant calls, sub-sequent calls are scheduled for next main loop ticks.\u000a *\u000a * When the task execution (`tick` method) is called in re-entrant way this is detected and\u000a * we are limiting the task execution per call stack to exactly one, but scheduling/post-poning further\u000a * task processing on the next main loop iteration (also known as "next tick" in the Node/JS runtime lingo).\u000a */\u000avar TaskLoop = /*#__PURE__*/function (_EventHandler) {\u000a  task_loop_inheritsLoose(TaskLoop, _EventHandler);\u000a\u000a  function TaskLoop(hls) {\u000a    var _this;\u000a\u000a    for (var _len = arguments.length, events = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\u000a      events[_key - 1] = arguments[_key];\u000a    }\u000a\u000a    _this = _EventHandler.call.apply(_EventHandler, [this, hls].concat(events)) || this;\u000a    _this._boundTick = void 0;\u000a    _this._tickTimer = null;\u000a    _this._tickInterval = null;\u000a    _this._tickCallCount = 0;\u000a    _this._boundTick = _this.tick.bind(_assertThisInitialized(_this));\u000a    return _this;\u000a  }\u000a  /**\u000a   * @override\u000a   */\u000a\u000a\u000a  var _proto = TaskLoop.prototype;\u000a\u000a  _proto.onHandlerDestroying = function onHandlerDestroying() {\u000a    // clear all timers before unregistering from event bus\u000a    this.clearNextTick();\u000a    this.clearInterval();\u000a  }\u000a  /**\u000a   * @returns {boolean}\u000a   */\u000a  ;\u000a\u000a  _proto.hasInterval = function hasInterval() {\u000a    return !!this._tickInterval;\u000a  }\u000a  /**\u000a   * @returns {boolean}\u000a   */\u000a  ;\u000a\u000a  _proto.hasNextTick = function hasNextTick() {\u000a    return !!this._tickTimer;\u000a  }\u000a  /**\u000a   * @param {number} millis Interval time (ms)\u000a   * @returns {boolean} True when interval has been scheduled, false when already scheduled (no effect)\u000a   */\u000a  ;\u000a\u000a  _proto.setInterval = function setInterval(millis) {\u000a    if (!this._tickInterval) {\u000a      this._tickInterval = self.setInterval(this._boundTick, millis);\u000a      return true;\u000a    }\u000a\u000a    return false;\u000a  }\u000a  /**\u000a   * @returns {boolean} True when interval was cleared, false when none was set (no effect)\u000a   */\u000a  ;\u000a\u000a  _proto.clearInterval = function clearInterval() {\u000a    if (this._tickInterval) {\u000a      self.clearInterval(this._tickInterval);\u000a      this._tickInterval = null;\u000a      return true;\u000a    }\u000a\u000a    return false;\u000a  }\u000a  /**\u000a   * @returns {boolean} True when timeout was cleared, false when none was set (no effect)\u000a   */\u000a  ;\u000a\u000a  _proto.clearNextTick = function clearNextTick() {\u000a    if (this._tickTimer) {\u000a      self.clearTimeout(this._tickTimer);\u000a      this._tickTimer = null;\u000a      return true;\u000a    }\u000a\u000a    return false;\u000a  }\u000a  /**\u000a   * Will call the subclass doTick implementation in this main loop tick\u000a   * or in the next one (via setTimeout(,0)) in case it has already been called\u000a   * in this tick (in case this is a re-entrant call).\u000a   */\u000a  ;\u000a\u000a  _proto.tick = function tick() {\u000a    this._tickCallCount++;\u000a\u000a    if (this._tickCallCount === 1) {\u000a      this.doTick(); // re-entrant call to tick from previous doTick call stack\u000a      // -> schedule a call on the next main loop iteration to process this task processing request\u000a\u000a      if (this._tickCallCount > 1) {\u000a        // make sure only one timer exists at any time at max\u000a        this.clearNextTick();\u000a        this._tickTimer = self.setTimeout(this._boundTick, 0);\u000a      }\u000a\u000a      this._tickCallCount = 0;\u000a    }\u000a  }\u000a  /**\u000a   * For subclass to implement task logic\u000a   * @abstract\u000a   */\u000a  ;\u000a\u000a  _proto.doTick = function doTick() {};\u000a\u000a  return TaskLoop;\u000a}(event_handler);\u000a\u000a\u000a// CONCATENATED MODULE: ./src/controller/base-stream-controller.js\u000a\u000a\u000afunction base_stream_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a\u000a\u000a\u000a\u000avar State = {\u000a  STOPPED: 'STOPPED',\u000a  STARTING: 'STARTING',\u000a  IDLE: 'IDLE',\u000a  PAUSED: 'PAUSED',\u000a  KEY_LOADING: 'KEY_LOADING',\u000a  FRAG_LOADING: 'FRAG_LOADING',\u000a  FRAG_LOADING_WAITING_RETRY: 'FRAG_LOADING_WAITING_RETRY',\u000a  WAITING_TRACK: 'WAITING_TRACK',\u000a  PARSING: 'PARSING',\u000a  PARSED: 'PARSED',\u000a  BUFFER_FLUSHING: 'BUFFER_FLUSHING',\u000a  ENDED: 'ENDED',\u000a  ERROR: 'ERROR',\u000a  WAITING_INIT_PTS: 'WAITING_INIT_PTS',\u000a  WAITING_LEVEL: 'WAITING_LEVEL'\u000a};\u000a\u000avar base_stream_controller_BaseStreamController = /*#__PURE__*/function (_TaskLoop) {\u000a  base_stream_controller_inheritsLoose(BaseStreamController, _TaskLoop);\u000a\u000a  function BaseStreamController() {\u000a    return _TaskLoop.apply(this, arguments) || this;\u000a  }\u000a\u000a  var _proto = BaseStreamController.prototype;\u000a\u000a  _proto.doTick = function doTick() {};\u000a\u000a  _proto.startLoad = function startLoad() {};\u000a\u000a  _proto.stopLoad = function stopLoad() {\u000a    var frag = this.fragCurrent;\u000a\u000a    if (frag) {\u000a      if (frag.loader) {\u000a        frag.loader.abort();\u000a      }\u000a\u000a      this.fragmentTracker.removeFragment(frag);\u000a    }\u000a\u000a    if (this.demuxer) {\u000a      this.demuxer.destroy();\u000a      this.demuxer = null;\u000a    }\u000a\u000a    this.fragCurrent = null;\u000a    this.fragPrevious = null;\u000a    this.clearInterval();\u000a    this.clearNextTick();\u000a    this.state = State.STOPPED;\u000a  };\u000a\u000a  _proto._streamEnded = function _streamEnded(bufferInfo, levelDetails) {\u000a    var fragCurrent = this.fragCurrent,\u000a        fragmentTracker = this.fragmentTracker; // we just got done loading the final fragment and there is no other buffered range after ...\u000a    // rationale is that in case there are any buffered ranges after, it means that there are unbuffered portion in between\u000a    // so we should not switch to ENDED in that case, to be able to buffer them\u000a    // dont switch to ENDED if we need to backtrack last fragment\u000a\u000a    if (!levelDetails.live && fragCurrent && !fragCurrent.backtracked && fragCurrent.sn === levelDetails.endSN && !bufferInfo.nextStart) {\u000a      var fragState = fragmentTracker.getState(fragCurrent);\u000a      return fragState === FragmentState.PARTIAL || fragState === FragmentState.OK;\u000a    }\u000a\u000a    return false;\u000a  };\u000a\u000a  _proto.onMediaSeeking = function onMediaSeeking() {\u000a    var config = this.config,\u000a        media = this.media,\u000a        mediaBuffer = this.mediaBuffer,\u000a        state = this.state;\u000a    var currentTime = media ? media.currentTime : null;\u000a    var bufferInfo = BufferHelper.bufferInfo(mediaBuffer || media, currentTime, this.config.maxBufferHole);\u000a\u000a    if (Object(number["isFiniteNumber"])(currentTime)) {\u000a      logger["logger"].log("media seeking to " + currentTime.toFixed(3));\u000a    }\u000a\u000a    if (state === State.FRAG_LOADING) {\u000a      var fragCurrent = this.fragCurrent; // check if we are seeking to a unbuffered area AND if frag loading is in progress\u000a\u000a      if (bufferInfo.len === 0 && fragCurrent) {\u000a        var tolerance = config.maxFragLookUpTolerance;\u000a        var fragStartOffset = fragCurrent.start - tolerance;\u000a        var fragEndOffset = fragCurrent.start + fragCurrent.duration + tolerance; // check if we seek position will be out of currently loaded frag range : if out cancel frag load, if in, don't do anything\u000a\u000a        if (currentTime < fragStartOffset || currentTime > fragEndOffset) {\u000a          if (fragCurrent.loader) {\u000a            logger["logger"].log('seeking outside of buffer while fragment load in progress, cancel fragment load');\u000a            fragCurrent.loader.abort();\u000a          }\u000a\u000a          this.fragCurrent = null;\u000a          this.fragPrevious = null; // switch to IDLE state to load new fragment\u000a\u000a          this.state = State.IDLE;\u000a        } else {\u000a          logger["logger"].log('seeking outside of buffer but within currently loaded fragment range');\u000a        }\u000a      }\u000a    } else if (state === State.ENDED) {\u000a      // if seeking to unbuffered area, clean up fragPrevious\u000a      if (bufferInfo.len === 0) {\u000a        this.fragPrevious = null;\u000a        this.fragCurrent = null;\u000a      } // switch to IDLE state to check for potential new fragment\u000a\u000a\u000a      this.state = State.IDLE;\u000a    }\u000a\u000a    if (media) {\u000a      this.lastCurrentTime = currentTime;\u000a    } // in case seeking occurs although no media buffered, adjust startPosition and nextLoadPosition to seek target\u000a\u000a\u000a    if (!this.loadedmetadata) {\u000a      this.nextLoadPosition = this.startPosition = currentTime;\u000a    } // tick to speed up processing\u000a\u000a\u000a    this.tick();\u000a  };\u000a\u000a  _proto.onMediaEnded = function onMediaEnded() {\u000a    // reset startPosition and lastCurrentTime to restart playback @ stream beginning\u000a    this.startPosition = this.lastCurrentTime = 0;\u000a  };\u000a\u000a  _proto.onHandlerDestroying = function onHandlerDestroying() {\u000a    this.stopLoad();\u000a\u000a    _TaskLoop.prototype.onHandlerDestroying.call(this);\u000a  };\u000a\u000a  _proto.onHandlerDestroyed = function onHandlerDestroyed() {\u000a    this.state = State.STOPPED;\u000a    this.fragmentTracker = null;\u000a  };\u000a\u000a  _proto.computeLivePosition = function computeLivePosition(sliding, levelDetails) {\u000a    var targetLatency = this.config.liveSyncDuration !== undefined ? this.config.liveSyncDuration : this.config.liveSyncDurationCount * levelDetails.targetduration;\u000a    return sliding + Math.max(0, levelDetails.totalduration - targetLatency);\u000a  };\u000a\u000a  return BaseStreamController;\u000a}(TaskLoop);\u000a\u000a\u000a// CONCATENATED MODULE: ./src/controller/stream-controller.js\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000afunction stream_controller_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction stream_controller_createClass(Constructor, protoProps, staticProps) { if (protoProps) stream_controller_defineProperties(Constructor.prototype, protoProps); if (staticProps) stream_controller_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000afunction stream_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * Stream Controller\u000a*/\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000avar TICK_INTERVAL = 100; // how often to tick in ms\u000a\u000avar stream_controller_StreamController = /*#__PURE__*/function (_BaseStreamController) {\u000a  stream_controller_inheritsLoose(StreamController, _BaseStreamController);\u000a\u000a  function StreamController(hls, fragmentTracker) {\u000a    var _this;\u000a\u000a    _this = _BaseStreamController.call(this, hls, events["default"].MEDIA_ATTACHED, events["default"].MEDIA_DETACHING, events["default"].MANIFEST_LOADING, events["default"].MANIFEST_PARSED, events["default"].LEVEL_LOADED, events["default"].LEVELS_UPDATED, events["default"].KEY_LOADED, events["default"].FRAG_LOADED, events["default"].FRAG_LOAD_EMERGENCY_ABORTED, events["default"].FRAG_PARSING_INIT_SEGMENT, events["default"].FRAG_PARSING_DATA, events["default"].FRAG_PARSED, events["default"].ERROR, events["default"].AUDIO_TRACK_SWITCHING, events["default"].AUDIO_TRACK_SWITCHED, events["default"].BUFFER_CREATED, events["default"].BUFFER_APPENDED, events["default"].BUFFER_FLUSHED) || this;\u000a    _this.fragmentTracker = fragmentTracker;\u000a    _this.config = hls.config;\u000a    _this.audioCodecSwap = false;\u000a    _this._state = State.STOPPED;\u000a    _this.stallReported = false;\u000a    _this.gapController = null;\u000a    _this.altAudio = false;\u000a    _this.audioOnly = false;\u000a    _this.bitrateTest = false;\u000a    return _this;\u000a  }\u000a\u000a  var _proto = StreamController.prototype;\u000a\u000a  _proto.startLoad = function startLoad(startPosition) {\u000a    if (this.levels) {\u000a      var lastCurrentTime = this.lastCurrentTime,\u000a          hls = this.hls;\u000a      this.stopLoad();\u000a      this.setInterval(TICK_INTERVAL);\u000a      this.level = -1;\u000a      this.fragLoadError = 0;\u000a\u000a      if (!this.startFragRequested) {\u000a        // determine load level\u000a        var startLevel = hls.startLevel;\u000a\u000a        if (startLevel === -1) {\u000a          if (hls.config.testBandwidth) {\u000a            // -1 : guess start Level by doing a bitrate test by loading first fragment of lowest quality level\u000a            startLevel = 0;\u000a            this.bitrateTest = true;\u000a          } else {\u000a            startLevel = hls.nextAutoLevel;\u000a          }\u000a        } // set new level to playlist loader : this will trigger start level load\u000a        // hls.nextLoadLevel remains until it is set to a new value or until a new frag is successfully loaded\u000a\u000a\u000a        this.level = hls.nextLoadLevel = startLevel;\u000a        this.loadedmetadata = false;\u000a      } // if startPosition undefined but lastCurrentTime set, set startPosition to last currentTime\u000a\u000a\u000a      if (lastCurrentTime > 0 && startPosition === -1) {\u000a        logger["logger"].log("override startPosition with lastCurrentTime @" + lastCurrentTime.toFixed(3));\u000a        startPosition = lastCurrentTime;\u000a      }\u000a\u000a      this.state = State.IDLE;\u000a      this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;\u000a      this.tick();\u000a    } else {\u000a      this.forceStartLoad = true;\u000a      this.state = State.STOPPED;\u000a    }\u000a  };\u000a\u000a  _proto.stopLoad = function stopLoad() {\u000a    this.forceStartLoad = false;\u000a\u000a    _BaseStreamController.prototype.stopLoad.call(this);\u000a  };\u000a\u000a  _proto.doTick = function doTick() {\u000a    switch (this.state) {\u000a      case State.BUFFER_FLUSHING:\u000a        // in buffer flushing state, reset fragLoadError counter\u000a        this.fragLoadError = 0;\u000a        break;\u000a\u000a      case State.IDLE:\u000a        this._doTickIdle();\u000a\u000a        break;\u000a\u000a      case State.WAITING_LEVEL:\u000a        var level = this.levels[this.level]; // check if playlist is already loaded\u000a\u000a        if (level && level.details) {\u000a          this.state = State.IDLE;\u000a        }\u000a\u000a        break;\u000a\u000a      case State.FRAG_LOADING_WAITING_RETRY:\u000a        var now = window.performance.now();\u000a        var retryDate = this.retryDate; // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading\u000a\u000a        if (!retryDate || now >= retryDate || this.media && this.media.seeking) {\u000a          logger["logger"].log('mediaController: retryDate reached, switch back to IDLE state');\u000a          this.state = State.IDLE;\u000a        }\u000a\u000a        break;\u000a\u000a      case State.ERROR:\u000a      case State.STOPPED:\u000a      case State.FRAG_LOADING:\u000a      case State.PARSING:\u000a      case State.PARSED:\u000a      case State.ENDED:\u000a        break;\u000a\u000a      default:\u000a        break;\u000a    } // check buffer\u000a\u000a\u000a    this._checkBuffer(); // check/update current fragment\u000a\u000a\u000a    this._checkFragmentChanged();\u000a  } // Ironically the "idle" state is the on we do the most logic in it seems ....\u000a  // NOTE: Maybe we could rather schedule a check for buffer length after half of the currently\u000a  //       played segment, or on pause/play/seek instead of naively checking every 100ms?\u000a  ;\u000a\u000a  _proto._doTickIdle = function _doTickIdle() {\u000a    var hls = this.hls,\u000a        config = hls.config,\u000a        media = this.media; // if start level not parsed yet OR\u000a    // if video not attached AND start fragment already requested OR start frag prefetch disable\u000a    // exit loop, as we either need more info (level not parsed) or we need media to be attached to load new fragment\u000a\u000a    if (this.levelLastLoaded === undefined || !media && (this.startFragRequested || !config.startFragPrefetch)) {\u000a      return;\u000a    } // If the "main" level is audio-only but we are loading an alternate track in the same group, do not load anything\u000a\u000a\u000a    if (this.altAudio && this.audioOnly) {\u000a      // Clear audio demuxer state so when switching back to main audio we're not still appending where we left off\u000a      this.demuxer.frag = null;\u000a      return;\u000a    } // if we have not yet loaded any fragment, start loading from start position\u000a\u000a\u000a    var pos;\u000a\u000a    if (this.loadedmetadata) {\u000a      pos = media.currentTime;\u000a    } else {\u000a      pos = this.nextLoadPosition;\u000a    } // determine next load level\u000a\u000a\u000a    var level = hls.nextLoadLevel,\u000a        levelInfo = this.levels[level];\u000a\u000a    if (!levelInfo) {\u000a      return;\u000a    }\u000a\u000a    var levelBitrate = levelInfo.bitrate,\u000a        maxBufLen; // compute max Buffer Length that we could get from this load level, based on level bitrate.\u000a\u000a    if (levelBitrate) {\u000a      maxBufLen = Math.max(8 * config.maxBufferSize / levelBitrate, config.maxBufferLength);\u000a    } else {\u000a      maxBufLen = config.maxBufferLength;\u000a    }\u000a\u000a    maxBufLen = Math.min(maxBufLen, config.maxMaxBufferLength); // determine next candidate fragment to be loaded, based on current position and end of buffer position\u000a    // ensure up to `config.maxMaxBufferLength` of buffer upfront\u000a\u000a    var maxBufferHole = pos < config.maxBufferHole ? Math.max(MAX_START_GAP_JUMP, config.maxBufferHole) : config.maxBufferHole;\u000a    var bufferInfo = BufferHelper.bufferInfo(this.mediaBuffer ? this.mediaBuffer : media, pos, maxBufferHole);\u000a    var bufferLen = bufferInfo.len; // Stay idle if we are still with buffer margins\u000a\u000a    if (bufferLen >= maxBufLen) {\u000a      return;\u000a    } // if buffer length is less than maxBufLen try to load a new fragment ...\u000a\u000a\u000a    logger["logger"].trace("buffer length of " + bufferLen.toFixed(3) + " is below max of " + maxBufLen.toFixed(3) + ". checking for more payload ..."); // set next load level : this will trigger a playlist load if needed\u000a\u000a    this.level = hls.nextLoadLevel = level;\u000a    var levelDetails = levelInfo.details; // if level info not retrieved yet, switch state and wait for level retrieval\u000a    // if live playlist, ensure that new playlist has been refreshed to avoid loading/try to load\u000a    // a useless and outdated fragment (that might even introduce load error if it is already out of the live playlist)\u000a\u000a    if (!levelDetails || levelDetails.live && this.levelLastLoaded !== level) {\u000a      this.state = State.WAITING_LEVEL;\u000a      return;\u000a    }\u000a\u000a    if (this._streamEnded(bufferInfo, levelDetails)) {\u000a      var data = {};\u000a\u000a      if (this.altAudio) {\u000a        data.type = 'video';\u000a      }\u000a\u000a      this.hls.trigger(events["default"].BUFFER_EOS, data);\u000a      this.state = State.ENDED;\u000a      return;\u000a    } // if we have the levelDetails for the selected variant, lets continue enrichen our stream (load keys/fragments or trigger EOS, etc..)\u000a\u000a\u000a    this._fetchPayloadOrEos(pos, bufferInfo, levelDetails);\u000a  };\u000a\u000a  _proto._fetchPayloadOrEos = function _fetchPayloadOrEos(pos, bufferInfo, levelDetails) {\u000a    var fragPrevious = this.fragPrevious,\u000a        level = this.level,\u000a        fragments = levelDetails.fragments,\u000a        fragLen = fragments.length; // empty playlist\u000a\u000a    if (fragLen === 0) {\u000a      return;\u000a    } // find fragment index, contiguous with end of buffer position\u000a\u000a\u000a    var start = fragments[0].start,\u000a        end = fragments[fragLen - 1].start + fragments[fragLen - 1].duration,\u000a        bufferEnd = bufferInfo.end,\u000a        frag;\u000a\u000a    if (levelDetails.initSegment && !levelDetails.initSegment.data) {\u000a      frag = levelDetails.initSegment;\u000a    } else {\u000a      // in case of live playlist we need to ensure that requested position is not located before playlist start\u000a      if (levelDetails.live) {\u000a        var initialLiveManifestSize = this.config.initialLiveManifestSize;\u000a\u000a        if (fragLen < initialLiveManifestSize) {\u000a          logger["logger"].warn("Can not start playback of a level, reason: not enough fragments " + fragLen + " < " + initialLiveManifestSize);\u000a          return;\u000a        }\u000a\u000a        frag = this._ensureFragmentAtLivePoint(levelDetails, bufferEnd, start, end, fragPrevious, fragments); // if it explicitely returns null don't load any fragment and exit function now\u000a\u000a        if (frag === null) {\u000a          return;\u000a        }\u000a      } else {\u000a        // VoD playlist: if bufferEnd before start of playlist, load first fragment\u000a        if (bufferEnd < start) {\u000a          frag = fragments[0];\u000a        }\u000a      }\u000a    }\u000a\u000a    if (!frag) {\u000a      frag = this._findFragment(start, fragPrevious, fragLen, fragments, bufferEnd, end, levelDetails);\u000a    }\u000a\u000a    if (frag) {\u000a      if (frag.encrypted) {\u000a        this._loadKey(frag, levelDetails);\u000a      } else {\u000a        this._loadFragment(frag, levelDetails, pos, bufferEnd);\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto._ensureFragmentAtLivePoint = function _ensureFragmentAtLivePoint(levelDetails, bufferEnd, start, end, fragPrevious, fragments) {\u000a    var config = this.hls.config,\u000a        media = this.media;\u000a    var frag; // check if requested position is within seekable boundaries :\u000a    // logger.log(`start/pos/bufEnd/seeking:${start.toFixed(3)}/${pos.toFixed(3)}/${bufferEnd.toFixed(3)}/${this.media.seeking}`);\u000a\u000a    var maxLatency = Infinity;\u000a\u000a    if (config.liveMaxLatencyDuration !== undefined) {\u000a      maxLatency = config.liveMaxLatencyDuration;\u000a    } else if (Object(number["isFiniteNumber"])(config.liveMaxLatencyDurationCount)) {\u000a      maxLatency = config.liveMaxLatencyDurationCount * levelDetails.targetduration;\u000a    }\u000a\u000a    if (bufferEnd < Math.max(start - config.maxFragLookUpTolerance, end - maxLatency)) {\u000a      var liveSyncPosition = this.liveSyncPosition = this.computeLivePosition(start, levelDetails);\u000a      bufferEnd = liveSyncPosition;\u000a\u000a      if (media && !media.paused && media.readyState && media.duration > liveSyncPosition && liveSyncPosition > media.currentTime) {\u000a        logger["logger"].log("buffer end: " + bufferEnd.toFixed(3) + " is located too far from the end of live sliding playlist, reset currentTime to : " + liveSyncPosition.toFixed(3));\u000a        media.currentTime = liveSyncPosition;\u000a      }\u000a\u000a      this.nextLoadPosition = liveSyncPosition;\u000a    } // if end of buffer greater than live edge, don't load any fragment\u000a    // this could happen if live playlist intermittently slides in the past.\u000a    // level 1 loaded [182580161,182580167]\u000a    // level 1 loaded [182580162,182580169]\u000a    // Loading 182580168 of [182580162 ,182580169],level 1 ..\u000a    // Loading 182580169 of [182580162 ,182580169],level 1 ..\u000a    // level 1 loaded [182580162,182580168] <============= here we should have bufferEnd > end. in that case break to avoid reloading 182580168\u000a    // level 1 loaded [182580164,182580171]\u000a    //\u000a    // don't return null in case media not loaded yet (readystate === 0)\u000a\u000a\u000a    if (levelDetails.PTSKnown && bufferEnd > end && media && media.readyState) {\u000a      return null;\u000a    }\u000a\u000a    if (this.startFragRequested && !levelDetails.PTSKnown) {\u000a      /* we are switching level on live playlist, but we don't have any PTS info for that quality level ...\u000a         try to load frag matching with next SN.\u000a         even if SN are not synchronized between playlists, loading this frag will help us\u000a         compute playlist sliding and find the right one after in case it was not the right consecutive one */\u000a      if (fragPrevious) {\u000a        if (levelDetails.hasProgramDateTime) {\u000a          // Relies on PDT in order to switch bitrates (Support EXT-X-DISCONTINUITY without EXT-X-DISCONTINUITY-SEQUENCE)\u000a          logger["logger"].log("live playlist, switching playlist, load frag with same PDT: " + fragPrevious.programDateTime);\u000a          frag = findFragmentByPDT(fragments, fragPrevious.endProgramDateTime, config.maxFragLookUpTolerance);\u000a        } else {\u000a          // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)\u000a          var targetSN = fragPrevious.sn + 1;\u000a\u000a          if (targetSN >= levelDetails.startSN && targetSN <= levelDetails.endSN) {\u000a            var fragNext = fragments[targetSN - levelDetails.startSN];\u000a\u000a            if (fragPrevious.cc === fragNext.cc) {\u000a              frag = fragNext;\u000a              logger["logger"].log("live playlist, switching playlist, load frag with next SN: " + frag.sn);\u000a            }\u000a          } // next frag SN not available (or not with same continuity counter)\u000a          // look for a frag sharing the same CC\u000a\u000a\u000a          if (!frag) {\u000a            frag = binary_search.search(fragments, function (frag) {\u000a              return fragPrevious.cc - frag.cc;\u000a            });\u000a\u000a            if (frag) {\u000a              logger["logger"].log("live playlist, switching playlist, load frag with same CC: " + frag.sn);\u000a            }\u000a          }\u000a        }\u000a      }\u000a    }\u000a\u000a    return frag;\u000a  };\u000a\u000a  _proto._findFragment = function _findFragment(start, fragPreviousLoad, fragmentIndexRange, fragments, bufferEnd, end, levelDetails) {\u000a    var config = this.hls.config;\u000a    var fragNextLoad;\u000a\u000a    if (bufferEnd < end) {\u000a      var lookupTolerance = bufferEnd > end - config.maxFragLookUpTolerance ? 0 : config.maxFragLookUpTolerance; // Remove the tolerance if it would put the bufferEnd past the actual end of stream\u000a      // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)\u000a\u000a      fragNextLoad = findFragmentByPTS(fragPreviousLoad, fragments, bufferEnd, lookupTolerance);\u000a    } else {\u000a      // reach end of playlist\u000a      fragNextLoad = fragments[fragmentIndexRange - 1];\u000a    }\u000a\u000a    if (fragNextLoad) {\u000a      var curSNIdx = fragNextLoad.sn - levelDetails.startSN;\u000a      var sameLevel = fragPreviousLoad && fragNextLoad.level === fragPreviousLoad.level;\u000a      var prevSnFrag = fragments[curSNIdx - 1];\u000a      var nextSnFrag = fragments[curSNIdx + 1]; // logger.log('find SN matching with pos:' +  bufferEnd + ':' + frag.sn);\u000a\u000a      if (fragPreviousLoad && fragNextLoad.sn === fragPreviousLoad.sn) {\u000a        if (sameLevel && !fragNextLoad.backtracked) {\u000a          if (fragNextLoad.sn < levelDetails.endSN) {\u000a            var deltaPTS = fragPreviousLoad.deltaPTS; // if there is a significant delta between audio and video, larger than max allowed hole,\u000a            // and if previous remuxed fragment did not start with a keyframe. (fragPrevious.dropped)\u000a            // let's try to load previous fragment again to get last keyframe\u000a            // then we will reload again current fragment (that way we should be able to fill the buffer hole ...)\u000a\u000a            if (deltaPTS && deltaPTS > config.maxBufferHole && fragPreviousLoad.dropped && curSNIdx) {\u000a              fragNextLoad = prevSnFrag;\u000a              logger["logger"].warn('Previous fragment was dropped with large PTS gap between audio and video. Maybe fragment is not starting with a keyframe? Loading previous one to try to overcome this');\u000a            } else {\u000a              fragNextLoad = nextSnFrag;\u000a              logger["logger"].log("Re-loading fragment with SN: " + fragNextLoad.sn);\u000a            }\u000a          } else {\u000a            fragNextLoad = null;\u000a          }\u000a        } else if (fragNextLoad.backtracked) {\u000a          // Only backtrack a max of 1 consecutive fragment to prevent sliding back too far when little or no frags start with keyframes\u000a          if (nextSnFrag && nextSnFrag.backtracked) {\u000a            logger["logger"].warn("Already backtracked from fragment " + nextSnFrag.sn + ", will not backtrack to fragment " + fragNextLoad.sn + ". Loading fragment " + nextSnFrag.sn);\u000a            fragNextLoad = nextSnFrag;\u000a          } else {\u000a            // If a fragment has dropped frames and it's in a same level/sequence, load the previous fragment to try and find the keyframe\u000a            // Reset the dropped count now since it won't be reset until we parse the fragment again, which prevents infinite backtracking on the same segment\u000a            logger["logger"].warn('Loaded fragment with dropped frames, backtracking 1 segment to find a keyframe');\u000a            fragNextLoad.dropped = 0;\u000a\u000a            if (prevSnFrag) {\u000a              fragNextLoad = prevSnFrag;\u000a              fragNextLoad.backtracked = true;\u000a            } else if (curSNIdx) {\u000a              // can't backtrack on very first fragment\u000a              fragNextLoad = null;\u000a            }\u000a          }\u000a        }\u000a      }\u000a    }\u000a\u000a    return fragNextLoad;\u000a  };\u000a\u000a  _proto._loadKey = function _loadKey(frag, levelDetails) {\u000a    logger["logger"].log("Loading key for " + frag.sn + " of [" + levelDetails.startSN + " ," + levelDetails.endSN + "],level " + this.level);\u000a    this.state = State.KEY_LOADING;\u000a    this.hls.trigger(events["default"].KEY_LOADING, {\u000a      frag: frag\u000a    });\u000a  };\u000a\u000a  _proto._loadFragment = function _loadFragment(frag, levelDetails, pos, bufferEnd) {\u000a    // Check if fragment is not loaded\u000a    var fragState = this.fragmentTracker.getState(frag);\u000a    this.fragCurrent = frag;\u000a\u000a    if (frag.sn !== 'initSegment') {\u000a      this.startFragRequested = true;\u000a    } // Don't update nextLoadPosition for fragments which are not buffered\u000a\u000a\u000a    if (Object(number["isFiniteNumber"])(frag.sn) && !frag.bitrateTest) {\u000a      this.nextLoadPosition = frag.start + frag.duration;\u000a    } // Allow backtracked fragments to load\u000a\u000a\u000a    if (frag.backtracked || fragState === FragmentState.NOT_LOADED || fragState === FragmentState.PARTIAL) {\u000a      frag.autoLevel = this.hls.autoLevelEnabled;\u000a      frag.bitrateTest = this.bitrateTest;\u000a      logger["logger"].log("Loading " + frag.sn + " of [" + levelDetails.startSN + " ," + levelDetails.endSN + "],level " + this.level + ", currentTime:" + pos.toFixed(3) + ",bufferEnd:" + bufferEnd.toFixed(3));\u000a      this.hls.trigger(events["default"].FRAG_LOADING, {\u000a        frag: frag\u000a      }); // lazy demuxer init, as this could take some time ... do it during frag loading\u000a\u000a      if (!this.demuxer) {\u000a        this.demuxer = new demux_demuxer(this.hls, 'main');\u000a      }\u000a\u000a      this.state = State.FRAG_LOADING;\u000a    } else if (fragState === FragmentState.APPENDING) {\u000a      // Lower the buffer size and try again\u000a      if (this._reduceMaxBufferLength(frag.duration)) {\u000a        this.fragmentTracker.removeFragment(frag);\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.getBufferedFrag = function getBufferedFrag(position) {\u000a    return this.fragmentTracker.getBufferedFrag(position, PlaylistLevelType.MAIN);\u000a  };\u000a\u000a  _proto.followingBufferedFrag = function followingBufferedFrag(frag) {\u000a    if (frag) {\u000a      // try to get range of next fragment (500ms after this range)\u000a      return this.getBufferedFrag(frag.endPTS + 0.5);\u000a    }\u000a\u000a    return null;\u000a  };\u000a\u000a  _proto._checkFragmentChanged = function _checkFragmentChanged() {\u000a    var fragPlayingCurrent,\u000a        currentTime,\u000a        video = this.media;\u000a\u000a    if (video && video.readyState && video.seeking === false) {\u000a      currentTime = video.currentTime;\u000a      /* if video element is in seeked state, currentTime can only increase.\u000a        (assuming that playback rate is positive ...)\u000a        As sometimes currentTime jumps back to zero after a\u000a        media decode error, check this, to avoid seeking back to\u000a        wrong position after a media decode error\u000a      */\u000a\u000a      if (currentTime > this.lastCurrentTime) {\u000a        this.lastCurrentTime = currentTime;\u000a      }\u000a\u000a      if (BufferHelper.isBuffered(video, currentTime)) {\u000a        fragPlayingCurrent = this.getBufferedFrag(currentTime);\u000a      } else if (BufferHelper.isBuffered(video, currentTime + 0.1)) {\u000a        /* ensure that FRAG_CHANGED event is triggered at startup,\u000a          when first video frame is displayed and playback is paused.\u000a          add a tolerance of 100ms, in case current position is not buffered,\u000a          check if current pos+100ms is buffered and use that buffer range\u000a          for FRAG_CHANGED event reporting */\u000a        fragPlayingCurrent = this.getBufferedFrag(currentTime + 0.1);\u000a      }\u000a\u000a      if (fragPlayingCurrent) {\u000a        var fragPlaying = fragPlayingCurrent;\u000a\u000a        if (fragPlaying !== this.fragPlaying) {\u000a          this.hls.trigger(events["default"].FRAG_CHANGED, {\u000a            frag: fragPlaying\u000a          });\u000a          var fragPlayingLevel = fragPlaying.level;\u000a\u000a          if (!this.fragPlaying || this.fragPlaying.level !== fragPlayingLevel) {\u000a            this.hls.trigger(events["default"].LEVEL_SWITCHED, {\u000a              level: fragPlayingLevel\u000a            });\u000a          }\u000a\u000a          this.fragPlaying = fragPlaying;\u000a        }\u000a      }\u000a    }\u000a  }\u000a  /*\u000a    on immediate level switch :\u000a     - pause playback if playing\u000a     - cancel any pending load request\u000a     - and trigger a buffer flush\u000a  */\u000a  ;\u000a\u000a  _proto.immediateLevelSwitch = function immediateLevelSwitch() {\u000a    logger["logger"].log('immediateLevelSwitch');\u000a\u000a    if (!this.immediateSwitch) {\u000a      this.immediateSwitch = true;\u000a      var media = this.media,\u000a          previouslyPaused;\u000a\u000a      if (media) {\u000a        previouslyPaused = media.paused;\u000a        media.pause();\u000a      } else {\u000a        // don't restart playback after instant level switch in case media not attached\u000a        previouslyPaused = true;\u000a      }\u000a\u000a      this.previouslyPaused = previouslyPaused;\u000a    }\u000a\u000a    var fragCurrent = this.fragCurrent;\u000a\u000a    if (fragCurrent && fragCurrent.loader) {\u000a      fragCurrent.loader.abort();\u000a    }\u000a\u000a    this.fragCurrent = null; // flush everything\u000a\u000a    this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\u000a  }\u000a  /**\u000a   * on immediate level switch end, after new fragment has been buffered:\u000a   * - nudge video decoder by slightly adjusting video currentTime (if currentTime buffered)\u000a   * - resume the playback if needed\u000a   */\u000a  ;\u000a\u000a  _proto.immediateLevelSwitchEnd = function immediateLevelSwitchEnd() {\u000a    var media = this.media;\u000a\u000a    if (media && media.buffered.length) {\u000a      this.immediateSwitch = false;\u000a\u000a      if (BufferHelper.isBuffered(media, media.currentTime)) {\u000a        // only nudge if currentTime is buffered\u000a        media.currentTime -= 0.0001;\u000a      }\u000a\u000a      if (!this.previouslyPaused) {\u000a        media.play();\u000a      }\u000a    }\u000a  }\u000a  /**\u000a   * try to switch ASAP without breaking video playback:\u000a   * in order to ensure smooth but quick level switching,\u000a   * we need to find the next flushable buffer range\u000a   * we should take into account new segment fetch time\u000a   */\u000a  ;\u000a\u000a  _proto.nextLevelSwitch = function nextLevelSwitch() {\u000a    var media = this.media; // ensure that media is defined and that metadata are available (to retrieve currentTime)\u000a\u000a    if (media && media.readyState) {\u000a      var fetchdelay, fragPlayingCurrent, nextBufferedFrag;\u000a      fragPlayingCurrent = this.getBufferedFrag(media.currentTime);\u000a\u000a      if (fragPlayingCurrent && fragPlayingCurrent.startPTS > 1) {\u000a        // flush buffer preceding current fragment (flush until current fragment start offset)\u000a        // minus 1s to avoid video freezing, that could happen if we flush keyframe of current video ...\u000a        this.flushMainBuffer(0, fragPlayingCurrent.startPTS - 1);\u000a      }\u000a\u000a      if (!media.paused) {\u000a        // add a safety delay of 1s\u000a        var nextLevelId = this.hls.nextLoadLevel,\u000a            nextLevel = this.levels[nextLevelId],\u000a            fragLastKbps = this.fragLastKbps;\u000a\u000a        if (fragLastKbps && this.fragCurrent) {\u000a          fetchdelay = this.fragCurrent.duration * nextLevel.bitrate / (1000 * fragLastKbps) + 1;\u000a        } else {\u000a          fetchdelay = 0;\u000a        }\u000a      } else {\u000a        fetchdelay = 0;\u000a      } // logger.log('fetchdelay:'+fetchdelay);\u000a      // find buffer range that will be reached once new fragment will be fetched\u000a\u000a\u000a      nextBufferedFrag = this.getBufferedFrag(media.currentTime + fetchdelay);\u000a\u000a      if (nextBufferedFrag) {\u000a        // we can flush buffer range following this one without stalling playback\u000a        nextBufferedFrag = this.followingBufferedFrag(nextBufferedFrag);\u000a\u000a        if (nextBufferedFrag) {\u000a          // if we are here, we can also cancel any loading/demuxing in progress, as they are useless\u000a          var fragCurrent = this.fragCurrent;\u000a\u000a          if (fragCurrent && fragCurrent.loader) {\u000a            fragCurrent.loader.abort();\u000a          }\u000a\u000a          this.fragCurrent = null; // start flush position is the start PTS of next buffered frag.\u000a          // we use frag.naxStartPTS which is max(audio startPTS, video startPTS).\u000a          // in case there is a small PTS Delta between audio and video, using maxStartPTS avoids flushing last samples from current fragment\u000a\u000a          this.flushMainBuffer(nextBufferedFrag.maxStartPTS, Number.POSITIVE_INFINITY);\u000a        }\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.flushMainBuffer = function flushMainBuffer(startOffset, endOffset) {\u000a    this.state = State.BUFFER_FLUSHING;\u000a    var flushScope = {\u000a      startOffset: startOffset,\u000a      endOffset: endOffset\u000a    }; // if alternate audio tracks are used, only flush video, otherwise flush everything\u000a\u000a    if (this.altAudio) {\u000a      flushScope.type = 'video';\u000a    }\u000a\u000a    this.hls.trigger(events["default"].BUFFER_FLUSHING, flushScope);\u000a  };\u000a\u000a  _proto.onMediaAttached = function onMediaAttached(data) {\u000a    var media = this.media = this.mediaBuffer = data.media;\u000a    this.onvseeking = this.onMediaSeeking.bind(this);\u000a    this.onvseeked = this.onMediaSeeked.bind(this);\u000a    this.onvended = this.onMediaEnded.bind(this);\u000a    media.addEventListener('seeking', this.onvseeking);\u000a    media.addEventListener('seeked', this.onvseeked);\u000a    media.addEventListener('ended', this.onvended);\u000a    var config = this.config;\u000a\u000a    if (this.levels && config.autoStartLoad) {\u000a      this.hls.startLoad(config.startPosition);\u000a    }\u000a\u000a    this.gapController = new gap_controller_GapController(config, media, this.fragmentTracker, this.hls);\u000a  };\u000a\u000a  _proto.onMediaDetaching = function onMediaDetaching() {\u000a    var media = this.media;\u000a\u000a    if (media && media.ended) {\u000a      logger["logger"].log('MSE detaching and video ended, reset startPosition');\u000a      this.startPosition = this.lastCurrentTime = 0;\u000a    } // reset fragment backtracked flag\u000a\u000a\u000a    var levels = this.levels;\u000a\u000a    if (levels) {\u000a      levels.forEach(function (level) {\u000a        if (level.details) {\u000a          level.details.fragments.forEach(function (fragment) {\u000a            fragment.backtracked = undefined;\u000a          });\u000a        }\u000a      });\u000a    } // remove video listeners\u000a\u000a\u000a    if (media) {\u000a      media.removeEventListener('seeking', this.onvseeking);\u000a      media.removeEventListener('seeked', this.onvseeked);\u000a      media.removeEventListener('ended', this.onvended);\u000a      this.onvseeking = this.onvseeked = this.onvended = null;\u000a    }\u000a\u000a    this.fragmentTracker.removeAllFragments();\u000a    this.media = this.mediaBuffer = null;\u000a    this.loadedmetadata = false;\u000a    this.stopLoad();\u000a  };\u000a\u000a  _proto.onMediaSeeked = function onMediaSeeked() {\u000a    var media = this.media;\u000a    var currentTime = media ? media.currentTime : undefined;\u000a\u000a    if (Object(number["isFiniteNumber"])(currentTime)) {\u000a      logger["logger"].log("media seeked to " + currentTime.toFixed(3));\u000a    } // tick to speed up FRAGMENT_PLAYING triggering\u000a\u000a\u000a    this.tick();\u000a  };\u000a\u000a  _proto.onManifestLoading = function onManifestLoading() {\u000a    // reset buffer on manifest loading\u000a    logger["logger"].log('trigger BUFFER_RESET');\u000a    this.hls.trigger(events["default"].BUFFER_RESET);\u000a    this.fragmentTracker.removeAllFragments();\u000a    this.stalled = false;\u000a    this.startPosition = this.lastCurrentTime = 0;\u000a  };\u000a\u000a  _proto.onManifestParsed = function onManifestParsed(data) {\u000a    var aac = false,\u000a        heaac = false,\u000a        codec;\u000a    data.levels.forEach(function (level) {\u000a      // detect if we have different kind of audio codecs used amongst playlists\u000a      codec = level.audioCodec;\u000a\u000a      if (codec) {\u000a        if (codec.indexOf('mp4a.40.2') !== -1) {\u000a          aac = true;\u000a        }\u000a\u000a        if (codec.indexOf('mp4a.40.5') !== -1) {\u000a          heaac = true;\u000a        }\u000a      }\u000a    });\u000a    this.audioCodecSwitch = aac && heaac;\u000a\u000a    if (this.audioCodecSwitch) {\u000a      logger["logger"].log('both AAC/HE-AAC audio found in levels; declaring level codec as HE-AAC');\u000a    }\u000a\u000a    this.altAudio = data.altAudio;\u000a    this.levels = data.levels;\u000a    this.startFragRequested = false;\u000a    var config = this.config;\u000a\u000a    if (config.autoStartLoad || this.forceStartLoad) {\u000a      this.hls.startLoad(config.startPosition);\u000a    }\u000a  };\u000a\u000a  _proto.onLevelLoaded = function onLevelLoaded(data) {\u000a    var newDetails = data.details;\u000a    var newLevelId = data.level;\u000a    var lastLevel = this.levels[this.levelLastLoaded];\u000a    var curLevel = this.levels[newLevelId];\u000a    var duration = newDetails.totalduration;\u000a    var sliding = 0;\u000a    logger["logger"].log("level " + newLevelId + " loaded [" + newDetails.startSN + "," + newDetails.endSN + "],duration:" + duration);\u000a\u000a    if (newDetails.live) {\u000a      var curDetails = curLevel.details;\u000a\u000a      if (curDetails && newDetails.fragments.length > 0) {\u000a        // we already have details for that level, merge them\u000a        mergeDetails(curDetails, newDetails);\u000a        sliding = newDetails.fragments[0].start;\u000a        this.liveSyncPosition = this.computeLivePosition(sliding, curDetails);\u000a\u000a        if (newDetails.PTSKnown && Object(number["isFiniteNumber"])(sliding)) {\u000a          logger["logger"].log("live playlist sliding:" + sliding.toFixed(3));\u000a        } else {\u000a          logger["logger"].log('live playlist - outdated PTS, unknown sliding');\u000a          alignStream(this.fragPrevious, lastLevel, newDetails);\u000a        }\u000a      } else {\u000a        logger["logger"].log('live playlist - first load, unknown sliding');\u000a        newDetails.PTSKnown = false;\u000a        alignStream(this.fragPrevious, lastLevel, newDetails);\u000a      }\u000a    } else {\u000a      newDetails.PTSKnown = false;\u000a    } // override level info\u000a\u000a\u000a    curLevel.details = newDetails;\u000a    this.levelLastLoaded = newLevelId;\u000a    this.hls.trigger(events["default"].LEVEL_UPDATED, {\u000a      details: newDetails,\u000a      level: newLevelId\u000a    });\u000a\u000a    if (this.startFragRequested === false) {\u000a      // compute start position if set to -1. use it straight away if value is defined\u000a      if (this.startPosition === -1 || this.lastCurrentTime === -1) {\u000a        // first, check if start time offset has been set in playlist, if yes, use this value\u000a        var startTimeOffset = newDetails.startTimeOffset;\u000a\u000a        if (Object(number["isFiniteNumber"])(startTimeOffset)) {\u000a          if (startTimeOffset < 0) {\u000a            logger["logger"].log("negative start time offset " + startTimeOffset + ", count from end of last fragment");\u000a            startTimeOffset = sliding + duration + startTimeOffset;\u000a          }\u000a\u000a          logger["logger"].log("start time offset found in playlist, adjust startPosition to " + startTimeOffset);\u000a          this.startPosition = startTimeOffset;\u000a        } else {\u000a          // if live playlist, set start position to be fragment N-this.config.liveSyncDurationCount (usually 3)\u000a          if (newDetails.live) {\u000a            this.startPosition = this.computeLivePosition(sliding, newDetails);\u000a            logger["logger"].log("configure startPosition to " + this.startPosition);\u000a          } else {\u000a            this.startPosition = 0;\u000a          }\u000a        }\u000a\u000a        this.lastCurrentTime = this.startPosition;\u000a      }\u000a\u000a      this.nextLoadPosition = this.startPosition;\u000a    } // only switch batck to IDLE state if we were waiting for level to start downloading a new fragment\u000a\u000a\u000a    if (this.state === State.WAITING_LEVEL) {\u000a      this.state = State.IDLE;\u000a    } // trigger handler right now\u000a\u000a\u000a    this.tick();\u000a  };\u000a\u000a  _proto.onKeyLoaded = function onKeyLoaded() {\u000a    if (this.state === State.KEY_LOADING) {\u000a      this.state = State.IDLE;\u000a      this.tick();\u000a    }\u000a  };\u000a\u000a  _proto.onFragLoaded = function onFragLoaded(data) {\u000a    var fragCurrent = this.fragCurrent,\u000a        hls = this.hls,\u000a        levels = this.levels,\u000a        media = this.media;\u000a    var fragLoaded = data.frag;\u000a\u000a    if (this.state === State.FRAG_LOADING && fragCurrent && fragLoaded.type === 'main' && fragLoaded.level === fragCurrent.level && fragLoaded.sn === fragCurrent.sn) {\u000a      var stats = data.stats;\u000a      var currentLevel = levels[fragCurrent.level];\u000a      var details = currentLevel.details; // reset frag bitrate test in any case after frag loaded event\u000a      // if this frag was loaded to perform a bitrate test AND if hls.nextLoadLevel is greater than 0\u000a      // then this means that we should be able to load a fragment at a higher quality level\u000a\u000a      this.bitrateTest = false;\u000a      this.stats = stats;\u000a      logger["logger"].log("Loaded " + fragCurrent.sn + " of [" + details.startSN + " ," + details.endSN + "],level " + fragCurrent.level);\u000a\u000a      if (fragLoaded.bitrateTest && hls.nextLoadLevel) {\u000a        // switch back to IDLE state ... we just loaded a fragment to determine adequate start bitrate and initialize autoswitch algo\u000a        this.state = State.IDLE;\u000a        this.startFragRequested = false;\u000a        stats.tparsed = stats.tbuffered = window.performance.now();\u000a        hls.trigger(events["default"].FRAG_BUFFERED, {\u000a          stats: stats,\u000a          frag: fragCurrent,\u000a          id: 'main'\u000a        });\u000a        this.tick();\u000a      } else if (fragLoaded.sn === 'initSegment') {\u000a        this.state = State.IDLE;\u000a        stats.tparsed = stats.tbuffered = window.performance.now();\u000a        details.initSegment.data = data.payload;\u000a        hls.trigger(events["default"].FRAG_BUFFERED, {\u000a          stats: stats,\u000a          frag: fragCurrent,\u000a          id: 'main'\u000a        });\u000a        this.tick();\u000a      } else {\u000a        logger["logger"].log("Parsing " + fragCurrent.sn + " of [" + details.startSN + " ," + details.endSN + "],level " + fragCurrent.level + ", cc " + fragCurrent.cc);\u000a        this.state = State.PARSING;\u000a        this.pendingBuffering = true;\u000a        this.appended = false; // Bitrate test frags are not usually buffered so the fragment tracker ignores them. If Hls.js decides to buffer\u000a        // it (and therefore ends up at this line), then the fragment tracker needs to be manually informed.\u000a\u000a        if (fragLoaded.bitrateTest) {\u000a          fragLoaded.bitrateTest = false;\u000a          this.fragmentTracker.onFragLoaded({\u000a            frag: fragLoaded\u000a          });\u000a        } // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live) and if media is not seeking (this is to overcome potential timestamp drifts between playlists and fragments)\u000a\u000a\u000a        var accurateTimeOffset = !(media && media.seeking) && (details.PTSKnown || !details.live);\u000a        var initSegmentData = details.initSegment ? details.initSegment.data : [];\u000a\u000a        var audioCodec = this._getAudioCodec(currentLevel); // transmux the MPEG-TS data to ISO-BMFF segments\u000a\u000a\u000a        var demuxer = this.demuxer = this.demuxer || new demux_demuxer(this.hls, 'main');\u000a        demuxer.push(data.payload, initSegmentData, audioCodec, currentLevel.videoCodec, fragCurrent, details.totalduration, accurateTimeOffset);\u000a      }\u000a    }\u000a\u000a    this.fragLoadError = 0;\u000a  };\u000a\u000a  _proto.onFragParsingInitSegment = function onFragParsingInitSegment(data) {\u000a    var fragCurrent = this.fragCurrent;\u000a    var fragNew = data.frag;\u000a\u000a    if (fragCurrent && data.id === 'main' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === State.PARSING) {\u000a      var tracks = data.tracks,\u000a          trackName,\u000a          track;\u000a      this.audioOnly = tracks.audio && !tracks.video; // if audio track is expected to come from audio stream controller, discard any coming from main\u000a\u000a      if (this.altAudio && !this.audioOnly) {\u000a        delete tracks.audio;\u000a      } // include levelCodec in audio and video tracks\u000a\u000a\u000a      track = tracks.audio;\u000a\u000a      if (track) {\u000a        var audioCodec = this.levels[this.level].audioCodec,\u000a            ua = navigator.userAgent.toLowerCase();\u000a\u000a        if (audioCodec && this.audioCodecSwap) {\u000a          logger["logger"].log('swapping playlist audio codec');\u000a\u000a          if (audioCodec.indexOf('mp4a.40.5') !== -1) {\u000a            audioCodec = 'mp4a.40.2';\u000a          } else {\u000a            audioCodec = 'mp4a.40.5';\u000a          }\u000a        } // in case AAC and HE-AAC audio codecs are signalled in manifest\u000a        // force HE-AAC , as it seems that most browsers prefers that way,\u000a        // except for mono streams OR on FF\u000a        // these conditions might need to be reviewed ...\u000a\u000a\u000a        if (this.audioCodecSwitch) {\u000a          // don't force HE-AAC if mono stream\u000a          if (track.metadata.channelCount !== 1 && // don't force HE-AAC if firefox\u000a          ua.indexOf('firefox') === -1) {\u000a            audioCodec = 'mp4a.40.5';\u000a          }\u000a        } // HE-AAC is broken on Android, always signal audio codec as AAC even if variant manifest states otherwise\u000a\u000a\u000a        if (ua.indexOf('android') !== -1 && track.container !== 'audio/mpeg') {\u000a          // Exclude mpeg audio\u000a          audioCodec = 'mp4a.40.2';\u000a          logger["logger"].log("Android: force audio codec to " + audioCodec);\u000a        }\u000a\u000a        track.levelCodec = audioCodec;\u000a        track.id = data.id;\u000a      }\u000a\u000a      track = tracks.video;\u000a\u000a      if (track) {\u000a        track.levelCodec = this.levels[this.level].videoCodec;\u000a        track.id = data.id;\u000a      }\u000a\u000a      this.hls.trigger(events["default"].BUFFER_CODECS, tracks); // loop through tracks that are going to be provided to bufferController\u000a\u000a      for (trackName in tracks) {\u000a        track = tracks[trackName];\u000a        logger["logger"].log("main track:" + trackName + ",container:" + track.container + ",codecs[level/parsed]=[" + track.levelCodec + "/" + track.codec + "]");\u000a        var initSegment = track.initSegment;\u000a\u000a        if (initSegment) {\u000a          this.appended = true; // arm pending Buffering flag before appending a segment\u000a\u000a          this.pendingBuffering = true;\u000a          this.hls.trigger(events["default"].BUFFER_APPENDING, {\u000a            type: trackName,\u000a            data: initSegment,\u000a            parent: 'main',\u000a            content: 'initSegment'\u000a          });\u000a        }\u000a      } // trigger handler right now\u000a\u000a\u000a      this.tick();\u000a    }\u000a  };\u000a\u000a  _proto.onFragParsingData = function onFragParsingData(data) {\u000a    var _this2 = this;\u000a\u000a    var fragCurrent = this.fragCurrent;\u000a    var fragNew = data.frag;\u000a\u000a    if (fragCurrent && data.id === 'main' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && !(data.type === 'audio' && this.altAudio) && // filter out main audio if audio track is loaded through audio stream controller\u000a    this.state === State.PARSING) {\u000a      var level = this.levels[this.level],\u000a          frag = fragCurrent;\u000a\u000a      if (!Object(number["isFiniteNumber"])(data.endPTS)) {\u000a        data.endPTS = data.startPTS + fragCurrent.duration;\u000a        data.endDTS = data.startDTS + fragCurrent.duration;\u000a      }\u000a\u000a      if (data.hasAudio === true) {\u000a        frag.addElementaryStream(ElementaryStreamTypes.AUDIO);\u000a      }\u000a\u000a      if (data.hasVideo === true) {\u000a        frag.addElementaryStream(ElementaryStreamTypes.VIDEO);\u000a      }\u000a\u000a      logger["logger"].log("Parsed " + data.type + ",PTS:[" + data.startPTS.toFixed(3) + "," + data.endPTS.toFixed(3) + "],DTS:[" + data.startDTS.toFixed(3) + "/" + data.endDTS.toFixed(3) + "],nb:" + data.nb + ",dropped:" + (data.dropped || 0)); // Detect gaps in a fragment  and try to fix it by finding a keyframe in the previous fragment (see _findFragments)\u000a\u000a      if (data.type === 'video') {\u000a        frag.dropped = data.dropped;\u000a\u000a        if (frag.dropped) {\u000a          if (!frag.backtracked) {\u000a            var levelDetails = level.details;\u000a\u000a            if (levelDetails && frag.sn === levelDetails.startSN) {\u000a              logger["logger"].warn('missing video frame(s) on first frag, appending with gap', frag.sn);\u000a            } else {\u000a              logger["logger"].warn('missing video frame(s), backtracking fragment', frag.sn); // Return back to the IDLE state without appending to buffer\u000a              // Causes findFragments to backtrack a segment and find the keyframe\u000a              // Audio fragments arriving before video sets the nextLoadPosition, causing _findFragments to skip the backtracked fragment\u000a\u000a              this.fragmentTracker.removeFragment(frag);\u000a              frag.backtracked = true;\u000a              this.nextLoadPosition = data.startPTS;\u000a              this.state = State.IDLE;\u000a              this.fragPrevious = frag;\u000a\u000a              if (this.demuxer) {\u000a                this.demuxer.destroy();\u000a                this.demuxer = null;\u000a              }\u000a\u000a              this.tick();\u000a              return;\u000a            }\u000a          } else {\u000a            logger["logger"].warn('Already backtracked on this fragment, appending with the gap', frag.sn);\u000a          }\u000a        } else {\u000a          // Only reset the backtracked flag if we've loaded the frag without any dropped frames\u000a          frag.backtracked = false;\u000a        }\u000a      }\u000a\u000a      var drift = updateFragPTSDTS(level.details, frag, data.startPTS, data.endPTS, data.startDTS, data.endDTS),\u000a          hls = this.hls;\u000a      hls.trigger(events["default"].LEVEL_PTS_UPDATED, {\u000a        details: level.details,\u000a        level: this.level,\u000a        drift: drift,\u000a        type: data.type,\u000a        start: data.startPTS,\u000a        end: data.endPTS\u000a      }); // has remuxer dropped video frames located before first keyframe ?\u000a\u000a      [data.data1, data.data2].forEach(function (buffer) {\u000a        // only append in PARSING state (rationale is that an appending error could happen synchronously on first segment appending)\u000a        // in that case it is useless to append following segments\u000a        if (buffer && buffer.length && _this2.state === State.PARSING) {\u000a          _this2.appended = true; // arm pending Buffering flag before appending a segment\u000a\u000a          _this2.pendingBuffering = true;\u000a          hls.trigger(events["default"].BUFFER_APPENDING, {\u000a            type: data.type,\u000a            data: buffer,\u000a            parent: 'main',\u000a            content: 'data'\u000a          });\u000a        }\u000a      }); // trigger handler right now\u000a\u000a      this.tick();\u000a    }\u000a  };\u000a\u000a  _proto.onFragParsed = function onFragParsed(data) {\u000a    var fragCurrent = this.fragCurrent;\u000a    var fragNew = data.frag;\u000a\u000a    if (fragCurrent && data.id === 'main' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === State.PARSING) {\u000a      this.stats.tparsed = window.performance.now();\u000a      this.state = State.PARSED;\u000a\u000a      this._checkAppendedParsed();\u000a    }\u000a  };\u000a\u000a  _proto.onAudioTrackSwitching = function onAudioTrackSwitching(data) {\u000a    // if any URL found on new audio track, it is an alternate audio track\u000a    var altAudio = !!data.url,\u000a        trackId = data.id; // if we switch on main audio, ensure that main fragment scheduling is synced with media.buffered\u000a    // don't do anything if we switch to alt audio: audio stream controller is handling it.\u000a    // we will just have to change buffer scheduling on audioTrackSwitched\u000a\u000a    if (!altAudio) {\u000a      if (this.mediaBuffer !== this.media) {\u000a        logger["logger"].log('switching on main audio, use media.buffered to schedule main fragment loading');\u000a        this.mediaBuffer = this.media;\u000a        var fragCurrent = this.fragCurrent; // we need to refill audio buffer from main: cancel any frag loading to speed up audio switch\u000a\u000a        if (fragCurrent.loader) {\u000a          logger["logger"].log('switching to main audio track, cancel main fragment load');\u000a          fragCurrent.loader.abort();\u000a        }\u000a\u000a        this.fragCurrent = null;\u000a        this.fragPrevious = null; // destroy demuxer to force init segment generation (following audio switch)\u000a\u000a        if (this.demuxer) {\u000a          this.demuxer.destroy();\u000a          this.demuxer = null;\u000a        } // switch to IDLE state to load new fragment\u000a\u000a\u000a        this.state = State.IDLE;\u000a      }\u000a\u000a      var hls = this.hls; // switching to main audio, flush all audio and trigger track switched\u000a\u000a      hls.trigger(events["default"].BUFFER_FLUSHING, {\u000a        startOffset: 0,\u000a        endOffset: Number.POSITIVE_INFINITY,\u000a        type: 'audio'\u000a      });\u000a      hls.trigger(events["default"].AUDIO_TRACK_SWITCHED, {\u000a        id: trackId\u000a      });\u000a      this.altAudio = false;\u000a    }\u000a  };\u000a\u000a  _proto.onAudioTrackSwitched = function onAudioTrackSwitched(data) {\u000a    var trackId = data.id,\u000a        altAudio = !!this.hls.audioTracks[trackId].url;\u000a\u000a    if (altAudio) {\u000a      var videoBuffer = this.videoBuffer; // if we switched on alternate audio, ensure that main fragment scheduling is synced with video sourcebuffer buffered\u000a\u000a      if (videoBuffer && this.mediaBuffer !== videoBuffer) {\u000a        logger["logger"].log('switching on alternate audio, use video.buffered to schedule main fragment loading');\u000a        this.mediaBuffer = videoBuffer;\u000a      }\u000a    }\u000a\u000a    this.altAudio = altAudio;\u000a    this.tick();\u000a  };\u000a\u000a  _proto.onBufferCreated = function onBufferCreated(data) {\u000a    var tracks = data.tracks,\u000a        mediaTrack,\u000a        name,\u000a        alternate = false;\u000a\u000a    for (var type in tracks) {\u000a      var track = tracks[type];\u000a\u000a      if (track.id === 'main') {\u000a        name = type;\u000a        mediaTrack = track; // keep video source buffer reference\u000a\u000a        if (type === 'video') {\u000a          this.videoBuffer = tracks[type].buffer;\u000a        }\u000a      } else {\u000a        alternate = true;\u000a      }\u000a    }\u000a\u000a    if (alternate && mediaTrack) {\u000a      logger["logger"].log("alternate track found, use " + name + ".buffered to schedule main fragment loading");\u000a      this.mediaBuffer = mediaTrack.buffer;\u000a    } else {\u000a      this.mediaBuffer = this.media;\u000a    }\u000a  };\u000a\u000a  _proto.onBufferAppended = function onBufferAppended(data) {\u000a    if (data.parent === 'main') {\u000a      var state = this.state;\u000a\u000a      if (state === State.PARSING || state === State.PARSED) {\u000a        // check if all buffers have been appended\u000a        this.pendingBuffering = data.pending > 0;\u000a\u000a        this._checkAppendedParsed();\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto._checkAppendedParsed = function _checkAppendedParsed() {\u000a    // trigger handler right now\u000a    if (this.state === State.PARSED && (!this.appended || !this.pendingBuffering)) {\u000a      var frag = this.fragCurrent;\u000a\u000a      if (frag) {\u000a        var media = this.mediaBuffer ? this.mediaBuffer : this.media;\u000a        logger["logger"].log("main buffered : " + time_ranges.toString(media.buffered));\u000a        this.fragPrevious = frag;\u000a        var stats = this.stats;\u000a        stats.tbuffered = window.performance.now(); // we should get rid of this.fragLastKbps\u000a\u000a        this.fragLastKbps = Math.round(8 * stats.total / (stats.tbuffered - stats.tfirst));\u000a        this.hls.trigger(events["default"].FRAG_BUFFERED, {\u000a          stats: stats,\u000a          frag: frag,\u000a          id: 'main'\u000a        });\u000a        this.state = State.IDLE;\u000a      } // Do not tick when _seekToStartPos needs to be called as seeking to the start can fail on live streams at this point\u000a\u000a\u000a      if (this.loadedmetadata || this.startPosition <= 0) {\u000a        this.tick();\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onError = function onError(data) {\u000a    var frag = data.frag || this.fragCurrent; // don't handle frag error not related to main fragment\u000a\u000a    if (frag && frag.type !== 'main') {\u000a      return;\u000a    } // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end\u000a\u000a\u000a    var mediaBuffered = !!this.media && BufferHelper.isBuffered(this.media, this.media.currentTime) && BufferHelper.isBuffered(this.media, this.media.currentTime + 0.5);\u000a\u000a    switch (data.details) {\u000a      case errors["ErrorDetails"].FRAG_LOAD_ERROR:\u000a      case errors["ErrorDetails"].FRAG_LOAD_TIMEOUT:\u000a      case errors["ErrorDetails"].KEY_LOAD_ERROR:\u000a      case errors["ErrorDetails"].KEY_LOAD_TIMEOUT:\u000a        if (!data.fatal) {\u000a          // keep retrying until the limit will be reached\u000a          if (this.fragLoadError + 1 <= this.config.fragLoadingMaxRetry) {\u000a            // exponential backoff capped to config.fragLoadingMaxRetryTimeout\u000a            var delay = Math.min(Math.pow(2, this.fragLoadError) * this.config.fragLoadingRetryDelay, this.config.fragLoadingMaxRetryTimeout);\u000a            logger["logger"].warn("mediaController: frag loading failed, retry in " + delay + " ms");\u000a            this.retryDate = window.performance.now() + delay; // retry loading state\u000a            // if loadedmetadata is not set, it means that we are emergency switch down on first frag\u000a            // in that case, reset startFragRequested flag\u000a\u000a            if (!this.loadedmetadata) {\u000a              this.startFragRequested = false;\u000a              this.nextLoadPosition = this.startPosition;\u000a            }\u000a\u000a            this.fragLoadError++;\u000a            this.state = State.FRAG_LOADING_WAITING_RETRY;\u000a          } else {\u000a            logger["logger"].error("mediaController: " + data.details + " reaches max retry, redispatch as fatal ..."); // switch error to fatal\u000a\u000a            data.fatal = true;\u000a            this.state = State.ERROR;\u000a          }\u000a        }\u000a\u000a        break;\u000a\u000a      case errors["ErrorDetails"].LEVEL_LOAD_ERROR:\u000a      case errors["ErrorDetails"].LEVEL_LOAD_TIMEOUT:\u000a        if (this.state !== State.ERROR) {\u000a          if (data.fatal) {\u000a            // if fatal error, stop processing\u000a            this.state = State.ERROR;\u000a            logger["logger"].warn("streamController: " + data.details + ",switch to " + this.state + " state ...");\u000a          } else {\u000a            // in case of non fatal error while loading level, if level controller is not retrying to load level , switch back to IDLE\u000a            if (!data.levelRetry && this.state === State.WAITING_LEVEL) {\u000a              this.state = State.IDLE;\u000a            }\u000a          }\u000a        }\u000a\u000a        break;\u000a\u000a      case errors["ErrorDetails"].BUFFER_FULL_ERROR:\u000a        // if in appending state\u000a        if (data.parent === 'main' && (this.state === State.PARSING || this.state === State.PARSED)) {\u000a          // reduce max buf len if current position is buffered\u000a          if (mediaBuffered) {\u000a            this._reduceMaxBufferLength(this.config.maxBufferLength);\u000a\u000a            this.state = State.IDLE;\u000a          } else {\u000a            // current position is not buffered, but browser is still complaining about buffer full error\u000a            // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708\u000a            // in that case flush the whole buffer to recover\u000a            logger["logger"].warn('buffer full error also media.currentTime is not buffered, flush everything');\u000a            this.fragCurrent = null; // flush everything\u000a\u000a            this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\u000a          }\u000a        }\u000a\u000a        break;\u000a\u000a      default:\u000a        break;\u000a    }\u000a  };\u000a\u000a  _proto._reduceMaxBufferLength = function _reduceMaxBufferLength(minLength) {\u000a    var config = this.config;\u000a\u000a    if (config.maxMaxBufferLength >= minLength) {\u000a      // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...\u000a      config.maxMaxBufferLength /= 2;\u000a      logger["logger"].warn("main:reduce max buffer length to " + config.maxMaxBufferLength + "s");\u000a      return true;\u000a    }\u000a\u000a    return false;\u000a  }\u000a  /**\u000a   * Checks the health of the buffer and attempts to resolve playback stalls.\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._checkBuffer = function _checkBuffer() {\u000a    var media = this.media;\u000a\u000a    if (!media || media.readyState === 0) {\u000a      // Exit early if we don't have media or if the media hasn't bufferd anything yet (readyState 0)\u000a      return;\u000a    }\u000a\u000a    var mediaBuffer = this.mediaBuffer ? this.mediaBuffer : media;\u000a    var buffered = mediaBuffer.buffered;\u000a\u000a    if (!this.loadedmetadata && buffered.length) {\u000a      this.loadedmetadata = true;\u000a\u000a      this._seekToStartPos();\u000a    } else if (this.immediateSwitch) {\u000a      this.immediateLevelSwitchEnd();\u000a    } else {\u000a      this.gapController.poll(this.lastCurrentTime, buffered);\u000a    }\u000a  };\u000a\u000a  _proto.onFragLoadEmergencyAborted = function onFragLoadEmergencyAborted() {\u000a    this.state = State.IDLE; // if loadedmetadata is not set, it means that we are emergency switch down on first frag\u000a    // in that case, reset startFragRequested flag\u000a\u000a    if (!this.loadedmetadata) {\u000a      this.startFragRequested = false;\u000a      this.nextLoadPosition = this.startPosition;\u000a    }\u000a\u000a    this.tick();\u000a  };\u000a\u000a  _proto.onBufferFlushed = function onBufferFlushed() {\u000a    /* after successful buffer flushing, filter flushed fragments from bufferedFrags\u000a      use mediaBuffered instead of media (so that we will check against video.buffered ranges in case of alt audio track)\u000a    */\u000a    var media = this.mediaBuffer ? this.mediaBuffer : this.media;\u000a\u000a    if (media) {\u000a      // filter fragments potentially evicted from buffer. this is to avoid memleak on live streams\u000a      var elementaryStreamType = this.audioOnly ? ElementaryStreamTypes.AUDIO : ElementaryStreamTypes.VIDEO;\u000a      this.fragmentTracker.detectEvictedFragments(elementaryStreamType, media.buffered);\u000a    } // move to IDLE once flush complete. this should trigger new fragment loading\u000a\u000a\u000a    this.state = State.IDLE; // reset reference to frag\u000a\u000a    this.fragPrevious = null;\u000a  };\u000a\u000a  _proto.onLevelsUpdated = function onLevelsUpdated(data) {\u000a    this.levels = data.levels;\u000a  };\u000a\u000a  _proto.swapAudioCodec = function swapAudioCodec() {\u000a    this.audioCodecSwap = !this.audioCodecSwap;\u000a  }\u000a  /**\u000a   * Seeks to the set startPosition if not equal to the mediaElement's current time.\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._seekToStartPos = function _seekToStartPos() {\u000a    var media = this.media,\u000a        startPosition = this.startPosition;\u000a    var currentTime = media.currentTime; // only adjust currentTime if different from startPosition or if startPosition not buffered\u000a    // at that stage, there should be only one buffered range, as we reach that code after first fragment has been buffered\u000a\u000a    if (currentTime !== startPosition && startPosition >= 0) {\u000a      if (media.seeking) {\u000a        logger["logger"].log("could not seek to " + startPosition + ", already seeking at " + currentTime);\u000a        return;\u000a      }\u000a\u000a      logger["logger"].log("seek to target start position " + startPosition + " from current time " + currentTime + ". ready state " + media.readyState);\u000a      media.currentTime = startPosition;\u000a    }\u000a  };\u000a\u000a  _proto._getAudioCodec = function _getAudioCodec(currentLevel) {\u000a    var audioCodec = this.config.defaultAudioCodec || currentLevel.audioCodec;\u000a\u000a    if (this.audioCodecSwap) {\u000a      logger["logger"].log('swapping playlist audio codec');\u000a\u000a      if (audioCodec) {\u000a        if (audioCodec.indexOf('mp4a.40.5') !== -1) {\u000a          audioCodec = 'mp4a.40.2';\u000a        } else {\u000a          audioCodec = 'mp4a.40.5';\u000a        }\u000a      }\u000a    }\u000a\u000a    return audioCodec;\u000a  };\u000a\u000a  stream_controller_createClass(StreamController, [{\u000a    key: "state",\u000a    set: function set(nextState) {\u000a      if (this.state !== nextState) {\u000a        var previousState = this.state;\u000a        this._state = nextState;\u000a        logger["logger"].log("main stream-controller: " + previousState + "->" + nextState);\u000a        this.hls.trigger(events["default"].STREAM_STATE_TRANSITION, {\u000a          previousState: previousState,\u000a          nextState: nextState\u000a        });\u000a      }\u000a    },\u000a    get: function get() {\u000a      return this._state;\u000a    }\u000a  }, {\u000a    key: "currentLevel",\u000a    get: function get() {\u000a      var media = this.media;\u000a\u000a      if (media) {\u000a        var frag = this.getBufferedFrag(media.currentTime);\u000a\u000a        if (frag) {\u000a          return frag.level;\u000a        }\u000a      }\u000a\u000a      return -1;\u000a    }\u000a  }, {\u000a    key: "nextBufferedFrag",\u000a    get: function get() {\u000a      var media = this.media;\u000a\u000a      if (media) {\u000a        // first get end range of current fragment\u000a        return this.followingBufferedFrag(this.getBufferedFrag(media.currentTime));\u000a      } else {\u000a        return null;\u000a      }\u000a    }\u000a  }, {\u000a    key: "nextLevel",\u000a    get: function get() {\u000a      var frag = this.nextBufferedFrag;\u000a\u000a      if (frag) {\u000a        return frag.level;\u000a      } else {\u000a        return -1;\u000a      }\u000a    }\u000a  }, {\u000a    key: "liveSyncPosition",\u000a    get: function get() {\u000a      return this._liveSyncPosition;\u000a    },\u000a    set: function set(value) {\u000a      this._liveSyncPosition = value;\u000a    }\u000a  }]);\u000a\u000a  return StreamController;\u000a}(base_stream_controller_BaseStreamController);\u000a\u000a/* harmony default export */ var stream_controller = (stream_controller_StreamController);\u000a// CONCATENATED MODULE: ./src/controller/level-controller.js\u000afunction level_controller_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction level_controller_createClass(Constructor, protoProps, staticProps) { if (protoProps) level_controller_defineProperties(Constructor.prototype, protoProps); if (staticProps) level_controller_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000afunction level_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * Level Controller\u000a*/\u000a\u000a\u000a\u000a\u000a\u000a\u000avar chromeOrFirefox;\u000a\u000avar level_controller_LevelController = /*#__PURE__*/function (_EventHandler) {\u000a  level_controller_inheritsLoose(LevelController, _EventHandler);\u000a\u000a  function LevelController(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].MANIFEST_LOADED, events["default"].LEVEL_LOADED, events["default"].AUDIO_TRACK_SWITCHED, events["default"].FRAG_LOADED, events["default"].ERROR) || this;\u000a    _this.canload = false;\u000a    _this.currentLevelIndex = null;\u000a    _this.manualLevelIndex = -1;\u000a    _this.timer = null;\u000a    chromeOrFirefox = /chrome|firefox/.test(navigator.userAgent.toLowerCase());\u000a    return _this;\u000a  }\u000a\u000a  var _proto = LevelController.prototype;\u000a\u000a  _proto.onHandlerDestroying = function onHandlerDestroying() {\u000a    this.clearTimer();\u000a    this.manualLevelIndex = -1;\u000a  };\u000a\u000a  _proto.clearTimer = function clearTimer() {\u000a    if (this.timer !== null) {\u000a      clearTimeout(this.timer);\u000a      this.timer = null;\u000a    }\u000a  };\u000a\u000a  _proto.startLoad = function startLoad() {\u000a    var levels = this._levels;\u000a    this.canload = true;\u000a    this.levelRetryCount = 0; // clean up live level details to force reload them, and reset load errors\u000a\u000a    if (levels) {\u000a      levels.forEach(function (level) {\u000a        level.loadError = 0;\u000a        var levelDetails = level.details;\u000a\u000a        if (levelDetails && levelDetails.live) {\u000a          level.details = undefined;\u000a        }\u000a      });\u000a    } // speed up live playlist refresh if timer exists\u000a\u000a\u000a    if (this.timer !== null) {\u000a      this.loadLevel();\u000a    }\u000a  };\u000a\u000a  _proto.stopLoad = function stopLoad() {\u000a    this.canload = false;\u000a  };\u000a\u000a  _proto.onManifestLoaded = function onManifestLoaded(data) {\u000a    var levels = [];\u000a    var audioTracks = [];\u000a    var bitrateStart;\u000a    var levelSet = {};\u000a    var levelFromSet = null;\u000a    var videoCodecFound = false;\u000a    var audioCodecFound = false; // regroup redundant levels together\u000a\u000a    data.levels.forEach(function (level) {\u000a      var attributes = level.attrs;\u000a      level.loadError = 0;\u000a      level.fragmentError = false;\u000a      videoCodecFound = videoCodecFound || !!level.videoCodec;\u000a      audioCodecFound = audioCodecFound || !!level.audioCodec; // erase audio codec info if browser does not support mp4a.40.34.\u000a      // demuxer will autodetect codec and fallback to mpeg/audio\u000a\u000a      if (chromeOrFirefox && level.audioCodec && level.audioCodec.indexOf('mp4a.40.34') !== -1) {\u000a        level.audioCodec = undefined;\u000a      }\u000a\u000a      levelFromSet = levelSet[level.bitrate]; // FIXME: we would also have to match the resolution here\u000a\u000a      if (!levelFromSet) {\u000a        level.url = [level.url];\u000a        level.urlId = 0;\u000a        levelSet[level.bitrate] = level;\u000a        levels.push(level);\u000a      } else {\u000a        levelFromSet.url.push(level.url);\u000a      }\u000a\u000a      if (attributes) {\u000a        if (attributes.AUDIO) {\u000a          addGroupId(levelFromSet || level, 'audio', attributes.AUDIO);\u000a        }\u000a\u000a        if (attributes.SUBTITLES) {\u000a          addGroupId(levelFromSet || level, 'text', attributes.SUBTITLES);\u000a        }\u000a      }\u000a    }); // remove audio-only level if we also have levels with audio+video codecs signalled\u000a\u000a    if (videoCodecFound && audioCodecFound) {\u000a      levels = levels.filter(function (_ref) {\u000a        var videoCodec = _ref.videoCodec;\u000a        return !!videoCodec;\u000a      });\u000a    } // only keep levels with supported audio/video codecs\u000a\u000a\u000a    levels = levels.filter(function (_ref2) {\u000a      var audioCodec = _ref2.audioCodec,\u000a          videoCodec = _ref2.videoCodec;\u000a      return (!audioCodec || isCodecSupportedInMp4(audioCodec, 'audio')) && (!videoCodec || isCodecSupportedInMp4(videoCodec, 'video'));\u000a    });\u000a\u000a    if (data.audioTracks) {\u000a      audioTracks = data.audioTracks.filter(function (track) {\u000a        return !track.audioCodec || isCodecSupportedInMp4(track.audioCodec, 'audio');\u000a      }); // Reassign id's after filtering since they're used as array indices\u000a\u000a      audioTracks.forEach(function (track, index) {\u000a        track.id = index;\u000a      });\u000a    }\u000a\u000a    if (levels.length > 0) {\u000a      // start bitrate is the first bitrate of the manifest\u000a      bitrateStart = levels[0].bitrate; // sort level on bitrate\u000a\u000a      levels.sort(function (a, b) {\u000a        return a.bitrate - b.bitrate;\u000a      });\u000a      this._levels = levels; // find index of first level in sorted levels\u000a\u000a      for (var i = 0; i < levels.length; i++) {\u000a        if (levels[i].bitrate === bitrateStart) {\u000a          this._firstLevel = i;\u000a          logger["logger"].log("manifest loaded," + levels.length + " level(s) found, first bitrate:" + bitrateStart);\u000a          break;\u000a        }\u000a      } // Audio is only alternate if manifest include a URI along with the audio group tag,\u000a      // and this is not an audio-only stream where levels contain audio-only\u000a\u000a\u000a      var audioOnly = audioCodecFound && !videoCodecFound;\u000a      this.hls.trigger(events["default"].MANIFEST_PARSED, {\u000a        levels: levels,\u000a        audioTracks: audioTracks,\u000a        firstLevel: this._firstLevel,\u000a        stats: data.stats,\u000a        audio: audioCodecFound,\u000a        video: videoCodecFound,\u000a        altAudio: !audioOnly && audioTracks.some(function (t) {\u000a          return !!t.url;\u000a        })\u000a      });\u000a    } else {\u000a      this.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        details: errors["ErrorDetails"].MANIFEST_INCOMPATIBLE_CODECS_ERROR,\u000a        fatal: true,\u000a        url: this.hls.url,\u000a        reason: 'no level with compatible codecs found in manifest'\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.setLevelInternal = function setLevelInternal(newLevel) {\u000a    var levels = this._levels;\u000a    var hls = this.hls; // check if level idx is valid\u000a\u000a    if (newLevel >= 0 && newLevel < levels.length) {\u000a      // stopping live reloading timer if any\u000a      this.clearTimer();\u000a\u000a      if (this.currentLevelIndex !== newLevel) {\u000a        logger["logger"].log("switching to level " + newLevel);\u000a        this.currentLevelIndex = newLevel;\u000a        var levelProperties = levels[newLevel];\u000a        levelProperties.level = newLevel;\u000a        hls.trigger(events["default"].LEVEL_SWITCHING, levelProperties);\u000a      }\u000a\u000a      var level = levels[newLevel];\u000a      var levelDetails = level.details; // check if we need to load playlist for this level\u000a\u000a      if (!levelDetails || levelDetails.live) {\u000a        // level not retrieved yet, or live playlist we need to (re)load it\u000a        var urlId = level.urlId;\u000a        hls.trigger(events["default"].LEVEL_LOADING, {\u000a          url: level.url[urlId],\u000a          level: newLevel,\u000a          id: urlId\u000a        });\u000a      }\u000a    } else {\u000a      // invalid level id given, trigger error\u000a      hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].OTHER_ERROR,\u000a        details: errors["ErrorDetails"].LEVEL_SWITCH_ERROR,\u000a        level: newLevel,\u000a        fatal: false,\u000a        reason: 'invalid level idx'\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.onError = function onError(data) {\u000a    if (data.fatal) {\u000a      if (data.type === errors["ErrorTypes"].NETWORK_ERROR) {\u000a        this.clearTimer();\u000a      }\u000a\u000a      return;\u000a    }\u000a\u000a    var levelError = false,\u000a        fragmentError = false;\u000a    var levelIndex; // try to recover not fatal errors\u000a\u000a    switch (data.details) {\u000a      case errors["ErrorDetails"].FRAG_LOAD_ERROR:\u000a      case errors["ErrorDetails"].FRAG_LOAD_TIMEOUT:\u000a      case errors["ErrorDetails"].KEY_LOAD_ERROR:\u000a      case errors["ErrorDetails"].KEY_LOAD_TIMEOUT:\u000a        levelIndex = data.frag.level;\u000a        fragmentError = true;\u000a        break;\u000a\u000a      case errors["ErrorDetails"].LEVEL_LOAD_ERROR:\u000a      case errors["ErrorDetails"].LEVEL_LOAD_TIMEOUT:\u000a        levelIndex = data.context.level;\u000a        levelError = true;\u000a        break;\u000a\u000a      case errors["ErrorDetails"].REMUX_ALLOC_ERROR:\u000a        levelIndex = data.level;\u000a        levelError = true;\u000a        break;\u000a    }\u000a\u000a    if (levelIndex !== undefined) {\u000a      this.recoverLevel(data, levelIndex, levelError, fragmentError);\u000a    }\u000a  }\u000a  /**\u000a   * Switch to a redundant stream if any available.\u000a   * If redundant stream is not available, emergency switch down if ABR mode is enabled.\u000a   *\u000a   * @param {Object} errorEvent\u000a   * @param {Number} levelIndex current level index\u000a   * @param {Boolean} levelError\u000a   * @param {Boolean} fragmentError\u000a   */\u000a  // FIXME Find a better abstraction where fragment/level retry management is well decoupled\u000a  ;\u000a\u000a  _proto.recoverLevel = function recoverLevel(errorEvent, levelIndex, levelError, fragmentError) {\u000a    var _this2 = this;\u000a\u000a    var config = this.hls.config;\u000a    var errorDetails = errorEvent.details;\u000a    var level = this._levels[levelIndex];\u000a    var redundantLevels, delay, nextLevel;\u000a    level.loadError++;\u000a    level.fragmentError = fragmentError;\u000a\u000a    if (levelError) {\u000a      if (this.levelRetryCount + 1 <= config.levelLoadingMaxRetry) {\u000a        // exponential backoff capped to max retry timeout\u000a        delay = Math.min(Math.pow(2, this.levelRetryCount) * config.levelLoadingRetryDelay, config.levelLoadingMaxRetryTimeout); // Schedule level reload\u000a\u000a        this.timer = setTimeout(function () {\u000a          return _this2.loadLevel();\u000a        }, delay); // boolean used to inform stream controller not to switch back to IDLE on non fatal error\u000a\u000a        errorEvent.levelRetry = true;\u000a        this.levelRetryCount++;\u000a        logger["logger"].warn("level controller, " + errorDetails + ", retry in " + delay + " ms, current retry count is " + this.levelRetryCount);\u000a      } else {\u000a        logger["logger"].error("level controller, cannot recover from " + errorDetails + " error");\u000a        this.currentLevelIndex = null; // stopping live reloading timer if any\u000a\u000a        this.clearTimer(); // switch error to fatal\u000a\u000a        errorEvent.fatal = true;\u000a        return;\u000a      }\u000a    } // Try any redundant streams if available for both errors: level and fragment\u000a    // If level.loadError reaches redundantLevels it means that we tried them all, no hope  => let's switch down\u000a\u000a\u000a    if (levelError || fragmentError) {\u000a      redundantLevels = level.url.length;\u000a\u000a      if (redundantLevels > 1 && level.loadError < redundantLevels) {\u000a        level.urlId = (level.urlId + 1) % redundantLevels;\u000a        level.details = undefined;\u000a        logger["logger"].warn("level controller, " + errorDetails + " for level " + levelIndex + ": switching to redundant URL-id " + level.urlId); // console.log('Current audio track group ID:', this.hls.audioTracks[this.hls.audioTrack].groupId);\u000a        // console.log('New video quality level audio group id:', level.attrs.AUDIO);\u000a      } else {\u000a        // Search for available level\u000a        if (this.manualLevelIndex === -1) {\u000a          // When lowest level has been reached, let's start hunt from the top\u000a          nextLevel = levelIndex === 0 ? this._levels.length - 1 : levelIndex - 1;\u000a          logger["logger"].warn("level controller, " + errorDetails + ": switch to " + nextLevel);\u000a          this.hls.nextAutoLevel = this.currentLevelIndex = nextLevel;\u000a        } else if (fragmentError) {\u000a          // Allow fragment retry as long as configuration allows.\u000a          // reset this._level so that another call to set level() will trigger again a frag load\u000a          logger["logger"].warn("level controller, " + errorDetails + ": reload a fragment");\u000a          this.currentLevelIndex = null;\u000a        }\u000a      }\u000a    }\u000a  } // reset errors on the successful load of a fragment\u000a  ;\u000a\u000a  _proto.onFragLoaded = function onFragLoaded(_ref3) {\u000a    var frag = _ref3.frag;\u000a\u000a    if (frag !== undefined && frag.type === 'main') {\u000a      var level = this._levels[frag.level];\u000a\u000a      if (level !== undefined) {\u000a        level.fragmentError = false;\u000a        level.loadError = 0;\u000a        this.levelRetryCount = 0;\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onLevelLoaded = function onLevelLoaded(data) {\u000a    var _this3 = this;\u000a\u000a    var level = data.level,\u000a        details = data.details; // only process level loaded events matching with expected level\u000a\u000a    if (level !== this.currentLevelIndex) {\u000a      return;\u000a    }\u000a\u000a    var curLevel = this._levels[level]; // reset level load error counter on successful level loaded only if there is no issues with fragments\u000a\u000a    if (!curLevel.fragmentError) {\u000a      curLevel.loadError = 0;\u000a      this.levelRetryCount = 0;\u000a    } // if current playlist is a live playlist, arm a timer to reload it\u000a\u000a\u000a    if (details.live) {\u000a      var reloadInterval = computeReloadInterval(curLevel.details, details, data.stats.trequest);\u000a      logger["logger"].log("live playlist, reload in " + Math.round(reloadInterval) + " ms");\u000a      this.timer = setTimeout(function () {\u000a        return _this3.loadLevel();\u000a      }, reloadInterval);\u000a    } else {\u000a      this.clearTimer();\u000a    }\u000a  };\u000a\u000a  _proto.onAudioTrackSwitched = function onAudioTrackSwitched(data) {\u000a    var audioGroupId = this.hls.audioTracks[data.id].groupId;\u000a    var currentLevel = this.hls.levels[this.currentLevelIndex];\u000a\u000a    if (!currentLevel) {\u000a      return;\u000a    }\u000a\u000a    if (currentLevel.audioGroupIds) {\u000a      var urlId = -1;\u000a\u000a      for (var i = 0; i < currentLevel.audioGroupIds.length; i++) {\u000a        if (currentLevel.audioGroupIds[i] === audioGroupId) {\u000a          urlId = i;\u000a          break;\u000a        }\u000a      }\u000a\u000a      if (urlId !== currentLevel.urlId) {\u000a        currentLevel.urlId = urlId;\u000a        this.startLoad();\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.loadLevel = function loadLevel() {\u000a    logger["logger"].debug('call to loadLevel');\u000a\u000a    if (this.currentLevelIndex !== null && this.canload) {\u000a      var levelObject = this._levels[this.currentLevelIndex];\u000a\u000a      if (typeof levelObject === 'object' && levelObject.url.length > 0) {\u000a        var level = this.currentLevelIndex;\u000a        var id = levelObject.urlId;\u000a        var url = levelObject.url[id];\u000a        logger["logger"].log("Attempt loading level index " + level + " with URL-id " + id); // console.log('Current audio track group ID:', this.hls.audioTracks[this.hls.audioTrack].groupId);\u000a        // console.log('New video quality level audio group id:', levelObject.attrs.AUDIO, level);\u000a\u000a        this.hls.trigger(events["default"].LEVEL_LOADING, {\u000a          url: url,\u000a          level: level,\u000a          id: id\u000a        });\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.removeLevel = function removeLevel(levelIndex, urlId) {\u000a    var levels = this.levels.filter(function (level, index) {\u000a      if (index !== levelIndex) {\u000a        return true;\u000a      }\u000a\u000a      if (level.url.length > 1 && urlId !== undefined) {\u000a        level.url = level.url.filter(function (url, id) {\u000a          return id !== urlId;\u000a        });\u000a        level.urlId = 0;\u000a        return true;\u000a      }\u000a\u000a      return false;\u000a    }).map(function (level, index) {\u000a      var details = level.details;\u000a\u000a      if (details && details.fragments) {\u000a        details.fragments.forEach(function (fragment) {\u000a          fragment.level = index;\u000a        });\u000a      }\u000a\u000a      return level;\u000a    });\u000a    this._levels = levels;\u000a    this.hls.trigger(events["default"].LEVELS_UPDATED, {\u000a      levels: levels\u000a    });\u000a  };\u000a\u000a  level_controller_createClass(LevelController, [{\u000a    key: "levels",\u000a    get: function get() {\u000a      return this._levels;\u000a    }\u000a  }, {\u000a    key: "level",\u000a    get: function get() {\u000a      return this.currentLevelIndex;\u000a    },\u000a    set: function set(newLevel) {\u000a      var levels = this._levels;\u000a\u000a      if (levels) {\u000a        newLevel = Math.min(newLevel, levels.length - 1);\u000a\u000a        if (this.currentLevelIndex !== newLevel || !levels[newLevel].details) {\u000a          this.setLevelInternal(newLevel);\u000a        }\u000a      }\u000a    }\u000a  }, {\u000a    key: "manualLevel",\u000a    get: function get() {\u000a      return this.manualLevelIndex;\u000a    },\u000a    set: function set(newLevel) {\u000a      this.manualLevelIndex = newLevel;\u000a\u000a      if (this._startLevel === undefined) {\u000a        this._startLevel = newLevel;\u000a      }\u000a\u000a      if (newLevel !== -1) {\u000a        this.level = newLevel;\u000a      }\u000a    }\u000a  }, {\u000a    key: "firstLevel",\u000a    get: function get() {\u000a      return this._firstLevel;\u000a    },\u000a    set: function set(newLevel) {\u000a      this._firstLevel = newLevel;\u000a    }\u000a  }, {\u000a    key: "startLevel",\u000a    get: function get() {\u000a      // hls.startLevel takes precedence over config.startLevel\u000a      // if none of these values are defined, fallback on this._firstLevel (first quality level appearing in variant manifest)\u000a      if (this._startLevel === undefined) {\u000a        var configStartLevel = this.hls.config.startLevel;\u000a\u000a        if (configStartLevel !== undefined) {\u000a          return configStartLevel;\u000a        } else {\u000a          return this._firstLevel;\u000a        }\u000a      } else {\u000a        return this._startLevel;\u000a      }\u000a    },\u000a    set: function set(newLevel) {\u000a      this._startLevel = newLevel;\u000a    }\u000a  }, {\u000a    key: "nextLoadLevel",\u000a    get: function get() {\u000a      if (this.manualLevelIndex !== -1) {\u000a        return this.manualLevelIndex;\u000a      } else {\u000a        return this.hls.nextAutoLevel;\u000a      }\u000a    },\u000a    set: function set(nextLevel) {\u000a      this.level = nextLevel;\u000a\u000a      if (this.manualLevelIndex === -1) {\u000a        this.hls.nextAutoLevel = nextLevel;\u000a      }\u000a    }\u000a  }]);\u000a\u000a  return LevelController;\u000a}(event_handler);\u000a\u000a\u000a// EXTERNAL MODULE: ./src/demux/id3.js\u000avar id3 = __webpack_require__("./src/demux/id3.js");\u000a\u000a// CONCATENATED MODULE: ./src/utils/texttrack-utils.ts\u000afunction sendAddTrackEvent(track, videoEl) {\u000a  var event;\u000a\u000a  try {\u000a    event = new Event('addtrack');\u000a  } catch (err) {\u000a    // for IE11\u000a    event = document.createEvent('Event');\u000a    event.initEvent('addtrack', false, false);\u000a  }\u000a\u000a  event.track = track;\u000a  videoEl.dispatchEvent(event);\u000a}\u000afunction clearCurrentCues(track) {\u000a  if (track === null || track === void 0 ? void 0 : track.cues) {\u000a    while (track.cues.length > 0) {\u000a      track.removeCue(track.cues[0]);\u000a    }\u000a  }\u000a}\u000a/**\u000a *  Given a list of Cues, finds the closest cue matching the given time.\u000a *  Modified verison of binary search O(log(n)).\u000a *\u000a * @export\u000a * @param {(TextTrackCueList | TextTrackCue[])} cues - List of cues.\u000a * @param {number} time - Target time, to find closest cue to.\u000a * @returns {TextTrackCue}\u000a */\u000a\u000afunction getClosestCue(cues, time) {\u000a  // If the offset is less than the first element, the first element is the closest.\u000a  if (time < cues[0].endTime) {\u000a    return cues[0];\u000a  } // If the offset is greater than the last cue, the last is the closest.\u000a\u000a\u000a  if (time > cues[cues.length - 1].endTime) {\u000a    return cues[cues.length - 1];\u000a  }\u000a\u000a  var left = 0;\u000a  var right = cues.length - 1;\u000a\u000a  while (left <= right) {\u000a    var mid = Math.floor((right + left) / 2);\u000a\u000a    if (time < cues[mid].endTime) {\u000a      right = mid - 1;\u000a    } else if (time > cues[mid].endTime) {\u000a      left = mid + 1;\u000a    } else {\u000a      // If it's not lower or higher, it must be equal.\u000a      return cues[mid];\u000a    }\u000a  } // At this point, left and right have swapped.\u000a  // No direct match was found, left or right element must be the closest. Check which one has the smallest diff.\u000a\u000a\u000a  return cues[left].endTime - time < time - cues[right].endTime ? cues[left] : cues[right];\u000a}\u000a// CONCATENATED MODULE: ./src/controller/id3-track-controller.js\u000afunction id3_track_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * id3 metadata track controller\u000a*/\u000a\u000a\u000a\u000a\u000a\u000a\u000avar id3_track_controller_ID3TrackController = /*#__PURE__*/function (_EventHandler) {\u000a  id3_track_controller_inheritsLoose(ID3TrackController, _EventHandler);\u000a\u000a  function ID3TrackController(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].MEDIA_ATTACHED, events["default"].MEDIA_DETACHING, events["default"].FRAG_PARSING_METADATA, events["default"].LIVE_BACK_BUFFER_REACHED) || this;\u000a    _this.id3Track = undefined;\u000a    _this.media = undefined;\u000a    return _this;\u000a  }\u000a\u000a  var _proto = ID3TrackController.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    event_handler.prototype.destroy.call(this);\u000a  } // Add ID3 metatadata text track.\u000a  ;\u000a\u000a  _proto.onMediaAttached = function onMediaAttached(data) {\u000a    this.media = data.media;\u000a\u000a    if (!this.media) {}\u000a  };\u000a\u000a  _proto.onMediaDetaching = function onMediaDetaching() {\u000a    clearCurrentCues(this.id3Track);\u000a    this.id3Track = undefined;\u000a    this.media = undefined;\u000a  };\u000a\u000a  _proto.getID3Track = function getID3Track(textTracks) {\u000a    for (var i = 0; i < textTracks.length; i++) {\u000a      var textTrack = textTracks[i];\u000a\u000a      if (textTrack.kind === 'metadata' && textTrack.label === 'id3') {\u000a        // send 'addtrack' when reusing the textTrack for metadata,\u000a        // same as what we do for captions\u000a        sendAddTrackEvent(textTrack, this.media);\u000a        return textTrack;\u000a      }\u000a    }\u000a\u000a    return this.media.addTextTrack('metadata', 'id3');\u000a  };\u000a\u000a  _proto.onFragParsingMetadata = function onFragParsingMetadata(data) {\u000a    var fragment = data.frag;\u000a    var samples = data.samples; // create track dynamically\u000a\u000a    if (!this.id3Track) {\u000a      this.id3Track = this.getID3Track(this.media.textTracks);\u000a      this.id3Track.mode = 'hidden';\u000a    } // Attempt to recreate Safari functionality by creating\u000a    // WebKitDataCue objects when available and store the decoded\u000a    // ID3 data in the value property of the cue\u000a\u000a\u000a    var Cue = window.WebKitDataCue || window.VTTCue || window.TextTrackCue;\u000a\u000a    for (var i = 0; i < samples.length; i++) {\u000a      var frames = id3["default"].getID3Frames(samples[i].data);\u000a\u000a      if (frames) {\u000a        // Ensure the pts is positive - sometimes it's reported as a small negative number\u000a        var startTime = Math.max(samples[i].pts, 0);\u000a        var endTime = i < samples.length - 1 ? samples[i + 1].pts : fragment.endPTS;\u000a\u000a        if (!endTime) {\u000a          endTime = fragment.start + fragment.duration;\u000a        }\u000a\u000a        if (startTime === endTime) {\u000a          // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE\u000a          endTime += 0.0001;\u000a        } else if (startTime > endTime) {\u000a          logger["logger"].warn('detected an id3 sample with endTime < startTime, adjusting endTime to (startTime + 0.25)');\u000a          endTime = startTime + 0.25;\u000a        }\u000a\u000a        for (var j = 0; j < frames.length; j++) {\u000a          var frame = frames[j]; // Safari doesn't put the timestamp frame in the TextTrack\u000a\u000a          if (!id3["default"].isTimeStampFrame(frame)) {\u000a            var cue = new Cue(startTime, endTime, '');\u000a            cue.value = frame;\u000a            this.id3Track.addCue(cue);\u000a          }\u000a        }\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onLiveBackBufferReached = function onLiveBackBufferReached(_ref) {\u000a    var bufferEnd = _ref.bufferEnd;\u000a    var id3Track = this.id3Track;\u000a\u000a    if (!id3Track || !id3Track.cues || !id3Track.cues.length) {\u000a      return;\u000a    }\u000a\u000a    var foundCue = getClosestCue(id3Track.cues, bufferEnd);\u000a\u000a    if (!foundCue) {\u000a      return;\u000a    }\u000a\u000a    while (id3Track.cues[0] !== foundCue) {\u000a      id3Track.removeCue(id3Track.cues[0]);\u000a    }\u000a  };\u000a\u000a  return ID3TrackController;\u000a}(event_handler);\u000a\u000a/* harmony default export */ var id3_track_controller = (id3_track_controller_ID3TrackController);\u000a// CONCATENATED MODULE: ./src/is-supported.ts\u000a\u000afunction is_supported_isSupported() {\u000a  var mediaSource = getMediaSource();\u000a\u000a  if (!mediaSource) {\u000a    return false;\u000a  }\u000a\u000a  var sourceBuffer = self.SourceBuffer || self.WebKitSourceBuffer;\u000a  var isTypeSupported = mediaSource && typeof mediaSource.isTypeSupported === 'function' && mediaSource.isTypeSupported('video/mp4; codecs="avc1.42E01E,mp4a.40.2"'); // if SourceBuffer is exposed ensure its API is valid\u000a  // safari and old version of Chrome doe not expose SourceBuffer globally so checking SourceBuffer.prototype is impossible\u000a\u000a  var sourceBufferValidAPI = !sourceBuffer || sourceBuffer.prototype && typeof sourceBuffer.prototype.appendBuffer === 'function' && typeof sourceBuffer.prototype.remove === 'function';\u000a  return !!isTypeSupported && !!sourceBufferValidAPI;\u000a}\u000a// CONCATENATED MODULE: ./src/utils/ewma.ts\u000a/*\u000a * compute an Exponential Weighted moving average\u000a * - https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average\u000a *  - heavily inspired from shaka-player\u000a */\u000avar EWMA = /*#__PURE__*/function () {\u000a  //  About half of the estimated value will be from the last |halfLife| samples by weight.\u000a  function EWMA(halfLife) {\u000a    this.alpha_ = void 0;\u000a    this.estimate_ = void 0;\u000a    this.totalWeight_ = void 0;\u000a    // Larger values of alpha expire historical data more slowly.\u000a    this.alpha_ = halfLife ? Math.exp(Math.log(0.5) / halfLife) : 0;\u000a    this.estimate_ = 0;\u000a    this.totalWeight_ = 0;\u000a  }\u000a\u000a  var _proto = EWMA.prototype;\u000a\u000a  _proto.sample = function sample(weight, value) {\u000a    var adjAlpha = Math.pow(this.alpha_, weight);\u000a    this.estimate_ = value * (1 - adjAlpha) + adjAlpha * this.estimate_;\u000a    this.totalWeight_ += weight;\u000a  };\u000a\u000a  _proto.getTotalWeight = function getTotalWeight() {\u000a    return this.totalWeight_;\u000a  };\u000a\u000a  _proto.getEstimate = function getEstimate() {\u000a    if (this.alpha_) {\u000a      var zeroFactor = 1 - Math.pow(this.alpha_, this.totalWeight_);\u000a      return this.estimate_ / zeroFactor;\u000a    } else {\u000a      return this.estimate_;\u000a    }\u000a  };\u000a\u000a  return EWMA;\u000a}();\u000a\u000a/* harmony default export */ var ewma = (EWMA);\u000a// CONCATENATED MODULE: ./src/utils/ewma-bandwidth-estimator.ts\u000a/*\u000a * EWMA Bandwidth Estimator\u000a *  - heavily inspired from shaka-player\u000a * Tracks bandwidth samples and estimates available bandwidth.\u000a * Based on the minimum of two exponentially-weighted moving averages with\u000a * different half-lives.\u000a */\u000a\u000a\u000avar ewma_bandwidth_estimator_EwmaBandWidthEstimator = /*#__PURE__*/function () {\u000a  // TODO(typescript-hls)\u000a  function EwmaBandWidthEstimator(hls, slow, fast, defaultEstimate) {\u000a    this.hls = void 0;\u000a    this.defaultEstimate_ = void 0;\u000a    this.minWeight_ = void 0;\u000a    this.minDelayMs_ = void 0;\u000a    this.slow_ = void 0;\u000a    this.fast_ = void 0;\u000a    this.hls = hls;\u000a    this.defaultEstimate_ = defaultEstimate;\u000a    this.minWeight_ = 0.001;\u000a    this.minDelayMs_ = 50;\u000a    this.slow_ = new ewma(slow);\u000a    this.fast_ = new ewma(fast);\u000a  }\u000a\u000a  var _proto = EwmaBandWidthEstimator.prototype;\u000a\u000a  _proto.sample = function sample(durationMs, numBytes) {\u000a    durationMs = Math.max(durationMs, this.minDelayMs_);\u000a    var numBits = 8 * numBytes,\u000a        // weight is duration in seconds\u000a    durationS = durationMs / 1000,\u000a        // value is bandwidth in bits/s\u000a    bandwidthInBps = numBits / durationS;\u000a    this.fast_.sample(durationS, bandwidthInBps);\u000a    this.slow_.sample(durationS, bandwidthInBps);\u000a  };\u000a\u000a  _proto.canEstimate = function canEstimate() {\u000a    var fast = this.fast_;\u000a    return fast && fast.getTotalWeight() >= this.minWeight_;\u000a  };\u000a\u000a  _proto.getEstimate = function getEstimate() {\u000a    if (this.canEstimate()) {\u000a      // console.log('slow estimate:'+ Math.round(this.slow_.getEstimate()));\u000a      // console.log('fast estimate:'+ Math.round(this.fast_.getEstimate()));\u000a      // Take the minimum of these two estimates.  This should have the effect of\u000a      // adapting down quickly, but up more slowly.\u000a      return Math.min(this.fast_.getEstimate(), this.slow_.getEstimate());\u000a    } else {\u000a      return this.defaultEstimate_;\u000a    }\u000a  };\u000a\u000a  _proto.destroy = function destroy() {};\u000a\u000a  return EwmaBandWidthEstimator;\u000a}();\u000a\u000a/* harmony default export */ var ewma_bandwidth_estimator = (ewma_bandwidth_estimator_EwmaBandWidthEstimator);\u000a// CONCATENATED MODULE: ./src/controller/abr-controller.js\u000a\u000a\u000a\u000afunction abr_controller_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction abr_controller_createClass(Constructor, protoProps, staticProps) { if (protoProps) abr_controller_defineProperties(Constructor.prototype, protoProps); if (staticProps) abr_controller_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000afunction abr_controller_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return self; }\u000a\u000afunction abr_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * simple ABR Controller\u000a *  - compute next level based on last fragment bw heuristics\u000a *  - implement an abandon rules triggered if we have less than 2 frag buffered and if computed bw shows that we risk buffer stalling\u000a */\u000a\u000a\u000a\u000a\u000a\u000a\u000avar abr_controller_window = window,\u000a    abr_controller_performance = abr_controller_window.performance;\u000a\u000avar abr_controller_AbrController = /*#__PURE__*/function (_EventHandler) {\u000a  abr_controller_inheritsLoose(AbrController, _EventHandler);\u000a\u000a  function AbrController(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].FRAG_LOADING, events["default"].FRAG_LOADED, events["default"].FRAG_BUFFERED, events["default"].ERROR) || this;\u000a    _this.lastLoadedFragLevel = 0;\u000a    _this._nextAutoLevel = -1;\u000a    _this.hls = hls;\u000a    _this.timer = null;\u000a    _this._bwEstimator = null;\u000a    _this.onCheck = _this._abandonRulesCheck.bind(abr_controller_assertThisInitialized(_this));\u000a    return _this;\u000a  }\u000a\u000a  var _proto = AbrController.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    this.clearTimer();\u000a    event_handler.prototype.destroy.call(this);\u000a  };\u000a\u000a  _proto.onFragLoading = function onFragLoading(data) {\u000a    var frag = data.frag;\u000a\u000a    if (frag.type === 'main') {\u000a      if (!this.timer) {\u000a        this.fragCurrent = frag;\u000a        this.timer = setInterval(this.onCheck, 100);\u000a      } // lazy init of BwEstimator, rationale is that we use different params for Live/VoD\u000a      // so we need to wait for stream manifest / playlist type to instantiate it.\u000a\u000a\u000a      if (!this._bwEstimator) {\u000a        var hls = this.hls;\u000a        var config = hls.config;\u000a        var level = frag.level;\u000a        var isLive = hls.levels[level].details.live;\u000a        var ewmaFast;\u000a        var ewmaSlow;\u000a\u000a        if (isLive) {\u000a          ewmaFast = config.abrEwmaFastLive;\u000a          ewmaSlow = config.abrEwmaSlowLive;\u000a        } else {\u000a          ewmaFast = config.abrEwmaFastVoD;\u000a          ewmaSlow = config.abrEwmaSlowVoD;\u000a        }\u000a\u000a        this._bwEstimator = new ewma_bandwidth_estimator(hls, ewmaSlow, ewmaFast, config.abrEwmaDefaultEstimate);\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto._abandonRulesCheck = function _abandonRulesCheck() {\u000a    /*\u000a      monitor fragment retrieval time...\u000a      we compute expected time of arrival of the complete fragment.\u000a      we compare it to expected time of buffer starvation\u000a    */\u000a    var hls = this.hls;\u000a    var video = hls.media;\u000a    var frag = this.fragCurrent;\u000a\u000a    if (!frag) {\u000a      return;\u000a    }\u000a\u000a    var loader = frag.loader; // if loader has been destroyed or loading has been aborted, stop timer and return\u000a\u000a    if (!loader || loader.stats && loader.stats.aborted) {\u000a      logger["logger"].warn('frag loader destroy or aborted, disarm abandonRules');\u000a      this.clearTimer(); // reset forced auto level value so that next level will be selected\u000a\u000a      this._nextAutoLevel = -1;\u000a      return;\u000a    }\u000a\u000a    var stats = loader.stats;\u000a    /* only monitor frag retrieval time if\u000a    (video not paused OR first fragment being loaded(ready state === HAVE_NOTHING = 0)) AND autoswitching enabled AND not lowest level (=> means that we have several levels) */\u000a\u000a    if (video && stats && (!video.paused && video.playbackRate !== 0 || !video.readyState) && frag.autoLevel && frag.level) {\u000a      var requestDelay = abr_controller_performance.now() - stats.trequest;\u000a      var playbackRate = Math.abs(video.playbackRate); // monitor fragment load progress after half of expected fragment duration,to stabilize bitrate\u000a\u000a      if (requestDelay > 500 * frag.duration / playbackRate) {\u000a        var levels = hls.levels;\u000a        var loadRate = Math.max(1, stats.bw ? stats.bw / 8 : stats.loaded * 1000 / requestDelay); // byte/s; at least 1 byte/s to avoid division by zero\u000a        // compute expected fragment length using frag duration and level bitrate. also ensure that expected len is gte than already loaded size\u000a\u000a        var level = levels[frag.level];\u000a\u000a        if (!level) {\u000a          return;\u000a        }\u000a\u000a        var levelBitrate = level.realBitrate ? Math.max(level.realBitrate, level.bitrate) : level.bitrate;\u000a        var expectedLen = stats.total ? stats.total : Math.max(stats.loaded, Math.round(frag.duration * levelBitrate / 8));\u000a        var pos = video.currentTime;\u000a        var fragLoadedDelay = (expectedLen - stats.loaded) / loadRate;\u000a        var bufferStarvationDelay = (BufferHelper.bufferInfo(video, pos, hls.config.maxBufferHole).end - pos) / playbackRate; // consider emergency switch down only if we have less than 2 frag buffered AND\u000a        // time to finish loading current fragment is bigger than buffer starvation delay\u000a        // ie if we risk buffer starvation if bw does not increase quickly\u000a\u000a        if (bufferStarvationDelay < 2 * frag.duration / playbackRate && fragLoadedDelay > bufferStarvationDelay) {\u000a          var minAutoLevel = hls.minAutoLevel;\u000a          var fragLevelNextLoadedDelay;\u000a          var nextLoadLevel; // lets iterate through lower level and try to find the biggest one that could avoid rebuffering\u000a          // we start from current level - 1 and we step down , until we find a matching level\u000a\u000a          for (nextLoadLevel = frag.level - 1; nextLoadLevel > minAutoLevel; nextLoadLevel--) {\u000a            // compute time to load next fragment at lower level\u000a            // 0.8 : consider only 80% of current bw to be conservative\u000a            // 8 = bits per byte (bps/Bps)\u000a            var levelNextBitrate = levels[nextLoadLevel].realBitrate ? Math.max(levels[nextLoadLevel].realBitrate, levels[nextLoadLevel].bitrate) : levels[nextLoadLevel].bitrate;\u000a\u000a            var _fragLevelNextLoadedDelay = frag.duration * levelNextBitrate / (8 * 0.8 * loadRate);\u000a\u000a            if (_fragLevelNextLoadedDelay < bufferStarvationDelay) {\u000a              // we found a lower level that be rebuffering free with current estimated bw !\u000a              break;\u000a            }\u000a          } // only emergency switch down if it takes less time to load new fragment at lowest level instead\u000a          // of finishing loading current one ...\u000a\u000a\u000a          if (fragLevelNextLoadedDelay < fragLoadedDelay) {\u000a            logger["logger"].warn("loading too slow, abort fragment loading and switch to level " + nextLoadLevel + ":fragLoadedDelay[" + nextLoadLevel + "]<fragLoadedDelay[" + (frag.level - 1) + "];bufferStarvationDelay:" + fragLevelNextLoadedDelay.toFixed(1) + "<" + fragLoadedDelay.toFixed(1) + ":" + bufferStarvationDelay.toFixed(1)); // force next load level in auto mode\u000a\u000a            hls.nextLoadLevel = nextLoadLevel; // update bw estimate for this fragment before cancelling load (this will help reducing the bw)\u000a\u000a            this._bwEstimator.sample(requestDelay, stats.loaded); // abort fragment loading\u000a\u000a\u000a            loader.abort(); // stop abandon rules timer\u000a\u000a            this.clearTimer();\u000a            hls.trigger(events["default"].FRAG_LOAD_EMERGENCY_ABORTED, {\u000a              frag: frag,\u000a              stats: stats\u000a            });\u000a          }\u000a        }\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onFragLoaded = function onFragLoaded(data) {\u000a    var frag = data.frag;\u000a\u000a    if (frag.type === 'main' && Object(number["isFiniteNumber"])(frag.sn)) {\u000a      // stop monitoring bw once frag loaded\u000a      this.clearTimer(); // store level id after successful fragment load\u000a\u000a      this.lastLoadedFragLevel = frag.level; // reset forced auto level value so that next level will be selected\u000a\u000a      this._nextAutoLevel = -1; // compute level average bitrate\u000a\u000a      if (this.hls.config.abrMaxWithRealBitrate) {\u000a        var level = this.hls.levels[frag.level];\u000a        var loadedBytes = (level.loaded ? level.loaded.bytes : 0) + data.stats.loaded;\u000a        var loadedDuration = (level.loaded ? level.loaded.duration : 0) + data.frag.duration;\u000a        level.loaded = {\u000a          bytes: loadedBytes,\u000a          duration: loadedDuration\u000a        };\u000a        level.realBitrate = Math.round(8 * loadedBytes / loadedDuration);\u000a      } // if fragment has been loaded to perform a bitrate test,\u000a\u000a\u000a      if (data.frag.bitrateTest) {\u000a        var stats = data.stats;\u000a        stats.tparsed = stats.tbuffered = stats.tload;\u000a        this.onFragBuffered(data);\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onFragBuffered = function onFragBuffered(data) {\u000a    var stats = data.stats;\u000a    var frag = data.frag; // only update stats on first frag buffering\u000a    // if same frag is loaded multiple times, it might be in browser cache, and loaded quickly\u000a    // and leading to wrong bw estimation\u000a    // on bitrate test, also only update stats once (if tload = tbuffered == on FRAG_LOADED)\u000a\u000a    if (stats.aborted !== true && frag.type === 'main' && Object(number["isFiniteNumber"])(frag.sn) && (!frag.bitrateTest || stats.tload === stats.tbuffered)) {\u000a      // use tparsed-trequest instead of tbuffered-trequest to compute fragLoadingProcessing; rationale is that  buffer appending only happens once media is attached\u000a      // in case we use config.startFragPrefetch while media is not attached yet, fragment might be parsed while media not attached yet, but it will only be buffered on media attached\u000a      // as a consequence it could happen really late in the process. meaning that appending duration might appears huge ... leading to underestimated throughput estimation\u000a      var fragLoadingProcessingMs = stats.tparsed - stats.trequest;\u000a      logger["logger"].log("latency/loading/parsing/append/kbps:" + Math.round(stats.tfirst - stats.trequest) + "/" + Math.round(stats.tload - stats.tfirst) + "/" + Math.round(stats.tparsed - stats.tload) + "/" + Math.round(stats.tbuffered - stats.tparsed) + "/" + Math.round(8 * stats.loaded / (stats.tbuffered - stats.trequest)));\u000a\u000a      this._bwEstimator.sample(fragLoadingProcessingMs, stats.loaded);\u000a\u000a      stats.bwEstimate = this._bwEstimator.getEstimate(); // if fragment has been loaded to perform a bitrate test, (hls.startLevel = -1), store bitrate test delay duration\u000a\u000a      if (frag.bitrateTest) {\u000a        this.bitrateTestDelay = fragLoadingProcessingMs / 1000;\u000a      } else {\u000a        this.bitrateTestDelay = 0;\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onError = function onError(data) {\u000a    // stop timer in case of frag loading error\u000a    switch (data.details) {\u000a      case errors["ErrorDetails"].FRAG_LOAD_ERROR:\u000a      case errors["ErrorDetails"].FRAG_LOAD_TIMEOUT:\u000a        this.clearTimer();\u000a        break;\u000a\u000a      default:\u000a        break;\u000a    }\u000a  };\u000a\u000a  _proto.clearTimer = function clearTimer() {\u000a    clearInterval(this.timer);\u000a    this.timer = null;\u000a  } // return next auto level\u000a  ;\u000a\u000a  _proto._findBestLevel = function _findBestLevel(currentLevel, currentFragDuration, currentBw, minAutoLevel, maxAutoLevel, maxFetchDuration, bwFactor, bwUpFactor, levels) {\u000a    for (var i = maxAutoLevel; i >= minAutoLevel; i--) {\u000a      var levelInfo = levels[i];\u000a\u000a      if (!levelInfo) {\u000a        continue;\u000a      }\u000a\u000a      var levelDetails = levelInfo.details;\u000a      var avgDuration = levelDetails ? levelDetails.totalduration / levelDetails.fragments.length : currentFragDuration;\u000a      var live = levelDetails ? levelDetails.live : false;\u000a      var adjustedbw = void 0; // follow algorithm captured from stagefright :\u000a      // https://android.googlesource.com/platform/frameworks/av/+/master/media/libstagefright/httplive/LiveSession.cpp\u000a      // Pick the highest bandwidth stream below or equal to estimated bandwidth.\u000a      // consider only 80% of the available bandwidth, but if we are switching up,\u000a      // be even more conservative (70%) to avoid overestimating and immediately\u000a      // switching back.\u000a\u000a      if (i <= currentLevel) {\u000a        adjustedbw = bwFactor * currentBw;\u000a      } else {\u000a        adjustedbw = bwUpFactor * currentBw;\u000a      }\u000a\u000a      var bitrate = levels[i].realBitrate ? Math.max(levels[i].realBitrate, levels[i].bitrate) : levels[i].bitrate;\u000a      var fetchDuration = bitrate * avgDuration / adjustedbw;\u000a      logger["logger"].trace("level/adjustedbw/bitrate/avgDuration/maxFetchDuration/fetchDuration: " + i + "/" + Math.round(adjustedbw) + "/" + bitrate + "/" + avgDuration + "/" + maxFetchDuration + "/" + fetchDuration); // if adjusted bw is greater than level bitrate AND\u000a\u000a      if (adjustedbw > bitrate && ( // fragment fetchDuration unknown OR live stream OR fragment fetchDuration less than max allowed fetch duration, then this level matches\u000a      // we don't account for max Fetch Duration for live streams, this is to avoid switching down when near the edge of live sliding window ...\u000a      // special case to support startLevel = -1 (bitrateTest) on live streams : in that case we should not exit loop so that _findBestLevel will return -1\u000a      !fetchDuration || live && !this.bitrateTestDelay || fetchDuration < maxFetchDuration)) {\u000a        // as we are looping from highest to lowest, this will return the best achievable quality level\u000a        return i;\u000a      }\u000a    } // not enough time budget even with quality level 0 ... rebuffering might happen\u000a\u000a\u000a    return -1;\u000a  };\u000a\u000a  abr_controller_createClass(AbrController, [{\u000a    key: "nextAutoLevel",\u000a    get: function get() {\u000a      var forcedAutoLevel = this._nextAutoLevel;\u000a      var bwEstimator = this._bwEstimator; // in case next auto level has been forced, and bw not available or not reliable, return forced value\u000a\u000a      if (forcedAutoLevel !== -1 && (!bwEstimator || !bwEstimator.canEstimate())) {\u000a        return forcedAutoLevel;\u000a      } // compute next level using ABR logic\u000a\u000a\u000a      var nextABRAutoLevel = this._nextABRAutoLevel; // if forced auto level has been defined, use it to cap ABR computed quality level\u000a\u000a      if (forcedAutoLevel !== -1) {\u000a        nextABRAutoLevel = Math.min(forcedAutoLevel, nextABRAutoLevel);\u000a      }\u000a\u000a      return nextABRAutoLevel;\u000a    },\u000a    set: function set(nextLevel) {\u000a      this._nextAutoLevel = nextLevel;\u000a    }\u000a  }, {\u000a    key: "_nextABRAutoLevel",\u000a    get: function get() {\u000a      var hls = this.hls;\u000a      var maxAutoLevel = hls.maxAutoLevel,\u000a          levels = hls.levels,\u000a          config = hls.config,\u000a          minAutoLevel = hls.minAutoLevel;\u000a      var video = hls.media;\u000a      var currentLevel = this.lastLoadedFragLevel;\u000a      var currentFragDuration = this.fragCurrent ? this.fragCurrent.duration : 0;\u000a      var pos = video ? video.currentTime : 0; // playbackRate is the absolute value of the playback rate; if video.playbackRate is 0, we use 1 to load as\u000a      // if we're playing back at the normal rate.\u000a\u000a      var playbackRate = video && video.playbackRate !== 0 ? Math.abs(video.playbackRate) : 1.0;\u000a      var avgbw = this._bwEstimator ? this._bwEstimator.getEstimate() : config.abrEwmaDefaultEstimate; // bufferStarvationDelay is the wall-clock time left until the playback buffer is exhausted.\u000a\u000a      var bufferStarvationDelay = (BufferHelper.bufferInfo(video, pos, config.maxBufferHole).end - pos) / playbackRate; // First, look to see if we can find a level matching with our avg bandwidth AND that could also guarantee no rebuffering at all\u000a\u000a      var bestLevel = this._findBestLevel(currentLevel, currentFragDuration, avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, config.abrBandWidthFactor, config.abrBandWidthUpFactor, levels);\u000a\u000a      if (bestLevel >= 0) {\u000a        return bestLevel;\u000a      } else {\u000a        logger["logger"].trace('rebuffering expected to happen, lets try to find a quality level minimizing the rebuffering'); // not possible to get rid of rebuffering ... let's try to find level that will guarantee less than maxStarvationDelay of rebuffering\u000a        // if no matching level found, logic will return 0\u000a\u000a        var maxStarvationDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxStarvationDelay) : config.maxStarvationDelay;\u000a        var bwFactor = config.abrBandWidthFactor;\u000a        var bwUpFactor = config.abrBandWidthUpFactor;\u000a\u000a        if (bufferStarvationDelay === 0) {\u000a          // in case buffer is empty, let's check if previous fragment was loaded to perform a bitrate test\u000a          var bitrateTestDelay = this.bitrateTestDelay;\u000a\u000a          if (bitrateTestDelay) {\u000a            // if it is the case, then we need to adjust our max starvation delay using maxLoadingDelay config value\u000a            // max video loading delay used in  automatic start level selection :\u000a            // in that mode ABR controller will ensure that video loading time (ie the time to fetch the first fragment at lowest quality level +\u000a            // the time to fetch the fragment at the appropriate quality level is less than ```maxLoadingDelay``` )\u000a            // cap maxLoadingDelay and ensure it is not bigger 'than bitrate test' frag duration\u000a            var maxLoadingDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxLoadingDelay) : config.maxLoadingDelay;\u000a            maxStarvationDelay = maxLoadingDelay - bitrateTestDelay;\u000a            logger["logger"].trace("bitrate test took " + Math.round(1000 * bitrateTestDelay) + "ms, set first fragment max fetchDuration to " + Math.round(1000 * maxStarvationDelay) + " ms"); // don't use conservative factor on bitrate test\u000a\u000a            bwFactor = bwUpFactor = 1;\u000a          }\u000a        }\u000a\u000a        bestLevel = this._findBestLevel(currentLevel, currentFragDuration, avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay + maxStarvationDelay, bwFactor, bwUpFactor, levels);\u000a        return Math.max(bestLevel, 0);\u000a      }\u000a    }\u000a  }]);\u000a\u000a  return AbrController;\u000a}(event_handler);\u000a\u000a/* harmony default export */ var abr_controller = (abr_controller_AbrController);\u000a// CONCATENATED MODULE: ./src/controller/buffer-controller.ts\u000a\u000a\u000afunction buffer_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * Buffer Controller\u000a */\u000a\u000a\u000a\u000a\u000a\u000avar buffer_controller_MediaSource = getMediaSource();\u000a\u000avar buffer_controller_BufferController = /*#__PURE__*/function (_EventHandler) {\u000a  buffer_controller_inheritsLoose(BufferController, _EventHandler);\u000a\u000a  // the value that we have set mediasource.duration to\u000a  // (the actual duration may be tweaked slighly by the browser)\u000a  // the value that we want to set mediaSource.duration to\u000a  // the target duration of the current media playlist\u000a  // current stream state: true - for live broadcast, false - for VoD content\u000a  // cache the self generated object url to detect hijack of video tag\u000a  // signals that the sourceBuffers need to be flushed\u000a  // signals that mediaSource should have endOfStream called\u000a  // this is optional because this property is removed from the class sometimes\u000a  // The number of BUFFER_CODEC events received before any sourceBuffers are created\u000a  // The total number of BUFFER_CODEC events received\u000a  // A reference to the attached media element\u000a  // A reference to the active media source\u000a  // List of pending segments to be appended to source buffer\u000a  // A guard to see if we are currently appending to the source buffer\u000a  // counters\u000a  function BufferController(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].MEDIA_ATTACHING, events["default"].MEDIA_DETACHING, events["default"].MANIFEST_PARSED, events["default"].BUFFER_RESET, events["default"].BUFFER_APPENDING, events["default"].BUFFER_CODECS, events["default"].BUFFER_EOS, events["default"].BUFFER_FLUSHING, events["default"].LEVEL_PTS_UPDATED, events["default"].LEVEL_UPDATED) || this;\u000a    _this._msDuration = null;\u000a    _this._levelDuration = null;\u000a    _this._levelTargetDuration = 10;\u000a    _this._live = null;\u000a    _this._objectUrl = null;\u000a    _this._needsFlush = false;\u000a    _this._needsEos = false;\u000a    _this.config = void 0;\u000a    _this.audioTimestampOffset = void 0;\u000a    _this.bufferCodecEventsExpected = 0;\u000a    _this._bufferCodecEventsTotal = 0;\u000a    _this.media = null;\u000a    _this.mediaSource = null;\u000a    _this.segments = [];\u000a    _this.parent = void 0;\u000a    _this.appending = false;\u000a    _this.appended = 0;\u000a    _this.appendError = 0;\u000a    _this.flushBufferCounter = 0;\u000a    _this.tracks = {};\u000a    _this.pendingTracks = {};\u000a    _this.sourceBuffer = {};\u000a    _this.flushRange = [];\u000a\u000a    _this._onMediaSourceOpen = function () {\u000a      logger["logger"].log('media source opened');\u000a\u000a      _this.hls.trigger(events["default"].MEDIA_ATTACHED, {\u000a        media: _this.media\u000a      });\u000a\u000a      var mediaSource = _this.mediaSource;\u000a\u000a      if (mediaSource) {\u000a        // once received, don't listen anymore to sourceopen event\u000a        mediaSource.removeEventListener('sourceopen', _this._onMediaSourceOpen);\u000a      }\u000a\u000a      _this.checkPendingTracks();\u000a    };\u000a\u000a    _this._onMediaSourceClose = function () {\u000a      logger["logger"].log('media source closed');\u000a    };\u000a\u000a    _this._onMediaSourceEnded = function () {\u000a      logger["logger"].log('media source ended');\u000a    };\u000a\u000a    _this._onSBUpdateEnd = function () {\u000a      // update timestampOffset\u000a      if (_this.audioTimestampOffset && _this.sourceBuffer.audio) {\u000a        var audioBuffer = _this.sourceBuffer.audio;\u000a        logger["logger"].warn("change mpeg audio timestamp offset from " + audioBuffer.timestampOffset + " to " + _this.audioTimestampOffset);\u000a        audioBuffer.timestampOffset = _this.audioTimestampOffset;\u000a        delete _this.audioTimestampOffset;\u000a      }\u000a\u000a      if (_this._needsFlush) {\u000a        _this.doFlush();\u000a      }\u000a\u000a      if (_this._needsEos) {\u000a        _this.checkEos();\u000a      }\u000a\u000a      _this.appending = false;\u000a      var parent = _this.parent; // count nb of pending segments waiting for appending on this sourcebuffer\u000a\u000a      var pending = _this.segments.reduce(function (counter, segment) {\u000a        return segment.parent === parent ? counter + 1 : counter;\u000a      }, 0); // this.sourceBuffer is better to use than media.buffered as it is closer to the PTS data from the fragments\u000a\u000a\u000a      var timeRanges = {};\u000a      var sbSet = _this.sourceBuffer;\u000a\u000a      for (var streamType in sbSet) {\u000a        var sb = sbSet[streamType];\u000a\u000a        if (!sb) {\u000a          throw Error("handling source buffer update end error: source buffer for " + streamType + " uninitilized and unable to update buffered TimeRanges.");\u000a        }\u000a\u000a        timeRanges[streamType] = sb.buffered;\u000a      }\u000a\u000a      _this.hls.trigger(events["default"].BUFFER_APPENDED, {\u000a        parent: parent,\u000a        pending: pending,\u000a        timeRanges: timeRanges\u000a      }); // don't append in flushing mode\u000a\u000a\u000a      if (!_this._needsFlush) {\u000a        _this.doAppending();\u000a      }\u000a\u000a      _this.updateMediaElementDuration(); // appending goes first\u000a\u000a\u000a      if (pending === 0) {\u000a        _this.flushLiveBackBuffer();\u000a      }\u000a    };\u000a\u000a    _this._onSBUpdateError = function (event) {\u000a      logger["logger"].error('sourceBuffer error:', event); // according to http://www.w3.org/TR/media-source/#sourcebuffer-append-error\u000a      // this error might not always be fatal (it is fatal if decode error is set, in that case\u000a      // it will be followed by a mediaElement error ...)\u000a\u000a      _this.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        details: errors["ErrorDetails"].BUFFER_APPENDING_ERROR,\u000a        fatal: false\u000a      }); // we don't need to do more than that, as accordin to the spec, updateend will be fired just after\u000a\u000a    };\u000a\u000a    _this.config = hls.config;\u000a    return _this;\u000a  }\u000a\u000a  var _proto = BufferController.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    event_handler.prototype.destroy.call(this);\u000a  };\u000a\u000a  _proto.onLevelPtsUpdated = function onLevelPtsUpdated(data) {\u000a    var type = data.type;\u000a    var audioTrack = this.tracks.audio; // Adjusting `SourceBuffer.timestampOffset` (desired point in the timeline where the next frames should be appended)\u000a    // in Chrome browser when we detect MPEG audio container and time delta between level PTS and `SourceBuffer.timestampOffset`\u000a    // is greater than 100ms (this is enough to handle seek for VOD or level change for LIVE videos). At the time of change we issue\u000a    // `SourceBuffer.abort()` and adjusting `SourceBuffer.timestampOffset` if `SourceBuffer.updating` is false or awaiting `updateend`\u000a    // event if SB is in updating state.\u000a    // More info here: https://github.com/video-dev/hls.js/issues/332#issuecomment-257986486\u000a\u000a    if (type === 'audio' && audioTrack && audioTrack.container === 'audio/mpeg') {\u000a      // Chrome audio mp3 track\u000a      var audioBuffer = this.sourceBuffer.audio;\u000a\u000a      if (!audioBuffer) {\u000a        throw Error('Level PTS Updated and source buffer for audio uninitalized');\u000a      }\u000a\u000a      var delta = Math.abs(audioBuffer.timestampOffset - data.start); // adjust timestamp offset if time delta is greater than 100ms\u000a\u000a      if (delta > 0.1) {\u000a        var updating = audioBuffer.updating;\u000a\u000a        try {\u000a          audioBuffer.abort();\u000a        } catch (err) {\u000a          logger["logger"].warn('can not abort audio buffer: ' + err);\u000a        }\u000a\u000a        if (!updating) {\u000a          logger["logger"].warn('change mpeg audio timestamp offset from ' + audioBuffer.timestampOffset + ' to ' + data.start);\u000a          audioBuffer.timestampOffset = data.start;\u000a        } else {\u000a          this.audioTimestampOffset = data.start;\u000a        }\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onManifestParsed = function onManifestParsed(data) {\u000a    // in case of alt audio (where all tracks have urls) 2 BUFFER_CODECS events will be triggered, one per stream controller\u000a    // sourcebuffers will be created all at once when the expected nb of tracks will be reached\u000a    // in case alt audio is not used, only one BUFFER_CODEC event will be fired from main stream controller\u000a    // it will contain the expected nb of source buffers, no need to compute it\u000a    var codecEvents = 2;\u000a\u000a    if (data.audio && !data.video || !data.altAudio) {\u000a      codecEvents = 1;\u000a    }\u000a\u000a    this.bufferCodecEventsExpected = this._bufferCodecEventsTotal = codecEvents;\u000a    logger["logger"].log(this.bufferCodecEventsExpected + " bufferCodec event(s) expected");\u000a  };\u000a\u000a  _proto.onMediaAttaching = function onMediaAttaching(data) {\u000a    var media = this.media = data.media;\u000a\u000a    if (media && buffer_controller_MediaSource) {\u000a      // setup the media source\u000a      var ms = this.mediaSource = new buffer_controller_MediaSource(); // Media Source listeners\u000a\u000a      ms.addEventListener('sourceopen', this._onMediaSourceOpen);\u000a      ms.addEventListener('sourceended', this._onMediaSourceEnded);\u000a      ms.addEventListener('sourceclose', this._onMediaSourceClose); // link video and media Source\u000a\u000a      media.src = window.URL.createObjectURL(ms); // cache the locally generated object url\u000a\u000a      this._objectUrl = media.src;\u000a    }\u000a  };\u000a\u000a  _proto.onMediaDetaching = function onMediaDetaching() {\u000a    logger["logger"].log('media source detaching');\u000a    var ms = this.mediaSource;\u000a\u000a    if (ms) {\u000a      if (ms.readyState === 'open') {\u000a        try {\u000a          // endOfStream could trigger exception if any sourcebuffer is in updating state\u000a          // we don't really care about checking sourcebuffer state here,\u000a          // as we are anyway detaching the MediaSource\u000a          // let's just avoid this exception to propagate\u000a          ms.endOfStream();\u000a        } catch (err) {\u000a          logger["logger"].warn("onMediaDetaching:" + err.message + " while calling endOfStream");\u000a        }\u000a      }\u000a\u000a      ms.removeEventListener('sourceopen', this._onMediaSourceOpen);\u000a      ms.removeEventListener('sourceended', this._onMediaSourceEnded);\u000a      ms.removeEventListener('sourceclose', this._onMediaSourceClose); // Detach properly the MediaSource from the HTMLMediaElement as\u000a      // suggested in https://github.com/w3c/media-source/issues/53.\u000a\u000a      if (this.media) {\u000a        if (this._objectUrl) {\u000a          window.URL.revokeObjectURL(this._objectUrl);\u000a        } // clean up video tag src only if it's our own url. some external libraries might\u000a        // hijack the video tag and change its 'src' without destroying the Hls instance first\u000a\u000a\u000a        if (this.media.src === this._objectUrl) {\u000a          this.media.removeAttribute('src');\u000a          this.media.load();\u000a        } else {\u000a          logger["logger"].warn('media.src was changed by a third party - skip cleanup');\u000a        }\u000a      }\u000a\u000a      this.mediaSource = null;\u000a      this.media = null;\u000a      this._objectUrl = null;\u000a      this.bufferCodecEventsExpected = this._bufferCodecEventsTotal;\u000a      this.pendingTracks = {};\u000a      this.tracks = {};\u000a      this.sourceBuffer = {};\u000a      this.flushRange = [];\u000a      this.segments = [];\u000a      this.appended = 0;\u000a    }\u000a\u000a    this.hls.trigger(events["default"].MEDIA_DETACHED);\u000a  };\u000a\u000a  _proto.checkPendingTracks = function checkPendingTracks() {\u000a    var bufferCodecEventsExpected = this.bufferCodecEventsExpected,\u000a        pendingTracks = this.pendingTracks; // Check if we've received all of the expected bufferCodec events. When none remain, create all the sourceBuffers at once.\u000a    // This is important because the MSE spec allows implementations to throw QuotaExceededErrors if creating new sourceBuffers after\u000a    // data has been appended to existing ones.\u000a    // 2 tracks is the max (one for audio, one for video). If we've reach this max go ahead and create the buffers.\u000a\u000a    var pendingTracksCount = Object.keys(pendingTracks).length;\u000a\u000a    if (pendingTracksCount && !bufferCodecEventsExpected || pendingTracksCount === 2) {\u000a      // ok, let's create them now !\u000a      this.createSourceBuffers(pendingTracks);\u000a      this.pendingTracks = {}; // append any pending segments now !\u000a\u000a      this.doAppending();\u000a    }\u000a  };\u000a\u000a  _proto.onBufferReset = function onBufferReset() {\u000a    var sourceBuffer = this.sourceBuffer;\u000a\u000a    for (var type in sourceBuffer) {\u000a      var sb = sourceBuffer[type];\u000a\u000a      try {\u000a        if (sb) {\u000a          if (this.mediaSource) {\u000a            this.mediaSource.removeSourceBuffer(sb);\u000a          }\u000a\u000a          sb.removeEventListener('updateend', this._onSBUpdateEnd);\u000a          sb.removeEventListener('error', this._onSBUpdateError);\u000a        }\u000a      } catch (err) {}\u000a    }\u000a\u000a    this.sourceBuffer = {};\u000a    this.flushRange = [];\u000a    this.segments = [];\u000a    this.appended = 0;\u000a  };\u000a\u000a  _proto.onBufferCodecs = function onBufferCodecs(tracks) {\u000a    var _this2 = this;\u000a\u000a    // if source buffer(s) not created yet, appended buffer tracks in this.pendingTracks\u000a    // if sourcebuffers already created, do nothing ...\u000a    if (Object.keys(this.sourceBuffer).length) {\u000a      return;\u000a    }\u000a\u000a    Object.keys(tracks).forEach(function (trackName) {\u000a      _this2.pendingTracks[trackName] = tracks[trackName];\u000a    });\u000a    this.bufferCodecEventsExpected = Math.max(this.bufferCodecEventsExpected - 1, 0);\u000a\u000a    if (this.mediaSource && this.mediaSource.readyState === 'open') {\u000a      this.checkPendingTracks();\u000a    }\u000a  };\u000a\u000a  _proto.createSourceBuffers = function createSourceBuffers(tracks) {\u000a    var sourceBuffer = this.sourceBuffer,\u000a        mediaSource = this.mediaSource;\u000a\u000a    if (!mediaSource) {\u000a      throw Error('createSourceBuffers called when mediaSource was null');\u000a    }\u000a\u000a    for (var trackName in tracks) {\u000a      if (!sourceBuffer[trackName]) {\u000a        var track = tracks[trackName];\u000a\u000a        if (!track) {\u000a          throw Error("source buffer exists for track " + trackName + ", however track does not");\u000a        } // use levelCodec as first priority\u000a\u000a\u000a        var codec = track.levelCodec || track.codec;\u000a        var mimeType = track.container + ";codecs=" + codec;\u000a        logger["logger"].log("creating sourceBuffer(" + mimeType + ")");\u000a\u000a        try {\u000a          var sb = sourceBuffer[trackName] = mediaSource.addSourceBuffer(mimeType);\u000a          sb.addEventListener('updateend', this._onSBUpdateEnd);\u000a          sb.addEventListener('error', this._onSBUpdateError);\u000a          this.tracks[trackName] = {\u000a            buffer: sb,\u000a            codec: codec,\u000a            id: track.id,\u000a            container: track.container,\u000a            levelCodec: track.levelCodec\u000a          };\u000a        } catch (err) {\u000a          logger["logger"].error("error while trying to add sourceBuffer:" + err.message);\u000a          this.hls.trigger(events["default"].ERROR, {\u000a            type: errors["ErrorTypes"].MEDIA_ERROR,\u000a            details: errors["ErrorDetails"].BUFFER_ADD_CODEC_ERROR,\u000a            fatal: false,\u000a            err: err,\u000a            mimeType: mimeType\u000a          });\u000a        }\u000a      }\u000a    }\u000a\u000a    this.hls.trigger(events["default"].BUFFER_CREATED, {\u000a      tracks: this.tracks\u000a    });\u000a  };\u000a\u000a  _proto.onBufferAppending = function onBufferAppending(data) {\u000a    if (!this._needsFlush) {\u000a      if (!this.segments) {\u000a        this.segments = [data];\u000a      } else {\u000a        this.segments.push(data);\u000a      }\u000a\u000a      this.doAppending();\u000a    }\u000a  } // on BUFFER_EOS mark matching sourcebuffer(s) as ended and trigger checkEos()\u000a  // an undefined data.type will mark all buffers as EOS.\u000a  ;\u000a\u000a  _proto.onBufferEos = function onBufferEos(data) {\u000a    for (var type in this.sourceBuffer) {\u000a      if (!data.type || data.type === type) {\u000a        var sb = this.sourceBuffer[type];\u000a\u000a        if (sb && !sb.ended) {\u000a          sb.ended = true;\u000a          logger["logger"].log(type + " sourceBuffer now EOS");\u000a        }\u000a      }\u000a    }\u000a\u000a    this.checkEos();\u000a  } // if all source buffers are marked as ended, signal endOfStream() to MediaSource.\u000a  ;\u000a\u000a  _proto.checkEos = function checkEos() {\u000a    var sourceBuffer = this.sourceBuffer,\u000a        mediaSource = this.mediaSource;\u000a\u000a    if (!mediaSource || mediaSource.readyState !== 'open') {\u000a      this._needsEos = false;\u000a      return;\u000a    }\u000a\u000a    for (var type in sourceBuffer) {\u000a      var sb = sourceBuffer[type];\u000a      if (!sb) continue;\u000a\u000a      if (!sb.ended) {\u000a        return;\u000a      }\u000a\u000a      if (sb.updating) {\u000a        this._needsEos = true;\u000a        return;\u000a      }\u000a    }\u000a\u000a    logger["logger"].log('all media data are available, signal endOfStream() to MediaSource and stop loading fragment'); // Notify the media element that it now has all of the media data\u000a\u000a    try {\u000a      mediaSource.endOfStream();\u000a    } catch (e) {\u000a      logger["logger"].warn('exception while calling mediaSource.endOfStream()');\u000a    }\u000a\u000a    this._needsEos = false;\u000a  };\u000a\u000a  _proto.onBufferFlushing = function onBufferFlushing(data) {\u000a    if (data.type) {\u000a      this.flushRange.push({\u000a        start: data.startOffset,\u000a        end: data.endOffset,\u000a        type: data.type\u000a      });\u000a    } else {\u000a      this.flushRange.push({\u000a        start: data.startOffset,\u000a        end: data.endOffset,\u000a        type: 'video'\u000a      });\u000a      this.flushRange.push({\u000a        start: data.startOffset,\u000a        end: data.endOffset,\u000a        type: 'audio'\u000a      });\u000a    } // attempt flush immediately\u000a\u000a\u000a    this.flushBufferCounter = 0;\u000a    this.doFlush();\u000a  };\u000a\u000a  _proto.flushLiveBackBuffer = function flushLiveBackBuffer() {\u000a    // clear back buffer for live only\u000a    if (!this._live) {\u000a      return;\u000a    }\u000a\u000a    var liveBackBufferLength = this.config.liveBackBufferLength;\u000a\u000a    if (!isFinite(liveBackBufferLength) || liveBackBufferLength < 0) {\u000a      return;\u000a    }\u000a\u000a    if (!this.media) {\u000a      logger["logger"].error('flushLiveBackBuffer called without attaching media');\u000a      return;\u000a    }\u000a\u000a    var currentTime = this.media.currentTime;\u000a    var sourceBuffer = this.sourceBuffer;\u000a    var bufferTypes = Object.keys(sourceBuffer);\u000a    var targetBackBufferPosition = currentTime - Math.max(liveBackBufferLength, this._levelTargetDuration);\u000a\u000a    for (var index = bufferTypes.length - 1; index >= 0; index--) {\u000a      var bufferType = bufferTypes[index];\u000a      var sb = sourceBuffer[bufferType];\u000a\u000a      if (sb) {\u000a        var buffered = sb.buffered; // when target buffer start exceeds actual buffer start\u000a\u000a        if (buffered.length > 0 && targetBackBufferPosition > buffered.start(0)) {\u000a          // remove buffer up until current time minus minimum back buffer length (removing buffer too close to current\u000a          // time will lead to playback freezing)\u000a          // credits for level target duration - https://github.com/videojs/http-streaming/blob/3132933b6aa99ddefab29c10447624efd6fd6e52/src/segment-loader.js#L91\u000a          if (this.removeBufferRange(bufferType, sb, 0, targetBackBufferPosition)) {\u000a            this.hls.trigger(events["default"].LIVE_BACK_BUFFER_REACHED, {\u000a              bufferEnd: targetBackBufferPosition\u000a            });\u000a          }\u000a        }\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onLevelUpdated = function onLevelUpdated(_ref) {\u000a    var details = _ref.details;\u000a\u000a    if (details.fragments.length > 0) {\u000a      this._levelDuration = details.totalduration + details.fragments[0].start;\u000a      this._levelTargetDuration = details.averagetargetduration || details.targetduration || 10;\u000a      this._live = details.live;\u000a      this.updateMediaElementDuration();\u000a    }\u000a  }\u000a  /**\u000a   * Update Media Source duration to current level duration or override to Infinity if configuration parameter\u000a   * 'liveDurationInfinity` is set to `true`\u000a   * More details: https://github.com/video-dev/hls.js/issues/355\u000a   */\u000a  ;\u000a\u000a  _proto.updateMediaElementDuration = function updateMediaElementDuration() {\u000a    var config = this.config;\u000a    var duration;\u000a\u000a    if (this._levelDuration === null || !this.media || !this.mediaSource || !this.sourceBuffer || this.media.readyState === 0 || this.mediaSource.readyState !== 'open') {\u000a      return;\u000a    }\u000a\u000a    for (var type in this.sourceBuffer) {\u000a      var sb = this.sourceBuffer[type];\u000a\u000a      if (sb && sb.updating === true) {\u000a        // can't set duration whilst a buffer is updating\u000a        return;\u000a      }\u000a    }\u000a\u000a    duration = this.media.duration; // initialise to the value that the media source is reporting\u000a\u000a    if (this._msDuration === null) {\u000a      this._msDuration = this.mediaSource.duration;\u000a    }\u000a\u000a    if (this._live === true && config.liveDurationInfinity === true) {\u000a      // Override duration to Infinity\u000a      logger["logger"].log('Media Source duration is set to Infinity');\u000a      this._msDuration = this.mediaSource.duration = Infinity;\u000a    } else if (this._levelDuration > this._msDuration && this._levelDuration > duration || !Object(number["isFiniteNumber"])(duration)) {\u000a      // levelDuration was the last value we set.\u000a      // not using mediaSource.duration as the browser may tweak this value\u000a      // only update Media Source duration if its value increase, this is to avoid\u000a      // flushing already buffered portion when switching between quality level\u000a      logger["logger"].log("Updating Media Source duration to " + this._levelDuration.toFixed(3));\u000a      this._msDuration = this.mediaSource.duration = this._levelDuration;\u000a    }\u000a  };\u000a\u000a  _proto.doFlush = function doFlush() {\u000a    // loop through all buffer ranges to flush\u000a    while (this.flushRange.length) {\u000a      var range = this.flushRange[0]; // flushBuffer will abort any buffer append in progress and flush Audio/Video Buffer\u000a\u000a      if (this.flushBuffer(range.start, range.end, range.type)) {\u000a        // range flushed, remove from flush array\u000a        this.flushRange.shift();\u000a        this.flushBufferCounter = 0;\u000a      } else {\u000a        this._needsFlush = true; // avoid looping, wait for SB update end to retrigger a flush\u000a\u000a        return;\u000a      }\u000a    }\u000a\u000a    if (this.flushRange.length === 0) {\u000a      // everything flushed\u000a      this._needsFlush = false; // let's recompute this.appended, which is used to avoid flush looping\u000a\u000a      var appended = 0;\u000a      var sourceBuffer = this.sourceBuffer;\u000a\u000a      try {\u000a        for (var type in sourceBuffer) {\u000a          var sb = sourceBuffer[type];\u000a\u000a          if (sb) {\u000a            appended += sb.buffered.length;\u000a          }\u000a        }\u000a      } catch (error) {\u000a        // error could be thrown while accessing buffered, in case sourcebuffer has already been removed from MediaSource\u000a        // this is harmess at this stage, catch this to avoid reporting an internal exception\u000a        logger["logger"].error('error while accessing sourceBuffer.buffered');\u000a      }\u000a\u000a      this.appended = appended;\u000a      this.hls.trigger(events["default"].BUFFER_FLUSHED);\u000a    }\u000a  };\u000a\u000a  _proto.doAppending = function doAppending() {\u000a    var config = this.config,\u000a        hls = this.hls,\u000a        segments = this.segments,\u000a        sourceBuffer = this.sourceBuffer;\u000a\u000a    if (!Object.keys(sourceBuffer).length) {\u000a      // early exit if no source buffers have been initialized yet\u000a      return;\u000a    }\u000a\u000a    if (!this.media || this.media.error) {\u000a      this.segments = [];\u000a      logger["logger"].error('trying to append although a media error occured, flush segment and abort');\u000a      return;\u000a    }\u000a\u000a    if (this.appending) {\u000a      // logger.log(`sb appending in progress`);\u000a      return;\u000a    }\u000a\u000a    var segment = segments.shift();\u000a\u000a    if (!segment) {\u000a      // handle undefined shift\u000a      return;\u000a    }\u000a\u000a    try {\u000a      var sb = sourceBuffer[segment.type];\u000a\u000a      if (!sb) {\u000a        // in case we don't have any source buffer matching with this segment type,\u000a        // it means that Mediasource fails to create sourcebuffer\u000a        // discard this segment, and trigger update end\u000a        this._onSBUpdateEnd();\u000a\u000a        return;\u000a      }\u000a\u000a      if (sb.updating) {\u000a        // if we are still updating the source buffer from the last segment, place this back at the front of the queue\u000a        segments.unshift(segment);\u000a        return;\u000a      } // reset sourceBuffer ended flag before appending segment\u000a\u000a\u000a      sb.ended = false; // logger.log(`appending ${segment.content} ${type} SB, size:${segment.data.length}, ${segment.parent}`);\u000a\u000a      this.parent = segment.parent;\u000a      sb.appendBuffer(segment.data);\u000a      this.appendError = 0;\u000a      this.appended++;\u000a      this.appending = true;\u000a    } catch (err) {\u000a      // in case any error occured while appending, put back segment in segments table\u000a      logger["logger"].error("error while trying to append buffer:" + err.message);\u000a      segments.unshift(segment);\u000a      var event = {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        parent: segment.parent,\u000a        details: '',\u000a        fatal: false\u000a      };\u000a\u000a      if (err.code === 22) {\u000a        // QuotaExceededError: http://www.w3.org/TR/html5/infrastructure.html#quotaexceedederror\u000a        // let's stop appending any segments, and report BUFFER_FULL_ERROR error\u000a        this.segments = [];\u000a        event.details = errors["ErrorDetails"].BUFFER_FULL_ERROR;\u000a      } else {\u000a        this.appendError++;\u000a        event.details = errors["ErrorDetails"].BUFFER_APPEND_ERROR;\u000a        /* with UHD content, we could get loop of quota exceeded error until\u000a          browser is able to evict some data from sourcebuffer. retrying help recovering this\u000a        */\u000a\u000a        if (this.appendError > config.appendErrorMaxRetry) {\u000a          logger["logger"].log("fail " + config.appendErrorMaxRetry + " times to append segment in sourceBuffer");\u000a          this.segments = [];\u000a          event.fatal = true;\u000a        }\u000a      }\u000a\u000a      hls.trigger(events["default"].ERROR, event);\u000a    }\u000a  }\u000a  /*\u000a    flush specified buffered range,\u000a    return true once range has been flushed.\u000a    as sourceBuffer.remove() is asynchronous, flushBuffer will be retriggered on sourceBuffer update end\u000a  */\u000a  ;\u000a\u000a  _proto.flushBuffer = function flushBuffer(startOffset, endOffset, sbType) {\u000a    var sourceBuffer = this.sourceBuffer; // exit if no sourceBuffers are initialized\u000a\u000a    if (!Object.keys(sourceBuffer).length) {\u000a      return true;\u000a    }\u000a\u000a    var currentTime = 'null';\u000a\u000a    if (this.media) {\u000a      currentTime = this.media.currentTime.toFixed(3);\u000a    }\u000a\u000a    logger["logger"].log("flushBuffer,pos/start/end: " + currentTime + "/" + startOffset + "/" + endOffset); // safeguard to avoid infinite looping : don't try to flush more than the nb of appended segments\u000a\u000a    if (this.flushBufferCounter >= this.appended) {\u000a      logger["logger"].warn('abort flushing too many retries');\u000a      return true;\u000a    }\u000a\u000a    var sb = sourceBuffer[sbType]; // we are going to flush buffer, mark source buffer as 'not ended'\u000a\u000a    if (sb) {\u000a      sb.ended = false;\u000a\u000a      if (!sb.updating) {\u000a        if (this.removeBufferRange(sbType, sb, startOffset, endOffset)) {\u000a          this.flushBufferCounter++;\u000a          return false;\u000a        }\u000a      } else {\u000a        logger["logger"].warn('cannot flush, sb updating in progress');\u000a        return false;\u000a      }\u000a    }\u000a\u000a    logger["logger"].log('buffer flushed'); // everything flushed !\u000a\u000a    return true;\u000a  }\u000a  /**\u000a   * Removes first buffered range from provided source buffer that lies within given start and end offsets.\u000a   *\u000a   * @param {string} type Type of the source buffer, logging purposes only.\u000a   * @param {SourceBuffer} sb Target SourceBuffer instance.\u000a   * @param {number} startOffset\u000a   * @param {number} endOffset\u000a   *\u000a   * @returns {boolean} True when source buffer remove requested.\u000a   */\u000a  ;\u000a\u000a  _proto.removeBufferRange = function removeBufferRange(type, sb, startOffset, endOffset) {\u000a    try {\u000a      for (var i = 0; i < sb.buffered.length; i++) {\u000a        var bufStart = sb.buffered.start(i);\u000a        var bufEnd = sb.buffered.end(i);\u000a        var removeStart = Math.max(bufStart, startOffset);\u000a        var removeEnd = Math.min(bufEnd, endOffset);\u000a        /* sometimes sourcebuffer.remove() does not flush\u000a          the exact expected time range.\u000a          to avoid rounding issues/infinite loop,\u000a          only flush buffer range of length greater than 500ms.\u000a        */\u000a\u000a        if (Math.min(removeEnd, bufEnd) - removeStart > 0.5) {\u000a          var currentTime = 'null';\u000a\u000a          if (this.media) {\u000a            currentTime = this.media.currentTime.toString();\u000a          }\u000a\u000a          logger["logger"].log("sb remove " + type + " [" + removeStart + "," + removeEnd + "], of [" + bufStart + "," + bufEnd + "], pos:" + currentTime);\u000a          sb.remove(removeStart, removeEnd);\u000a          return true;\u000a        }\u000a      }\u000a    } catch (error) {\u000a      logger["logger"].warn('removeBufferRange failed', error);\u000a    }\u000a\u000a    return false;\u000a  };\u000a\u000a  return BufferController;\u000a}(event_handler);\u000a\u000a/* harmony default export */ var buffer_controller = (buffer_controller_BufferController);\u000a// CONCATENATED MODULE: ./src/controller/cap-level-controller.js\u000afunction cap_level_controller_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction cap_level_controller_createClass(Constructor, protoProps, staticProps) { if (protoProps) cap_level_controller_defineProperties(Constructor.prototype, protoProps); if (staticProps) cap_level_controller_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000afunction cap_level_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * cap stream level to media size dimension controller\u000a*/\u000a\u000a\u000a\u000avar cap_level_controller_CapLevelController = /*#__PURE__*/function (_EventHandler) {\u000a  cap_level_controller_inheritsLoose(CapLevelController, _EventHandler);\u000a\u000a  function CapLevelController(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].FPS_DROP_LEVEL_CAPPING, events["default"].MEDIA_ATTACHING, events["default"].MANIFEST_PARSED, events["default"].LEVELS_UPDATED, events["default"].BUFFER_CODECS, events["default"].MEDIA_DETACHING) || this;\u000a    _this.autoLevelCapping = Number.POSITIVE_INFINITY;\u000a    _this.firstLevel = null;\u000a    _this.levels = [];\u000a    _this.media = null;\u000a    _this.restrictedLevels = [];\u000a    _this.timer = null;\u000a    _this.clientRect = null;\u000a    return _this;\u000a  }\u000a\u000a  var _proto = CapLevelController.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    if (this.hls.config.capLevelToPlayerSize) {\u000a      this.media = null;\u000a      this.clientRect = null;\u000a      this.stopCapping();\u000a    }\u000a  };\u000a\u000a  _proto.onFpsDropLevelCapping = function onFpsDropLevelCapping(data) {\u000a    // Don't add a restricted level more than once\u000a    if (CapLevelController.isLevelAllowed(data.droppedLevel, this.restrictedLevels)) {\u000a      this.restrictedLevels.push(data.droppedLevel);\u000a    }\u000a  };\u000a\u000a  _proto.onMediaAttaching = function onMediaAttaching(data) {\u000a    this.media = data.media instanceof window.HTMLVideoElement ? data.media : null;\u000a  };\u000a\u000a  _proto.onManifestParsed = function onManifestParsed(data) {\u000a    var hls = this.hls;\u000a    this.restrictedLevels = [];\u000a    this.levels = data.levels;\u000a    this.firstLevel = data.firstLevel;\u000a\u000a    if (hls.config.capLevelToPlayerSize && data.video) {\u000a      // Start capping immediately if the manifest has signaled video codecs\u000a      this.startCapping();\u000a    }\u000a  } // Only activate capping when playing a video stream; otherwise, multi-bitrate audio-only streams will be restricted\u000a  // to the first level\u000a  ;\u000a\u000a  _proto.onBufferCodecs = function onBufferCodecs(data) {\u000a    var hls = this.hls;\u000a\u000a    if (hls.config.capLevelToPlayerSize && data.video) {\u000a      // If the manifest did not signal a video codec capping has been deferred until we're certain video is present\u000a      this.startCapping();\u000a    }\u000a  };\u000a\u000a  _proto.onLevelsUpdated = function onLevelsUpdated(data) {\u000a    this.levels = data.levels;\u000a  };\u000a\u000a  _proto.onMediaDetaching = function onMediaDetaching() {\u000a    this.stopCapping();\u000a  };\u000a\u000a  _proto.detectPlayerSize = function detectPlayerSize() {\u000a    if (this.media) {\u000a      var levelsLength = this.levels ? this.levels.length : 0;\u000a\u000a      if (levelsLength) {\u000a        var hls = this.hls;\u000a        hls.autoLevelCapping = this.getMaxLevel(levelsLength - 1);\u000a\u000a        if (hls.autoLevelCapping > this.autoLevelCapping) {\u000a          // if auto level capping has a higher value for the previous one, flush the buffer using nextLevelSwitch\u000a          // usually happen when the user go to the fullscreen mode.\u000a          hls.streamController.nextLevelSwitch();\u000a        }\u000a\u000a        this.autoLevelCapping = hls.autoLevelCapping;\u000a      }\u000a    }\u000a  }\u000a  /*\u000a  * returns level should be the one with the dimensions equal or greater than the media (player) dimensions (so the video will be downscaled)\u000a  */\u000a  ;\u000a\u000a  _proto.getMaxLevel = function getMaxLevel(capLevelIndex) {\u000a    var _this2 = this;\u000a\u000a    if (!this.levels) {\u000a      return -1;\u000a    }\u000a\u000a    var validLevels = this.levels.filter(function (level, index) {\u000a      return CapLevelController.isLevelAllowed(index, _this2.restrictedLevels) && index <= capLevelIndex;\u000a    });\u000a    this.clientRect = null;\u000a    return CapLevelController.getMaxLevelByMediaSize(validLevels, this.mediaWidth, this.mediaHeight);\u000a  };\u000a\u000a  _proto.startCapping = function startCapping() {\u000a    if (this.timer) {\u000a      // Don't reset capping if started twice; this can happen if the manifest signals a video codec\u000a      return;\u000a    }\u000a\u000a    this.autoLevelCapping = Number.POSITIVE_INFINITY;\u000a    this.hls.firstLevel = this.getMaxLevel(this.firstLevel);\u000a    clearInterval(this.timer);\u000a    this.timer = setInterval(this.detectPlayerSize.bind(this), 1000);\u000a    this.detectPlayerSize();\u000a  };\u000a\u000a  _proto.stopCapping = function stopCapping() {\u000a    this.restrictedLevels = [];\u000a    this.firstLevel = null;\u000a    this.autoLevelCapping = Number.POSITIVE_INFINITY;\u000a\u000a    if (this.timer) {\u000a      this.timer = clearInterval(this.timer);\u000a      this.timer = null;\u000a    }\u000a  };\u000a\u000a  _proto.getDimensions = function getDimensions() {\u000a    if (this.clientRect) {\u000a      return this.clientRect;\u000a    }\u000a\u000a    var media = this.media;\u000a    var boundsRect = {\u000a      width: 0,\u000a      height: 0\u000a    };\u000a\u000a    if (media) {\u000a      var clientRect = media.getBoundingClientRect();\u000a      boundsRect.width = clientRect.width;\u000a      boundsRect.height = clientRect.height;\u000a\u000a      if (!boundsRect.width && !boundsRect.height) {\u000a        // When the media element has no width or height (equivalent to not being in the DOM),\u000a        // then use its width and height attributes (media.width, media.height)\u000a        boundsRect.width = clientRect.right - clientRect.left || media.width || 0;\u000a        boundsRect.height = clientRect.bottom - clientRect.top || media.height || 0;\u000a      }\u000a    }\u000a\u000a    this.clientRect = boundsRect;\u000a    return boundsRect;\u000a  };\u000a\u000a  CapLevelController.isLevelAllowed = function isLevelAllowed(level, restrictedLevels) {\u000a    if (restrictedLevels === void 0) {\u000a      restrictedLevels = [];\u000a    }\u000a\u000a    return restrictedLevels.indexOf(level) === -1;\u000a  };\u000a\u000a  CapLevelController.getMaxLevelByMediaSize = function getMaxLevelByMediaSize(levels, width, height) {\u000a    if (!levels || levels && !levels.length) {\u000a      return -1;\u000a    } // Levels can have the same dimensions but differing bandwidths - since levels are ordered, we can look to the next\u000a    // to determine whether we've chosen the greatest bandwidth for the media's dimensions\u000a\u000a\u000a    var atGreatestBandiwdth = function atGreatestBandiwdth(curLevel, nextLevel) {\u000a      if (!nextLevel) {\u000a        return true;\u000a      }\u000a\u000a      return curLevel.width !== nextLevel.width || curLevel.height !== nextLevel.height;\u000a    }; // If we run through the loop without breaking, the media's dimensions are greater than every level, so default to\u000a    // the max level\u000a\u000a\u000a    var maxLevelIndex = levels.length - 1;\u000a\u000a    for (var i = 0; i < levels.length; i += 1) {\u000a      var level = levels[i];\u000a\u000a      if ((level.width >= width || level.height >= height) && atGreatestBandiwdth(level, levels[i + 1])) {\u000a        maxLevelIndex = i;\u000a        break;\u000a      }\u000a    }\u000a\u000a    return maxLevelIndex;\u000a  };\u000a\u000a  cap_level_controller_createClass(CapLevelController, [{\u000a    key: "mediaWidth",\u000a    get: function get() {\u000a      return this.getDimensions().width * CapLevelController.contentScaleFactor;\u000a    }\u000a  }, {\u000a    key: "mediaHeight",\u000a    get: function get() {\u000a      return this.getDimensions().height * CapLevelController.contentScaleFactor;\u000a    }\u000a  }], [{\u000a    key: "contentScaleFactor",\u000a    get: function get() {\u000a      var pixelRatio = 1;\u000a\u000a      try {\u000a        pixelRatio = window.devicePixelRatio;\u000a      } catch (e) {}\u000a\u000a      return pixelRatio;\u000a    }\u000a  }]);\u000a\u000a  return CapLevelController;\u000a}(event_handler);\u000a\u000a/* harmony default export */ var cap_level_controller = (cap_level_controller_CapLevelController);\u000a// CONCATENATED MODULE: ./src/controller/fps-controller.js\u000afunction fps_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * FPS Controller\u000a*/\u000a\u000a\u000a\u000avar fps_controller_window = window,\u000a    fps_controller_performance = fps_controller_window.performance;\u000a\u000avar fps_controller_FPSController = /*#__PURE__*/function (_EventHandler) {\u000a  fps_controller_inheritsLoose(FPSController, _EventHandler);\u000a\u000a  function FPSController(hls) {\u000a    return _EventHandler.call(this, hls, events["default"].MEDIA_ATTACHING) || this;\u000a  }\u000a\u000a  var _proto = FPSController.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    if (this.timer) {\u000a      clearInterval(this.timer);\u000a    }\u000a\u000a    this.isVideoPlaybackQualityAvailable = false;\u000a  };\u000a\u000a  _proto.onMediaAttaching = function onMediaAttaching(data) {\u000a    var config = this.hls.config;\u000a\u000a    if (config.capLevelOnFPSDrop) {\u000a      var video = this.video = data.media instanceof window.HTMLVideoElement ? data.media : null;\u000a\u000a      if (typeof video.getVideoPlaybackQuality === 'function') {\u000a        this.isVideoPlaybackQualityAvailable = true;\u000a      }\u000a\u000a      clearInterval(this.timer);\u000a      this.timer = setInterval(this.checkFPSInterval.bind(this), config.fpsDroppedMonitoringPeriod);\u000a    }\u000a  };\u000a\u000a  _proto.checkFPS = function checkFPS(video, decodedFrames, droppedFrames) {\u000a    var currentTime = fps_controller_performance.now();\u000a\u000a    if (decodedFrames) {\u000a      if (this.lastTime) {\u000a        var currentPeriod = currentTime - this.lastTime,\u000a            currentDropped = droppedFrames - this.lastDroppedFrames,\u000a            currentDecoded = decodedFrames - this.lastDecodedFrames,\u000a            droppedFPS = 1000 * currentDropped / currentPeriod,\u000a            hls = this.hls;\u000a        hls.trigger(events["default"].FPS_DROP, {\u000a          currentDropped: currentDropped,\u000a          currentDecoded: currentDecoded,\u000a          totalDroppedFrames: droppedFrames\u000a        });\u000a\u000a        if (droppedFPS > 0) {\u000a          // logger.log('checkFPS : droppedFPS/decodedFPS:' + droppedFPS/(1000 * currentDecoded / currentPeriod));\u000a          if (currentDropped > hls.config.fpsDroppedMonitoringThreshold * currentDecoded) {\u000a            var currentLevel = hls.currentLevel;\u000a            logger["logger"].warn('drop FPS ratio greater than max allowed value for currentLevel: ' + currentLevel);\u000a\u000a            if (currentLevel > 0 && (hls.autoLevelCapping === -1 || hls.autoLevelCapping >= currentLevel)) {\u000a              currentLevel = currentLevel - 1;\u000a              hls.trigger(events["default"].FPS_DROP_LEVEL_CAPPING, {\u000a                level: currentLevel,\u000a                droppedLevel: hls.currentLevel\u000a              });\u000a              hls.autoLevelCapping = currentLevel;\u000a              hls.streamController.nextLevelSwitch();\u000a            }\u000a          }\u000a        }\u000a      }\u000a\u000a      this.lastTime = currentTime;\u000a      this.lastDroppedFrames = droppedFrames;\u000a      this.lastDecodedFrames = decodedFrames;\u000a    }\u000a  };\u000a\u000a  _proto.checkFPSInterval = function checkFPSInterval() {\u000a    var video = this.video;\u000a\u000a    if (video) {\u000a      if (this.isVideoPlaybackQualityAvailable) {\u000a        var videoPlaybackQuality = video.getVideoPlaybackQuality();\u000a        this.checkFPS(video, videoPlaybackQuality.totalVideoFrames, videoPlaybackQuality.droppedVideoFrames);\u000a      } else {\u000a        this.checkFPS(video, video.webkitDecodedFrameCount, video.webkitDroppedFrameCount);\u000a      }\u000a    }\u000a  };\u000a\u000a  return FPSController;\u000a}(event_handler);\u000a\u000a/* harmony default export */ var fps_controller = (fps_controller_FPSController);\u000a// CONCATENATED MODULE: ./src/utils/xhr-loader.js\u000a/**\u000a * XHR based logger\u000a*/\u000a\u000a\u000avar xhr_loader_XhrLoader = /*#__PURE__*/function () {\u000a  function XhrLoader(config) {\u000a    if (config && config.xhrSetup) {\u000a      this.xhrSetup = config.xhrSetup;\u000a    }\u000a  }\u000a\u000a  var _proto = XhrLoader.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    this.abort();\u000a    this.loader = null;\u000a  };\u000a\u000a  _proto.abort = function abort() {\u000a    var loader = this.loader;\u000a\u000a    if (loader && loader.readyState !== 4) {\u000a      this.stats.aborted = true;\u000a      loader.abort();\u000a    }\u000a\u000a    window.clearTimeout(this.requestTimeout);\u000a    this.requestTimeout = null;\u000a    window.clearTimeout(this.retryTimeout);\u000a    this.retryTimeout = null;\u000a  };\u000a\u000a  _proto.load = function load(context, config, callbacks) {\u000a    this.context = context;\u000a    this.config = config;\u000a    this.callbacks = callbacks;\u000a    this.stats = {\u000a      trequest: window.performance.now(),\u000a      retry: 0\u000a    };\u000a    this.retryDelay = config.retryDelay;\u000a    this.loadInternal();\u000a  };\u000a\u000a  _proto.loadInternal = function loadInternal() {\u000a    var xhr,\u000a        context = this.context;\u000a    xhr = this.loader = new window.XMLHttpRequest();\u000a    var stats = this.stats;\u000a    stats.tfirst = 0;\u000a    stats.loaded = 0;\u000a    var xhrSetup = this.xhrSetup;\u000a\u000a    try {\u000a      if (xhrSetup) {\u000a        try {\u000a          xhrSetup(xhr, context.url);\u000a        } catch (e) {\u000a          // fix xhrSetup: (xhr, url) => {xhr.setRequestHeader("Content-Language", "test");}\u000a          // not working, as xhr.setRequestHeader expects xhr.readyState === OPEN\u000a          xhr.open('GET', context.url, true);\u000a          xhrSetup(xhr, context.url);\u000a        }\u000a      }\u000a\u000a      if (!xhr.readyState) {\u000a        xhr.open('GET', context.url, true);\u000a      }\u000a    } catch (e) {\u000a      // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS\u000a      this.callbacks.onError({\u000a        code: xhr.status,\u000a        text: e.message\u000a      }, context, xhr);\u000a      return;\u000a    }\u000a\u000a    if (context.rangeEnd) {\u000a      xhr.setRequestHeader('Range', 'bytes=' + context.rangeStart + '-' + (context.rangeEnd - 1));\u000a    }\u000a\u000a    xhr.onreadystatechange = this.readystatechange.bind(this);\u000a    xhr.onprogress = this.loadprogress.bind(this);\u000a    xhr.responseType = context.responseType; // setup timeout before we perform request\u000a\u000a    this.requestTimeout = window.setTimeout(this.loadtimeout.bind(this), this.config.timeout);\u000a    xhr.send();\u000a  };\u000a\u000a  _proto.readystatechange = function readystatechange(event) {\u000a    var xhr = event.currentTarget,\u000a        readyState = xhr.readyState,\u000a        stats = this.stats,\u000a        context = this.context,\u000a        config = this.config; // don't proceed if xhr has been aborted\u000a\u000a    if (stats.aborted) {\u000a      return;\u000a    } // >= HEADERS_RECEIVED\u000a\u000a\u000a    if (readyState >= 2) {\u000a      // clear xhr timeout and rearm it if readyState less than 4\u000a      window.clearTimeout(this.requestTimeout);\u000a\u000a      if (stats.tfirst === 0) {\u000a        stats.tfirst = Math.max(window.performance.now(), stats.trequest);\u000a      }\u000a\u000a      if (readyState === 4) {\u000a        var status = xhr.status; // http status between 200 to 299 are all successful\u000a\u000a        if (status >= 200 && status < 300) {\u000a          stats.tload = Math.max(stats.tfirst, window.performance.now());\u000a          var data, len;\u000a\u000a          if (context.responseType === 'arraybuffer') {\u000a            data = xhr.response;\u000a            len = data.byteLength;\u000a          } else {\u000a            data = xhr.responseText;\u000a            len = data.length;\u000a          }\u000a\u000a          stats.loaded = stats.total = len;\u000a          var response = {\u000a            url: xhr.responseURL,\u000a            data: data\u000a          };\u000a          this.callbacks.onSuccess(response, stats, context, xhr);\u000a        } else {\u000a          // if max nb of retries reached or if http status between 400 and 499 (such error cannot be recovered, retrying is useless), return error\u000a          if (stats.retry >= config.maxRetry || status >= 400 && status < 499) {\u000a            logger["logger"].error(status + " while loading " + context.url);\u000a            this.callbacks.onError({\u000a              code: status,\u000a              text: xhr.statusText\u000a            }, context, xhr);\u000a          } else {\u000a            // retry\u000a            logger["logger"].warn(status + " while loading " + context.url + ", retrying in " + this.retryDelay + "..."); // aborts and resets internal state\u000a\u000a            this.destroy(); // schedule retry\u000a\u000a            this.retryTimeout = window.setTimeout(this.loadInternal.bind(this), this.retryDelay); // set exponential backoff\u000a\u000a            this.retryDelay = Math.min(2 * this.retryDelay, config.maxRetryDelay);\u000a            stats.retry++;\u000a          }\u000a        }\u000a      } else {\u000a        // readyState >= 2 AND readyState !==4 (readyState = HEADERS_RECEIVED || LOADING) rearm timeout as xhr not finished yet\u000a        this.requestTimeout = window.setTimeout(this.loadtimeout.bind(this), config.timeout);\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.loadtimeout = function loadtimeout() {\u000a    logger["logger"].warn("timeout while loading " + this.context.url);\u000a    this.callbacks.onTimeout(this.stats, this.context, null);\u000a  };\u000a\u000a  _proto.loadprogress = function loadprogress(event) {\u000a    var xhr = event.currentTarget,\u000a        stats = this.stats;\u000a    stats.loaded = event.loaded;\u000a\u000a    if (event.lengthComputable) {\u000a      stats.total = event.total;\u000a    }\u000a\u000a    var onProgress = this.callbacks.onProgress;\u000a\u000a    if (onProgress) {\u000a      // third arg is to provide on progress data\u000a      onProgress(stats, this.context, null, xhr);\u000a    }\u000a  };\u000a\u000a  return XhrLoader;\u000a}();\u000a\u000a/* harmony default export */ var xhr_loader = (xhr_loader_XhrLoader);\u000a// CONCATENATED MODULE: ./src/controller/audio-track-controller.js\u000afunction audio_track_controller_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction audio_track_controller_createClass(Constructor, protoProps, staticProps) { if (protoProps) audio_track_controller_defineProperties(Constructor.prototype, protoProps); if (staticProps) audio_track_controller_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000afunction audio_track_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a\u000a\u000a\u000a\u000a/**\u000a * @class AudioTrackController\u000a * @implements {EventHandler}\u000a *\u000a * Handles main manifest and audio-track metadata loaded,\u000a * owns and exposes the selectable audio-tracks data-models.\u000a *\u000a * Exposes internal interface to select available audio-tracks.\u000a *\u000a * Handles errors on loading audio-track playlists. Manages fallback mechanism\u000a * with redundants tracks (group-IDs).\u000a *\u000a * Handles level-loading and group-ID switches for video (fallback on video levels),\u000a * and eventually adapts the audio-track group-ID to match.\u000a *\u000a * @fires AUDIO_TRACK_LOADING\u000a * @fires AUDIO_TRACK_SWITCHING\u000a * @fires AUDIO_TRACKS_UPDATED\u000a * @fires ERROR\u000a *\u000a */\u000a\u000avar audio_track_controller_AudioTrackController = /*#__PURE__*/function (_TaskLoop) {\u000a  audio_track_controller_inheritsLoose(AudioTrackController, _TaskLoop);\u000a\u000a  function AudioTrackController(hls) {\u000a    var _this;\u000a\u000a    _this = _TaskLoop.call(this, hls, events["default"].MANIFEST_LOADING, events["default"].MANIFEST_PARSED, events["default"].AUDIO_TRACK_LOADED, events["default"].AUDIO_TRACK_SWITCHED, events["default"].LEVEL_LOADED, events["default"].ERROR) || this;\u000a    /**\u000a     * @private\u000a     * Currently selected index in `tracks`\u000a     * @member {number} trackId\u000a     */\u000a\u000a    _this._trackId = -1;\u000a    /**\u000a     * @private\u000a     * If should select tracks according to default track attribute\u000a     * @member {boolean} _selectDefaultTrack\u000a     */\u000a\u000a    _this._selectDefaultTrack = true;\u000a    /**\u000a     * @public\u000a     * All tracks available\u000a     * @member {AudioTrack[]}\u000a     */\u000a\u000a    _this.tracks = [];\u000a    /**\u000a     * @public\u000a     * List of blacklisted audio track IDs (that have caused failure)\u000a     * @member {number[]}\u000a     */\u000a\u000a    _this.trackIdBlacklist = Object.create(null);\u000a    /**\u000a     * @public\u000a     * The currently running group ID for audio\u000a     * (we grab this on manifest-parsed and new level-loaded)\u000a     * @member {string}\u000a     */\u000a\u000a    _this.audioGroupId = null;\u000a    return _this;\u000a  }\u000a  /**\u000a   * Reset audio tracks on new manifest loading.\u000a   */\u000a\u000a\u000a  var _proto = AudioTrackController.prototype;\u000a\u000a  _proto.onManifestLoading = function onManifestLoading() {\u000a    this.tracks = [];\u000a    this._trackId = -1;\u000a    this._selectDefaultTrack = true;\u000a  }\u000a  /**\u000a   * Store tracks data from manifest parsed data.\u000a   *\u000a   * Trigger AUDIO_TRACKS_UPDATED event.\u000a   *\u000a   * @param {*} data\u000a   */\u000a  ;\u000a\u000a  _proto.onManifestParsed = function onManifestParsed(data) {\u000a    var tracks = this.tracks = data.audioTracks || [];\u000a    this.hls.trigger(events["default"].AUDIO_TRACKS_UPDATED, {\u000a      audioTracks: tracks\u000a    });\u000a\u000a    this._selectAudioGroup(this.hls.nextLoadLevel);\u000a  }\u000a  /**\u000a   * Store track details of loaded track in our data-model.\u000a   *\u000a   * Set-up metadata update interval task for live-mode streams.\u000a   *\u000a   * @param {*} data\u000a   */\u000a  ;\u000a\u000a  _proto.onAudioTrackLoaded = function onAudioTrackLoaded(data) {\u000a    if (data.id >= this.tracks.length) {\u000a      logger["logger"].warn('Invalid audio track id:', data.id);\u000a      return;\u000a    }\u000a\u000a    logger["logger"].log("audioTrack " + data.id + " loaded");\u000a    this.tracks[data.id].details = data.details; // check if current playlist is a live playlist\u000a    // and if we have already our reload interval setup\u000a\u000a    if (data.details.live && !this.hasInterval()) {\u000a      // if live playlist we will have to reload it periodically\u000a      // set reload period to playlist target duration\u000a      var updatePeriodMs = data.details.targetduration * 1000;\u000a      this.setInterval(updatePeriodMs);\u000a    }\u000a\u000a    if (!data.details.live && this.hasInterval()) {\u000a      // playlist is not live and timer is scheduled: cancel it\u000a      this.clearInterval();\u000a    }\u000a  }\u000a  /**\u000a   * Update the internal group ID to any audio-track we may have set manually\u000a   * or because of a failure-handling fallback.\u000a   *\u000a   * Quality-levels should update to that group ID in this case.\u000a   *\u000a   * @param {*} data\u000a   */\u000a  ;\u000a\u000a  _proto.onAudioTrackSwitched = function onAudioTrackSwitched(data) {\u000a    var audioGroupId = this.tracks[data.id].groupId;\u000a\u000a    if (audioGroupId && this.audioGroupId !== audioGroupId) {\u000a      this.audioGroupId = audioGroupId;\u000a    }\u000a  }\u000a  /**\u000a   * When a level gets loaded, if it has redundant audioGroupIds (in the same ordinality as it's redundant URLs)\u000a   * we are setting our audio-group ID internally to the one set, if it is different from the group ID currently set.\u000a   *\u000a   * If group-ID got update, we re-select the appropriate audio-track with this group-ID matching the currently\u000a   * selected one (based on NAME property).\u000a   *\u000a   * @param {*} data\u000a   */\u000a  ;\u000a\u000a  _proto.onLevelLoaded = function onLevelLoaded(data) {\u000a    this._selectAudioGroup(data.level);\u000a  }\u000a  /**\u000a   * Handle network errors loading audio track manifests\u000a   * and also pausing on any netwok errors.\u000a   *\u000a   * @param {ErrorEventData} data\u000a   */\u000a  ;\u000a\u000a  _proto.onError = function onError(data) {\u000a    // Only handle network errors\u000a    if (data.type !== errors["ErrorTypes"].NETWORK_ERROR) {\u000a      return;\u000a    } // If fatal network error, cancel update task\u000a\u000a\u000a    if (data.fatal) {\u000a      this.clearInterval();\u000a    } // If not an audio-track loading error don't handle further\u000a\u000a\u000a    if (data.details !== errors["ErrorDetails"].AUDIO_TRACK_LOAD_ERROR) {\u000a      return;\u000a    }\u000a\u000a    logger["logger"].warn('Network failure on audio-track id:', data.context.id);\u000a\u000a    this._handleLoadError();\u000a  }\u000a  /**\u000a   * @type {AudioTrack[]} Audio-track list we own\u000a   */\u000a  ;\u000a\u000a  /**\u000a   * @private\u000a   * @param {number} newId\u000a   */\u000a  _proto._setAudioTrack = function _setAudioTrack(newId) {\u000a    // noop on same audio track id as already set\u000a    if (this._trackId === newId && this.tracks[this._trackId].details) {\u000a      logger["logger"].debug('Same id as current audio-track passed, and track details available -> no-op');\u000a      return;\u000a    } // check if level idx is valid\u000a\u000a\u000a    if (newId < 0 || newId >= this.tracks.length) {\u000a      logger["logger"].warn('Invalid id passed to audio-track controller');\u000a      return;\u000a    }\u000a\u000a    var audioTrack = this.tracks[newId];\u000a    logger["logger"].log("Now switching to audio-track index " + newId); // stopping live reloading timer if any\u000a\u000a    this.clearInterval();\u000a    this._trackId = newId;\u000a    var url = audioTrack.url,\u000a        type = audioTrack.type,\u000a        id = audioTrack.id;\u000a    this.hls.trigger(events["default"].AUDIO_TRACK_SWITCHING, {\u000a      id: id,\u000a      type: type,\u000a      url: url\u000a    });\u000a\u000a    this._loadTrackDetailsIfNeeded(audioTrack);\u000a  }\u000a  /**\u000a   * @override\u000a   */\u000a  ;\u000a\u000a  _proto.doTick = function doTick() {\u000a    this._updateTrack(this._trackId);\u000a  }\u000a  /**\u000a   * @param levelId\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._selectAudioGroup = function _selectAudioGroup(levelId) {\u000a    var levelInfo = this.hls.levels[levelId];\u000a\u000a    if (!levelInfo || !levelInfo.audioGroupIds) {\u000a      return;\u000a    }\u000a\u000a    var audioGroupId = levelInfo.audioGroupIds[levelInfo.urlId];\u000a\u000a    if (this.audioGroupId !== audioGroupId) {\u000a      this.audioGroupId = audioGroupId;\u000a\u000a      this._selectInitialAudioTrack();\u000a    }\u000a  }\u000a  /**\u000a   * Select initial track\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._selectInitialAudioTrack = function _selectInitialAudioTrack() {\u000a    var _this2 = this;\u000a\u000a    var tracks = this.tracks;\u000a\u000a    if (!tracks.length) {\u000a      return;\u000a    }\u000a\u000a    var currentAudioTrack = this.tracks[this._trackId];\u000a    var name = null;\u000a\u000a    if (currentAudioTrack) {\u000a      name = currentAudioTrack.name;\u000a    } // Pre-select default tracks if there are any\u000a\u000a\u000a    if (this._selectDefaultTrack) {\u000a      var defaultTracks = tracks.filter(function (track) {\u000a        return track.default;\u000a      });\u000a\u000a      if (defaultTracks.length) {\u000a        tracks = defaultTracks;\u000a      } else {\u000a        logger["logger"].warn('No default audio tracks defined');\u000a      }\u000a    }\u000a\u000a    var trackFound = false;\u000a\u000a    var traverseTracks = function traverseTracks() {\u000a      // Select track with right group ID\u000a      tracks.forEach(function (track) {\u000a        if (trackFound) {\u000a          return;\u000a        } // We need to match the (pre-)selected group ID\u000a        // and the NAME of the current track.\u000a\u000a\u000a        if ((!_this2.audioGroupId || track.groupId === _this2.audioGroupId) && (!name || name === track.name)) {\u000a          // If there was a previous track try to stay with the same `NAME`.\u000a          // It should be unique across tracks of same group, and consistent through redundant track groups.\u000a          _this2._setAudioTrack(track.id);\u000a\u000a          trackFound = true;\u000a        }\u000a      });\u000a    };\u000a\u000a    traverseTracks();\u000a\u000a    if (!trackFound) {\u000a      name = null;\u000a      traverseTracks();\u000a    }\u000a\u000a    if (!trackFound) {\u000a      logger["logger"].error("No track found for running audio group-ID: " + this.audioGroupId);\u000a      this.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].MEDIA_ERROR,\u000a        details: errors["ErrorDetails"].AUDIO_TRACK_LOAD_ERROR,\u000a        fatal: true\u000a      });\u000a    }\u000a  }\u000a  /**\u000a   * @private\u000a   * @param {AudioTrack} audioTrack\u000a   * @returns {boolean}\u000a   */\u000a  ;\u000a\u000a  _proto._needsTrackLoading = function _needsTrackLoading(audioTrack) {\u000a    var details = audioTrack.details,\u000a        url = audioTrack.url;\u000a\u000a    if (!details || details.live) {\u000a      // check if we face an audio track embedded in main playlist (audio track without URI attribute)\u000a      return !!url;\u000a    }\u000a\u000a    return false;\u000a  }\u000a  /**\u000a   * @private\u000a   * @param {AudioTrack} audioTrack\u000a   */\u000a  ;\u000a\u000a  _proto._loadTrackDetailsIfNeeded = function _loadTrackDetailsIfNeeded(audioTrack) {\u000a    if (this._needsTrackLoading(audioTrack)) {\u000a      var url = audioTrack.url,\u000a          id = audioTrack.id; // track not retrieved yet, or live playlist we need to (re)load it\u000a\u000a      logger["logger"].log("loading audio-track playlist for id: " + id);\u000a      this.hls.trigger(events["default"].AUDIO_TRACK_LOADING, {\u000a        url: url,\u000a        id: id\u000a      });\u000a    }\u000a  }\u000a  /**\u000a   * @private\u000a   * @param {number} newId\u000a   */\u000a  ;\u000a\u000a  _proto._updateTrack = function _updateTrack(newId) {\u000a    // check if level idx is valid\u000a    if (newId < 0 || newId >= this.tracks.length) {\u000a      return;\u000a    } // stopping live reloading timer if any\u000a\u000a\u000a    this.clearInterval();\u000a    this._trackId = newId;\u000a    logger["logger"].log("trying to update audio-track " + newId);\u000a    var audioTrack = this.tracks[newId];\u000a\u000a    this._loadTrackDetailsIfNeeded(audioTrack);\u000a  }\u000a  /**\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._handleLoadError = function _handleLoadError() {\u000a    // First, let's black list current track id\u000a    this.trackIdBlacklist[this._trackId] = true; // Let's try to fall back on a functional audio-track with the same group ID\u000a\u000a    var previousId = this._trackId;\u000a    var _this$tracks$previous = this.tracks[previousId],\u000a        name = _this$tracks$previous.name,\u000a        language = _this$tracks$previous.language,\u000a        groupId = _this$tracks$previous.groupId;\u000a    logger["logger"].warn("Loading failed on audio track id: " + previousId + ", group-id: " + groupId + ", name/language: \u005c"" + name + "\u005c" / \u005c"" + language + "\u005c""); // Find a non-blacklisted track ID with the same NAME\u000a    // At least a track that is not blacklisted, thus on another group-ID.\u000a\u000a    var newId = previousId;\u000a\u000a    for (var i = 0; i < this.tracks.length; i++) {\u000a      if (this.trackIdBlacklist[i]) {\u000a        continue;\u000a      }\u000a\u000a      var newTrack = this.tracks[i];\u000a\u000a      if (newTrack.name === name) {\u000a        newId = i;\u000a        break;\u000a      }\u000a    }\u000a\u000a    if (newId === previousId) {\u000a      logger["logger"].warn("No fallback audio-track found for name/language: \u005c"" + name + "\u005c" / \u005c"" + language + "\u005c"");\u000a      return;\u000a    }\u000a\u000a    logger["logger"].log('Attempting audio-track fallback id:', newId, 'group-id:', this.tracks[newId].groupId);\u000a\u000a    this._setAudioTrack(newId);\u000a  };\u000a\u000a  audio_track_controller_createClass(AudioTrackController, [{\u000a    key: "audioTracks",\u000a    get: function get() {\u000a      return this.tracks;\u000a    }\u000a    /**\u000a     * @type {number} Index into audio-tracks list of currently selected track.\u000a     */\u000a\u000a  }, {\u000a    key: "audioTrack",\u000a    get: function get() {\u000a      return this._trackId;\u000a    }\u000a    /**\u000a     * Select current track by index\u000a     */\u000a    ,\u000a    set: function set(newId) {\u000a      this._setAudioTrack(newId); // If audio track is selected from API then don't choose from the manifest default track\u000a\u000a\u000a      this._selectDefaultTrack = false;\u000a    }\u000a  }]);\u000a\u000a  return AudioTrackController;\u000a}(TaskLoop);\u000a\u000a/* harmony default export */ var audio_track_controller = (audio_track_controller_AudioTrackController);\u000a// CONCATENATED MODULE: ./src/controller/audio-stream-controller.js\u000a\u000a\u000a\u000a\u000afunction audio_stream_controller_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction audio_stream_controller_createClass(Constructor, protoProps, staticProps) { if (protoProps) audio_stream_controller_defineProperties(Constructor.prototype, protoProps); if (staticProps) audio_stream_controller_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000afunction audio_stream_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/*\u000a * Audio Stream Controller\u000a*/\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000avar audio_stream_controller_window = window,\u000a    audio_stream_controller_performance = audio_stream_controller_window.performance;\u000avar audio_stream_controller_TICK_INTERVAL = 100; // how often to tick in ms\u000a\u000avar audio_stream_controller_AudioStreamController = /*#__PURE__*/function (_BaseStreamController) {\u000a  audio_stream_controller_inheritsLoose(AudioStreamController, _BaseStreamController);\u000a\u000a  function AudioStreamController(hls, fragmentTracker) {\u000a    var _this;\u000a\u000a    _this = _BaseStreamController.call(this, hls, events["default"].MEDIA_ATTACHED, events["default"].MEDIA_DETACHING, events["default"].AUDIO_TRACKS_UPDATED, events["default"].AUDIO_TRACK_SWITCHING, events["default"].AUDIO_TRACK_LOADED, events["default"].KEY_LOADED, events["default"].FRAG_LOADED, events["default"].FRAG_PARSING_INIT_SEGMENT, events["default"].FRAG_PARSING_DATA, events["default"].FRAG_PARSED, events["default"].ERROR, events["default"].BUFFER_RESET, events["default"].BUFFER_CREATED, events["default"].BUFFER_APPENDED, events["default"].BUFFER_FLUSHED, events["default"].INIT_PTS_FOUND) || this;\u000a    _this.fragmentTracker = fragmentTracker;\u000a    _this.config = hls.config;\u000a    _this.audioCodecSwap = false;\u000a    _this._state = State.STOPPED;\u000a    _this.initPTS = [];\u000a    _this.waitingFragment = null;\u000a    _this.videoTrackCC = null;\u000a    return _this;\u000a  } // Signal that video PTS was found\u000a\u000a\u000a  var _proto = AudioStreamController.prototype;\u000a\u000a  _proto.onInitPtsFound = function onInitPtsFound(data) {\u000a    var demuxerId = data.id,\u000a        cc = data.frag.cc,\u000a        initPTS = data.initPTS;\u000a\u000a    if (demuxerId === 'main') {\u000a      // Always update the new INIT PTS\u000a      // Can change due level switch\u000a      this.initPTS[cc] = initPTS;\u000a      this.videoTrackCC = cc;\u000a      logger["logger"].log("InitPTS for cc: " + cc + " found from video track: " + initPTS); // If we are waiting we need to demux/remux the waiting frag\u000a      // With the new initPTS\u000a\u000a      if (this.state === State.WAITING_INIT_PTS) {\u000a        this.tick();\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.startLoad = function startLoad(startPosition) {\u000a    if (this.tracks) {\u000a      var lastCurrentTime = this.lastCurrentTime;\u000a      this.stopLoad();\u000a      this.setInterval(audio_stream_controller_TICK_INTERVAL);\u000a      this.fragLoadError = 0;\u000a\u000a      if (lastCurrentTime > 0 && startPosition === -1) {\u000a        logger["logger"].log("audio:override startPosition with lastCurrentTime @" + lastCurrentTime.toFixed(3));\u000a        this.state = State.IDLE;\u000a      } else {\u000a        this.lastCurrentTime = this.startPosition ? this.startPosition : startPosition;\u000a        this.state = State.STARTING;\u000a      }\u000a\u000a      this.nextLoadPosition = this.startPosition = this.lastCurrentTime;\u000a      this.tick();\u000a    } else {\u000a      this.startPosition = startPosition;\u000a      this.state = State.STOPPED;\u000a    }\u000a  };\u000a\u000a  _proto.doTick = function doTick() {\u000a    var pos,\u000a        track,\u000a        trackDetails,\u000a        hls = this.hls,\u000a        config = hls.config; // logger.log('audioStream:' + this.state);\u000a\u000a    switch (this.state) {\u000a      case State.ERROR: // don't do anything in error state to avoid breaking further ...\u000a\u000a      case State.PAUSED: // don't do anything in paused state either ...\u000a\u000a      case State.BUFFER_FLUSHING:\u000a        break;\u000a\u000a      case State.STARTING:\u000a        this.state = State.WAITING_TRACK;\u000a        this.loadedmetadata = false;\u000a        break;\u000a\u000a      case State.IDLE:\u000a        var tracks = this.tracks; // audio tracks not received => exit loop\u000a\u000a        if (!tracks) {\u000a          break;\u000a        } // if video not attached AND\u000a        // start fragment already requested OR start frag prefetch disable\u000a        // exit loop\u000a        // => if media not attached but start frag prefetch is enabled and start frag not requested yet, we will not exit loop\u000a\u000a\u000a        if (!this.media && (this.startFragRequested || !config.startFragPrefetch)) {\u000a          break;\u000a        } // determine next candidate fragment to be loaded, based on current position and\u000a        //  end of buffer position\u000a        // if we have not yet loaded any fragment, start loading from start position\u000a\u000a\u000a        if (this.loadedmetadata) {\u000a          pos = this.media.currentTime;\u000a        } else {\u000a          pos = this.nextLoadPosition;\u000a\u000a          if (pos === undefined) {\u000a            break;\u000a          }\u000a        }\u000a\u000a        var media = this.mediaBuffer ? this.mediaBuffer : this.media;\u000a        var videoBuffer = this.videoBuffer ? this.videoBuffer : this.media;\u000a        var maxBufferHole = pos < config.maxBufferHole ? Math.max(MAX_START_GAP_JUMP, config.maxBufferHole) : config.maxBufferHole;\u000a        var bufferInfo = BufferHelper.bufferInfo(media, pos, maxBufferHole);\u000a        var mainBufferInfo = BufferHelper.bufferInfo(videoBuffer, pos, maxBufferHole);\u000a        var bufferLen = bufferInfo.len;\u000a        var bufferEnd = bufferInfo.end;\u000a        var fragPrevious = this.fragPrevious; // ensure we buffer at least config.maxBufferLength (default 30s) or config.maxMaxBufferLength (default: 600s)\u000a        // whichever is smaller.\u000a        // once we reach that threshold, don't buffer more than video (mainBufferInfo.len)\u000a\u000a        var maxConfigBuffer = Math.min(config.maxBufferLength, config.maxMaxBufferLength);\u000a        var maxBufLen = Math.max(maxConfigBuffer, mainBufferInfo.len);\u000a        var audioSwitch = this.audioSwitch;\u000a        var trackId = this.trackId; // if buffer length is less than maxBufLen try to load a new fragment\u000a\u000a        if ((bufferLen < maxBufLen || audioSwitch) && trackId < tracks.length) {\u000a          trackDetails = tracks[trackId].details; // if track info not retrieved yet, switch state and wait for track retrieval\u000a\u000a          if (typeof trackDetails === 'undefined') {\u000a            this.state = State.WAITING_TRACK;\u000a            break;\u000a          }\u000a\u000a          if (!audioSwitch && this._streamEnded(bufferInfo, trackDetails)) {\u000a            this.hls.trigger(events["default"].BUFFER_EOS, {\u000a              type: 'audio'\u000a            });\u000a            this.state = State.ENDED;\u000a            return;\u000a          } // find fragment index, contiguous with end of buffer position\u000a\u000a\u000a          var fragments = trackDetails.fragments,\u000a              fragLen = fragments.length,\u000a              start = fragments[0].start,\u000a              end = fragments[fragLen - 1].start + fragments[fragLen - 1].duration,\u000a              frag; // When switching audio track, reload audio as close as possible to currentTime\u000a\u000a          if (audioSwitch) {\u000a            if (trackDetails.live && !trackDetails.PTSKnown) {\u000a              logger["logger"].log('switching audiotrack, live stream, unknown PTS,load first fragment');\u000a              bufferEnd = 0;\u000a            } else {\u000a              bufferEnd = pos; // if currentTime (pos) is less than alt audio playlist start time, it means that alt audio is ahead of currentTime\u000a\u000a              if (trackDetails.PTSKnown && pos < start) {\u000a                // if everything is buffered from pos to start or if audio buffer upfront, let's seek to start\u000a                if (bufferInfo.end > start || bufferInfo.nextStart) {\u000a                  logger["logger"].log('alt audio track ahead of main track, seek to start of alt audio track');\u000a                  this.media.currentTime = start + 0.05;\u000a                } else {\u000a                  return;\u000a                }\u000a              }\u000a            }\u000a          }\u000a\u000a          if (trackDetails.initSegment && !trackDetails.initSegment.data) {\u000a            frag = trackDetails.initSegment;\u000a          } // eslint-disable-line brace-style\u000a          // if bufferEnd before start of playlist, load first fragment\u000a          else if (bufferEnd <= start) {\u000a              frag = fragments[0];\u000a\u000a              if (this.videoTrackCC !== null && frag.cc !== this.videoTrackCC) {\u000a                // Ensure we find a fragment which matches the continuity of the video track\u000a                frag = findFragWithCC(fragments, this.videoTrackCC);\u000a              }\u000a\u000a              if (trackDetails.live && frag.loadIdx && frag.loadIdx === this.fragLoadIdx) {\u000a                // we just loaded this first fragment, and we are still lagging behind the start of the live playlist\u000a                // let's force seek to start\u000a                var nextBuffered = bufferInfo.nextStart ? bufferInfo.nextStart : start;\u000a                logger["logger"].log("no alt audio available @currentTime:" + this.media.currentTime + ", seeking @" + (nextBuffered + 0.05));\u000a                this.media.currentTime = nextBuffered + 0.05;\u000a                return;\u000a              }\u000a            } else {\u000a              var foundFrag;\u000a              var maxFragLookUpTolerance = config.maxFragLookUpTolerance;\u000a              var fragNext = fragPrevious ? fragments[fragPrevious.sn - fragments[0].sn + 1] : undefined;\u000a\u000a              var fragmentWithinToleranceTest = function fragmentWithinToleranceTest(candidate) {\u000a                // offset should be within fragment boundary - config.maxFragLookUpTolerance\u000a                // this is to cope with situations like\u000a                // bufferEnd = 9.991\u000a                // frag[] : [0,10]\u000a                // frag[1] : [10,20]\u000a                // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here\u000a                //              frag start               frag start+duration\u000a                //                  |-----------------------------|\u000a                //              <--->                         <--->\u000a                //  ...--------><-----------------------------><---------....\u000a                // previous frag         matching fragment         next frag\u000a                //  return -1             return 0                 return 1\u000a                // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);\u000a                // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments\u000a                var candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration);\u000a\u000a                if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) {\u000a                  return 1;\u000a                } else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) {\u000a                  // if maxFragLookUpTolerance will have negative value then don't return -1 for first element\u000a                  return -1;\u000a                }\u000a\u000a                return 0;\u000a              };\u000a\u000a              if (bufferEnd < end) {\u000a                if (bufferEnd > end - maxFragLookUpTolerance) {\u000a                  maxFragLookUpTolerance = 0;\u000a                } // Prefer the next fragment if it's within tolerance\u000a\u000a\u000a                if (fragNext && !fragmentWithinToleranceTest(fragNext)) {\u000a                  foundFrag = fragNext;\u000a                } else {\u000a                  foundFrag = binary_search.search(fragments, fragmentWithinToleranceTest);\u000a                }\u000a              } else {\u000a                // reach end of playlist\u000a                foundFrag = fragments[fragLen - 1];\u000a              }\u000a\u000a              if (foundFrag) {\u000a                frag = foundFrag;\u000a                start = foundFrag.start; // logger.log('find SN matching with pos:' +  bufferEnd + ':' + frag.sn);\u000a\u000a                if (fragPrevious && frag.level === fragPrevious.level && frag.sn === fragPrevious.sn) {\u000a                  if (frag.sn < trackDetails.endSN) {\u000a                    frag = fragments[frag.sn + 1 - trackDetails.startSN];\u000a                    logger["logger"].log("SN just loaded, load next one: " + frag.sn);\u000a                  } else {\u000a                    frag = null;\u000a                  }\u000a                }\u000a              }\u000a            }\u000a\u000a          if (frag) {\u000a            // logger.log('      loading frag ' + i +',pos/bufEnd:' + pos.toFixed(3) + '/' + bufferEnd.toFixed(3));\u000a            if (frag.encrypted) {\u000a              logger["logger"].log("Loading key for " + frag.sn + " of [" + trackDetails.startSN + " ," + trackDetails.endSN + "],track " + trackId);\u000a              this.state = State.KEY_LOADING;\u000a              hls.trigger(events["default"].KEY_LOADING, {\u000a                frag: frag\u000a              });\u000a            } else {\u000a              // only load if fragment is not loaded or if in audio switch\u000a              // we force a frag loading in audio switch as fragment tracker might not have evicted previous frags in case of quick audio switch\u000a              this.fragCurrent = frag;\u000a\u000a              if (audioSwitch || this.fragmentTracker.getState(frag) === FragmentState.NOT_LOADED) {\u000a                logger["logger"].log("Loading " + frag.sn + ", cc: " + frag.cc + " of [" + trackDetails.startSN + " ," + trackDetails.endSN + "],track " + trackId + ", currentTime:" + pos + ",bufferEnd:" + bufferEnd.toFixed(3));\u000a\u000a                if (frag.sn !== 'initSegment') {\u000a                  this.startFragRequested = true;\u000a                }\u000a\u000a                if (Object(number["isFiniteNumber"])(frag.sn)) {\u000a                  this.nextLoadPosition = frag.start + frag.duration;\u000a                }\u000a\u000a                hls.trigger(events["default"].FRAG_LOADING, {\u000a                  frag: frag\u000a                });\u000a                this.state = State.FRAG_LOADING;\u000a              }\u000a            }\u000a          }\u000a        }\u000a\u000a        break;\u000a\u000a      case State.WAITING_TRACK:\u000a        track = this.tracks[this.trackId]; // check if playlist is already loaded\u000a\u000a        if (track && track.details) {\u000a          this.state = State.IDLE;\u000a        }\u000a\u000a        break;\u000a\u000a      case State.FRAG_LOADING_WAITING_RETRY:\u000a        var now = audio_stream_controller_performance.now();\u000a        var retryDate = this.retryDate;\u000a        media = this.media;\u000a        var isSeeking = media && media.seeking; // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading\u000a\u000a        if (!retryDate || now >= retryDate || isSeeking) {\u000a          logger["logger"].log('audioStreamController: retryDate reached, switch back to IDLE state');\u000a          this.state = State.IDLE;\u000a        }\u000a\u000a        break;\u000a\u000a      case State.WAITING_INIT_PTS:\u000a        var videoTrackCC = this.videoTrackCC;\u000a\u000a        if (this.initPTS[videoTrackCC] === undefined) {\u000a          break;\u000a        } // Ensure we don't get stuck in the WAITING_INIT_PTS state if the waiting frag CC doesn't match any initPTS\u000a\u000a\u000a        var waitingFrag = this.waitingFragment;\u000a\u000a        if (waitingFrag) {\u000a          var waitingFragCC = waitingFrag.frag.cc;\u000a\u000a          if (videoTrackCC !== waitingFragCC) {\u000a            track = this.tracks[this.trackId];\u000a\u000a            if (track.details && track.details.live) {\u000a              logger["logger"].warn("Waiting fragment CC (" + waitingFragCC + ") does not match video track CC (" + videoTrackCC + ")");\u000a              this.waitingFragment = null;\u000a              this.state = State.IDLE;\u000a            }\u000a          } else {\u000a            this.state = State.FRAG_LOADING;\u000a            this.onFragLoaded(this.waitingFragment);\u000a            this.waitingFragment = null;\u000a          }\u000a        } else {\u000a          this.state = State.IDLE;\u000a        }\u000a\u000a        break;\u000a\u000a      case State.STOPPED:\u000a      case State.FRAG_LOADING:\u000a      case State.PARSING:\u000a      case State.PARSED:\u000a      case State.ENDED:\u000a        break;\u000a\u000a      default:\u000a        break;\u000a    }\u000a  };\u000a\u000a  _proto.onMediaAttached = function onMediaAttached(data) {\u000a    var media = this.media = this.mediaBuffer = data.media;\u000a    this.onvseeking = this.onMediaSeeking.bind(this);\u000a    this.onvended = this.onMediaEnded.bind(this);\u000a    media.addEventListener('seeking', this.onvseeking);\u000a    media.addEventListener('ended', this.onvended);\u000a    var config = this.config;\u000a\u000a    if (this.tracks && config.autoStartLoad) {\u000a      this.startLoad(config.startPosition);\u000a    }\u000a  };\u000a\u000a  _proto.onMediaDetaching = function onMediaDetaching() {\u000a    var media = this.media;\u000a\u000a    if (media && media.ended) {\u000a      logger["logger"].log('MSE detaching and video ended, reset startPosition');\u000a      this.startPosition = this.lastCurrentTime = 0;\u000a    } // remove video listeners\u000a\u000a\u000a    if (media) {\u000a      media.removeEventListener('seeking', this.onvseeking);\u000a      media.removeEventListener('ended', this.onvended);\u000a      this.onvseeking = this.onvseeked = this.onvended = null;\u000a    }\u000a\u000a    this.media = this.mediaBuffer = this.videoBuffer = null;\u000a    this.loadedmetadata = false;\u000a    this.fragmentTracker.removeAllFragments();\u000a    this.stopLoad();\u000a  };\u000a\u000a  _proto.onAudioTracksUpdated = function onAudioTracksUpdated(data) {\u000a    logger["logger"].log('audio tracks updated');\u000a    this.tracks = data.audioTracks;\u000a  };\u000a\u000a  _proto.onAudioTrackSwitching = function onAudioTrackSwitching(data) {\u000a    // if any URL found on new audio track, it is an alternate audio track\u000a    var altAudio = !!data.url;\u000a    this.trackId = data.id;\u000a    this.fragCurrent = null;\u000a    this.state = State.PAUSED;\u000a    this.waitingFragment = null; // destroy useless demuxer when switching audio to main\u000a\u000a    if (!altAudio) {\u000a      if (this.demuxer) {\u000a        this.demuxer.destroy();\u000a        this.demuxer = null;\u000a      }\u000a    } else {\u000a      // switching to audio track, start timer if not already started\u000a      this.setInterval(audio_stream_controller_TICK_INTERVAL);\u000a    } // should we switch tracks ?\u000a\u000a\u000a    if (altAudio) {\u000a      this.audioSwitch = true; // main audio track are handled by stream-controller, just do something if switching to alt audio track\u000a\u000a      this.state = State.IDLE;\u000a    }\u000a\u000a    this.tick();\u000a  };\u000a\u000a  _proto.onAudioTrackLoaded = function onAudioTrackLoaded(data) {\u000a    var newDetails = data.details,\u000a        trackId = data.id,\u000a        track = this.tracks[trackId],\u000a        duration = newDetails.totalduration,\u000a        sliding = 0;\u000a    logger["logger"].log("track " + trackId + " loaded [" + newDetails.startSN + "," + newDetails.endSN + "],duration:" + duration);\u000a\u000a    if (newDetails.live) {\u000a      var curDetails = track.details;\u000a\u000a      if (curDetails && newDetails.fragments.length > 0) {\u000a        // we already have details for that level, merge them\u000a        mergeDetails(curDetails, newDetails);\u000a        sliding = newDetails.fragments[0].start; // TODO\u000a        // this.liveSyncPosition = this.computeLivePosition(sliding, curDetails);\u000a\u000a        if (newDetails.PTSKnown) {\u000a          logger["logger"].log("live audio playlist sliding:" + sliding.toFixed(3));\u000a        } else {\u000a          logger["logger"].log('live audio playlist - outdated PTS, unknown sliding');\u000a        }\u000a      } else {\u000a        newDetails.PTSKnown = false;\u000a        logger["logger"].log('live audio playlist - first load, unknown sliding');\u000a      }\u000a    } else {\u000a      newDetails.PTSKnown = false;\u000a    }\u000a\u000a    track.details = newDetails; // compute start position\u000a\u000a    if (!this.startFragRequested) {\u000a      // compute start position if set to -1. use it straight away if value is defined\u000a      if (this.startPosition === -1) {\u000a        // first, check if start time offset has been set in playlist, if yes, use this value\u000a        var startTimeOffset = newDetails.startTimeOffset;\u000a\u000a        if (Object(number["isFiniteNumber"])(startTimeOffset)) {\u000a          logger["logger"].log("start time offset found in playlist, adjust startPosition to " + startTimeOffset);\u000a          this.startPosition = startTimeOffset;\u000a        } else {\u000a          if (newDetails.live) {\u000a            this.startPosition = this.computeLivePosition(sliding, newDetails);\u000a            logger["logger"].log("compute startPosition for audio-track to " + this.startPosition);\u000a          } else {\u000a            this.startPosition = 0;\u000a          }\u000a        }\u000a      }\u000a\u000a      this.nextLoadPosition = this.startPosition;\u000a    } // only switch batck to IDLE state if we were waiting for track to start downloading a new fragment\u000a\u000a\u000a    if (this.state === State.WAITING_TRACK) {\u000a      this.state = State.IDLE;\u000a    } // trigger handler right now\u000a\u000a\u000a    this.tick();\u000a  };\u000a\u000a  _proto.onKeyLoaded = function onKeyLoaded() {\u000a    if (this.state === State.KEY_LOADING) {\u000a      this.state = State.IDLE;\u000a      this.tick();\u000a    }\u000a  };\u000a\u000a  _proto.onFragLoaded = function onFragLoaded(data) {\u000a    var fragCurrent = this.fragCurrent,\u000a        fragLoaded = data.frag;\u000a\u000a    if (this.state === State.FRAG_LOADING && fragCurrent && fragLoaded.type === 'audio' && fragLoaded.level === fragCurrent.level && fragLoaded.sn === fragCurrent.sn) {\u000a      var track = this.tracks[this.trackId],\u000a          details = track.details,\u000a          duration = details.totalduration,\u000a          trackId = fragCurrent.level,\u000a          sn = fragCurrent.sn,\u000a          cc = fragCurrent.cc,\u000a          audioCodec = this.config.defaultAudioCodec || track.audioCodec || 'mp4a.40.2',\u000a          stats = this.stats = data.stats;\u000a\u000a      if (sn === 'initSegment') {\u000a        this.state = State.IDLE;\u000a        stats.tparsed = stats.tbuffered = audio_stream_controller_performance.now();\u000a        details.initSegment.data = data.payload;\u000a        this.hls.trigger(events["default"].FRAG_BUFFERED, {\u000a          stats: stats,\u000a          frag: fragCurrent,\u000a          id: 'audio'\u000a        });\u000a        this.tick();\u000a      } else {\u000a        this.state = State.PARSING; // transmux the MPEG-TS data to ISO-BMFF segments\u000a\u000a        this.appended = false;\u000a\u000a        if (!this.demuxer) {\u000a          this.demuxer = new demux_demuxer(this.hls, 'audio');\u000a        } // Check if we have video initPTS\u000a        // If not we need to wait for it\u000a\u000a\u000a        var initPTS = this.initPTS[cc];\u000a        var initSegmentData = details.initSegment ? details.initSegment.data : [];\u000a\u000a        if (details.initSegment || initPTS !== undefined) {\u000a          this.pendingBuffering = true;\u000a          logger["logger"].log("Demuxing " + sn + " of [" + details.startSN + " ," + details.endSN + "],track " + trackId); // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)\u000a\u000a          var accurateTimeOffset = false; // details.PTSKnown || !details.live;\u000a\u000a          this.demuxer.push(data.payload, initSegmentData, audioCodec, null, fragCurrent, duration, accurateTimeOffset, initPTS);\u000a        } else {\u000a          logger["logger"].log("unknown video PTS for continuity counter " + cc + ", waiting for video PTS before demuxing audio frag " + sn + " of [" + details.startSN + " ," + details.endSN + "],track " + trackId);\u000a          this.waitingFragment = data;\u000a          this.state = State.WAITING_INIT_PTS;\u000a        }\u000a      }\u000a    }\u000a\u000a    this.fragLoadError = 0;\u000a  };\u000a\u000a  _proto.onFragParsingInitSegment = function onFragParsingInitSegment(data) {\u000a    var fragCurrent = this.fragCurrent;\u000a    var fragNew = data.frag;\u000a\u000a    if (fragCurrent && data.id === 'audio' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === State.PARSING) {\u000a      var tracks = data.tracks,\u000a          track; // delete any video track found on audio demuxer\u000a\u000a      if (tracks.video) {\u000a        delete tracks.video;\u000a      } // include levelCodec in audio and video tracks\u000a\u000a\u000a      track = tracks.audio;\u000a\u000a      if (track) {\u000a        track.levelCodec = track.codec;\u000a        track.id = data.id;\u000a        this.hls.trigger(events["default"].BUFFER_CODECS, tracks);\u000a        logger["logger"].log("audio track:audio,container:" + track.container + ",codecs[level/parsed]=[" + track.levelCodec + "/" + track.codec + "]");\u000a        var initSegment = track.initSegment;\u000a\u000a        if (initSegment) {\u000a          var appendObj = {\u000a            type: 'audio',\u000a            data: initSegment,\u000a            parent: 'audio',\u000a            content: 'initSegment'\u000a          };\u000a\u000a          if (this.audioSwitch) {\u000a            this.pendingData = [appendObj];\u000a          } else {\u000a            this.appended = true; // arm pending Buffering flag before appending a segment\u000a\u000a            this.pendingBuffering = true;\u000a            this.hls.trigger(events["default"].BUFFER_APPENDING, appendObj);\u000a          }\u000a        } // trigger handler right now\u000a\u000a\u000a        this.tick();\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onFragParsingData = function onFragParsingData(data) {\u000a    var _this2 = this;\u000a\u000a    var fragCurrent = this.fragCurrent;\u000a    var fragNew = data.frag;\u000a\u000a    if (fragCurrent && data.id === 'audio' && data.type === 'audio' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === State.PARSING) {\u000a      var trackId = this.trackId,\u000a          track = this.tracks[trackId],\u000a          hls = this.hls;\u000a\u000a      if (!Object(number["isFiniteNumber"])(data.endPTS)) {\u000a        data.endPTS = data.startPTS + fragCurrent.duration;\u000a        data.endDTS = data.startDTS + fragCurrent.duration;\u000a      }\u000a\u000a      fragCurrent.addElementaryStream(ElementaryStreamTypes.AUDIO);\u000a      logger["logger"].log("parsed " + data.type + ",PTS:[" + data.startPTS.toFixed(3) + "," + data.endPTS.toFixed(3) + "],DTS:[" + data.startDTS.toFixed(3) + "/" + data.endDTS.toFixed(3) + "],nb:" + data.nb);\u000a      updateFragPTSDTS(track.details, fragCurrent, data.startPTS, data.endPTS);\u000a      var audioSwitch = this.audioSwitch,\u000a          media = this.media,\u000a          appendOnBufferFlush = false; // Only flush audio from old audio tracks when PTS is known on new audio track\u000a\u000a      if (audioSwitch) {\u000a        if (media && media.readyState) {\u000a          var currentTime = media.currentTime;\u000a          logger["logger"].log('switching audio track : currentTime:' + currentTime);\u000a\u000a          if (currentTime >= data.startPTS) {\u000a            logger["logger"].log('switching audio track : flushing all audio');\u000a            this.state = State.BUFFER_FLUSHING;\u000a            hls.trigger(events["default"].BUFFER_FLUSHING, {\u000a              startOffset: 0,\u000a              endOffset: Number.POSITIVE_INFINITY,\u000a              type: 'audio'\u000a            });\u000a            appendOnBufferFlush = true; // Lets announce that the initial audio track switch flush occur\u000a\u000a            this.audioSwitch = false;\u000a            hls.trigger(events["default"].AUDIO_TRACK_SWITCHED, {\u000a              id: trackId\u000a            });\u000a          }\u000a        } else {\u000a          // Lets announce that the initial audio track switch flush occur\u000a          this.audioSwitch = false;\u000a          hls.trigger(events["default"].AUDIO_TRACK_SWITCHED, {\u000a            id: trackId\u000a          });\u000a        }\u000a      }\u000a\u000a      var pendingData = this.pendingData;\u000a\u000a      if (!pendingData) {\u000a        logger["logger"].warn('Apparently attempt to enqueue media payload without codec initialization data upfront');\u000a        hls.trigger(events["default"].ERROR, {\u000a          type: errors["ErrorTypes"].MEDIA_ERROR,\u000a          details: null,\u000a          fatal: true\u000a        });\u000a        return;\u000a      }\u000a\u000a      if (!this.audioSwitch) {\u000a        [data.data1, data.data2].forEach(function (buffer) {\u000a          if (buffer && buffer.length) {\u000a            pendingData.push({\u000a              type: data.type,\u000a              data: buffer,\u000a              parent: 'audio',\u000a              content: 'data'\u000a            });\u000a          }\u000a        });\u000a\u000a        if (!appendOnBufferFlush && pendingData.length) {\u000a          pendingData.forEach(function (appendObj) {\u000a            // only append in PARSING state (rationale is that an appending error could happen synchronously on first segment appending)\u000a            // in that case it is useless to append following segments\u000a            if (_this2.state === State.PARSING) {\u000a              // arm pending Buffering flag before appending a segment\u000a              _this2.pendingBuffering = true;\u000a\u000a              _this2.hls.trigger(events["default"].BUFFER_APPENDING, appendObj);\u000a            }\u000a          });\u000a          this.pendingData = [];\u000a          this.appended = true;\u000a        }\u000a      } // trigger handler right now\u000a\u000a\u000a      this.tick();\u000a    }\u000a  };\u000a\u000a  _proto.onFragParsed = function onFragParsed(data) {\u000a    var fragCurrent = this.fragCurrent;\u000a    var fragNew = data.frag;\u000a\u000a    if (fragCurrent && data.id === 'audio' && fragNew.sn === fragCurrent.sn && fragNew.level === fragCurrent.level && this.state === State.PARSING) {\u000a      this.stats.tparsed = audio_stream_controller_performance.now();\u000a      this.state = State.PARSED;\u000a\u000a      this._checkAppendedParsed();\u000a    }\u000a  };\u000a\u000a  _proto.onBufferReset = function onBufferReset() {\u000a    // reset reference to sourcebuffers\u000a    this.mediaBuffer = this.videoBuffer = null;\u000a    this.loadedmetadata = false;\u000a  };\u000a\u000a  _proto.onBufferCreated = function onBufferCreated(data) {\u000a    var audioTrack = data.tracks.audio;\u000a\u000a    if (audioTrack) {\u000a      this.mediaBuffer = audioTrack.buffer;\u000a      this.loadedmetadata = true;\u000a    }\u000a\u000a    if (data.tracks.video) {\u000a      this.videoBuffer = data.tracks.video.buffer;\u000a    }\u000a  };\u000a\u000a  _proto.onBufferAppended = function onBufferAppended(data) {\u000a    if (data.parent === 'audio') {\u000a      var state = this.state;\u000a\u000a      if (state === State.PARSING || state === State.PARSED) {\u000a        // check if all buffers have been appended\u000a        this.pendingBuffering = data.pending > 0;\u000a\u000a        this._checkAppendedParsed();\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto._checkAppendedParsed = function _checkAppendedParsed() {\u000a    // trigger handler right now\u000a    if (this.state === State.PARSED && (!this.appended || !this.pendingBuffering)) {\u000a      var frag = this.fragCurrent,\u000a          stats = this.stats,\u000a          hls = this.hls;\u000a\u000a      if (frag) {\u000a        this.fragPrevious = frag;\u000a        stats.tbuffered = audio_stream_controller_performance.now();\u000a        hls.trigger(events["default"].FRAG_BUFFERED, {\u000a          stats: stats,\u000a          frag: frag,\u000a          id: 'audio'\u000a        });\u000a        var media = this.mediaBuffer ? this.mediaBuffer : this.media;\u000a\u000a        if (media) {\u000a          logger["logger"].log("audio buffered : " + time_ranges.toString(media.buffered));\u000a        }\u000a\u000a        if (this.audioSwitch && this.appended) {\u000a          this.audioSwitch = false;\u000a          hls.trigger(events["default"].AUDIO_TRACK_SWITCHED, {\u000a            id: this.trackId\u000a          });\u000a        }\u000a\u000a        this.state = State.IDLE;\u000a      }\u000a\u000a      this.tick();\u000a    }\u000a  };\u000a\u000a  _proto.onError = function onError(data) {\u000a    var frag = data.frag; // don't handle frag error not related to audio fragment\u000a\u000a    if (frag && frag.type !== 'audio') {\u000a      return;\u000a    }\u000a\u000a    switch (data.details) {\u000a      case errors["ErrorDetails"].FRAG_LOAD_ERROR:\u000a      case errors["ErrorDetails"].FRAG_LOAD_TIMEOUT:\u000a        var _frag = data.frag; // don't handle frag error not related to audio fragment\u000a\u000a        if (_frag && _frag.type !== 'audio') {\u000a          break;\u000a        }\u000a\u000a        if (!data.fatal) {\u000a          var loadError = this.fragLoadError;\u000a\u000a          if (loadError) {\u000a            loadError++;\u000a          } else {\u000a            loadError = 1;\u000a          }\u000a\u000a          var config = this.config;\u000a\u000a          if (loadError <= config.fragLoadingMaxRetry) {\u000a            this.fragLoadError = loadError; // exponential backoff capped to config.fragLoadingMaxRetryTimeout\u000a\u000a            var delay = Math.min(Math.pow(2, loadError - 1) * config.fragLoadingRetryDelay, config.fragLoadingMaxRetryTimeout);\u000a            logger["logger"].warn("AudioStreamController: frag loading failed, retry in " + delay + " ms");\u000a            this.retryDate = audio_stream_controller_performance.now() + delay; // retry loading state\u000a\u000a            this.state = State.FRAG_LOADING_WAITING_RETRY;\u000a          } else {\u000a            logger["logger"].error("AudioStreamController: " + data.details + " reaches max retry, redispatch as fatal ..."); // switch error to fatal\u000a\u000a            data.fatal = true;\u000a            this.state = State.ERROR;\u000a          }\u000a        }\u000a\u000a        break;\u000a\u000a      case errors["ErrorDetails"].AUDIO_TRACK_LOAD_ERROR:\u000a      case errors["ErrorDetails"].AUDIO_TRACK_LOAD_TIMEOUT:\u000a      case errors["ErrorDetails"].KEY_LOAD_ERROR:\u000a      case errors["ErrorDetails"].KEY_LOAD_TIMEOUT:\u000a        //  when in ERROR state, don't switch back to IDLE state in case a non-fatal error is received\u000a        if (this.state !== State.ERROR) {\u000a          // if fatal error, stop processing, otherwise move to IDLE to retry loading\u000a          this.state = data.fatal ? State.ERROR : State.IDLE;\u000a          logger["logger"].warn("AudioStreamController: " + data.details + " while loading frag, now switching to " + this.state + " state ...");\u000a        }\u000a\u000a        break;\u000a\u000a      case errors["ErrorDetails"].BUFFER_FULL_ERROR:\u000a        // if in appending state\u000a        if (data.parent === 'audio' && (this.state === State.PARSING || this.state === State.PARSED)) {\u000a          var media = this.mediaBuffer,\u000a              currentTime = this.media.currentTime,\u000a              mediaBuffered = media && BufferHelper.isBuffered(media, currentTime) && BufferHelper.isBuffered(media, currentTime + 0.5); // reduce max buf len if current position is buffered\u000a\u000a          if (mediaBuffered) {\u000a            var _config = this.config;\u000a\u000a            if (_config.maxMaxBufferLength >= _config.maxBufferLength) {\u000a              // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...\u000a              _config.maxMaxBufferLength /= 2;\u000a              logger["logger"].warn("AudioStreamController: reduce max buffer length to " + _config.maxMaxBufferLength + "s");\u000a            }\u000a\u000a            this.state = State.IDLE;\u000a          } else {\u000a            // current position is not buffered, but browser is still complaining about buffer full error\u000a            // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708\u000a            // in that case flush the whole audio buffer to recover\u000a            logger["logger"].warn('AudioStreamController: buffer full error also media.currentTime is not buffered, flush audio buffer');\u000a            this.fragCurrent = null; // flush everything\u000a\u000a            this.state = State.BUFFER_FLUSHING;\u000a            this.hls.trigger(events["default"].BUFFER_FLUSHING, {\u000a              startOffset: 0,\u000a              endOffset: Number.POSITIVE_INFINITY,\u000a              type: 'audio'\u000a            });\u000a          }\u000a        }\u000a\u000a        break;\u000a\u000a      default:\u000a        break;\u000a    }\u000a  };\u000a\u000a  _proto.onBufferFlushed = function onBufferFlushed() {\u000a    var _this3 = this;\u000a\u000a    var pendingData = this.pendingData;\u000a\u000a    if (pendingData && pendingData.length) {\u000a      logger["logger"].log('AudioStreamController: appending pending audio data after buffer flushed');\u000a      pendingData.forEach(function (appendObj) {\u000a        _this3.hls.trigger(events["default"].BUFFER_APPENDING, appendObj);\u000a      });\u000a      this.appended = true;\u000a      this.pendingData = [];\u000a      this.state = State.PARSED;\u000a    } else {\u000a      // move to IDLE once flush complete. this should trigger new fragment loading\u000a      this.state = State.IDLE; // reset reference to frag\u000a\u000a      this.fragPrevious = null;\u000a      this.tick();\u000a    }\u000a  };\u000a\u000a  audio_stream_controller_createClass(AudioStreamController, [{\u000a    key: "state",\u000a    set: function set(nextState) {\u000a      if (this.state !== nextState) {\u000a        var previousState = this.state;\u000a        this._state = nextState;\u000a        logger["logger"].log("audio stream:" + previousState + "->" + nextState);\u000a      }\u000a    },\u000a    get: function get() {\u000a      return this._state;\u000a    }\u000a  }]);\u000a\u000a  return AudioStreamController;\u000a}(base_stream_controller_BaseStreamController);\u000a\u000a/* harmony default export */ var audio_stream_controller = (audio_stream_controller_AudioStreamController);\u000a// CONCATENATED MODULE: ./src/utils/vttcue.js\u000a/**\u000a * Copyright 2013 vtt.js Contributors\u000a *\u000a * Licensed under the Apache License, Version 2.0 (the "License");\u000a * you may not use this file except in compliance with the License.\u000a * You may obtain a copy of the License at\u000a *\u000a *   http://www.apache.org/licenses/LICENSE-2.0\u000a *\u000a * Unless required by applicable law or agreed to in writing, software\u000a * distributed under the License is distributed on an "AS IS" BASIS,\u000a * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\u000a * See the License for the specific language governing permissions and\u000a * limitations under the License.\u000a */\u000a/* harmony default export */ var vttcue = ((function () {\u000a  if (typeof window !== 'undefined' && window.VTTCue) {\u000a    return window.VTTCue;\u000a  }\u000a\u000a  var autoKeyword = 'auto';\u000a  var directionSetting = {\u000a    '': true,\u000a    lr: true,\u000a    rl: true\u000a  };\u000a  var alignSetting = {\u000a    start: true,\u000a    middle: true,\u000a    end: true,\u000a    left: true,\u000a    right: true\u000a  };\u000a\u000a  function findDirectionSetting(value) {\u000a    if (typeof value !== 'string') {\u000a      return false;\u000a    }\u000a\u000a    var dir = directionSetting[value.toLowerCase()];\u000a    return dir ? value.toLowerCase() : false;\u000a  }\u000a\u000a  function findAlignSetting(value) {\u000a    if (typeof value !== 'string') {\u000a      return false;\u000a    }\u000a\u000a    var align = alignSetting[value.toLowerCase()];\u000a    return align ? value.toLowerCase() : false;\u000a  }\u000a\u000a  function extend(obj) {\u000a    var i = 1;\u000a\u000a    for (; i < arguments.length; i++) {\u000a      var cobj = arguments[i];\u000a\u000a      for (var p in cobj) {\u000a        obj[p] = cobj[p];\u000a      }\u000a    }\u000a\u000a    return obj;\u000a  }\u000a\u000a  function VTTCue(startTime, endTime, text) {\u000a    var cue = this;\u000a    var baseObj = {};\u000a    baseObj.enumerable = true;\u000a    /**\u000a     * Shim implementation specific properties. These properties are not in\u000a     * the spec.\u000a     */\u000a    // Lets us know when the VTTCue's data has changed in such a way that we need\u000a    // to recompute its display state. This lets us compute its display state\u000a    // lazily.\u000a\u000a    cue.hasBeenReset = false;\u000a    /**\u000a     * VTTCue and TextTrackCue properties\u000a     * http://dev.w3.org/html5/webvtt/#vttcue-interface\u000a     */\u000a\u000a    var _id = '';\u000a    var _pauseOnExit = false;\u000a    var _startTime = startTime;\u000a    var _endTime = endTime;\u000a    var _text = text;\u000a    var _region = null;\u000a    var _vertical = '';\u000a    var _snapToLines = true;\u000a    var _line = 'auto';\u000a    var _lineAlign = 'start';\u000a    var _position = 50;\u000a    var _positionAlign = 'middle';\u000a    var _size = 50;\u000a    var _align = 'middle';\u000a    Object.defineProperty(cue, 'id', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _id;\u000a      },\u000a      set: function set(value) {\u000a        _id = '' + value;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'pauseOnExit', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _pauseOnExit;\u000a      },\u000a      set: function set(value) {\u000a        _pauseOnExit = !!value;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'startTime', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _startTime;\u000a      },\u000a      set: function set(value) {\u000a        if (typeof value !== 'number') {\u000a          throw new TypeError('Start time must be set to a number.');\u000a        }\u000a\u000a        _startTime = value;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'endTime', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _endTime;\u000a      },\u000a      set: function set(value) {\u000a        if (typeof value !== 'number') {\u000a          throw new TypeError('End time must be set to a number.');\u000a        }\u000a\u000a        _endTime = value;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'text', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _text;\u000a      },\u000a      set: function set(value) {\u000a        _text = '' + value;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'region', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _region;\u000a      },\u000a      set: function set(value) {\u000a        _region = value;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'vertical', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _vertical;\u000a      },\u000a      set: function set(value) {\u000a        var setting = findDirectionSetting(value); // Have to check for false because the setting an be an empty string.\u000a\u000a        if (setting === false) {\u000a          throw new SyntaxError('An invalid or illegal string was specified.');\u000a        }\u000a\u000a        _vertical = setting;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'snapToLines', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _snapToLines;\u000a      },\u000a      set: function set(value) {\u000a        _snapToLines = !!value;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'line', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _line;\u000a      },\u000a      set: function set(value) {\u000a        if (typeof value !== 'number' && value !== autoKeyword) {\u000a          throw new SyntaxError('An invalid number or illegal string was specified.');\u000a        }\u000a\u000a        _line = value;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'lineAlign', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _lineAlign;\u000a      },\u000a      set: function set(value) {\u000a        var setting = findAlignSetting(value);\u000a\u000a        if (!setting) {\u000a          throw new SyntaxError('An invalid or illegal string was specified.');\u000a        }\u000a\u000a        _lineAlign = setting;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'position', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _position;\u000a      },\u000a      set: function set(value) {\u000a        if (value < 0 || value > 100) {\u000a          throw new Error('Position must be between 0 and 100.');\u000a        }\u000a\u000a        _position = value;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'positionAlign', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _positionAlign;\u000a      },\u000a      set: function set(value) {\u000a        var setting = findAlignSetting(value);\u000a\u000a        if (!setting) {\u000a          throw new SyntaxError('An invalid or illegal string was specified.');\u000a        }\u000a\u000a        _positionAlign = setting;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'size', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _size;\u000a      },\u000a      set: function set(value) {\u000a        if (value < 0 || value > 100) {\u000a          throw new Error('Size must be between 0 and 100.');\u000a        }\u000a\u000a        _size = value;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    Object.defineProperty(cue, 'align', extend({}, baseObj, {\u000a      get: function get() {\u000a        return _align;\u000a      },\u000a      set: function set(value) {\u000a        var setting = findAlignSetting(value);\u000a\u000a        if (!setting) {\u000a          throw new SyntaxError('An invalid or illegal string was specified.');\u000a        }\u000a\u000a        _align = setting;\u000a        this.hasBeenReset = true;\u000a      }\u000a    }));\u000a    /**\u000a     * Other <track> spec defined properties\u000a     */\u000a    // http://www.whatwg.org/specs/web-apps/current-work/multipage/the-video-element.html#text-track-cue-display-state\u000a\u000a    cue.displayState = void 0;\u000a  }\u000a  /**\u000a   * VTTCue methods\u000a   */\u000a\u000a\u000a  VTTCue.prototype.getCueAsHTML = function () {\u000a    // Assume WebVTT.convertCueToDOMTree is on the global.\u000a    var WebVTT = window.WebVTT;\u000a    return WebVTT.convertCueToDOMTree(window, this.text);\u000a  };\u000a\u000a  return VTTCue;\u000a})());\u000a// CONCATENATED MODULE: ./src/utils/vttparser.js\u000a/*\u000a * Source: https://github.com/mozilla/vtt.js/blob/master/dist/vtt.js#L1716\u000a */\u000a\u000a\u000avar StringDecoder = function StringDecoder() {\u000a  return {\u000a    decode: function decode(data) {\u000a      if (!data) {\u000a        return '';\u000a      }\u000a\u000a      if (typeof data !== 'string') {\u000a        throw new Error('Error - expected string data.');\u000a      }\u000a\u000a      return decodeURIComponent(encodeURIComponent(data));\u000a    }\u000a  };\u000a};\u000a\u000afunction VTTParser() {\u000a  this.window = window;\u000a  this.state = 'INITIAL';\u000a  this.buffer = '';\u000a  this.decoder = new StringDecoder();\u000a  this.regionList = [];\u000a} // Try to parse input as a time stamp.\u000a\u000a\u000afunction parseTimeStamp(input) {\u000a  function computeSeconds(h, m, s, f) {\u000a    return (h | 0) * 3600 + (m | 0) * 60 + (s | 0) + (f | 0) / 1000;\u000a  }\u000a\u000a  var m = input.match(/^(\u005cd+):(\u005cd{2})(:\u005cd{2})?\u005c.(\u005cd{3})/);\u000a\u000a  if (!m) {\u000a    return null;\u000a  }\u000a\u000a  if (m[3]) {\u000a    // Timestamp takes the form of [hours]:[minutes]:[seconds].[milliseconds]\u000a    return computeSeconds(m[1], m[2], m[3].replace(':', ''), m[4]);\u000a  } else if (m[1] > 59) {\u000a    // Timestamp takes the form of [hours]:[minutes].[milliseconds]\u000a    // First position is hours as it's over 59.\u000a    return computeSeconds(m[1], m[2], 0, m[4]);\u000a  } else {\u000a    // Timestamp takes the form of [minutes]:[seconds].[milliseconds]\u000a    return computeSeconds(0, m[1], m[2], m[4]);\u000a  }\u000a} // A settings object holds key/value pairs and will ignore anything but the first\u000a// assignment to a specific key.\u000a\u000a\u000afunction Settings() {\u000a  this.values = Object.create(null);\u000a}\u000a\u000aSettings.prototype = {\u000a  // Only accept the first assignment to any key.\u000a  set: function set(k, v) {\u000a    if (!this.get(k) && v !== '') {\u000a      this.values[k] = v;\u000a    }\u000a  },\u000a  // Return the value for a key, or a default value.\u000a  // If 'defaultKey' is passed then 'dflt' is assumed to be an object with\u000a  // a number of possible default values as properties where 'defaultKey' is\u000a  // the key of the property that will be chosen; otherwise it's assumed to be\u000a  // a single value.\u000a  get: function get(k, dflt, defaultKey) {\u000a    if (defaultKey) {\u000a      return this.has(k) ? this.values[k] : dflt[defaultKey];\u000a    }\u000a\u000a    return this.has(k) ? this.values[k] : dflt;\u000a  },\u000a  // Check whether we have a value for a key.\u000a  has: function has(k) {\u000a    return k in this.values;\u000a  },\u000a  // Accept a setting if its one of the given alternatives.\u000a  alt: function alt(k, v, a) {\u000a    for (var n = 0; n < a.length; ++n) {\u000a      if (v === a[n]) {\u000a        this.set(k, v);\u000a        break;\u000a      }\u000a    }\u000a  },\u000a  // Accept a setting if its a valid (signed) integer.\u000a  integer: function integer(k, v) {\u000a    if (/^-?\u005cd+$/.test(v)) {\u000a      // integer\u000a      this.set(k, parseInt(v, 10));\u000a    }\u000a  },\u000a  // Accept a setting if its a valid percentage.\u000a  percent: function percent(k, v) {\u000a    var m;\u000a\u000a    if (m = v.match(/^([\u005cd]{1,3})(\u005c.[\u005cd]*)?%$/)) {\u000a      v = parseFloat(v);\u000a\u000a      if (v >= 0 && v <= 100) {\u000a        this.set(k, v);\u000a        return true;\u000a      }\u000a    }\u000a\u000a    return false;\u000a  }\u000a}; // Helper function to parse input into groups separated by 'groupDelim', and\u000a// interprete each group as a key/value pair separated by 'keyValueDelim'.\u000a\u000afunction parseOptions(input, callback, keyValueDelim, groupDelim) {\u000a  var groups = groupDelim ? input.split(groupDelim) : [input];\u000a\u000a  for (var i in groups) {\u000a    if (typeof groups[i] !== 'string') {\u000a      continue;\u000a    }\u000a\u000a    var kv = groups[i].split(keyValueDelim);\u000a\u000a    if (kv.length !== 2) {\u000a      continue;\u000a    }\u000a\u000a    var k = kv[0];\u000a    var v = kv[1];\u000a    callback(k, v);\u000a  }\u000a}\u000a\u000avar defaults = new vttcue(0, 0, 0); // 'middle' was changed to 'center' in the spec: https://github.com/w3c/webvtt/pull/244\u000a//  Safari doesn't yet support this change, but FF and Chrome do.\u000a\u000avar center = defaults.align === 'middle' ? 'middle' : 'center';\u000a\u000afunction parseCue(input, cue, regionList) {\u000a  // Remember the original input if we need to throw an error.\u000a  var oInput = input; // 4.1 WebVTT timestamp\u000a\u000a  function consumeTimeStamp() {\u000a    var ts = parseTimeStamp(input);\u000a\u000a    if (ts === null) {\u000a      throw new Error('Malformed timestamp: ' + oInput);\u000a    } // Remove time stamp from input.\u000a\u000a\u000a    input = input.replace(/^[^\u005csa-zA-Z-]+/, '');\u000a    return ts;\u000a  } // 4.4.2 WebVTT cue settings\u000a\u000a\u000a  function consumeCueSettings(input, cue) {\u000a    var settings = new Settings();\u000a    parseOptions(input, function (k, v) {\u000a      switch (k) {\u000a        case 'region':\u000a          // Find the last region we parsed with the same region id.\u000a          for (var i = regionList.length - 1; i >= 0; i--) {\u000a            if (regionList[i].id === v) {\u000a              settings.set(k, regionList[i].region);\u000a              break;\u000a            }\u000a          }\u000a\u000a          break;\u000a\u000a        case 'vertical':\u000a          settings.alt(k, v, ['rl', 'lr']);\u000a          break;\u000a\u000a        case 'line':\u000a          var vals = v.split(','),\u000a              vals0 = vals[0];\u000a          settings.integer(k, vals0);\u000a\u000a          if (settings.percent(k, vals0)) {\u000a            settings.set('snapToLines', false);\u000a          }\u000a\u000a          settings.alt(k, vals0, ['auto']);\u000a\u000a          if (vals.length === 2) {\u000a            settings.alt('lineAlign', vals[1], ['start', center, 'end']);\u000a          }\u000a\u000a          break;\u000a\u000a        case 'position':\u000a          vals = v.split(',');\u000a          settings.percent(k, vals[0]);\u000a\u000a          if (vals.length === 2) {\u000a            settings.alt('positionAlign', vals[1], ['start', center, 'end', 'line-left', 'line-right', 'auto']);\u000a          }\u000a\u000a          break;\u000a\u000a        case 'size':\u000a          settings.percent(k, v);\u000a          break;\u000a\u000a        case 'align':\u000a          settings.alt(k, v, ['start', center, 'end', 'left', 'right']);\u000a          break;\u000a      }\u000a    }, /:/, /\u005cs/); // Apply default values for any missing fields.\u000a\u000a    cue.region = settings.get('region', null);\u000a    cue.vertical = settings.get('vertical', '');\u000a    var line = settings.get('line', 'auto');\u000a\u000a    if (line === 'auto' && defaults.line === -1) {\u000a      // set numeric line number for Safari\u000a      line = -1;\u000a    }\u000a\u000a    cue.line = line;\u000a    cue.lineAlign = settings.get('lineAlign', 'start');\u000a    cue.snapToLines = settings.get('snapToLines', true);\u000a    cue.size = settings.get('size', 100);\u000a    cue.align = settings.get('align', center);\u000a    var position = settings.get('position', 'auto');\u000a\u000a    if (position === 'auto' && defaults.position === 50) {\u000a      // set numeric position for Safari\u000a      position = cue.align === 'start' || cue.align === 'left' ? 0 : cue.align === 'end' || cue.align === 'right' ? 100 : 50;\u000a    }\u000a\u000a    cue.position = position;\u000a  }\u000a\u000a  function skipWhitespace() {\u000a    input = input.replace(/^\u005cs+/, '');\u000a  } // 4.1 WebVTT cue timings.\u000a\u000a\u000a  skipWhitespace();\u000a  cue.startTime = consumeTimeStamp(); // (1) collect cue start time\u000a\u000a  skipWhitespace();\u000a\u000a  if (input.substr(0, 3) !== '-->') {\u000a    // (3) next characters must match '-->'\u000a    throw new Error('Malformed time stamp (time stamps must be separated by \u005c'-->\u005c'): ' + oInput);\u000a  }\u000a\u000a  input = input.substr(3);\u000a  skipWhitespace();\u000a  cue.endTime = consumeTimeStamp(); // (5) collect cue end time\u000a  // 4.1 WebVTT cue settings list.\u000a\u000a  skipWhitespace();\u000a  consumeCueSettings(input, cue);\u000a}\u000a\u000afunction fixLineBreaks(input) {\u000a  return input.replace(/<br(?: \u005c/)?>/gi, '\u005cn');\u000a}\u000a\u000aVTTParser.prototype = {\u000a  parse: function parse(data) {\u000a    var self = this; // If there is no data then we won't decode it, but will just try to parse\u000a    // whatever is in buffer already. This may occur in circumstances, for\u000a    // example when flush() is called.\u000a\u000a    if (data) {\u000a      // Try to decode the data that we received.\u000a      self.buffer += self.decoder.decode(data, {\u000a        stream: true\u000a      });\u000a    }\u000a\u000a    function collectNextLine() {\u000a      var buffer = self.buffer;\u000a      var pos = 0;\u000a      buffer = fixLineBreaks(buffer);\u000a\u000a      while (pos < buffer.length && buffer[pos] !== '\u005cr' && buffer[pos] !== '\u005cn') {\u000a        ++pos;\u000a      }\u000a\u000a      var line = buffer.substr(0, pos); // Advance the buffer early in case we fail below.\u000a\u000a      if (buffer[pos] === '\u005cr') {\u000a        ++pos;\u000a      }\u000a\u000a      if (buffer[pos] === '\u005cn') {\u000a        ++pos;\u000a      }\u000a\u000a      self.buffer = buffer.substr(pos);\u000a      return line;\u000a    } // 3.2 WebVTT metadata header syntax\u000a\u000a\u000a    function parseHeader(input) {\u000a      parseOptions(input, function (k, v) {\u000a        switch (k) {\u000a          case 'Region':\u000a            // 3.3 WebVTT region metadata header syntax\u000a            // console.log('parse region', v);\u000a            // parseRegion(v);\u000a            break;\u000a        }\u000a      }, /:/);\u000a    } // 5.1 WebVTT file parsing.\u000a\u000a\u000a    try {\u000a      var line;\u000a\u000a      if (self.state === 'INITIAL') {\u000a        // We can't start parsing until we have the first line.\u000a        if (!/\u005cr\u005cn|\u005cn/.test(self.buffer)) {\u000a          return this;\u000a        }\u000a\u000a        line = collectNextLine(); // strip of UTF-8 BOM if any\u000a        // https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8\u000a\u000a        var m = line.match(/^()?WEBVTT([ \u005ct].*)?$/);\u000a\u000a        if (!m || !m[0]) {\u000a          throw new Error('Malformed WebVTT signature.');\u000a        }\u000a\u000a        self.state = 'HEADER';\u000a      }\u000a\u000a      var alreadyCollectedLine = false;\u000a\u000a      while (self.buffer) {\u000a        // We can't parse a line until we have the full line.\u000a        if (!/\u005cr\u005cn|\u005cn/.test(self.buffer)) {\u000a          return this;\u000a        }\u000a\u000a        if (!alreadyCollectedLine) {\u000a          line = collectNextLine();\u000a        } else {\u000a          alreadyCollectedLine = false;\u000a        }\u000a\u000a        switch (self.state) {\u000a          case 'HEADER':\u000a            // 13-18 - Allow a header (metadata) under the WEBVTT line.\u000a            if (/:/.test(line)) {\u000a              parseHeader(line);\u000a            } else if (!line) {\u000a              // An empty line terminates the header and starts the body (cues).\u000a              self.state = 'ID';\u000a            }\u000a\u000a            continue;\u000a\u000a          case 'NOTE':\u000a            // Ignore NOTE blocks.\u000a            if (!line) {\u000a              self.state = 'ID';\u000a            }\u000a\u000a            continue;\u000a\u000a          case 'ID':\u000a            // Check for the start of NOTE blocks.\u000a            if (/^NOTE($|[ \u005ct])/.test(line)) {\u000a              self.state = 'NOTE';\u000a              break;\u000a            } // 19-29 - Allow any number of line terminators, then initialize new cue values.\u000a\u000a\u000a            if (!line) {\u000a              continue;\u000a            }\u000a\u000a            self.cue = new vttcue(0, 0, '');\u000a            self.state = 'CUE'; // 30-39 - Check if self line contains an optional identifier or timing data.\u000a\u000a            if (line.indexOf('-->') === -1) {\u000a              self.cue.id = line;\u000a              continue;\u000a            }\u000a\u000a          // Process line as start of a cue.\u000a\u000a          /* falls through */\u000a\u000a          case 'CUE':\u000a            // 40 - Collect cue timings and settings.\u000a            try {\u000a              parseCue(line, self.cue, self.regionList);\u000a            } catch (e) {\u000a              // In case of an error ignore rest of the cue.\u000a              self.cue = null;\u000a              self.state = 'BADCUE';\u000a              continue;\u000a            }\u000a\u000a            self.state = 'CUETEXT';\u000a            continue;\u000a\u000a          case 'CUETEXT':\u000a            var hasSubstring = line.indexOf('-->') !== -1; // 34 - If we have an empty line then report the cue.\u000a            // 35 - If we have the special substring '-->' then report the cue,\u000a            // but do not collect the line as we need to process the current\u000a            // one as a new cue.\u000a\u000a            if (!line || hasSubstring && (alreadyCollectedLine = true)) {\u000a              // We are done parsing self cue.\u000a              if (self.oncue) {\u000a                self.oncue(self.cue);\u000a              }\u000a\u000a              self.cue = null;\u000a              self.state = 'ID';\u000a              continue;\u000a            }\u000a\u000a            if (self.cue.text) {\u000a              self.cue.text += '\u005cn';\u000a            }\u000a\u000a            self.cue.text += line;\u000a            continue;\u000a\u000a          case 'BADCUE':\u000a            // BADCUE\u000a            // 54-62 - Collect and discard the remaining cue.\u000a            if (!line) {\u000a              self.state = 'ID';\u000a            }\u000a\u000a            continue;\u000a        }\u000a      }\u000a    } catch (e) {\u000a      // If we are currently parsing a cue, report what we have.\u000a      if (self.state === 'CUETEXT' && self.cue && self.oncue) {\u000a        self.oncue(self.cue);\u000a      }\u000a\u000a      self.cue = null; // Enter BADWEBVTT state if header was not parsed correctly otherwise\u000a      // another exception occurred so enter BADCUE state.\u000a\u000a      self.state = self.state === 'INITIAL' ? 'BADWEBVTT' : 'BADCUE';\u000a    }\u000a\u000a    return this;\u000a  },\u000a  flush: function flush() {\u000a    var self = this;\u000a\u000a    try {\u000a      // Finish decoding the stream.\u000a      self.buffer += self.decoder.decode(); // Synthesize the end of the current cue or region.\u000a\u000a      if (self.cue || self.state === 'HEADER') {\u000a        self.buffer += '\u005cn\u005cn';\u000a        self.parse();\u000a      } // If we've flushed, parsed, and we're still on the INITIAL state then\u000a      // that means we don't have enough of the stream to parse the first\u000a      // line.\u000a\u000a\u000a      if (self.state === 'INITIAL') {\u000a        throw new Error('Malformed WebVTT signature.');\u000a      }\u000a    } catch (e) {\u000a      throw e;\u000a    }\u000a\u000a    if (self.onflush) {\u000a      self.onflush();\u000a    }\u000a\u000a    return this;\u000a  }\u000a};\u000a\u000a/* harmony default export */ var vttparser = (VTTParser);\u000a// CONCATENATED MODULE: ./src/utils/cues.ts\u000a\u000afunction newCue(track, startTime, endTime, captionScreen) {\u000a  var result = [];\u000a  var row; // the type data states this is VTTCue, but it can potentially be a TextTrackCue on old browsers\u000a\u000a  var cue;\u000a  var indenting;\u000a  var indent;\u000a  var text;\u000a  var VTTCue = window.VTTCue || TextTrackCue;\u000a\u000a  for (var r = 0; r < captionScreen.rows.length; r++) {\u000a    row = captionScreen.rows[r];\u000a    indenting = true;\u000a    indent = 0;\u000a    text = '';\u000a\u000a    if (!row.isEmpty()) {\u000a      for (var c = 0; c < row.chars.length; c++) {\u000a        if (row.chars[c].uchar.match(/\u005cs/) && indenting) {\u000a          indent++;\u000a        } else {\u000a          text += row.chars[c].uchar;\u000a          indenting = false;\u000a        }\u000a      } // To be used for cleaning-up orphaned roll-up captions\u000a\u000a\u000a      row.cueStartTime = startTime; // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE\u000a\u000a      if (startTime === endTime) {\u000a        endTime += 0.0001;\u000a      }\u000a\u000a      cue = new VTTCue(startTime, endTime, fixLineBreaks(text.trim()));\u000a\u000a      if (indent >= 16) {\u000a        indent--;\u000a      } else {\u000a        indent++;\u000a      } // VTTCue.line get's flakey when using controls, so let's now include line 13&14\u000a      // also, drop line 1 since it's to close to the top\u000a\u000a\u000a      if (navigator.userAgent.match(/Firefox\u005c//)) {\u000a        cue.line = r + 1;\u000a      } else {\u000a        cue.line = r > 7 ? r - 2 : r + 1;\u000a      }\u000a\u000a      cue.align = 'left'; // Clamp the position between 0 and 100 - if out of these bounds, Firefox throws an exception and captions break\u000a\u000a      cue.position = Math.max(0, Math.min(100, 100 * (indent / 32)));\u000a      result.push(cue);\u000a\u000a      if (track) {\u000a        track.addCue(cue);\u000a      }\u000a    }\u000a  }\u000a\u000a  return result;\u000a}\u000a// CONCATENATED MODULE: ./src/utils/cea-608-parser.ts\u000a\u000a/**\u000a *\u000a * This code was ported from the dash.js project at:\u000a *   https://github.com/Dash-Industry-Forum/dash.js/blob/development/externals/cea608-parser.js\u000a *   https://github.com/Dash-Industry-Forum/dash.js/commit/8269b26a761e0853bb21d78780ed945144ecdd4d#diff-71bc295a2d6b6b7093a1d3290d53a4b2\u000a *\u000a * The original copyright appears below:\u000a *\u000a * The copyright in this software is being made available under the BSD License,\u000a * included below. This software may be subject to other third party and contributor\u000a * rights, including patent rights, and no such rights are granted under this license.\u000a *\u000a * Copyright (c) 2015-2016, DASH Industry Forum.\u000a * All rights reserved.\u000a *\u000a * Redistribution and use in source and binary forms, with or without modification,\u000a * are permitted provided that the following conditions are met:\u000a *  1. Redistributions of source code must retain the above copyright notice, this\u000a *  list of conditions and the following disclaimer.\u000a *  * Redistributions in binary form must reproduce the above copyright notice,\u000a *  this list of conditions and the following disclaimer in the documentation and/or\u000a *  other materials provided with the distribution.\u000a *  2. Neither the name of Dash Industry Forum nor the names of its\u000a *  contributors may be used to endorse or promote products derived from this software\u000a *  without specific prior written permission.\u000a *\u000a *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS AS IS AND ANY\u000a *  EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\u000a *  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\u000a *  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,\u000a *  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\u000a *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\u000a *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\u000a *  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\u000a *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\u000a *  POSSIBILITY OF SUCH DAMAGE.\u000a */\u000a\u000a/**\u000a *  Exceptions from regular ASCII. CodePoints are mapped to UTF-16 codes\u000a */\u000a\u000avar specialCea608CharsCodes = {\u000a  0x2a: 0xe1,\u000a  // lowercase a, acute accent\u000a  0x5c: 0xe9,\u000a  // lowercase e, acute accent\u000a  0x5e: 0xed,\u000a  // lowercase i, acute accent\u000a  0x5f: 0xf3,\u000a  // lowercase o, acute accent\u000a  0x60: 0xfa,\u000a  // lowercase u, acute accent\u000a  0x7b: 0xe7,\u000a  // lowercase c with cedilla\u000a  0x7c: 0xf7,\u000a  // division symbol\u000a  0x7d: 0xd1,\u000a  // uppercase N tilde\u000a  0x7e: 0xf1,\u000a  // lowercase n tilde\u000a  0x7f: 0x2588,\u000a  // Full block\u000a  // THIS BLOCK INCLUDES THE 16 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\u000a  // THAT COME FROM HI BYTE=0x11 AND LOW BETWEEN 0x30 AND 0x3F\u000a  // THIS MEANS THAT \u005cx50 MUST BE ADDED TO THE VALUES\u000a  0x80: 0xae,\u000a  // Registered symbol (R)\u000a  0x81: 0xb0,\u000a  // degree sign\u000a  0x82: 0xbd,\u000a  // 1/2 symbol\u000a  0x83: 0xbf,\u000a  // Inverted (open) question mark\u000a  0x84: 0x2122,\u000a  // Trademark symbol (TM)\u000a  0x85: 0xa2,\u000a  // Cents symbol\u000a  0x86: 0xa3,\u000a  // Pounds sterling\u000a  0x87: 0x266a,\u000a  // Music 8'th note\u000a  0x88: 0xe0,\u000a  // lowercase a, grave accent\u000a  0x89: 0x20,\u000a  // transparent space (regular)\u000a  0x8a: 0xe8,\u000a  // lowercase e, grave accent\u000a  0x8b: 0xe2,\u000a  // lowercase a, circumflex accent\u000a  0x8c: 0xea,\u000a  // lowercase e, circumflex accent\u000a  0x8d: 0xee,\u000a  // lowercase i, circumflex accent\u000a  0x8e: 0xf4,\u000a  // lowercase o, circumflex accent\u000a  0x8f: 0xfb,\u000a  // lowercase u, circumflex accent\u000a  // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\u000a  // THAT COME FROM HI BYTE=0x12 AND LOW BETWEEN 0x20 AND 0x3F\u000a  0x90: 0xc1,\u000a  // capital letter A with acute\u000a  0x91: 0xc9,\u000a  // capital letter E with acute\u000a  0x92: 0xd3,\u000a  // capital letter O with acute\u000a  0x93: 0xda,\u000a  // capital letter U with acute\u000a  0x94: 0xdc,\u000a  // capital letter U with diaresis\u000a  0x95: 0xfc,\u000a  // lowercase letter U with diaeresis\u000a  0x96: 0x2018,\u000a  // opening single quote\u000a  0x97: 0xa1,\u000a  // inverted exclamation mark\u000a  0x98: 0x2a,\u000a  // asterisk\u000a  0x99: 0x2019,\u000a  // closing single quote\u000a  0x9a: 0x2501,\u000a  // box drawings heavy horizontal\u000a  0x9b: 0xa9,\u000a  // copyright sign\u000a  0x9c: 0x2120,\u000a  // Service mark\u000a  0x9d: 0x2022,\u000a  // (round) bullet\u000a  0x9e: 0x201c,\u000a  // Left double quotation mark\u000a  0x9f: 0x201d,\u000a  // Right double quotation mark\u000a  0xa0: 0xc0,\u000a  // uppercase A, grave accent\u000a  0xa1: 0xc2,\u000a  // uppercase A, circumflex\u000a  0xa2: 0xc7,\u000a  // uppercase C with cedilla\u000a  0xa3: 0xc8,\u000a  // uppercase E, grave accent\u000a  0xa4: 0xca,\u000a  // uppercase E, circumflex\u000a  0xa5: 0xcb,\u000a  // capital letter E with diaresis\u000a  0xa6: 0xeb,\u000a  // lowercase letter e with diaresis\u000a  0xa7: 0xce,\u000a  // uppercase I, circumflex\u000a  0xa8: 0xcf,\u000a  // uppercase I, with diaresis\u000a  0xa9: 0xef,\u000a  // lowercase i, with diaresis\u000a  0xaa: 0xd4,\u000a  // uppercase O, circumflex\u000a  0xab: 0xd9,\u000a  // uppercase U, grave accent\u000a  0xac: 0xf9,\u000a  // lowercase u, grave accent\u000a  0xad: 0xdb,\u000a  // uppercase U, circumflex\u000a  0xae: 0xab,\u000a  // left-pointing double angle quotation mark\u000a  0xaf: 0xbb,\u000a  // right-pointing double angle quotation mark\u000a  // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\u000a  // THAT COME FROM HI BYTE=0x13 AND LOW BETWEEN 0x20 AND 0x3F\u000a  0xb0: 0xc3,\u000a  // Uppercase A, tilde\u000a  0xb1: 0xe3,\u000a  // Lowercase a, tilde\u000a  0xb2: 0xcd,\u000a  // Uppercase I, acute accent\u000a  0xb3: 0xcc,\u000a  // Uppercase I, grave accent\u000a  0xb4: 0xec,\u000a  // Lowercase i, grave accent\u000a  0xb5: 0xd2,\u000a  // Uppercase O, grave accent\u000a  0xb6: 0xf2,\u000a  // Lowercase o, grave accent\u000a  0xb7: 0xd5,\u000a  // Uppercase O, tilde\u000a  0xb8: 0xf5,\u000a  // Lowercase o, tilde\u000a  0xb9: 0x7b,\u000a  // Open curly brace\u000a  0xba: 0x7d,\u000a  // Closing curly brace\u000a  0xbb: 0x5c,\u000a  // Backslash\u000a  0xbc: 0x5e,\u000a  // Caret\u000a  0xbd: 0x5f,\u000a  // Underscore\u000a  0xbe: 0x7c,\u000a  // Pipe (vertical line)\u000a  0xbf: 0x223c,\u000a  // Tilde operator\u000a  0xc0: 0xc4,\u000a  // Uppercase A, umlaut\u000a  0xc1: 0xe4,\u000a  // Lowercase A, umlaut\u000a  0xc2: 0xd6,\u000a  // Uppercase O, umlaut\u000a  0xc3: 0xf6,\u000a  // Lowercase o, umlaut\u000a  0xc4: 0xdf,\u000a  // Esszett (sharp S)\u000a  0xc5: 0xa5,\u000a  // Yen symbol\u000a  0xc6: 0xa4,\u000a  // Generic currency sign\u000a  0xc7: 0x2503,\u000a  // Box drawings heavy vertical\u000a  0xc8: 0xc5,\u000a  // Uppercase A, ring\u000a  0xc9: 0xe5,\u000a  // Lowercase A, ring\u000a  0xca: 0xd8,\u000a  // Uppercase O, stroke\u000a  0xcb: 0xf8,\u000a  // Lowercase o, strok\u000a  0xcc: 0x250f,\u000a  // Box drawings heavy down and right\u000a  0xcd: 0x2513,\u000a  // Box drawings heavy down and left\u000a  0xce: 0x2517,\u000a  // Box drawings heavy up and right\u000a  0xcf: 0x251b // Box drawings heavy up and left\u000a\u000a};\u000a/**\u000a * Utils\u000a */\u000a\u000avar getCharForByte = function getCharForByte(_byte) {\u000a  var charCode = _byte;\u000a\u000a  if (specialCea608CharsCodes.hasOwnProperty(_byte)) {\u000a    charCode = specialCea608CharsCodes[_byte];\u000a  }\u000a\u000a  return String.fromCharCode(charCode);\u000a};\u000a\u000avar NR_ROWS = 15;\u000avar NR_COLS = 100; // Tables to look up row from PAC data\u000a\u000avar rowsLowCh1 = {\u000a  0x11: 1,\u000a  0x12: 3,\u000a  0x15: 5,\u000a  0x16: 7,\u000a  0x17: 9,\u000a  0x10: 11,\u000a  0x13: 12,\u000a  0x14: 14\u000a};\u000avar rowsHighCh1 = {\u000a  0x11: 2,\u000a  0x12: 4,\u000a  0x15: 6,\u000a  0x16: 8,\u000a  0x17: 10,\u000a  0x13: 13,\u000a  0x14: 15\u000a};\u000avar rowsLowCh2 = {\u000a  0x19: 1,\u000a  0x1A: 3,\u000a  0x1D: 5,\u000a  0x1E: 7,\u000a  0x1F: 9,\u000a  0x18: 11,\u000a  0x1B: 12,\u000a  0x1C: 14\u000a};\u000avar rowsHighCh2 = {\u000a  0x19: 2,\u000a  0x1A: 4,\u000a  0x1D: 6,\u000a  0x1E: 8,\u000a  0x1F: 10,\u000a  0x1B: 13,\u000a  0x1C: 15\u000a};\u000avar backgroundColors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'black', 'transparent'];\u000avar VerboseLevel;\u000a\u000a(function (VerboseLevel) {\u000a  VerboseLevel[VerboseLevel["ERROR"] = 0] = "ERROR";\u000a  VerboseLevel[VerboseLevel["TEXT"] = 1] = "TEXT";\u000a  VerboseLevel[VerboseLevel["WARNING"] = 2] = "WARNING";\u000a  VerboseLevel[VerboseLevel["INFO"] = 2] = "INFO";\u000a  VerboseLevel[VerboseLevel["DEBUG"] = 3] = "DEBUG";\u000a  VerboseLevel[VerboseLevel["DATA"] = 3] = "DATA";\u000a})(VerboseLevel || (VerboseLevel = {}));\u000a\u000avar cea_608_parser_CaptionsLogger = /*#__PURE__*/function () {\u000a  function CaptionsLogger() {\u000a    this.time = null;\u000a    this.verboseLevel = VerboseLevel.ERROR;\u000a  }\u000a\u000a  var _proto = CaptionsLogger.prototype;\u000a\u000a  _proto.log = function log(severity, msg) {\u000a    if (this.verboseLevel >= severity) {\u000a      logger["logger"].log(this.time + " [" + severity + "] " + msg);\u000a    }\u000a  };\u000a\u000a  return CaptionsLogger;\u000a}();\u000a\u000avar numArrayToHexArray = function numArrayToHexArray(numArray) {\u000a  var hexArray = [];\u000a\u000a  for (var j = 0; j < numArray.length; j++) {\u000a    hexArray.push(numArray[j].toString(16));\u000a  }\u000a\u000a  return hexArray;\u000a};\u000a\u000avar PenState = /*#__PURE__*/function () {\u000a  function PenState(foreground, underline, italics, background, flash) {\u000a    this.foreground = void 0;\u000a    this.underline = void 0;\u000a    this.italics = void 0;\u000a    this.background = void 0;\u000a    this.flash = void 0;\u000a    this.foreground = foreground || 'white';\u000a    this.underline = underline || false;\u000a    this.italics = italics || false;\u000a    this.background = background || 'black';\u000a    this.flash = flash || false;\u000a  }\u000a\u000a  var _proto2 = PenState.prototype;\u000a\u000a  _proto2.reset = function reset() {\u000a    this.foreground = 'white';\u000a    this.underline = false;\u000a    this.italics = false;\u000a    this.background = 'black';\u000a    this.flash = false;\u000a  };\u000a\u000a  _proto2.setStyles = function setStyles(styles) {\u000a    var attribs = ['foreground', 'underline', 'italics', 'background', 'flash'];\u000a\u000a    for (var i = 0; i < attribs.length; i++) {\u000a      var style = attribs[i];\u000a\u000a      if (styles.hasOwnProperty(style)) {\u000a        this[style] = styles[style];\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto2.isDefault = function isDefault() {\u000a    return this.foreground === 'white' && !this.underline && !this.italics && this.background === 'black' && !this.flash;\u000a  };\u000a\u000a  _proto2.equals = function equals(other) {\u000a    return this.foreground === other.foreground && this.underline === other.underline && this.italics === other.italics && this.background === other.background && this.flash === other.flash;\u000a  };\u000a\u000a  _proto2.copy = function copy(newPenState) {\u000a    this.foreground = newPenState.foreground;\u000a    this.underline = newPenState.underline;\u000a    this.italics = newPenState.italics;\u000a    this.background = newPenState.background;\u000a    this.flash = newPenState.flash;\u000a  };\u000a\u000a  _proto2.toString = function toString() {\u000a    return 'color=' + this.foreground + ', underline=' + this.underline + ', italics=' + this.italics + ', background=' + this.background + ', flash=' + this.flash;\u000a  };\u000a\u000a  return PenState;\u000a}();\u000a/**\u000a * Unicode character with styling and background.\u000a * @constructor\u000a */\u000a\u000a\u000avar StyledUnicodeChar = /*#__PURE__*/function () {\u000a  function StyledUnicodeChar(uchar, foreground, underline, italics, background, flash) {\u000a    this.uchar = void 0;\u000a    this.penState = void 0;\u000a    this.uchar = uchar || ' '; // unicode character\u000a\u000a    this.penState = new PenState(foreground, underline, italics, background, flash);\u000a  }\u000a\u000a  var _proto3 = StyledUnicodeChar.prototype;\u000a\u000a  _proto3.reset = function reset() {\u000a    this.uchar = ' ';\u000a    this.penState.reset();\u000a  };\u000a\u000a  _proto3.setChar = function setChar(uchar, newPenState) {\u000a    this.uchar = uchar;\u000a    this.penState.copy(newPenState);\u000a  };\u000a\u000a  _proto3.setPenState = function setPenState(newPenState) {\u000a    this.penState.copy(newPenState);\u000a  };\u000a\u000a  _proto3.equals = function equals(other) {\u000a    return this.uchar === other.uchar && this.penState.equals(other.penState);\u000a  };\u000a\u000a  _proto3.copy = function copy(newChar) {\u000a    this.uchar = newChar.uchar;\u000a    this.penState.copy(newChar.penState);\u000a  };\u000a\u000a  _proto3.isEmpty = function isEmpty() {\u000a    return this.uchar === ' ' && this.penState.isDefault();\u000a  };\u000a\u000a  return StyledUnicodeChar;\u000a}();\u000a/**\u000a * CEA-608 row consisting of NR_COLS instances of StyledUnicodeChar.\u000a * @constructor\u000a */\u000a\u000a\u000avar Row = /*#__PURE__*/function () {\u000a  function Row(logger) {\u000a    this.chars = void 0;\u000a    this.pos = void 0;\u000a    this.currPenState = void 0;\u000a    this.cueStartTime = void 0;\u000a    this.logger = void 0;\u000a    this.chars = [];\u000a\u000a    for (var i = 0; i < NR_COLS; i++) {\u000a      this.chars.push(new StyledUnicodeChar());\u000a    }\u000a\u000a    this.logger = logger;\u000a    this.pos = 0;\u000a    this.currPenState = new PenState();\u000a  }\u000a\u000a  var _proto4 = Row.prototype;\u000a\u000a  _proto4.equals = function equals(other) {\u000a    var equal = true;\u000a\u000a    for (var i = 0; i < NR_COLS; i++) {\u000a      if (!this.chars[i].equals(other.chars[i])) {\u000a        equal = false;\u000a        break;\u000a      }\u000a    }\u000a\u000a    return equal;\u000a  };\u000a\u000a  _proto4.copy = function copy(other) {\u000a    for (var i = 0; i < NR_COLS; i++) {\u000a      this.chars[i].copy(other.chars[i]);\u000a    }\u000a  };\u000a\u000a  _proto4.isEmpty = function isEmpty() {\u000a    var empty = true;\u000a\u000a    for (var i = 0; i < NR_COLS; i++) {\u000a      if (!this.chars[i].isEmpty()) {\u000a        empty = false;\u000a        break;\u000a      }\u000a    }\u000a\u000a    return empty;\u000a  }\u000a  /**\u000a   *  Set the cursor to a valid column.\u000a   */\u000a  ;\u000a\u000a  _proto4.setCursor = function setCursor(absPos) {\u000a    if (this.pos !== absPos) {\u000a      this.pos = absPos;\u000a    }\u000a\u000a    if (this.pos < 0) {\u000a      this.logger.log(VerboseLevel.DEBUG, 'Negative cursor position ' + this.pos);\u000a      this.pos = 0;\u000a    } else if (this.pos > NR_COLS) {\u000a      this.logger.log(VerboseLevel.DEBUG, 'Too large cursor position ' + this.pos);\u000a      this.pos = NR_COLS;\u000a    }\u000a  }\u000a  /**\u000a   * Move the cursor relative to current position.\u000a   */\u000a  ;\u000a\u000a  _proto4.moveCursor = function moveCursor(relPos) {\u000a    var newPos = this.pos + relPos;\u000a\u000a    if (relPos > 1) {\u000a      for (var i = this.pos + 1; i < newPos + 1; i++) {\u000a        this.chars[i].setPenState(this.currPenState);\u000a      }\u000a    }\u000a\u000a    this.setCursor(newPos);\u000a  }\u000a  /**\u000a   * Backspace, move one step back and clear character.\u000a   */\u000a  ;\u000a\u000a  _proto4.backSpace = function backSpace() {\u000a    this.moveCursor(-1);\u000a    this.chars[this.pos].setChar(' ', this.currPenState);\u000a  };\u000a\u000a  _proto4.insertChar = function insertChar(_byte2) {\u000a    if (_byte2 >= 0x90) {\u000a      // Extended char\u000a      this.backSpace();\u000a    }\u000a\u000a    var _char = getCharForByte(_byte2);\u000a\u000a    if (this.pos >= NR_COLS) {\u000a      this.logger.log(VerboseLevel.ERROR, 'Cannot insert ' + _byte2.toString(16) + ' (' + _char + ') at position ' + this.pos + '. Skipping it!');\u000a      return;\u000a    }\u000a\u000a    this.chars[this.pos].setChar(_char, this.currPenState);\u000a    this.moveCursor(1);\u000a  };\u000a\u000a  _proto4.clearFromPos = function clearFromPos(startPos) {\u000a    var i;\u000a\u000a    for (i = startPos; i < NR_COLS; i++) {\u000a      this.chars[i].reset();\u000a    }\u000a  };\u000a\u000a  _proto4.clear = function clear() {\u000a    this.clearFromPos(0);\u000a    this.pos = 0;\u000a    this.currPenState.reset();\u000a  };\u000a\u000a  _proto4.clearToEndOfRow = function clearToEndOfRow() {\u000a    this.clearFromPos(this.pos);\u000a  };\u000a\u000a  _proto4.getTextString = function getTextString() {\u000a    var chars = [];\u000a    var empty = true;\u000a\u000a    for (var i = 0; i < NR_COLS; i++) {\u000a      var _char2 = this.chars[i].uchar;\u000a\u000a      if (_char2 !== ' ') {\u000a        empty = false;\u000a      }\u000a\u000a      chars.push(_char2);\u000a    }\u000a\u000a    if (empty) {\u000a      return '';\u000a    } else {\u000a      return chars.join('');\u000a    }\u000a  };\u000a\u000a  _proto4.setPenStyles = function setPenStyles(styles) {\u000a    this.currPenState.setStyles(styles);\u000a    var currChar = this.chars[this.pos];\u000a    currChar.setPenState(this.currPenState);\u000a  };\u000a\u000a  return Row;\u000a}();\u000a/**\u000a * Keep a CEA-608 screen of 32x15 styled characters\u000a * @constructor\u000a */\u000a\u000avar CaptionScreen = /*#__PURE__*/function () {\u000a  function CaptionScreen(logger) {\u000a    this.rows = void 0;\u000a    this.currRow = void 0;\u000a    this.nrRollUpRows = void 0;\u000a    this.lastOutputScreen = void 0;\u000a    this.logger = void 0;\u000a    this.rows = [];\u000a\u000a    for (var i = 0; i < NR_ROWS; i++) {\u000a      this.rows.push(new Row(logger));\u000a    } // Note that we use zero-based numbering (0-14)\u000a\u000a\u000a    this.logger = logger;\u000a    this.currRow = NR_ROWS - 1;\u000a    this.nrRollUpRows = null;\u000a    this.lastOutputScreen = null;\u000a    this.reset();\u000a  }\u000a\u000a  var _proto5 = CaptionScreen.prototype;\u000a\u000a  _proto5.reset = function reset() {\u000a    for (var i = 0; i < NR_ROWS; i++) {\u000a      this.rows[i].clear();\u000a    }\u000a\u000a    this.currRow = NR_ROWS - 1;\u000a  };\u000a\u000a  _proto5.equals = function equals(other) {\u000a    var equal = true;\u000a\u000a    for (var i = 0; i < NR_ROWS; i++) {\u000a      if (!this.rows[i].equals(other.rows[i])) {\u000a        equal = false;\u000a        break;\u000a      }\u000a    }\u000a\u000a    return equal;\u000a  };\u000a\u000a  _proto5.copy = function copy(other) {\u000a    for (var i = 0; i < NR_ROWS; i++) {\u000a      this.rows[i].copy(other.rows[i]);\u000a    }\u000a  };\u000a\u000a  _proto5.isEmpty = function isEmpty() {\u000a    var empty = true;\u000a\u000a    for (var i = 0; i < NR_ROWS; i++) {\u000a      if (!this.rows[i].isEmpty()) {\u000a        empty = false;\u000a        break;\u000a      }\u000a    }\u000a\u000a    return empty;\u000a  };\u000a\u000a  _proto5.backSpace = function backSpace() {\u000a    var row = this.rows[this.currRow];\u000a    row.backSpace();\u000a  };\u000a\u000a  _proto5.clearToEndOfRow = function clearToEndOfRow() {\u000a    var row = this.rows[this.currRow];\u000a    row.clearToEndOfRow();\u000a  }\u000a  /**\u000a   * Insert a character (without styling) in the current row.\u000a   */\u000a  ;\u000a\u000a  _proto5.insertChar = function insertChar(_char3) {\u000a    var row = this.rows[this.currRow];\u000a    row.insertChar(_char3);\u000a  };\u000a\u000a  _proto5.setPen = function setPen(styles) {\u000a    var row = this.rows[this.currRow];\u000a    row.setPenStyles(styles);\u000a  };\u000a\u000a  _proto5.moveCursor = function moveCursor(relPos) {\u000a    var row = this.rows[this.currRow];\u000a    row.moveCursor(relPos);\u000a  };\u000a\u000a  _proto5.setCursor = function setCursor(absPos) {\u000a    this.logger.log(VerboseLevel.INFO, 'setCursor: ' + absPos);\u000a    var row = this.rows[this.currRow];\u000a    row.setCursor(absPos);\u000a  };\u000a\u000a  _proto5.setPAC = function setPAC(pacData) {\u000a    this.logger.log(VerboseLevel.INFO, 'pacData = ' + JSON.stringify(pacData));\u000a    var newRow = pacData.row - 1;\u000a\u000a    if (this.nrRollUpRows && newRow < this.nrRollUpRows - 1) {\u000a      newRow = this.nrRollUpRows - 1;\u000a    } // Make sure this only affects Roll-up Captions by checking this.nrRollUpRows\u000a\u000a\u000a    if (this.nrRollUpRows && this.currRow !== newRow) {\u000a      // clear all rows first\u000a      for (var i = 0; i < NR_ROWS; i++) {\u000a        this.rows[i].clear();\u000a      } // Copy this.nrRollUpRows rows from lastOutputScreen and place it in the newRow location\u000a      // topRowIndex - the start of rows to copy (inclusive index)\u000a\u000a\u000a      var topRowIndex = this.currRow + 1 - this.nrRollUpRows; // We only copy if the last position was already shown.\u000a      // We use the cueStartTime value to check this.\u000a\u000a      var lastOutputScreen = this.lastOutputScreen;\u000a\u000a      if (lastOutputScreen) {\u000a        var prevLineTime = lastOutputScreen.rows[topRowIndex].cueStartTime;\u000a        var time = this.logger.time;\u000a\u000a        if (prevLineTime && time !== null && prevLineTime < time) {\u000a          for (var _i = 0; _i < this.nrRollUpRows; _i++) {\u000a            this.rows[newRow - this.nrRollUpRows + _i + 1].copy(lastOutputScreen.rows[topRowIndex + _i]);\u000a          }\u000a        }\u000a      }\u000a    }\u000a\u000a    this.currRow = newRow;\u000a    var row = this.rows[this.currRow];\u000a\u000a    if (pacData.indent !== null) {\u000a      var indent = pacData.indent;\u000a      var prevPos = Math.max(indent - 1, 0);\u000a      row.setCursor(pacData.indent);\u000a      pacData.color = row.chars[prevPos].penState.foreground;\u000a    }\u000a\u000a    var styles = {\u000a      foreground: pacData.color,\u000a      underline: pacData.underline,\u000a      italics: pacData.italics,\u000a      background: 'black',\u000a      flash: false\u000a    };\u000a    this.setPen(styles);\u000a  }\u000a  /**\u000a   * Set background/extra foreground, but first do back_space, and then insert space (backwards compatibility).\u000a   */\u000a  ;\u000a\u000a  _proto5.setBkgData = function setBkgData(bkgData) {\u000a    this.logger.log(VerboseLevel.INFO, 'bkgData = ' + JSON.stringify(bkgData));\u000a    this.backSpace();\u000a    this.setPen(bkgData);\u000a    this.insertChar(0x20); // Space\u000a  };\u000a\u000a  _proto5.setRollUpRows = function setRollUpRows(nrRows) {\u000a    this.nrRollUpRows = nrRows;\u000a  };\u000a\u000a  _proto5.rollUp = function rollUp() {\u000a    if (this.nrRollUpRows === null) {\u000a      this.logger.log(VerboseLevel.DEBUG, 'roll_up but nrRollUpRows not set yet');\u000a      return; // Not properly setup\u000a    }\u000a\u000a    this.logger.log(VerboseLevel.TEXT, this.getDisplayText());\u000a    var topRowIndex = this.currRow + 1 - this.nrRollUpRows;\u000a    var topRow = this.rows.splice(topRowIndex, 1)[0];\u000a    topRow.clear();\u000a    this.rows.splice(this.currRow, 0, topRow);\u000a    this.logger.log(VerboseLevel.INFO, 'Rolling up'); // this.logger.log(VerboseLevel.TEXT, this.get_display_text())\u000a  }\u000a  /**\u000a   * Get all non-empty rows with as unicode text.\u000a   */\u000a  ;\u000a\u000a  _proto5.getDisplayText = function getDisplayText(asOneRow) {\u000a    asOneRow = asOneRow || false;\u000a    var displayText = [];\u000a    var text = '';\u000a    var rowNr = -1;\u000a\u000a    for (var i = 0; i < NR_ROWS; i++) {\u000a      var rowText = this.rows[i].getTextString();\u000a\u000a      if (rowText) {\u000a        rowNr = i + 1;\u000a\u000a        if (asOneRow) {\u000a          displayText.push('Row ' + rowNr + ': \u005c'' + rowText + '\u005c'');\u000a        } else {\u000a          displayText.push(rowText.trim());\u000a        }\u000a      }\u000a    }\u000a\u000a    if (displayText.length > 0) {\u000a      if (asOneRow) {\u000a        text = '[' + displayText.join(' | ') + ']';\u000a      } else {\u000a        text = displayText.join('\u005cn');\u000a      }\u000a    }\u000a\u000a    return text;\u000a  };\u000a\u000a  _proto5.getTextAndFormat = function getTextAndFormat() {\u000a    return this.rows;\u000a  };\u000a\u000a  return CaptionScreen;\u000a}(); // var modes = ['MODE_ROLL-UP', 'MODE_POP-ON', 'MODE_PAINT-ON', 'MODE_TEXT'];\u000a\u000avar Cea608Channel = /*#__PURE__*/function () {\u000a  function Cea608Channel(channelNumber, outputFilter, logger) {\u000a    this.chNr = void 0;\u000a    this.outputFilter = void 0;\u000a    this.mode = void 0;\u000a    this.verbose = void 0;\u000a    this.displayedMemory = void 0;\u000a    this.nonDisplayedMemory = void 0;\u000a    this.lastOutputScreen = void 0;\u000a    this.currRollUpRow = void 0;\u000a    this.writeScreen = void 0;\u000a    this.cueStartTime = void 0;\u000a    this.logger = void 0;\u000a    this.chNr = channelNumber;\u000a    this.outputFilter = outputFilter;\u000a    this.mode = null;\u000a    this.verbose = 0;\u000a    this.displayedMemory = new CaptionScreen(logger);\u000a    this.nonDisplayedMemory = new CaptionScreen(logger);\u000a    this.lastOutputScreen = new CaptionScreen(logger);\u000a    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\u000a    this.writeScreen = this.displayedMemory;\u000a    this.mode = null;\u000a    this.cueStartTime = null; // Keeps track of where a cue started.\u000a\u000a    this.logger = logger;\u000a  }\u000a\u000a  var _proto6 = Cea608Channel.prototype;\u000a\u000a  _proto6.reset = function reset() {\u000a    this.mode = null;\u000a    this.displayedMemory.reset();\u000a    this.nonDisplayedMemory.reset();\u000a    this.lastOutputScreen.reset();\u000a    this.outputFilter.reset();\u000a    this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\u000a    this.writeScreen = this.displayedMemory;\u000a    this.mode = null;\u000a    this.cueStartTime = null;\u000a  };\u000a\u000a  _proto6.getHandler = function getHandler() {\u000a    return this.outputFilter;\u000a  };\u000a\u000a  _proto6.setHandler = function setHandler(newHandler) {\u000a    this.outputFilter = newHandler;\u000a  };\u000a\u000a  _proto6.setPAC = function setPAC(pacData) {\u000a    this.writeScreen.setPAC(pacData);\u000a  };\u000a\u000a  _proto6.setBkgData = function setBkgData(bkgData) {\u000a    this.writeScreen.setBkgData(bkgData);\u000a  };\u000a\u000a  _proto6.setMode = function setMode(newMode) {\u000a    if (newMode === this.mode) {\u000a      return;\u000a    }\u000a\u000a    this.mode = newMode;\u000a    this.logger.log(VerboseLevel.INFO, 'MODE=' + newMode);\u000a\u000a    if (this.mode === 'MODE_POP-ON') {\u000a      this.writeScreen = this.nonDisplayedMemory;\u000a    } else {\u000a      this.writeScreen = this.displayedMemory;\u000a      this.writeScreen.reset();\u000a    }\u000a\u000a    if (this.mode !== 'MODE_ROLL-UP') {\u000a      this.displayedMemory.nrRollUpRows = null;\u000a      this.nonDisplayedMemory.nrRollUpRows = null;\u000a    }\u000a\u000a    this.mode = newMode;\u000a  };\u000a\u000a  _proto6.insertChars = function insertChars(chars) {\u000a    for (var i = 0; i < chars.length; i++) {\u000a      this.writeScreen.insertChar(chars[i]);\u000a    }\u000a\u000a    var screen = this.writeScreen === this.displayedMemory ? 'DISP' : 'NON_DISP';\u000a    this.logger.log(VerboseLevel.INFO, screen + ': ' + this.writeScreen.getDisplayText(true));\u000a\u000a    if (this.mode === 'MODE_PAINT-ON' || this.mode === 'MODE_ROLL-UP') {\u000a      this.logger.log(VerboseLevel.TEXT, 'DISPLAYED: ' + this.displayedMemory.getDisplayText(true));\u000a      this.outputDataUpdate();\u000a    }\u000a  };\u000a\u000a  _proto6.ccRCL = function ccRCL() {\u000a    // Resume Caption Loading (switch mode to Pop On)\u000a    this.logger.log(VerboseLevel.INFO, 'RCL - Resume Caption Loading');\u000a    this.setMode('MODE_POP-ON');\u000a  };\u000a\u000a  _proto6.ccBS = function ccBS() {\u000a    // BackSpace\u000a    this.logger.log(VerboseLevel.INFO, 'BS - BackSpace');\u000a\u000a    if (this.mode === 'MODE_TEXT') {\u000a      return;\u000a    }\u000a\u000a    this.writeScreen.backSpace();\u000a\u000a    if (this.writeScreen === this.displayedMemory) {\u000a      this.outputDataUpdate();\u000a    }\u000a  };\u000a\u000a  _proto6.ccAOF = function ccAOF() {// Reserved (formerly Alarm Off)\u000a  };\u000a\u000a  _proto6.ccAON = function ccAON() {// Reserved (formerly Alarm On)\u000a  };\u000a\u000a  _proto6.ccDER = function ccDER() {\u000a    // Delete to End of Row\u000a    this.logger.log(VerboseLevel.INFO, 'DER- Delete to End of Row');\u000a    this.writeScreen.clearToEndOfRow();\u000a    this.outputDataUpdate();\u000a  };\u000a\u000a  _proto6.ccRU = function ccRU(nrRows) {\u000a    // Roll-Up Captions-2,3,or 4 Rows\u000a    this.logger.log(VerboseLevel.INFO, 'RU(' + nrRows + ') - Roll Up');\u000a    this.writeScreen = this.displayedMemory;\u000a    this.setMode('MODE_ROLL-UP');\u000a    this.writeScreen.setRollUpRows(nrRows);\u000a  };\u000a\u000a  _proto6.ccFON = function ccFON() {\u000a    // Flash On\u000a    this.logger.log(VerboseLevel.INFO, 'FON - Flash On');\u000a    this.writeScreen.setPen({\u000a      flash: true\u000a    });\u000a  };\u000a\u000a  _proto6.ccRDC = function ccRDC() {\u000a    // Resume Direct Captioning (switch mode to PaintOn)\u000a    this.logger.log(VerboseLevel.INFO, 'RDC - Resume Direct Captioning');\u000a    this.setMode('MODE_PAINT-ON');\u000a  };\u000a\u000a  _proto6.ccTR = function ccTR() {\u000a    // Text Restart in text mode (not supported, however)\u000a    this.logger.log(VerboseLevel.INFO, 'TR');\u000a    this.setMode('MODE_TEXT');\u000a  };\u000a\u000a  _proto6.ccRTD = function ccRTD() {\u000a    // Resume Text Display in Text mode (not supported, however)\u000a    this.logger.log(VerboseLevel.INFO, 'RTD');\u000a    this.setMode('MODE_TEXT');\u000a  };\u000a\u000a  _proto6.ccEDM = function ccEDM() {\u000a    // Erase Displayed Memory\u000a    this.logger.log(VerboseLevel.INFO, 'EDM - Erase Displayed Memory');\u000a    this.displayedMemory.reset();\u000a    this.outputDataUpdate(true);\u000a  };\u000a\u000a  _proto6.ccCR = function ccCR() {\u000a    // Carriage Return\u000a    this.logger.log(VerboseLevel.INFO, 'CR - Carriage Return');\u000a    this.writeScreen.rollUp();\u000a    this.outputDataUpdate(true);\u000a  };\u000a\u000a  _proto6.ccENM = function ccENM() {\u000a    // Erase Non-Displayed Memory\u000a    this.logger.log(VerboseLevel.INFO, 'ENM - Erase Non-displayed Memory');\u000a    this.nonDisplayedMemory.reset();\u000a  };\u000a\u000a  _proto6.ccEOC = function ccEOC() {\u000a    // End of Caption (Flip Memories)\u000a    this.logger.log(VerboseLevel.INFO, 'EOC - End Of Caption');\u000a\u000a    if (this.mode === 'MODE_POP-ON') {\u000a      var tmp = this.displayedMemory;\u000a      this.displayedMemory = this.nonDisplayedMemory;\u000a      this.nonDisplayedMemory = tmp;\u000a      this.writeScreen = this.nonDisplayedMemory;\u000a      this.logger.log(VerboseLevel.TEXT, 'DISP: ' + this.displayedMemory.getDisplayText());\u000a    }\u000a\u000a    this.outputDataUpdate(true);\u000a  };\u000a\u000a  _proto6.ccTO = function ccTO(nrCols) {\u000a    // Tab Offset 1,2, or 3 columns\u000a    this.logger.log(VerboseLevel.INFO, 'TO(' + nrCols + ') - Tab Offset');\u000a    this.writeScreen.moveCursor(nrCols);\u000a  };\u000a\u000a  _proto6.ccMIDROW = function ccMIDROW(secondByte) {\u000a    // Parse MIDROW command\u000a    var styles = {\u000a      flash: false\u000a    };\u000a    styles.underline = secondByte % 2 === 1;\u000a    styles.italics = secondByte >= 0x2e;\u000a\u000a    if (!styles.italics) {\u000a      var colorIndex = Math.floor(secondByte / 2) - 0x10;\u000a      var colors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta'];\u000a      styles.foreground = colors[colorIndex];\u000a    } else {\u000a      styles.foreground = 'white';\u000a    }\u000a\u000a    this.logger.log(VerboseLevel.INFO, 'MIDROW: ' + JSON.stringify(styles));\u000a    this.writeScreen.setPen(styles);\u000a  };\u000a\u000a  _proto6.outputDataUpdate = function outputDataUpdate(dispatch) {\u000a    if (dispatch === void 0) {\u000a      dispatch = false;\u000a    }\u000a\u000a    var time = this.logger.time;\u000a\u000a    if (time === null) {\u000a      return;\u000a    }\u000a\u000a    if (this.outputFilter) {\u000a      if (this.cueStartTime === null && !this.displayedMemory.isEmpty()) {\u000a        // Start of a new cue\u000a        this.cueStartTime = time;\u000a      } else {\u000a        if (!this.displayedMemory.equals(this.lastOutputScreen)) {\u000a          this.outputFilter.newCue(this.cueStartTime, time, this.lastOutputScreen);\u000a\u000a          if (dispatch && this.outputFilter.dispatchCue) {\u000a            this.outputFilter.dispatchCue();\u000a          }\u000a\u000a          this.cueStartTime = this.displayedMemory.isEmpty() ? null : time;\u000a        }\u000a      }\u000a\u000a      this.lastOutputScreen.copy(this.displayedMemory);\u000a    }\u000a  };\u000a\u000a  _proto6.cueSplitAtTime = function cueSplitAtTime(t) {\u000a    if (this.outputFilter) {\u000a      if (!this.displayedMemory.isEmpty()) {\u000a        if (this.outputFilter.newCue) {\u000a          this.outputFilter.newCue(this.cueStartTime, t, this.displayedMemory);\u000a        }\u000a\u000a        this.cueStartTime = t;\u000a      }\u000a    }\u000a  };\u000a\u000a  return Cea608Channel;\u000a}();\u000a\u000avar Cea608Parser = /*#__PURE__*/function () {\u000a  function Cea608Parser(field, out1, out2) {\u000a    this.channels = void 0;\u000a    this.currentChannel = 0;\u000a    this.cmdHistory = void 0;\u000a    this.logger = void 0;\u000a    var logger = new cea_608_parser_CaptionsLogger();\u000a    this.channels = [null, new Cea608Channel(field, out1, logger), new Cea608Channel(field + 1, out2, logger)];\u000a    this.cmdHistory = createCmdHistory();\u000a    this.logger = logger;\u000a  }\u000a\u000a  var _proto7 = Cea608Parser.prototype;\u000a\u000a  _proto7.getHandler = function getHandler(channel) {\u000a    return this.channels[channel].getHandler();\u000a  };\u000a\u000a  _proto7.setHandler = function setHandler(channel, newHandler) {\u000a    this.channels[channel].setHandler(newHandler);\u000a  }\u000a  /**\u000a   * Add data for time t in forms of list of bytes (unsigned ints). The bytes are treated as pairs.\u000a   */\u000a  ;\u000a\u000a  _proto7.addData = function addData(time, byteList) {\u000a    var cmdFound;\u000a    var a;\u000a    var b;\u000a    var charsFound = false;\u000a    this.logger.time = time;\u000a\u000a    for (var i = 0; i < byteList.length; i += 2) {\u000a      a = byteList[i] & 0x7f;\u000a      b = byteList[i + 1] & 0x7f;\u000a\u000a      if (a === 0 && b === 0) {\u000a        continue;\u000a      } else {\u000a        this.logger.log(VerboseLevel.DATA, '[' + numArrayToHexArray([byteList[i], byteList[i + 1]]) + '] -> (' + numArrayToHexArray([a, b]) + ')');\u000a      }\u000a\u000a      cmdFound = this.parseCmd(a, b);\u000a\u000a      if (!cmdFound) {\u000a        cmdFound = this.parseMidrow(a, b);\u000a      }\u000a\u000a      if (!cmdFound) {\u000a        cmdFound = this.parsePAC(a, b);\u000a      }\u000a\u000a      if (!cmdFound) {\u000a        cmdFound = this.parseBackgroundAttributes(a, b);\u000a      }\u000a\u000a      if (!cmdFound) {\u000a        charsFound = this.parseChars(a, b);\u000a\u000a        if (charsFound) {\u000a          var currChNr = this.currentChannel;\u000a\u000a          if (currChNr && currChNr > 0) {\u000a            var channel = this.channels[currChNr];\u000a            channel.insertChars(charsFound);\u000a          } else {\u000a            this.logger.log(VerboseLevel.WARNING, 'No channel found yet. TEXT-MODE?');\u000a          }\u000a        }\u000a      }\u000a\u000a      if (!cmdFound && !charsFound) {\u000a        this.logger.log(VerboseLevel.WARNING, 'Couldn\u005c't parse cleaned data ' + numArrayToHexArray([a, b]) + ' orig: ' + numArrayToHexArray([byteList[i], byteList[i + 1]]));\u000a      }\u000a    }\u000a  }\u000a  /**\u000a   * Parse Command.\u000a   * @returns {Boolean} Tells if a command was found\u000a   */\u000a  ;\u000a\u000a  _proto7.parseCmd = function parseCmd(a, b) {\u000a    var cmdHistory = this.cmdHistory;\u000a    var cond1 = (a === 0x14 || a === 0x1C || a === 0x15 || a === 0x1D) && b >= 0x20 && b <= 0x2F;\u000a    var cond2 = (a === 0x17 || a === 0x1F) && b >= 0x21 && b <= 0x23;\u000a\u000a    if (!(cond1 || cond2)) {\u000a      return false;\u000a    }\u000a\u000a    if (hasCmdRepeated(a, b, cmdHistory)) {\u000a      setLastCmd(null, null, cmdHistory);\u000a      this.logger.log(VerboseLevel.DEBUG, 'Repeated command (' + numArrayToHexArray([a, b]) + ') is dropped');\u000a      return true;\u000a    }\u000a\u000a    var chNr = a === 0x14 || a === 0x15 || a === 0x17 ? 1 : 2;\u000a    var channel = this.channels[chNr];\u000a\u000a    if (a === 0x14 || a === 0x15 || a === 0x1C || a === 0x1D) {\u000a      if (b === 0x20) {\u000a        channel.ccRCL();\u000a      } else if (b === 0x21) {\u000a        channel.ccBS();\u000a      } else if (b === 0x22) {\u000a        channel.ccAOF();\u000a      } else if (b === 0x23) {\u000a        channel.ccAON();\u000a      } else if (b === 0x24) {\u000a        channel.ccDER();\u000a      } else if (b === 0x25) {\u000a        channel.ccRU(2);\u000a      } else if (b === 0x26) {\u000a        channel.ccRU(3);\u000a      } else if (b === 0x27) {\u000a        channel.ccRU(4);\u000a      } else if (b === 0x28) {\u000a        channel.ccFON();\u000a      } else if (b === 0x29) {\u000a        channel.ccRDC();\u000a      } else if (b === 0x2A) {\u000a        channel.ccTR();\u000a      } else if (b === 0x2B) {\u000a        channel.ccRTD();\u000a      } else if (b === 0x2C) {\u000a        channel.ccEDM();\u000a      } else if (b === 0x2D) {\u000a        channel.ccCR();\u000a      } else if (b === 0x2E) {\u000a        channel.ccENM();\u000a      } else if (b === 0x2F) {\u000a        channel.ccEOC();\u000a      }\u000a    } else {\u000a      // a == 0x17 || a == 0x1F\u000a      channel.ccTO(b - 0x20);\u000a    }\u000a\u000a    setLastCmd(a, b, cmdHistory);\u000a    this.currentChannel = chNr;\u000a    return true;\u000a  }\u000a  /**\u000a   * Parse midrow styling command\u000a   * @returns {Boolean}\u000a   */\u000a  ;\u000a\u000a  _proto7.parseMidrow = function parseMidrow(a, b) {\u000a    var chNr = 0;\u000a\u000a    if ((a === 0x11 || a === 0x19) && b >= 0x20 && b <= 0x2f) {\u000a      if (a === 0x11) {\u000a        chNr = 1;\u000a      } else {\u000a        chNr = 2;\u000a      }\u000a\u000a      if (chNr !== this.currentChannel) {\u000a        this.logger.log(VerboseLevel.ERROR, 'Mismatch channel in midrow parsing');\u000a        return false;\u000a      }\u000a\u000a      var channel = this.channels[chNr];\u000a\u000a      if (!channel) {\u000a        return false;\u000a      }\u000a\u000a      channel.ccMIDROW(b);\u000a      this.logger.log(VerboseLevel.DEBUG, 'MIDROW (' + numArrayToHexArray([a, b]) + ')');\u000a      return true;\u000a    }\u000a\u000a    return false;\u000a  }\u000a  /**\u000a   * Parse Preable Access Codes (Table 53).\u000a   * @returns {Boolean} Tells if PAC found\u000a   */\u000a  ;\u000a\u000a  _proto7.parsePAC = function parsePAC(a, b) {\u000a    var row;\u000a    var cmdHistory = this.cmdHistory;\u000a    var case1 = (a >= 0x11 && a <= 0x17 || a >= 0x19 && a <= 0x1F) && b >= 0x40 && b <= 0x7F;\u000a    var case2 = (a === 0x10 || a === 0x18) && b >= 0x40 && b <= 0x5F;\u000a\u000a    if (!(case1 || case2)) {\u000a      return false;\u000a    }\u000a\u000a    if (hasCmdRepeated(a, b, cmdHistory)) {\u000a      setLastCmd(null, null, cmdHistory);\u000a      return true; // Repeated commands are dropped (once)\u000a    }\u000a\u000a    var chNr = a <= 0x17 ? 1 : 2;\u000a\u000a    if (b >= 0x40 && b <= 0x5F) {\u000a      row = chNr === 1 ? rowsLowCh1[a] : rowsLowCh2[a];\u000a    } else {\u000a      // 0x60 <= b <= 0x7F\u000a      row = chNr === 1 ? rowsHighCh1[a] : rowsHighCh2[a];\u000a    }\u000a\u000a    var channel = this.channels[chNr];\u000a\u000a    if (!channel) {\u000a      return false;\u000a    }\u000a\u000a    channel.setPAC(this.interpretPAC(row, b));\u000a    setLastCmd(a, b, cmdHistory);\u000a    this.currentChannel = chNr;\u000a    return true;\u000a  }\u000a  /**\u000a   * Interpret the second byte of the pac, and return the information.\u000a   * @returns {Object} pacData with style parameters.\u000a   */\u000a  ;\u000a\u000a  _proto7.interpretPAC = function interpretPAC(row, _byte3) {\u000a    var pacIndex = _byte3;\u000a    var pacData = {\u000a      color: null,\u000a      italics: false,\u000a      indent: null,\u000a      underline: false,\u000a      row: row\u000a    };\u000a\u000a    if (_byte3 > 0x5F) {\u000a      pacIndex = _byte3 - 0x60;\u000a    } else {\u000a      pacIndex = _byte3 - 0x40;\u000a    }\u000a\u000a    pacData.underline = (pacIndex & 1) === 1;\u000a\u000a    if (pacIndex <= 0xd) {\u000a      pacData.color = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'white'][Math.floor(pacIndex / 2)];\u000a    } else if (pacIndex <= 0xf) {\u000a      pacData.italics = true;\u000a      pacData.color = 'white';\u000a    } else {\u000a      pacData.indent = Math.floor((pacIndex - 0x10) / 2) * 4;\u000a    }\u000a\u000a    return pacData; // Note that row has zero offset. The spec uses 1.\u000a  }\u000a  /**\u000a   * Parse characters.\u000a   * @returns An array with 1 to 2 codes corresponding to chars, if found. null otherwise.\u000a   */\u000a  ;\u000a\u000a  _proto7.parseChars = function parseChars(a, b) {\u000a    var channelNr;\u000a    var charCodes = null;\u000a    var charCode1 = null;\u000a\u000a    if (a >= 0x19) {\u000a      channelNr = 2;\u000a      charCode1 = a - 8;\u000a    } else {\u000a      channelNr = 1;\u000a      charCode1 = a;\u000a    }\u000a\u000a    if (charCode1 >= 0x11 && charCode1 <= 0x13) {\u000a      // Special character\u000a      var oneCode = b;\u000a\u000a      if (charCode1 === 0x11) {\u000a        oneCode = b + 0x50;\u000a      } else if (charCode1 === 0x12) {\u000a        oneCode = b + 0x70;\u000a      } else {\u000a        oneCode = b + 0x90;\u000a      }\u000a\u000a      this.logger.log(VerboseLevel.INFO, 'Special char \u005c'' + getCharForByte(oneCode) + '\u005c' in channel ' + channelNr);\u000a      charCodes = [oneCode];\u000a    } else if (a >= 0x20 && a <= 0x7f) {\u000a      charCodes = b === 0 ? [a] : [a, b];\u000a    }\u000a\u000a    if (charCodes) {\u000a      var hexCodes = numArrayToHexArray(charCodes);\u000a      this.logger.log(VerboseLevel.DEBUG, 'Char codes =  ' + hexCodes.join(','));\u000a      setLastCmd(a, b, this.cmdHistory);\u000a    }\u000a\u000a    return charCodes;\u000a  }\u000a  /**\u000a   * Parse extended background attributes as well as new foreground color black.\u000a   * @returns {Boolean} Tells if background attributes are found\u000a   */\u000a  ;\u000a\u000a  _proto7.parseBackgroundAttributes = function parseBackgroundAttributes(a, b) {\u000a    var case1 = (a === 0x10 || a === 0x18) && b >= 0x20 && b <= 0x2f;\u000a    var case2 = (a === 0x17 || a === 0x1f) && b >= 0x2d && b <= 0x2f;\u000a\u000a    if (!(case1 || case2)) {\u000a      return false;\u000a    }\u000a\u000a    var index;\u000a    var bkgData = {};\u000a\u000a    if (a === 0x10 || a === 0x18) {\u000a      index = Math.floor((b - 0x20) / 2);\u000a      bkgData.background = backgroundColors[index];\u000a\u000a      if (b % 2 === 1) {\u000a        bkgData.background = bkgData.background + '_semi';\u000a      }\u000a    } else if (b === 0x2d) {\u000a      bkgData.background = 'transparent';\u000a    } else {\u000a      bkgData.foreground = 'black';\u000a\u000a      if (b === 0x2f) {\u000a        bkgData.underline = true;\u000a      }\u000a    }\u000a\u000a    var chNr = a <= 0x17 ? 1 : 2;\u000a    var channel = this.channels[chNr];\u000a    channel.setBkgData(bkgData);\u000a    setLastCmd(a, b, this.cmdHistory);\u000a    return true;\u000a  }\u000a  /**\u000a   * Reset state of parser and its channels.\u000a   */\u000a  ;\u000a\u000a  _proto7.reset = function reset() {\u000a    for (var i = 0; i < Object.keys(this.channels).length; i++) {\u000a      var channel = this.channels[i];\u000a\u000a      if (channel) {\u000a        channel.reset();\u000a      }\u000a    }\u000a\u000a    this.cmdHistory = createCmdHistory();\u000a  }\u000a  /**\u000a   * Trigger the generation of a cue, and the start of a new one if displayScreens are not empty.\u000a   */\u000a  ;\u000a\u000a  _proto7.cueSplitAtTime = function cueSplitAtTime(t) {\u000a    for (var i = 0; i < this.channels.length; i++) {\u000a      var channel = this.channels[i];\u000a\u000a      if (channel) {\u000a        channel.cueSplitAtTime(t);\u000a      }\u000a    }\u000a  };\u000a\u000a  return Cea608Parser;\u000a}();\u000a\u000afunction setLastCmd(a, b, cmdHistory) {\u000a  cmdHistory.a = a;\u000a  cmdHistory.b = b;\u000a}\u000a\u000afunction hasCmdRepeated(a, b, cmdHistory) {\u000a  return cmdHistory.a === a && cmdHistory.b === b;\u000a}\u000a\u000afunction createCmdHistory() {\u000a  return {\u000a    a: null,\u000a    b: null\u000a  };\u000a}\u000a\u000a/* harmony default export */ var cea_608_parser = (Cea608Parser);\u000a// CONCATENATED MODULE: ./src/utils/output-filter.ts\u000avar OutputFilter = /*#__PURE__*/function () {\u000a  function OutputFilter(timelineController, trackName) {\u000a    this.timelineController = void 0;\u000a    this.cueRanges = [];\u000a    this.trackName = void 0;\u000a    this.startTime = null;\u000a    this.endTime = null;\u000a    this.screen = null;\u000a    this.timelineController = timelineController;\u000a    this.trackName = trackName;\u000a  }\u000a\u000a  var _proto = OutputFilter.prototype;\u000a\u000a  _proto.dispatchCue = function dispatchCue() {\u000a    if (this.startTime === null) {\u000a      return;\u000a    }\u000a\u000a    this.timelineController.addCues(this.trackName, this.startTime, this.endTime, this.screen, this.cueRanges);\u000a    this.startTime = null;\u000a  };\u000a\u000a  _proto.newCue = function newCue(startTime, endTime, screen) {\u000a    if (this.startTime === null || this.startTime > startTime) {\u000a      this.startTime = startTime;\u000a    }\u000a\u000a    this.endTime = endTime;\u000a    this.screen = screen;\u000a    this.timelineController.createCaptionsTrack(this.trackName);\u000a  };\u000a\u000a  _proto.reset = function reset() {\u000a    this.cueRanges = [];\u000a  };\u000a\u000a  return OutputFilter;\u000a}();\u000a\u000a\u000a// CONCATENATED MODULE: ./src/utils/webvtt-parser.js\u000a\u000a\u000a\u000a\u000a\u000a // String.prototype.startsWith is not supported in IE11\u000a\u000avar startsWith = function startsWith(inputString, searchString, position) {\u000a  return inputString.substr(position || 0, searchString.length) === searchString;\u000a};\u000a\u000avar webvtt_parser_cueString2millis = function cueString2millis(timeString) {\u000a  var ts = parseInt(timeString.substr(-3));\u000a  var secs = parseInt(timeString.substr(-6, 2));\u000a  var mins = parseInt(timeString.substr(-9, 2));\u000a  var hours = timeString.length > 9 ? parseInt(timeString.substr(0, timeString.indexOf(':'))) : 0;\u000a\u000a  if (!Object(number["isFiniteNumber"])(ts) || !Object(number["isFiniteNumber"])(secs) || !Object(number["isFiniteNumber"])(mins) || !Object(number["isFiniteNumber"])(hours)) {\u000a    throw Error("Malformed X-TIMESTAMP-MAP: Local:" + timeString);\u000a  }\u000a\u000a  ts += 1000 * secs;\u000a  ts += 60 * 1000 * mins;\u000a  ts += 60 * 60 * 1000 * hours;\u000a  return ts;\u000a}; // From https://github.com/darkskyapp/string-hash\u000a\u000a\u000avar hash = function hash(text) {\u000a  var hash = 5381;\u000a  var i = text.length;\u000a\u000a  while (i) {\u000a    hash = hash * 33 ^ text.charCodeAt(--i);\u000a  }\u000a\u000a  return (hash >>> 0).toString();\u000a};\u000a\u000avar calculateOffset = function calculateOffset(vttCCs, cc, presentationTime) {\u000a  var currCC = vttCCs[cc];\u000a  var prevCC = vttCCs[currCC.prevCC]; // This is the first discontinuity or cues have been processed since the last discontinuity\u000a  // Offset = current discontinuity time\u000a\u000a  if (!prevCC || !prevCC.new && currCC.new) {\u000a    vttCCs.ccOffset = vttCCs.presentationOffset = currCC.start;\u000a    currCC.new = false;\u000a    return;\u000a  } // There have been discontinuities since cues were last parsed.\u000a  // Offset = time elapsed\u000a\u000a\u000a  while (prevCC && prevCC.new) {\u000a    vttCCs.ccOffset += currCC.start - prevCC.start;\u000a    currCC.new = false;\u000a    currCC = prevCC;\u000a    prevCC = vttCCs[currCC.prevCC];\u000a  }\u000a\u000a  vttCCs.presentationOffset = presentationTime;\u000a};\u000a\u000avar WebVTTParser = {\u000a  parse: function parse(vttByteArray, syncPTS, vttCCs, cc, callBack, errorCallBack) {\u000a    // Convert byteArray into string, replacing any somewhat exotic linefeeds with "\u005cn", then split on that character.\u000a    var re = /\u005cr\u005cn|\u005cn\u005cr|\u005cn|\u005cr/g; // Uint8Array.prototype.reduce is not implemented in IE11\u000a\u000a    var vttLines = Object(id3["utf8ArrayToStr"])(new Uint8Array(vttByteArray)).trim().replace(re, '\u005cn').split('\u005cn');\u000a    var cueTime = '00:00.000';\u000a    var mpegTs = 0;\u000a    var localTime = 0;\u000a    var presentationTime = 0;\u000a    var cues = [];\u000a    var parsingError;\u000a    var inHeader = true;\u000a    var timestampMap = false; // let VTTCue = VTTCue || window.TextTrackCue;\u000a    // Create parser object using VTTCue with TextTrackCue fallback on certain browsers.\u000a\u000a    var parser = new vttparser();\u000a\u000a    parser.oncue = function (cue) {\u000a      // Adjust cue timing; clamp cues to start no earlier than - and drop cues that don't end after - 0 on timeline.\u000a      var currCC = vttCCs[cc];\u000a      var cueOffset = vttCCs.ccOffset; // Update offsets for new discontinuities\u000a\u000a      if (currCC && currCC.new) {\u000a        if (localTime !== undefined) {\u000a          // When local time is provided, offset = discontinuity start time - local time\u000a          cueOffset = vttCCs.ccOffset = currCC.start;\u000a        } else {\u000a          calculateOffset(vttCCs, cc, presentationTime);\u000a        }\u000a      }\u000a\u000a      if (presentationTime) {\u000a        // If we have MPEGTS, offset = presentation time + discontinuity offset\u000a        cueOffset = presentationTime - vttCCs.presentationOffset;\u000a      }\u000a\u000a      if (timestampMap) {\u000a        cue.startTime += cueOffset - localTime;\u000a        cue.endTime += cueOffset - localTime;\u000a      } // Create a unique hash id for a cue based on start/end times and text.\u000a      // This helps timeline-controller to avoid showing repeated captions.\u000a\u000a\u000a      cue.id = hash(cue.startTime.toString()) + hash(cue.endTime.toString()) + hash(cue.text); // Fix encoding of special characters. TODO: Test with all sorts of weird characters.\u000a\u000a      cue.text = decodeURIComponent(encodeURIComponent(cue.text));\u000a\u000a      if (cue.endTime > 0) {\u000a        cues.push(cue);\u000a      }\u000a    };\u000a\u000a    parser.onparsingerror = function (e) {\u000a      parsingError = e;\u000a    };\u000a\u000a    parser.onflush = function () {\u000a      if (parsingError && errorCallBack) {\u000a        errorCallBack(parsingError);\u000a        return;\u000a      }\u000a\u000a      callBack(cues);\u000a    }; // Go through contents line by line.\u000a\u000a\u000a    vttLines.forEach(function (line) {\u000a      if (inHeader) {\u000a        // Look for X-TIMESTAMP-MAP in header.\u000a        if (startsWith(line, 'X-TIMESTAMP-MAP=')) {\u000a          // Once found, no more are allowed anyway, so stop searching.\u000a          inHeader = false;\u000a          timestampMap = true; // Extract LOCAL and MPEGTS.\u000a\u000a          line.substr(16).split(',').forEach(function (timestamp) {\u000a            if (startsWith(timestamp, 'LOCAL:')) {\u000a              cueTime = timestamp.substr(6);\u000a            } else if (startsWith(timestamp, 'MPEGTS:')) {\u000a              mpegTs = parseInt(timestamp.substr(7));\u000a            }\u000a          });\u000a\u000a          try {\u000a            // Calculate subtitle offset in milliseconds.\u000a            if (syncPTS + (vttCCs[cc].start * 90000 || 0) < 0) {\u000a              syncPTS += 8589934592;\u000a            } // Adjust MPEGTS by sync PTS.\u000a\u000a\u000a            mpegTs -= syncPTS; // Convert cue time to seconds\u000a\u000a            localTime = webvtt_parser_cueString2millis(cueTime) / 1000; // Convert MPEGTS to seconds from 90kHz.\u000a\u000a            presentationTime = mpegTs / 90000;\u000a          } catch (e) {\u000a            timestampMap = false;\u000a            parsingError = e;\u000a          } // Return without parsing X-TIMESTAMP-MAP line.\u000a\u000a\u000a          return;\u000a        } else if (line === '') {\u000a          inHeader = false;\u000a        }\u000a      } // Parse line by default.\u000a\u000a\u000a      parser.parse(line + '\u005cn');\u000a    });\u000a    parser.flush();\u000a  }\u000a};\u000a/* harmony default export */ var webvtt_parser = (WebVTTParser);\u000a// CONCATENATED MODULE: ./src/controller/timeline-controller.ts\u000a\u000a\u000a\u000afunction timeline_controller_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return self; }\u000a\u000afunction timeline_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000avar timeline_controller_TimelineController = /*#__PURE__*/function (_EventHandler) {\u000a  timeline_controller_inheritsLoose(TimelineController, _EventHandler);\u000a\u000a  function TimelineController(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].MEDIA_ATTACHING, events["default"].MEDIA_DETACHING, events["default"].FRAG_PARSING_USERDATA, events["default"].FRAG_DECRYPTED, events["default"].MANIFEST_LOADING, events["default"].MANIFEST_LOADED, events["default"].FRAG_LOADED, events["default"].INIT_PTS_FOUND) || this;\u000a    _this.media = null;\u000a    _this.config = void 0;\u000a    _this.enabled = true;\u000a    _this.Cues = void 0;\u000a    _this.textTracks = [];\u000a    _this.tracks = [];\u000a    _this.initPTS = [];\u000a    _this.unparsedVttFrags = [];\u000a    _this.captionsTracks = {};\u000a    _this.nonNativeCaptionsTracks = {};\u000a    _this.captionsProperties = void 0;\u000a    _this.cea608Parser1 = void 0;\u000a    _this.cea608Parser2 = void 0;\u000a    _this.lastSn = -1;\u000a    _this.prevCC = -1;\u000a    _this.vttCCs = newVTTCCs();\u000a    _this.hls = hls;\u000a    _this.config = hls.config;\u000a    _this.Cues = hls.config.cueHandler;\u000a    _this.captionsProperties = {\u000a      textTrack1: {\u000a        label: _this.config.captionsTextTrack1Label,\u000a        languageCode: _this.config.captionsTextTrack1LanguageCode\u000a      },\u000a      textTrack2: {\u000a        label: _this.config.captionsTextTrack2Label,\u000a        languageCode: _this.config.captionsTextTrack2LanguageCode\u000a      },\u000a      textTrack3: {\u000a        label: _this.config.captionsTextTrack3Label,\u000a        languageCode: _this.config.captionsTextTrack3LanguageCode\u000a      },\u000a      textTrack4: {\u000a        label: _this.config.captionsTextTrack4Label,\u000a        languageCode: _this.config.captionsTextTrack4LanguageCode\u000a      }\u000a    };\u000a\u000a    if (_this.config.enableCEA708Captions) {\u000a      var channel1 = new OutputFilter(timeline_controller_assertThisInitialized(_this), 'textTrack1');\u000a      var channel2 = new OutputFilter(timeline_controller_assertThisInitialized(_this), 'textTrack2');\u000a      var channel3 = new OutputFilter(timeline_controller_assertThisInitialized(_this), 'textTrack3');\u000a      var channel4 = new OutputFilter(timeline_controller_assertThisInitialized(_this), 'textTrack4');\u000a      _this.cea608Parser1 = new cea_608_parser(1, channel1, channel2);\u000a      _this.cea608Parser2 = new cea_608_parser(3, channel3, channel4);\u000a    }\u000a\u000a    return _this;\u000a  }\u000a\u000a  var _proto = TimelineController.prototype;\u000a\u000a  _proto.addCues = function addCues(trackName, startTime, endTime, screen, cueRanges) {\u000a    // skip cues which overlap more than 50% with previously parsed time ranges\u000a    var merged = false;\u000a\u000a    for (var i = cueRanges.length; i--;) {\u000a      var cueRange = cueRanges[i];\u000a      var overlap = intersection(cueRange[0], cueRange[1], startTime, endTime);\u000a\u000a      if (overlap >= 0) {\u000a        cueRange[0] = Math.min(cueRange[0], startTime);\u000a        cueRange[1] = Math.max(cueRange[1], endTime);\u000a        merged = true;\u000a\u000a        if (overlap / (endTime - startTime) > 0.5) {\u000a          return;\u000a        }\u000a      }\u000a    }\u000a\u000a    if (!merged) {\u000a      cueRanges.push([startTime, endTime]);\u000a    }\u000a\u000a    if (this.config.renderTextTracksNatively) {\u000a      this.Cues.newCue(this.captionsTracks[trackName], startTime, endTime, screen);\u000a    } else {\u000a      var cues = this.Cues.newCue(null, startTime, endTime, screen);\u000a      this.hls.trigger(events["default"].CUES_PARSED, {\u000a        type: 'captions',\u000a        cues: cues,\u000a        track: trackName\u000a      });\u000a    }\u000a  } // Triggered when an initial PTS is found; used for synchronisation of WebVTT.\u000a  ;\u000a\u000a  _proto.onInitPtsFound = function onInitPtsFound(data) {\u000a    var _this2 = this;\u000a\u000a    var frag = data.frag,\u000a        id = data.id,\u000a        initPTS = data.initPTS;\u000a    var unparsedVttFrags = this.unparsedVttFrags;\u000a\u000a    if (id === 'main') {\u000a      this.initPTS[frag.cc] = initPTS;\u000a    } // Due to asynchronous processing, initial PTS may arrive later than the first VTT fragments are loaded.\u000a    // Parse any unparsed fragments upon receiving the initial PTS.\u000a\u000a\u000a    if (unparsedVttFrags.length) {\u000a      this.unparsedVttFrags = [];\u000a      unparsedVttFrags.forEach(function (frag) {\u000a        _this2.onFragLoaded(frag);\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.getExistingTrack = function getExistingTrack(trackName) {\u000a    var media = this.media;\u000a\u000a    if (media) {\u000a      for (var i = 0; i < media.textTracks.length; i++) {\u000a        var textTrack = media.textTracks[i];\u000a\u000a        if (textTrack[trackName]) {\u000a          return textTrack;\u000a        }\u000a      }\u000a    }\u000a\u000a    return null;\u000a  };\u000a\u000a  _proto.createCaptionsTrack = function createCaptionsTrack(trackName) {\u000a    if (this.config.renderTextTracksNatively) {\u000a      this.createNativeTrack(trackName);\u000a    } else {\u000a      this.createNonNativeTrack(trackName);\u000a    }\u000a  };\u000a\u000a  _proto.createNativeTrack = function createNativeTrack(trackName) {\u000a    if (this.captionsTracks[trackName]) {\u000a      return;\u000a    }\u000a\u000a    var captionsProperties = this.captionsProperties,\u000a        captionsTracks = this.captionsTracks,\u000a        media = this.media;\u000a    var _captionsProperties$t = captionsProperties[trackName],\u000a        label = _captionsProperties$t.label,\u000a        languageCode = _captionsProperties$t.languageCode; // Enable reuse of existing text track.\u000a\u000a    var existingTrack = this.getExistingTrack(trackName);\u000a\u000a    if (!existingTrack) {\u000a      var textTrack = this.createTextTrack('captions', label, languageCode);\u000a\u000a      if (textTrack) {\u000a        // Set a special property on the track so we know it's managed by Hls.js\u000a        textTrack[trackName] = true;\u000a        captionsTracks[trackName] = textTrack;\u000a      }\u000a    } else {\u000a      captionsTracks[trackName] = existingTrack;\u000a      clearCurrentCues(captionsTracks[trackName]);\u000a      sendAddTrackEvent(captionsTracks[trackName], media);\u000a    }\u000a  };\u000a\u000a  _proto.createNonNativeTrack = function createNonNativeTrack(trackName) {\u000a    if (this.nonNativeCaptionsTracks[trackName]) {\u000a      return;\u000a    } // Create a list of a single track for the provider to consume\u000a\u000a\u000a    var trackProperties = this.captionsProperties[trackName];\u000a\u000a    if (!trackProperties) {\u000a      return;\u000a    }\u000a\u000a    var label = trackProperties.label;\u000a    var track = {\u000a      _id: trackName,\u000a      label: label,\u000a      kind: 'captions',\u000a      default: trackProperties.media ? !!trackProperties.media.default : false,\u000a      closedCaptions: trackProperties.media\u000a    };\u000a    this.nonNativeCaptionsTracks[trackName] = track;\u000a    this.hls.trigger(events["default"].NON_NATIVE_TEXT_TRACKS_FOUND, {\u000a      tracks: [track]\u000a    });\u000a  };\u000a\u000a  _proto.createTextTrack = function createTextTrack(kind, label, lang) {\u000a    var media = this.media;\u000a\u000a    if (!media) {\u000a      return;\u000a    }\u000a\u000a    return media.addTextTrack(kind, label, lang);\u000a  };\u000a\u000a  _proto.destroy = function destroy() {\u000a    _EventHandler.prototype.destroy.call(this);\u000a  };\u000a\u000a  _proto.onMediaAttaching = function onMediaAttaching(data) {\u000a    this.media = data.media;\u000a\u000a    this._cleanTracks();\u000a  };\u000a\u000a  _proto.onMediaDetaching = function onMediaDetaching() {\u000a    var captionsTracks = this.captionsTracks;\u000a    Object.keys(captionsTracks).forEach(function (trackName) {\u000a      clearCurrentCues(captionsTracks[trackName]);\u000a      delete captionsTracks[trackName];\u000a    });\u000a    this.nonNativeCaptionsTracks = {};\u000a  };\u000a\u000a  _proto.onManifestLoading = function onManifestLoading() {\u000a    this.lastSn = -1; // Detect discontiguity in fragment parsing\u000a\u000a    this.prevCC = -1;\u000a    this.vttCCs = newVTTCCs(); // Detect discontinuity in subtitle manifests\u000a\u000a    this._cleanTracks();\u000a\u000a    this.tracks = [];\u000a    this.captionsTracks = {};\u000a    this.nonNativeCaptionsTracks = {};\u000a  };\u000a\u000a  _proto._cleanTracks = function _cleanTracks() {\u000a    // clear outdated subtitles\u000a    var media = this.media;\u000a\u000a    if (!media) {\u000a      return;\u000a    }\u000a\u000a    var textTracks = media.textTracks;\u000a\u000a    if (textTracks) {\u000a      for (var i = 0; i < textTracks.length; i++) {\u000a        clearCurrentCues(textTracks[i]);\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onManifestLoaded = function onManifestLoaded(data) {\u000a    var _this3 = this;\u000a\u000a    this.textTracks = [];\u000a    this.unparsedVttFrags = this.unparsedVttFrags || [];\u000a    this.initPTS = [];\u000a\u000a    if (this.cea608Parser1 && this.cea608Parser2) {\u000a      this.cea608Parser1.reset();\u000a      this.cea608Parser2.reset();\u000a    }\u000a\u000a    if (this.config.enableWebVTT) {\u000a      var tracks = data.subtitles || [];\u000a      var sameTracks = this.tracks && tracks && this.tracks.length === tracks.length;\u000a      this.tracks = data.subtitles || [];\u000a\u000a      if (this.config.renderTextTracksNatively) {\u000a        var inUseTracks = this.media ? this.media.textTracks : [];\u000a        this.tracks.forEach(function (track, index) {\u000a          var textTrack;\u000a\u000a          if (index < inUseTracks.length) {\u000a            var inUseTrack = null;\u000a\u000a            for (var i = 0; i < inUseTracks.length; i++) {\u000a              if (canReuseVttTextTrack(inUseTracks[i], track)) {\u000a                inUseTrack = inUseTracks[i];\u000a                break;\u000a              }\u000a            } // Reuse tracks with the same label, but do not reuse 608/708 tracks\u000a\u000a\u000a            if (inUseTrack) {\u000a              textTrack = inUseTrack;\u000a            }\u000a          }\u000a\u000a          if (!textTrack) {\u000a            textTrack = _this3.createTextTrack('subtitles', track.name, track.lang);\u000a          }\u000a\u000a          if (track.default) {\u000a            textTrack.mode = _this3.hls.subtitleDisplay ? 'showing' : 'hidden';\u000a          } else {\u000a            textTrack.mode = 'disabled';\u000a          }\u000a\u000a          _this3.textTracks.push(textTrack);\u000a        });\u000a      } else if (!sameTracks && this.tracks && this.tracks.length) {\u000a        // Create a list of tracks for the provider to consume\u000a        var tracksList = this.tracks.map(function (track) {\u000a          return {\u000a            label: track.name,\u000a            kind: track.type.toLowerCase(),\u000a            default: track.default,\u000a            subtitleTrack: track\u000a          };\u000a        });\u000a        this.hls.trigger(events["default"].NON_NATIVE_TEXT_TRACKS_FOUND, {\u000a          tracks: tracksList\u000a        });\u000a      }\u000a    }\u000a\u000a    if (this.config.enableCEA708Captions && data.captions) {\u000a      data.captions.forEach(function (captionsTrack) {\u000a        var instreamIdMatch = /(?:CC|SERVICE)([1-4])/.exec(captionsTrack.instreamId);\u000a\u000a        if (!instreamIdMatch) {\u000a          return;\u000a        }\u000a\u000a        var trackName = "textTrack" + instreamIdMatch[1];\u000a        var trackProperties = _this3.captionsProperties[trackName];\u000a\u000a        if (!trackProperties) {\u000a          return;\u000a        }\u000a\u000a        trackProperties.label = captionsTrack.name;\u000a\u000a        if (captionsTrack.lang) {\u000a          // optional attribute\u000a          trackProperties.languageCode = captionsTrack.lang;\u000a        }\u000a\u000a        trackProperties.media = captionsTrack;\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.onFragLoaded = function onFragLoaded(data) {\u000a    var frag = data.frag,\u000a        payload = data.payload;\u000a    var cea608Parser1 = this.cea608Parser1,\u000a        cea608Parser2 = this.cea608Parser2,\u000a        initPTS = this.initPTS,\u000a        lastSn = this.lastSn,\u000a        unparsedVttFrags = this.unparsedVttFrags;\u000a\u000a    if (frag.type === 'main') {\u000a      var sn = frag.sn; // if this frag isn't contiguous, clear the parser so cues with bad start/end times aren't added to the textTrack\u000a\u000a      if (frag.sn !== lastSn + 1) {\u000a        if (cea608Parser1 && cea608Parser2) {\u000a          cea608Parser1.reset();\u000a          cea608Parser2.reset();\u000a        }\u000a      }\u000a\u000a      this.lastSn = sn;\u000a    } // eslint-disable-line brace-style\u000a    // If fragment is subtitle type, parse as WebVTT.\u000a    else if (frag.type === 'subtitle') {\u000a        if (payload.byteLength) {\u000a          // We need an initial synchronisation PTS. Store fragments as long as none has arrived.\u000a          if (!Object(number["isFiniteNumber"])(initPTS[frag.cc])) {\u000a            unparsedVttFrags.push(data);\u000a\u000a            if (initPTS.length) {\u000a              // finish unsuccessfully, otherwise the subtitle-stream-controller could be blocked from loading new frags.\u000a              this.hls.trigger(events["default"].SUBTITLE_FRAG_PROCESSED, {\u000a                success: false,\u000a                frag: frag\u000a              });\u000a            }\u000a\u000a            return;\u000a          }\u000a\u000a          var decryptData = frag.decryptdata; // If the subtitles are not encrypted, parse VTTs now. Otherwise, we need to wait.\u000a\u000a          if (decryptData == null || decryptData.key == null || decryptData.method !== 'AES-128') {\u000a            this._parseVTTs(frag, payload);\u000a          }\u000a        } else {\u000a          // In case there is no payload, finish unsuccessfully.\u000a          this.hls.trigger(events["default"].SUBTITLE_FRAG_PROCESSED, {\u000a            success: false,\u000a            frag: frag\u000a          });\u000a        }\u000a      }\u000a  };\u000a\u000a  _proto._parseVTTs = function _parseVTTs(frag, payload) {\u000a    var _this4 = this;\u000a\u000a    var hls = this.hls,\u000a        prevCC = this.prevCC,\u000a        textTracks = this.textTracks,\u000a        vttCCs = this.vttCCs;\u000a\u000a    if (!vttCCs[frag.cc]) {\u000a      vttCCs[frag.cc] = {\u000a        start: frag.start,\u000a        prevCC: prevCC,\u000a        new: true\u000a      };\u000a      this.prevCC = frag.cc;\u000a    } // Parse the WebVTT file contents.\u000a\u000a\u000a    webvtt_parser.parse(payload, this.initPTS[frag.cc], vttCCs, frag.cc, function (cues) {\u000a      if (_this4.config.renderTextTracksNatively) {\u000a        var currentTrack = textTracks[frag.level]; // WebVTTParser.parse is an async method and if the currently selected text track mode is set to "disabled"\u000a        // before parsing is done then don't try to access currentTrack.cues.getCueById as cues will be null\u000a        // and trying to access getCueById method of cues will throw an exception\u000a        // Because we check if the mode is diabled, we can force check `cues` below. They can't be null.\u000a\u000a        if (currentTrack.mode === 'disabled') {\u000a          hls.trigger(events["default"].SUBTITLE_FRAG_PROCESSED, {\u000a            success: false,\u000a            frag: frag\u000a          });\u000a          return;\u000a        } // Add cues and trigger event with success true.\u000a\u000a\u000a        cues.forEach(function (cue) {\u000a          // Sometimes there are cue overlaps on segmented vtts so the same\u000a          // cue can appear more than once in different vtt files.\u000a          // This avoid showing duplicated cues with same timecode and text.\u000a          if (!currentTrack.cues.getCueById(cue.id)) {\u000a            try {\u000a              currentTrack.addCue(cue);\u000a\u000a              if (!currentTrack.cues.getCueById(cue.id)) {\u000a                throw new Error("addCue is failed for: " + cue);\u000a              }\u000a            } catch (err) {\u000a              logger["logger"].debug("Failed occurred on adding cues: " + err);\u000a              var textTrackCue = new window.TextTrackCue(cue.startTime, cue.endTime, cue.text);\u000a              textTrackCue.id = cue.id;\u000a              currentTrack.addCue(textTrackCue);\u000a            }\u000a          }\u000a        });\u000a      } else {\u000a        var trackId = _this4.tracks[frag.level].default ? 'default' : 'subtitles' + frag.level;\u000a        hls.trigger(events["default"].CUES_PARSED, {\u000a          type: 'subtitles',\u000a          cues: cues,\u000a          track: trackId\u000a        });\u000a      }\u000a\u000a      hls.trigger(events["default"].SUBTITLE_FRAG_PROCESSED, {\u000a        success: true,\u000a        frag: frag\u000a      });\u000a    }, function (e) {\u000a      // Something went wrong while parsing. Trigger event with success false.\u000a      logger["logger"].log("Failed to parse VTT cue: " + e);\u000a      hls.trigger(events["default"].SUBTITLE_FRAG_PROCESSED, {\u000a        success: false,\u000a        frag: frag\u000a      });\u000a    });\u000a  };\u000a\u000a  _proto.onFragDecrypted = function onFragDecrypted(data) {\u000a    var frag = data.frag,\u000a        payload = data.payload;\u000a\u000a    if (frag.type === 'subtitle') {\u000a      if (!Object(number["isFiniteNumber"])(this.initPTS[frag.cc])) {\u000a        this.unparsedVttFrags.push(data);\u000a        return;\u000a      }\u000a\u000a      this._parseVTTs(frag, payload);\u000a    }\u000a  };\u000a\u000a  _proto.onFragParsingUserdata = function onFragParsingUserdata(data) {\u000a    var cea608Parser1 = this.cea608Parser1,\u000a        cea608Parser2 = this.cea608Parser2;\u000a\u000a    if (!this.enabled || !(cea608Parser1 && cea608Parser2)) {\u000a      return;\u000a    } // If the event contains captions (found in the bytes property), push all bytes into the parser immediately\u000a    // It will create the proper timestamps based on the PTS value\u000a\u000a\u000a    for (var i = 0; i < data.samples.length; i++) {\u000a      var ccBytes = data.samples[i].bytes;\u000a\u000a      if (ccBytes) {\u000a        var ccdatas = this.extractCea608Data(ccBytes);\u000a        cea608Parser1.addData(data.samples[i].pts, ccdatas[0]);\u000a        cea608Parser2.addData(data.samples[i].pts, ccdatas[1]);\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.extractCea608Data = function extractCea608Data(byteArray) {\u000a    var count = byteArray[0] & 31;\u000a    var position = 2;\u000a    var actualCCBytes = [[], []];\u000a\u000a    for (var j = 0; j < count; j++) {\u000a      var tmpByte = byteArray[position++];\u000a      var ccbyte1 = 0x7F & byteArray[position++];\u000a      var ccbyte2 = 0x7F & byteArray[position++];\u000a      var ccValid = (4 & tmpByte) !== 0;\u000a      var ccType = 3 & tmpByte;\u000a\u000a      if (ccbyte1 === 0 && ccbyte2 === 0) {\u000a        continue;\u000a      }\u000a\u000a      if (ccValid) {\u000a        if (ccType === 0 || ccType === 1) {\u000a          actualCCBytes[ccType].push(ccbyte1);\u000a          actualCCBytes[ccType].push(ccbyte2);\u000a        }\u000a      }\u000a    }\u000a\u000a    return actualCCBytes;\u000a  };\u000a\u000a  return TimelineController;\u000a}(event_handler);\u000a\u000afunction canReuseVttTextTrack(inUseTrack, manifestTrack) {\u000a  return inUseTrack && inUseTrack.label === manifestTrack.name && !(inUseTrack.textTrack1 || inUseTrack.textTrack2);\u000a}\u000a\u000afunction intersection(x1, x2, y1, y2) {\u000a  return Math.min(x2, y2) - Math.max(x1, y1);\u000a}\u000a\u000afunction newVTTCCs() {\u000a  return {\u000a    ccOffset: 0,\u000a    presentationOffset: 0,\u000a    0: {\u000a      start: 0,\u000a      prevCC: -1,\u000a      new: false\u000a    }\u000a  };\u000a}\u000a\u000a/* harmony default export */ var timeline_controller = (timeline_controller_TimelineController);\u000a// CONCATENATED MODULE: ./src/controller/subtitle-track-controller.js\u000a\u000a\u000a\u000a\u000afunction subtitle_track_controller_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction subtitle_track_controller_createClass(Constructor, protoProps, staticProps) { if (protoProps) subtitle_track_controller_defineProperties(Constructor.prototype, protoProps); if (staticProps) subtitle_track_controller_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000afunction subtitle_track_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000avar subtitle_track_controller_SubtitleTrackController = /*#__PURE__*/function (_EventHandler) {\u000a  subtitle_track_controller_inheritsLoose(SubtitleTrackController, _EventHandler);\u000a\u000a  function SubtitleTrackController(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].MEDIA_ATTACHED, events["default"].MEDIA_DETACHING, events["default"].MANIFEST_LOADED, events["default"].SUBTITLE_TRACK_LOADED) || this;\u000a    _this.tracks = [];\u000a    _this.trackId = -1;\u000a    _this.media = null;\u000a    _this.stopped = true;\u000a    /**\u000a     * @member {boolean} subtitleDisplay Enable/disable subtitle display rendering\u000a     */\u000a\u000a    _this.subtitleDisplay = true;\u000a    /**\u000a     * Keeps reference to a default track id when media has not been attached yet\u000a     * @member {number}\u000a     */\u000a\u000a    _this.queuedDefaultTrack = null;\u000a    return _this;\u000a  }\u000a\u000a  var _proto = SubtitleTrackController.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    event_handler.prototype.destroy.call(this);\u000a  } // Listen for subtitle track change, then extract the current track ID.\u000a  ;\u000a\u000a  _proto.onMediaAttached = function onMediaAttached(data) {\u000a    var _this2 = this;\u000a\u000a    this.media = data.media;\u000a\u000a    if (!this.media) {\u000a      return;\u000a    }\u000a\u000a    if (Object(number["isFiniteNumber"])(this.queuedDefaultTrack)) {\u000a      this.subtitleTrack = this.queuedDefaultTrack;\u000a      this.queuedDefaultTrack = null;\u000a    }\u000a\u000a    this.trackChangeListener = this._onTextTracksChanged.bind(this);\u000a    this.useTextTrackPolling = !(this.media.textTracks && 'onchange' in this.media.textTracks);\u000a\u000a    if (this.useTextTrackPolling) {\u000a      this.subtitlePollingInterval = setInterval(function () {\u000a        _this2.trackChangeListener();\u000a      }, 500);\u000a    } else {\u000a      this.media.textTracks.addEventListener('change', this.trackChangeListener);\u000a    }\u000a  };\u000a\u000a  _proto.onMediaDetaching = function onMediaDetaching() {\u000a    if (!this.media) {\u000a      return;\u000a    }\u000a\u000a    if (this.useTextTrackPolling) {\u000a      clearInterval(this.subtitlePollingInterval);\u000a    } else {\u000a      this.media.textTracks.removeEventListener('change', this.trackChangeListener);\u000a    }\u000a\u000a    if (Object(number["isFiniteNumber"])(this.subtitleTrack)) {\u000a      this.queuedDefaultTrack = this.subtitleTrack;\u000a    }\u000a\u000a    var textTracks = filterSubtitleTracks(this.media.textTracks); // Clear loaded cues on media detachment from tracks\u000a\u000a    textTracks.forEach(function (track) {\u000a      clearCurrentCues(track);\u000a    }); // Disable all subtitle tracks before detachment so when reattached only tracks in that content are enabled.\u000a\u000a    this.subtitleTrack = -1;\u000a    this.media = null;\u000a  } // Fired whenever a new manifest is loaded.\u000a  ;\u000a\u000a  _proto.onManifestLoaded = function onManifestLoaded(data) {\u000a    var _this3 = this;\u000a\u000a    var tracks = data.subtitles || [];\u000a    this.tracks = tracks;\u000a    this.hls.trigger(events["default"].SUBTITLE_TRACKS_UPDATED, {\u000a      subtitleTracks: tracks\u000a    }); // loop through available subtitle tracks and autoselect default if needed\u000a    // TODO: improve selection logic to handle forced, etc\u000a\u000a    tracks.forEach(function (track) {\u000a      if (track.default) {\u000a        // setting this.subtitleTrack will trigger internal logic\u000a        // if media has not been attached yet, it will fail\u000a        // we keep a reference to the default track id\u000a        // and we'll set subtitleTrack when onMediaAttached is triggered\u000a        if (_this3.media) {\u000a          _this3.subtitleTrack = track.id;\u000a        } else {\u000a          _this3.queuedDefaultTrack = track.id;\u000a        }\u000a      }\u000a    });\u000a  };\u000a\u000a  _proto.onSubtitleTrackLoaded = function onSubtitleTrackLoaded(data) {\u000a    var _this4 = this;\u000a\u000a    var id = data.id,\u000a        details = data.details;\u000a    var trackId = this.trackId,\u000a        tracks = this.tracks;\u000a    var currentTrack = tracks[trackId];\u000a\u000a    if (id >= tracks.length || id !== trackId || !currentTrack || this.stopped) {\u000a      this._clearReloadTimer();\u000a\u000a      return;\u000a    }\u000a\u000a    logger["logger"].log("subtitle track " + id + " loaded");\u000a\u000a    if (details.live) {\u000a      var reloadInterval = computeReloadInterval(currentTrack.details, details, data.stats.trequest);\u000a      logger["logger"].log("Reloading live subtitle playlist in " + reloadInterval + "ms");\u000a      this.timer = setTimeout(function () {\u000a        _this4._loadCurrentTrack();\u000a      }, reloadInterval);\u000a    } else {\u000a      this._clearReloadTimer();\u000a    }\u000a  };\u000a\u000a  _proto.startLoad = function startLoad() {\u000a    this.stopped = false;\u000a\u000a    this._loadCurrentTrack();\u000a  };\u000a\u000a  _proto.stopLoad = function stopLoad() {\u000a    this.stopped = true;\u000a\u000a    this._clearReloadTimer();\u000a  }\u000a  /** get alternate subtitle tracks list from playlist **/\u000a  ;\u000a\u000a  _proto._clearReloadTimer = function _clearReloadTimer() {\u000a    if (this.timer) {\u000a      clearTimeout(this.timer);\u000a      this.timer = null;\u000a    }\u000a  };\u000a\u000a  _proto._loadCurrentTrack = function _loadCurrentTrack() {\u000a    var trackId = this.trackId,\u000a        tracks = this.tracks,\u000a        hls = this.hls;\u000a    var currentTrack = tracks[trackId];\u000a\u000a    if (trackId < 0 || !currentTrack || currentTrack.details && !currentTrack.details.live) {\u000a      return;\u000a    }\u000a\u000a    logger["logger"].log("Loading subtitle track " + trackId);\u000a    hls.trigger(events["default"].SUBTITLE_TRACK_LOADING, {\u000a      url: currentTrack.url,\u000a      id: trackId\u000a    });\u000a  }\u000a  /**\u000a   * Disables the old subtitleTrack and sets current mode on the next subtitleTrack.\u000a   * This operates on the DOM textTracks.\u000a   * A value of -1 will disable all subtitle tracks.\u000a   * @param newId - The id of the next track to enable\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._toggleTrackModes = function _toggleTrackModes(newId) {\u000a    var media = this.media,\u000a        subtitleDisplay = this.subtitleDisplay,\u000a        trackId = this.trackId;\u000a\u000a    if (!media) {\u000a      return;\u000a    }\u000a\u000a    var textTracks = filterSubtitleTracks(media.textTracks);\u000a\u000a    if (newId === -1) {\u000a      [].slice.call(textTracks).forEach(function (track) {\u000a        track.mode = 'disabled';\u000a      });\u000a    } else {\u000a      var oldTrack = textTracks[trackId];\u000a\u000a      if (oldTrack) {\u000a        oldTrack.mode = 'disabled';\u000a      }\u000a    }\u000a\u000a    var nextTrack = textTracks[newId];\u000a\u000a    if (nextTrack) {\u000a      nextTrack.mode = subtitleDisplay ? 'showing' : 'hidden';\u000a    }\u000a  }\u000a  /**\u000a     * This method is responsible for validating the subtitle index and periodically reloading if live.\u000a     * Dispatches the SUBTITLE_TRACK_SWITCH event, which instructs the subtitle-stream-controller to load the selected track.\u000a     * @param newId - The id of the subtitle track to activate.\u000a     */\u000a  ;\u000a\u000a  _proto._setSubtitleTrackInternal = function _setSubtitleTrackInternal(newId) {\u000a    var hls = this.hls,\u000a        tracks = this.tracks;\u000a\u000a    if (!Object(number["isFiniteNumber"])(newId) || newId < -1 || newId >= tracks.length) {\u000a      return;\u000a    }\u000a\u000a    this.trackId = newId;\u000a    logger["logger"].log("Switching to subtitle track " + newId);\u000a    hls.trigger(events["default"].SUBTITLE_TRACK_SWITCH, {\u000a      id: newId\u000a    });\u000a\u000a    this._loadCurrentTrack();\u000a  };\u000a\u000a  _proto._onTextTracksChanged = function _onTextTracksChanged() {\u000a    // Media is undefined when switching streams via loadSource()\u000a    if (!this.media || !this.hls.config.renderTextTracksNatively) {\u000a      return;\u000a    }\u000a\u000a    var trackId = -1;\u000a    var tracks = filterSubtitleTracks(this.media.textTracks);\u000a\u000a    for (var id = 0; id < tracks.length; id++) {\u000a      if (tracks[id].mode === 'hidden') {\u000a        // Do not break in case there is a following track with showing.\u000a        trackId = id;\u000a      } else if (tracks[id].mode === 'showing') {\u000a        trackId = id;\u000a        break;\u000a      }\u000a    } // Setting current subtitleTrack will invoke code.\u000a\u000a\u000a    this.subtitleTrack = trackId;\u000a  };\u000a\u000a  subtitle_track_controller_createClass(SubtitleTrackController, [{\u000a    key: "subtitleTracks",\u000a    get: function get() {\u000a      return this.tracks;\u000a    }\u000a    /** get index of the selected subtitle track (index in subtitle track lists) **/\u000a\u000a  }, {\u000a    key: "subtitleTrack",\u000a    get: function get() {\u000a      return this.trackId;\u000a    }\u000a    /** select a subtitle track, based on its index in subtitle track lists**/\u000a    ,\u000a    set: function set(subtitleTrackId) {\u000a      if (this.trackId !== subtitleTrackId) {\u000a        this._toggleTrackModes(subtitleTrackId);\u000a\u000a        this._setSubtitleTrackInternal(subtitleTrackId);\u000a      }\u000a    }\u000a  }]);\u000a\u000a  return SubtitleTrackController;\u000a}(event_handler);\u000a\u000afunction filterSubtitleTracks(textTrackList) {\u000a  var tracks = [];\u000a\u000a  for (var i = 0; i < textTrackList.length; i++) {\u000a    var track = textTrackList[i]; // Edge adds a track without a label; we don't want to use it\u000a\u000a    if (track.kind === 'subtitles' && track.label) {\u000a      tracks.push(textTrackList[i]);\u000a    }\u000a  }\u000a\u000a  return tracks;\u000a}\u000a\u000a/* harmony default export */ var subtitle_track_controller = (subtitle_track_controller_SubtitleTrackController);\u000a// EXTERNAL MODULE: ./src/crypt/decrypter.js + 3 modules\u000avar decrypter = __webpack_require__("./src/crypt/decrypter.js");\u000a\u000a// CONCATENATED MODULE: ./src/controller/subtitle-stream-controller.js\u000afunction subtitle_stream_controller_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return self; }\u000a\u000afunction subtitle_stream_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/**\u000a * @class SubtitleStreamController\u000a */\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000avar subtitle_stream_controller_window = window,\u000a    subtitle_stream_controller_performance = subtitle_stream_controller_window.performance;\u000avar subtitle_stream_controller_TICK_INTERVAL = 500; // how often to tick in ms\u000a\u000avar subtitle_stream_controller_SubtitleStreamController = /*#__PURE__*/function (_BaseStreamController) {\u000a  subtitle_stream_controller_inheritsLoose(SubtitleStreamController, _BaseStreamController);\u000a\u000a  function SubtitleStreamController(hls, fragmentTracker) {\u000a    var _this;\u000a\u000a    _this = _BaseStreamController.call(this, hls, events["default"].MEDIA_ATTACHED, events["default"].MEDIA_DETACHING, events["default"].ERROR, events["default"].KEY_LOADED, events["default"].FRAG_LOADED, events["default"].SUBTITLE_TRACKS_UPDATED, events["default"].SUBTITLE_TRACK_SWITCH, events["default"].SUBTITLE_TRACK_LOADED, events["default"].SUBTITLE_FRAG_PROCESSED, events["default"].LEVEL_UPDATED) || this;\u000a    _this.fragmentTracker = fragmentTracker;\u000a    _this.config = hls.config;\u000a    _this.state = State.STOPPED;\u000a    _this.tracks = [];\u000a    _this.tracksBuffered = [];\u000a    _this.currentTrackId = -1;\u000a    _this.decrypter = new decrypter["default"](hls, hls.config); // lastAVStart stores the time in seconds for the start time of a level load\u000a\u000a    _this.lastAVStart = 0;\u000a    _this._onMediaSeeking = _this.onMediaSeeking.bind(subtitle_stream_controller_assertThisInitialized(_this));\u000a    return _this;\u000a  }\u000a\u000a  var _proto = SubtitleStreamController.prototype;\u000a\u000a  _proto.onSubtitleFragProcessed = function onSubtitleFragProcessed(data) {\u000a    var frag = data.frag,\u000a        success = data.success;\u000a    this.fragPrevious = frag;\u000a    this.state = State.IDLE;\u000a\u000a    if (!success) {\u000a      return;\u000a    }\u000a\u000a    var buffered = this.tracksBuffered[this.currentTrackId];\u000a\u000a    if (!buffered) {\u000a      return;\u000a    } // Create/update a buffered array matching the interface used by BufferHelper.bufferedInfo\u000a    // so we can re-use the logic used to detect how much have been buffered\u000a\u000a\u000a    var timeRange;\u000a    var fragStart = frag.start;\u000a\u000a    for (var i = 0; i < buffered.length; i++) {\u000a      if (fragStart >= buffered[i].start && fragStart <= buffered[i].end) {\u000a        timeRange = buffered[i];\u000a        break;\u000a      }\u000a    }\u000a\u000a    var fragEnd = frag.start + frag.duration;\u000a\u000a    if (timeRange) {\u000a      timeRange.end = fragEnd;\u000a    } else {\u000a      timeRange = {\u000a        start: fragStart,\u000a        end: fragEnd\u000a      };\u000a      buffered.push(timeRange);\u000a    }\u000a  };\u000a\u000a  _proto.onMediaAttached = function onMediaAttached(_ref) {\u000a    var media = _ref.media;\u000a    this.media = media;\u000a    media.addEventListener('seeking', this._onMediaSeeking);\u000a    this.state = State.IDLE;\u000a  };\u000a\u000a  _proto.onMediaDetaching = function onMediaDetaching() {\u000a    var _this2 = this;\u000a\u000a    if (!this.media) {\u000a      return;\u000a    }\u000a\u000a    this.media.removeEventListener('seeking', this._onMediaSeeking);\u000a    this.fragmentTracker.removeAllFragments();\u000a    this.currentTrackId = -1;\u000a    this.tracks.forEach(function (track) {\u000a      _this2.tracksBuffered[track.id] = [];\u000a    });\u000a    this.media = null;\u000a    this.state = State.STOPPED;\u000a  } // If something goes wrong, proceed to next frag, if we were processing one.\u000a  ;\u000a\u000a  _proto.onError = function onError(data) {\u000a    var frag = data.frag; // don't handle error not related to subtitle fragment\u000a\u000a    if (!frag || frag.type !== 'subtitle') {\u000a      return;\u000a    }\u000a\u000a    this.state = State.IDLE;\u000a  } // Got all new subtitle tracks.\u000a  ;\u000a\u000a  _proto.onSubtitleTracksUpdated = function onSubtitleTracksUpdated(data) {\u000a    var _this3 = this;\u000a\u000a    logger["logger"].log('subtitle tracks updated');\u000a    this.tracksBuffered = [];\u000a    this.tracks = data.subtitleTracks;\u000a    this.tracks.forEach(function (track) {\u000a      _this3.tracksBuffered[track.id] = [];\u000a    });\u000a  };\u000a\u000a  _proto.onSubtitleTrackSwitch = function onSubtitleTrackSwitch(data) {\u000a    this.currentTrackId = data.id;\u000a\u000a    if (!this.tracks || !this.tracks.length || this.currentTrackId === -1) {\u000a      this.clearInterval();\u000a      return;\u000a    } // Check if track has the necessary details to load fragments\u000a\u000a\u000a    var currentTrack = this.tracks[this.currentTrackId];\u000a\u000a    if (currentTrack && currentTrack.details) {\u000a      this.setInterval(subtitle_stream_controller_TICK_INTERVAL);\u000a    }\u000a  } // Got a new set of subtitle fragments.\u000a  ;\u000a\u000a  _proto.onSubtitleTrackLoaded = function onSubtitleTrackLoaded(data) {\u000a    var id = data.id,\u000a        details = data.details;\u000a    var currentTrackId = this.currentTrackId,\u000a        tracks = this.tracks;\u000a    var currentTrack = tracks[currentTrackId];\u000a\u000a    if (id >= tracks.length || id !== currentTrackId || !currentTrack) {\u000a      return;\u000a    }\u000a\u000a    if (details.live) {\u000a      mergeSubtitlePlaylists(currentTrack.details, details, this.lastAVStart);\u000a    }\u000a\u000a    currentTrack.details = details;\u000a    this.setInterval(subtitle_stream_controller_TICK_INTERVAL);\u000a  };\u000a\u000a  _proto.onKeyLoaded = function onKeyLoaded() {\u000a    if (this.state === State.KEY_LOADING) {\u000a      this.state = State.IDLE;\u000a    }\u000a  };\u000a\u000a  _proto.onFragLoaded = function onFragLoaded(data) {\u000a    var fragCurrent = this.fragCurrent;\u000a    var decryptData = data.frag.decryptdata;\u000a    var fragLoaded = data.frag;\u000a    var hls = this.hls;\u000a\u000a    if (this.state === State.FRAG_LOADING && fragCurrent && data.frag.type === 'subtitle' && fragCurrent.sn === data.frag.sn) {\u000a      // check to see if the payload needs to be decrypted\u000a      if (data.payload.byteLength > 0 && decryptData && decryptData.key && decryptData.method === 'AES-128') {\u000a        var startTime = subtitle_stream_controller_performance.now(); // decrypt the subtitles\u000a\u000a        this.decrypter.decrypt(data.payload, decryptData.key.buffer, decryptData.iv.buffer, function (decryptedData) {\u000a          var endTime = subtitle_stream_controller_performance.now();\u000a          hls.trigger(events["default"].FRAG_DECRYPTED, {\u000a            frag: fragLoaded,\u000a            payload: decryptedData,\u000a            stats: {\u000a              tstart: startTime,\u000a              tdecrypt: endTime\u000a            }\u000a          });\u000a        });\u000a      }\u000a    }\u000a  };\u000a\u000a  _proto.onLevelUpdated = function onLevelUpdated(_ref2) {\u000a    var details = _ref2.details;\u000a    var frags = details.fragments;\u000a    this.lastAVStart = frags.length ? frags[0].start : 0;\u000a  };\u000a\u000a  _proto.doTick = function doTick() {\u000a    if (!this.media) {\u000a      this.state = State.IDLE;\u000a      return;\u000a    }\u000a\u000a    switch (this.state) {\u000a      case State.IDLE:\u000a        {\u000a          var config = this.config,\u000a              currentTrackId = this.currentTrackId,\u000a              fragmentTracker = this.fragmentTracker,\u000a              media = this.media,\u000a              tracks = this.tracks;\u000a\u000a          if (!tracks || !tracks[currentTrackId] || !tracks[currentTrackId].details) {\u000a            break;\u000a          }\u000a\u000a          var maxBufferHole = config.maxBufferHole,\u000a              maxFragLookUpTolerance = config.maxFragLookUpTolerance;\u000a          var maxConfigBuffer = Math.min(config.maxBufferLength, config.maxMaxBufferLength);\u000a          var bufferedInfo = BufferHelper.bufferedInfo(this._getBuffered(), media.currentTime, maxBufferHole);\u000a          var bufferEnd = bufferedInfo.end,\u000a              bufferLen = bufferedInfo.len;\u000a          var trackDetails = tracks[currentTrackId].details;\u000a          var fragments = trackDetails.fragments;\u000a          var fragLen = fragments.length;\u000a          var end = fragments[fragLen - 1].start + fragments[fragLen - 1].duration;\u000a\u000a          if (bufferLen > maxConfigBuffer) {\u000a            return;\u000a          }\u000a\u000a          var foundFrag;\u000a          var fragPrevious = this.fragPrevious;\u000a\u000a          if (bufferEnd < end) {\u000a            if (fragPrevious && trackDetails.hasProgramDateTime) {\u000a              foundFrag = findFragmentByPDT(fragments, fragPrevious.endProgramDateTime, maxFragLookUpTolerance);\u000a            }\u000a\u000a            if (!foundFrag) {\u000a              foundFrag = findFragmentByPTS(fragPrevious, fragments, bufferEnd, maxFragLookUpTolerance);\u000a            }\u000a          } else {\u000a            foundFrag = fragments[fragLen - 1];\u000a          }\u000a\u000a          if (foundFrag && foundFrag.encrypted) {\u000a            logger["logger"].log("Loading key for " + foundFrag.sn);\u000a            this.state = State.KEY_LOADING;\u000a            this.hls.trigger(events["default"].KEY_LOADING, {\u000a              frag: foundFrag\u000a            });\u000a          } else if (foundFrag && fragmentTracker.getState(foundFrag) === FragmentState.NOT_LOADED) {\u000a            // only load if fragment is not loaded\u000a            this.fragCurrent = foundFrag;\u000a            this.state = State.FRAG_LOADING;\u000a            this.hls.trigger(events["default"].FRAG_LOADING, {\u000a              frag: foundFrag\u000a            });\u000a          }\u000a        }\u000a    }\u000a  };\u000a\u000a  _proto.stopLoad = function stopLoad() {\u000a    this.lastAVStart = 0;\u000a\u000a    _BaseStreamController.prototype.stopLoad.call(this);\u000a  };\u000a\u000a  _proto._getBuffered = function _getBuffered() {\u000a    return this.tracksBuffered[this.currentTrackId] || [];\u000a  };\u000a\u000a  _proto.onMediaSeeking = function onMediaSeeking() {\u000a    this.fragPrevious = null;\u000a  };\u000a\u000a  return SubtitleStreamController;\u000a}(base_stream_controller_BaseStreamController);\u000a// CONCATENATED MODULE: ./src/utils/mediakeys-helper.ts\u000a/**\u000a * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/requestMediaKeySystemAccess\u000a */\u000avar KeySystems;\u000a\u000a(function (KeySystems) {\u000a  KeySystems["WIDEVINE"] = "com.widevine.alpha";\u000a  KeySystems["PLAYREADY"] = "com.microsoft.playready";\u000a})(KeySystems || (KeySystems = {}));\u000a\u000avar requestMediaKeySystemAccess = function () {\u000a  if (typeof window !== 'undefined' && window.navigator && window.navigator.requestMediaKeySystemAccess) {\u000a    return window.navigator.requestMediaKeySystemAccess.bind(window.navigator);\u000a  } else {\u000a    return null;\u000a  }\u000a}();\u000a\u000a\u000a// CONCATENATED MODULE: ./src/controller/eme-controller.ts\u000afunction eme_controller_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction eme_controller_createClass(Constructor, protoProps, staticProps) { if (protoProps) eme_controller_defineProperties(Constructor.prototype, protoProps); if (staticProps) eme_controller_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000afunction eme_controller_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a/**\u000a * @author Stephan Hesse <disparat@gmail.com> | <tchakabam@gmail.com>\u000a *\u000a * DRM support for Hls.js\u000a */\u000a\u000a\u000a\u000a\u000a\u000avar MAX_LICENSE_REQUEST_FAILURES = 3;\u000a/**\u000a * @see https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemConfiguration\u000a * @param {Array<string>} audioCodecs List of required audio codecs to support\u000a * @param {Array<string>} videoCodecs List of required video codecs to support\u000a * @param {object} drmSystemOptions Optional parameters/requirements for the key-system\u000a * @returns {Array<MediaSystemConfiguration>} An array of supported configurations\u000a */\u000a\u000avar createWidevineMediaKeySystemConfigurations = function createWidevineMediaKeySystemConfigurations(audioCodecs, videoCodecs, drmSystemOptions) {\u000a  /* jshint ignore:line */\u000a  var baseConfig = {\u000a    // initDataTypes: ['keyids', 'mp4'],\u000a    // label: "",\u000a    // persistentState: "not-allowed", // or "required" ?\u000a    // distinctiveIdentifier: "not-allowed", // or "required" ?\u000a    // sessionTypes: ['temporary'],\u000a    audioCapabilities: [],\u000a    // { contentType: 'audio/mp4; codecs="mp4a.40.2"' }\u000a    videoCapabilities: [] // { contentType: 'video/mp4; codecs="avc1.42E01E"' }\u000a\u000a  };\u000a  audioCodecs.forEach(function (codec) {\u000a    baseConfig.audioCapabilities.push({\u000a      contentType: "audio/mp4; codecs=\u005c"" + codec + "\u005c"",\u000a      robustness: drmSystemOptions.audioRobustness || ''\u000a    });\u000a  });\u000a  videoCodecs.forEach(function (codec) {\u000a    baseConfig.videoCapabilities.push({\u000a      contentType: "video/mp4; codecs=\u005c"" + codec + "\u005c"",\u000a      robustness: drmSystemOptions.videoRobustness || ''\u000a    });\u000a  });\u000a  return [baseConfig];\u000a};\u000a/**\u000a * The idea here is to handle key-system (and their respective platforms) specific configuration differences\u000a * in order to work with the local requestMediaKeySystemAccess method.\u000a *\u000a * We can also rule-out platform-related key-system support at this point by throwing an error.\u000a *\u000a * @param {string} keySystem Identifier for the key-system, see `KeySystems` enum\u000a * @param {Array<string>} audioCodecs List of required audio codecs to support\u000a * @param {Array<string>} videoCodecs List of required video codecs to support\u000a * @throws will throw an error if a unknown key system is passed\u000a * @returns {Array<MediaSystemConfiguration>} A non-empty Array of MediaKeySystemConfiguration objects\u000a */\u000a\u000a\u000avar eme_controller_getSupportedMediaKeySystemConfigurations = function getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, drmSystemOptions) {\u000a  switch (keySystem) {\u000a    case KeySystems.WIDEVINE:\u000a      return createWidevineMediaKeySystemConfigurations(audioCodecs, videoCodecs, drmSystemOptions);\u000a\u000a    default:\u000a      throw new Error("Unknown key-system: " + keySystem);\u000a  }\u000a};\u000a\u000a/**\u000a * Controller to deal with encrypted media extensions (EME)\u000a * @see https://developer.mozilla.org/en-US/docs/Web/API/Encrypted_Media_Extensions_API\u000a *\u000a * @class\u000a * @constructor\u000a */\u000avar eme_controller_EMEController = /*#__PURE__*/function (_EventHandler) {\u000a  eme_controller_inheritsLoose(EMEController, _EventHandler);\u000a\u000a  /**\u000a     * @constructs\u000a     * @param {Hls} hls Our Hls.js instance\u000a     */\u000a  function EMEController(hls) {\u000a    var _this;\u000a\u000a    _this = _EventHandler.call(this, hls, events["default"].MEDIA_ATTACHED, events["default"].MEDIA_DETACHED, events["default"].MANIFEST_PARSED) || this;\u000a    _this._widevineLicenseUrl = void 0;\u000a    _this._licenseXhrSetup = void 0;\u000a    _this._emeEnabled = void 0;\u000a    _this._requestMediaKeySystemAccess = void 0;\u000a    _this._drmSystemOptions = void 0;\u000a    _this._config = void 0;\u000a    _this._mediaKeysList = [];\u000a    _this._media = null;\u000a    _this._hasSetMediaKeys = false;\u000a    _this._requestLicenseFailureCount = 0;\u000a    _this.mediaKeysPromise = null;\u000a\u000a    _this._onMediaEncrypted = function (e) {\u000a      logger["logger"].log("Media is encrypted using \u005c"" + e.initDataType + "\u005c" init data type");\u000a\u000a      if (!_this.mediaKeysPromise) {\u000a        logger["logger"].error('Fatal: Media is encrypted but no CDM access or no keys have been requested');\u000a\u000a        _this.hls.trigger(events["default"].ERROR, {\u000a          type: errors["ErrorTypes"].KEY_SYSTEM_ERROR,\u000a          details: errors["ErrorDetails"].KEY_SYSTEM_NO_KEYS,\u000a          fatal: true\u000a        });\u000a\u000a        return;\u000a      }\u000a\u000a      var finallySetKeyAndStartSession = function finallySetKeyAndStartSession(mediaKeys) {\u000a        if (!_this._media) {\u000a          return;\u000a        }\u000a\u000a        _this._attemptSetMediaKeys(mediaKeys);\u000a\u000a        _this._generateRequestWithPreferredKeySession(e.initDataType, e.initData);\u000a      }; // Could use `Promise.finally` but some Promise polyfills are missing it\u000a\u000a\u000a      _this.mediaKeysPromise.then(finallySetKeyAndStartSession).catch(finallySetKeyAndStartSession);\u000a    };\u000a\u000a    _this._config = hls.config;\u000a    _this._widevineLicenseUrl = _this._config.widevineLicenseUrl;\u000a    _this._licenseXhrSetup = _this._config.licenseXhrSetup;\u000a    _this._emeEnabled = _this._config.emeEnabled;\u000a    _this._requestMediaKeySystemAccess = _this._config.requestMediaKeySystemAccessFunc;\u000a    _this._drmSystemOptions = hls.config.drmSystemOptions;\u000a    return _this;\u000a  }\u000a  /**\u000a   * @param {string} keySystem Identifier for the key-system, see `KeySystems` enum\u000a   * @returns {string} License server URL for key-system (if any configured, otherwise causes error)\u000a   * @throws if a unsupported keysystem is passed\u000a   */\u000a\u000a\u000a  var _proto = EMEController.prototype;\u000a\u000a  _proto.getLicenseServerUrl = function getLicenseServerUrl(keySystem) {\u000a    switch (keySystem) {\u000a      case KeySystems.WIDEVINE:\u000a        if (!this._widevineLicenseUrl) {\u000a          break;\u000a        }\u000a\u000a        return this._widevineLicenseUrl;\u000a    }\u000a\u000a    throw new Error("no license server URL configured for key-system \u005c"" + keySystem + "\u005c"");\u000a  }\u000a  /**\u000a     * Requests access object and adds it to our list upon success\u000a     * @private\u000a     * @param {string} keySystem System ID (see `KeySystems`)\u000a     * @param {Array<string>} audioCodecs List of required audio codecs to support\u000a     * @param {Array<string>} videoCodecs List of required video codecs to support\u000a     * @throws When a unsupported KeySystem is passed\u000a     */\u000a  ;\u000a\u000a  _proto._attemptKeySystemAccess = function _attemptKeySystemAccess(keySystem, audioCodecs, videoCodecs) {\u000a    var _this2 = this;\u000a\u000a    // This can throw, but is caught in event handler callpath\u000a    var mediaKeySystemConfigs = eme_controller_getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, this._drmSystemOptions);\u000a    logger["logger"].log('Requesting encrypted media key-system access'); // expecting interface like window.navigator.requestMediaKeySystemAccess\u000a\u000a    var keySystemAccessPromise = this.requestMediaKeySystemAccess(keySystem, mediaKeySystemConfigs);\u000a    this.mediaKeysPromise = keySystemAccessPromise.then(function (mediaKeySystemAccess) {\u000a      return _this2._onMediaKeySystemAccessObtained(keySystem, mediaKeySystemAccess);\u000a    });\u000a    keySystemAccessPromise.catch(function (err) {\u000a      logger["logger"].error("Failed to obtain key-system \u005c"" + keySystem + "\u005c" access:", err);\u000a    });\u000a  };\u000a\u000a  /**\u000a     * Handles obtaining access to a key-system\u000a     * @private\u000a     * @param {string} keySystem\u000a     * @param {MediaKeySystemAccess} mediaKeySystemAccess https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemAccess\u000a     */\u000a  _proto._onMediaKeySystemAccessObtained = function _onMediaKeySystemAccessObtained(keySystem, mediaKeySystemAccess) {\u000a    var _this3 = this;\u000a\u000a    logger["logger"].log("Access for key-system \u005c"" + keySystem + "\u005c" obtained");\u000a    var mediaKeysListItem = {\u000a      mediaKeysSessionInitialized: false,\u000a      mediaKeySystemAccess: mediaKeySystemAccess,\u000a      mediaKeySystemDomain: keySystem\u000a    };\u000a\u000a    this._mediaKeysList.push(mediaKeysListItem);\u000a\u000a    var mediaKeysPromise = Promise.resolve().then(function () {\u000a      return mediaKeySystemAccess.createMediaKeys();\u000a    }).then(function (mediaKeys) {\u000a      mediaKeysListItem.mediaKeys = mediaKeys;\u000a      logger["logger"].log("Media-keys created for key-system \u005c"" + keySystem + "\u005c"");\u000a\u000a      _this3._onMediaKeysCreated();\u000a\u000a      return mediaKeys;\u000a    });\u000a    mediaKeysPromise.catch(function (err) {\u000a      logger["logger"].error('Failed to create media-keys:', err);\u000a    });\u000a    return mediaKeysPromise;\u000a  }\u000a  /**\u000a   * Handles key-creation (represents access to CDM). We are going to create key-sessions upon this\u000a   * for all existing keys where no session exists yet.\u000a   *\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._onMediaKeysCreated = function _onMediaKeysCreated() {\u000a    var _this4 = this;\u000a\u000a    // check for all key-list items if a session exists, otherwise, create one\u000a    this._mediaKeysList.forEach(function (mediaKeysListItem) {\u000a      if (!mediaKeysListItem.mediaKeysSession) {\u000a        // mediaKeys is definitely initialized here\u000a        mediaKeysListItem.mediaKeysSession = mediaKeysListItem.mediaKeys.createSession();\u000a\u000a        _this4._onNewMediaKeySession(mediaKeysListItem.mediaKeysSession);\u000a      }\u000a    });\u000a  }\u000a  /**\u000a     * @private\u000a     * @param {*} keySession\u000a     */\u000a  ;\u000a\u000a  _proto._onNewMediaKeySession = function _onNewMediaKeySession(keySession) {\u000a    var _this5 = this;\u000a\u000a    logger["logger"].log("New key-system session " + keySession.sessionId);\u000a    keySession.addEventListener('message', function (event) {\u000a      _this5._onKeySessionMessage(keySession, event.message);\u000a    }, false);\u000a  }\u000a  /**\u000a   * @private\u000a   * @param {MediaKeySession} keySession\u000a   * @param {ArrayBuffer} message\u000a   */\u000a  ;\u000a\u000a  _proto._onKeySessionMessage = function _onKeySessionMessage(keySession, message) {\u000a    logger["logger"].log('Got EME message event, creating license request');\u000a\u000a    this._requestLicense(message, function (data) {\u000a      logger["logger"].log("Received license data (length: " + (data ? data.byteLength : data) + "), updating key-session");\u000a      keySession.update(data);\u000a    });\u000a  }\u000a  /**\u000a   * @private\u000a   * @param e {MediaEncryptedEvent}\u000a   */\u000a  ;\u000a\u000a  /**\u000a   * @private\u000a   */\u000a  _proto._attemptSetMediaKeys = function _attemptSetMediaKeys(mediaKeys) {\u000a    if (!this._media) {\u000a      throw new Error('Attempted to set mediaKeys without first attaching a media element');\u000a    }\u000a\u000a    if (!this._hasSetMediaKeys) {\u000a      // FIXME: see if we can/want/need-to really to deal with several potential key-sessions?\u000a      var keysListItem = this._mediaKeysList[0];\u000a\u000a      if (!keysListItem || !keysListItem.mediaKeys) {\u000a        logger["logger"].error('Fatal: Media is encrypted but no CDM access or no keys have been obtained yet');\u000a        this.hls.trigger(events["default"].ERROR, {\u000a          type: errors["ErrorTypes"].KEY_SYSTEM_ERROR,\u000a          details: errors["ErrorDetails"].KEY_SYSTEM_NO_KEYS,\u000a          fatal: true\u000a        });\u000a        return;\u000a      }\u000a\u000a      logger["logger"].log('Setting keys for encrypted media');\u000a\u000a      this._media.setMediaKeys(keysListItem.mediaKeys);\u000a\u000a      this._hasSetMediaKeys = true;\u000a    }\u000a  }\u000a  /**\u000a   * @private\u000a   */\u000a  ;\u000a\u000a  _proto._generateRequestWithPreferredKeySession = function _generateRequestWithPreferredKeySession(initDataType, initData) {\u000a    var _this6 = this;\u000a\u000a    // FIXME: see if we can/want/need-to really to deal with several potential key-sessions?\u000a    var keysListItem = this._mediaKeysList[0];\u000a\u000a    if (!keysListItem) {\u000a      logger["logger"].error('Fatal: Media is encrypted but not any key-system access has been obtained yet');\u000a      this.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].KEY_SYSTEM_ERROR,\u000a        details: errors["ErrorDetails"].KEY_SYSTEM_NO_ACCESS,\u000a        fatal: true\u000a      });\u000a      return;\u000a    }\u000a\u000a    if (keysListItem.mediaKeysSessionInitialized) {\u000a      logger["logger"].warn('Key-Session already initialized but requested again');\u000a      return;\u000a    }\u000a\u000a    var keySession = keysListItem.mediaKeysSession;\u000a\u000a    if (!keySession) {\u000a      logger["logger"].error('Fatal: Media is encrypted but no key-session existing');\u000a      this.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].KEY_SYSTEM_ERROR,\u000a        details: errors["ErrorDetails"].KEY_SYSTEM_NO_SESSION,\u000a        fatal: true\u000a      });\u000a      return;\u000a    } // initData is null if the media is not CORS-same-origin\u000a\u000a\u000a    if (!initData) {\u000a      logger["logger"].warn('Fatal: initData required for generating a key session is null');\u000a      this.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].KEY_SYSTEM_ERROR,\u000a        details: errors["ErrorDetails"].KEY_SYSTEM_NO_INIT_DATA,\u000a        fatal: true\u000a      });\u000a      return;\u000a    }\u000a\u000a    logger["logger"].log("Generating key-session request for \u005c"" + initDataType + "\u005c" init data type");\u000a    keysListItem.mediaKeysSessionInitialized = true;\u000a    keySession.generateRequest(initDataType, initData).then(function () {\u000a      logger["logger"].debug('Key-session generation succeeded');\u000a    }).catch(function (err) {\u000a      logger["logger"].error('Error generating key-session request:', err);\u000a\u000a      _this6.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].KEY_SYSTEM_ERROR,\u000a        details: errors["ErrorDetails"].KEY_SYSTEM_NO_SESSION,\u000a        fatal: false\u000a      });\u000a    });\u000a  }\u000a  /**\u000a   * @private\u000a   * @param {string} url License server URL\u000a   * @param {ArrayBuffer} keyMessage Message data issued by key-system\u000a   * @param {function} callback Called when XHR has succeeded\u000a   * @returns {XMLHttpRequest} Unsent (but opened state) XHR object\u000a   * @throws if XMLHttpRequest construction failed\u000a   */\u000a  ;\u000a\u000a  _proto._createLicenseXhr = function _createLicenseXhr(url, keyMessage, callback) {\u000a    var xhr = new XMLHttpRequest();\u000a    var licenseXhrSetup = this._licenseXhrSetup;\u000a\u000a    try {\u000a      if (licenseXhrSetup) {\u000a        try {\u000a          licenseXhrSetup(xhr, url);\u000a        } catch (e) {\u000a          // let's try to open before running setup\u000a          xhr.open('POST', url, true);\u000a          licenseXhrSetup(xhr, url);\u000a        }\u000a      } // if licenseXhrSetup did not yet call open, let's do it now\u000a\u000a\u000a      if (!xhr.readyState) {\u000a        xhr.open('POST', url, true);\u000a      }\u000a    } catch (e) {\u000a      // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS\u000a      throw new Error("issue setting up KeySystem license XHR " + e);\u000a    } // Because we set responseType to ArrayBuffer here, callback is typed as handling only array buffers\u000a\u000a\u000a    xhr.responseType = 'arraybuffer';\u000a    xhr.onreadystatechange = this._onLicenseRequestReadyStageChange.bind(this, xhr, url, keyMessage, callback);\u000a    return xhr;\u000a  }\u000a  /**\u000a   * @private\u000a   * @param {XMLHttpRequest} xhr\u000a   * @param {string} url License server URL\u000a   * @param {ArrayBuffer} keyMessage Message data issued by key-system\u000a   * @param {function} callback Called when XHR has succeeded\u000a   */\u000a  ;\u000a\u000a  _proto._onLicenseRequestReadyStageChange = function _onLicenseRequestReadyStageChange(xhr, url, keyMessage, callback) {\u000a    switch (xhr.readyState) {\u000a      case 4:\u000a        if (xhr.status === 200) {\u000a          this._requestLicenseFailureCount = 0;\u000a          logger["logger"].log('License request succeeded');\u000a\u000a          if (xhr.responseType !== 'arraybuffer') {\u000a            logger["logger"].warn('xhr response type was not set to the expected arraybuffer for license request');\u000a          }\u000a\u000a          callback(xhr.response);\u000a        } else {\u000a          logger["logger"].error("License Request XHR failed (" + url + "). Status: " + xhr.status + " (" + xhr.statusText + ")");\u000a          this._requestLicenseFailureCount++;\u000a\u000a          if (this._requestLicenseFailureCount > MAX_LICENSE_REQUEST_FAILURES) {\u000a            this.hls.trigger(events["default"].ERROR, {\u000a              type: errors["ErrorTypes"].KEY_SYSTEM_ERROR,\u000a              details: errors["ErrorDetails"].KEY_SYSTEM_LICENSE_REQUEST_FAILED,\u000a              fatal: true\u000a            });\u000a            return;\u000a          }\u000a\u000a          var attemptsLeft = MAX_LICENSE_REQUEST_FAILURES - this._requestLicenseFailureCount + 1;\u000a          logger["logger"].warn("Retrying license request, " + attemptsLeft + " attempts left");\u000a\u000a          this._requestLicense(keyMessage, callback);\u000a        }\u000a\u000a        break;\u000a    }\u000a  }\u000a  /**\u000a   * @private\u000a   * @param {MediaKeysListItem} keysListItem\u000a   * @param {ArrayBuffer} keyMessage\u000a   * @returns {ArrayBuffer} Challenge data posted to license server\u000a   * @throws if KeySystem is unsupported\u000a   */\u000a  ;\u000a\u000a  _proto._generateLicenseRequestChallenge = function _generateLicenseRequestChallenge(keysListItem, keyMessage) {\u000a    switch (keysListItem.mediaKeySystemDomain) {\u000a      // case KeySystems.PLAYREADY:\u000a      // from https://github.com/MicrosoftEdge/Demos/blob/master/eme/scripts/demo.js\u000a\u000a      /*\u000a        if (this.licenseType !== this.LICENSE_TYPE_WIDEVINE) {\u000a          // For PlayReady CDMs, we need to dig the Challenge out of the XML.\u000a          var keyMessageXml = new DOMParser().parseFromString(String.fromCharCode.apply(null, new Uint16Array(keyMessage)), 'application/xml');\u000a          if (keyMessageXml.getElementsByTagName('Challenge')[0]) {\u000a              challenge = atob(keyMessageXml.getElementsByTagName('Challenge')[0].childNodes[0].nodeValue);\u000a          } else {\u000a              throw 'Cannot find <Challenge> in key message';\u000a          }\u000a          var headerNames = keyMessageXml.getElementsByTagName('name');\u000a          var headerValues = keyMessageXml.getElementsByTagName('value');\u000a          if (headerNames.length !== headerValues.length) {\u000a              throw 'Mismatched header <name>/<value> pair in key message';\u000a          }\u000a          for (var i = 0; i < headerNames.length; i++) {\u000a              xhr.setRequestHeader(headerNames[i].childNodes[0].nodeValue, headerValues[i].childNodes[0].nodeValue);\u000a          }\u000a        }\u000a        break;\u000a      */\u000a      case KeySystems.WIDEVINE:\u000a        // For Widevine CDMs, the challenge is the keyMessage.\u000a        return keyMessage;\u000a    }\u000a\u000a    throw new Error("unsupported key-system: " + keysListItem.mediaKeySystemDomain);\u000a  }\u000a  /**\u000a   * @private\u000a   * @param keyMessage\u000a   * @param callback\u000a   */\u000a  ;\u000a\u000a  _proto._requestLicense = function _requestLicense(keyMessage, callback) {\u000a    logger["logger"].log('Requesting content license for key-system');\u000a    var keysListItem = this._mediaKeysList[0];\u000a\u000a    if (!keysListItem) {\u000a      logger["logger"].error('Fatal error: Media is encrypted but no key-system access has been obtained yet');\u000a      this.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].KEY_SYSTEM_ERROR,\u000a        details: errors["ErrorDetails"].KEY_SYSTEM_NO_ACCESS,\u000a        fatal: true\u000a      });\u000a      return;\u000a    }\u000a\u000a    try {\u000a      var _url = this.getLicenseServerUrl(keysListItem.mediaKeySystemDomain);\u000a\u000a      var _xhr = this._createLicenseXhr(_url, keyMessage, callback);\u000a\u000a      logger["logger"].log("Sending license request to URL: " + _url);\u000a\u000a      var challenge = this._generateLicenseRequestChallenge(keysListItem, keyMessage);\u000a\u000a      _xhr.send(challenge);\u000a    } catch (e) {\u000a      logger["logger"].error("Failure requesting DRM license: " + e);\u000a      this.hls.trigger(events["default"].ERROR, {\u000a        type: errors["ErrorTypes"].KEY_SYSTEM_ERROR,\u000a        details: errors["ErrorDetails"].KEY_SYSTEM_LICENSE_REQUEST_FAILED,\u000a        fatal: true\u000a      });\u000a    }\u000a  };\u000a\u000a  _proto.onMediaAttached = function onMediaAttached(data) {\u000a    if (!this._emeEnabled) {\u000a      return;\u000a    }\u000a\u000a    var media = data.media; // keep reference of media\u000a\u000a    this._media = media;\u000a    media.addEventListener('encrypted', this._onMediaEncrypted);\u000a  };\u000a\u000a  _proto.onMediaDetached = function onMediaDetached() {\u000a    var media = this._media;\u000a    var mediaKeysList = this._mediaKeysList;\u000a\u000a    if (!media) {\u000a      return;\u000a    }\u000a\u000a    media.removeEventListener('encrypted', this._onMediaEncrypted);\u000a    this._media = null;\u000a    this._mediaKeysList = []; // Close all sessions and remove media keys from the video element.\u000a\u000a    Promise.all(mediaKeysList.map(function (mediaKeysListItem) {\u000a      if (mediaKeysListItem.mediaKeysSession) {\u000a        return mediaKeysListItem.mediaKeysSession.close().catch(function () {// Ignore errors when closing the sessions. Closing a session that\u000a          // generated no key requests will throw an error.\u000a        });\u000a      }\u000a    })).then(function () {\u000a      return media.setMediaKeys(null);\u000a    }).catch(function () {// Ignore any failures while removing media keys from the video element.\u000a    });\u000a  } // TODO: Use manifest types here when they are defined\u000a  ;\u000a\u000a  _proto.onManifestParsed = function onManifestParsed(data) {\u000a    if (!this._emeEnabled) {\u000a      return;\u000a    }\u000a\u000a    var audioCodecs = data.levels.map(function (level) {\u000a      return level.audioCodec;\u000a    });\u000a    var videoCodecs = data.levels.map(function (level) {\u000a      return level.videoCodec;\u000a    });\u000a\u000a    this._attemptKeySystemAccess(KeySystems.WIDEVINE, audioCodecs, videoCodecs);\u000a  };\u000a\u000a  eme_controller_createClass(EMEController, [{\u000a    key: "requestMediaKeySystemAccess",\u000a    get: function get() {\u000a      if (!this._requestMediaKeySystemAccess) {\u000a        throw new Error('No requestMediaKeySystemAccess function configured');\u000a      }\u000a\u000a      return this._requestMediaKeySystemAccess;\u000a    }\u000a  }]);\u000a\u000a  return EMEController;\u000a}(event_handler);\u000a\u000a/* harmony default export */ var eme_controller = (eme_controller_EMEController);\u000a// CONCATENATED MODULE: ./src/config.ts\u000afunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\u000a\u000afunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\u000a\u000afunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\u000a\u000a/**\u000a * HLS config\u000a */\u000a\u000a\u000a\u000a\u000a // import FetchLoader from './utils/fetch-loader';\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a// If possible, keep hlsDefaultConfig shallow\u000a// It is cloned whenever a new Hls instance is created, by keeping the config\u000a// shallow the properties are cloned, and we don't end up manipulating the default\u000avar hlsDefaultConfig = _objectSpread(_objectSpread({\u000a  autoStartLoad: true,\u000a  // used by stream-controller\u000a  startPosition: -1,\u000a  // used by stream-controller\u000a  defaultAudioCodec: void 0,\u000a  // used by stream-controller\u000a  debug: false,\u000a  // used by logger\u000a  capLevelOnFPSDrop: false,\u000a  // used by fps-controller\u000a  capLevelToPlayerSize: false,\u000a  // used by cap-level-controller\u000a  initialLiveManifestSize: 1,\u000a  // used by stream-controller\u000a  maxBufferLength: 30,\u000a  // used by stream-controller\u000a  maxBufferSize: 60 * 1000 * 1000,\u000a  // used by stream-controller\u000a  maxBufferHole: 0.5,\u000a  // used by stream-controller\u000a  lowBufferWatchdogPeriod: 0.5,\u000a  // used by stream-controller\u000a  highBufferWatchdogPeriod: 3,\u000a  // used by stream-controller\u000a  nudgeOffset: 0.1,\u000a  // used by stream-controller\u000a  nudgeMaxRetry: 3,\u000a  // used by stream-controller\u000a  maxFragLookUpTolerance: 0.25,\u000a  // used by stream-controller\u000a  liveSyncDurationCount: 3,\u000a  // used by stream-controller\u000a  liveMaxLatencyDurationCount: Infinity,\u000a  // used by stream-controller\u000a  liveSyncDuration: void 0,\u000a  // used by stream-controller\u000a  liveMaxLatencyDuration: void 0,\u000a  // used by stream-controller\u000a  liveDurationInfinity: false,\u000a  // used by buffer-controller\u000a  liveBackBufferLength: Infinity,\u000a  // used by buffer-controller\u000a  maxMaxBufferLength: 600,\u000a  // used by stream-controller\u000a  enableWorker: true,\u000a  // used by demuxer\u000a  enableSoftwareAES: true,\u000a  // used by decrypter\u000a  manifestLoadingTimeOut: 10000,\u000a  // used by playlist-loader\u000a  manifestLoadingMaxRetry: 1,\u000a  // used by playlist-loader\u000a  manifestLoadingRetryDelay: 1000,\u000a  // used by playlist-loader\u000a  manifestLoadingMaxRetryTimeout: 64000,\u000a  // used by playlist-loader\u000a  startLevel: void 0,\u000a  // used by level-controller\u000a  levelLoadingTimeOut: 10000,\u000a  // used by playlist-loader\u000a  levelLoadingMaxRetry: 4,\u000a  // used by playlist-loader\u000a  levelLoadingRetryDelay: 1000,\u000a  // used by playlist-loader\u000a  levelLoadingMaxRetryTimeout: 64000,\u000a  // used by playlist-loader\u000a  fragLoadingTimeOut: 20000,\u000a  // used by fragment-loader\u000a  fragLoadingMaxRetry: 6,\u000a  // used by fragment-loader\u000a  fragLoadingRetryDelay: 1000,\u000a  // used by fragment-loader\u000a  fragLoadingMaxRetryTimeout: 64000,\u000a  // used by fragment-loader\u000a  startFragPrefetch: false,\u000a  // used by stream-controller\u000a  fpsDroppedMonitoringPeriod: 5000,\u000a  // used by fps-controller\u000a  fpsDroppedMonitoringThreshold: 0.2,\u000a  // used by fps-controller\u000a  appendErrorMaxRetry: 3,\u000a  // used by buffer-controller\u000a  loader: xhr_loader,\u000a  // loader: FetchLoader,\u000a  fLoader: void 0,\u000a  // used by fragment-loader\u000a  pLoader: void 0,\u000a  // used by playlist-loader\u000a  xhrSetup: void 0,\u000a  // used by xhr-loader\u000a  licenseXhrSetup: void 0,\u000a  // used by eme-controller\u000a  // fetchSetup: void 0,\u000a  abrController: abr_controller,\u000a  bufferController: buffer_controller,\u000a  capLevelController: cap_level_controller,\u000a  fpsController: fps_controller,\u000a  stretchShortVideoTrack: false,\u000a  // used by mp4-remuxer\u000a  maxAudioFramesDrift: 1,\u000a  // used by mp4-remuxer\u000a  forceKeyFrameOnDiscontinuity: true,\u000a  // used by ts-demuxer\u000a  abrEwmaFastLive: 3,\u000a  // used by abr-controller\u000a  abrEwmaSlowLive: 9,\u000a  // used by abr-controller\u000a  abrEwmaFastVoD: 3,\u000a  // used by abr-controller\u000a  abrEwmaSlowVoD: 9,\u000a  // used by abr-controller\u000a  abrEwmaDefaultEstimate: 5e5,\u000a  // 500 kbps  // used by abr-controller\u000a  abrBandWidthFactor: 0.95,\u000a  // used by abr-controller\u000a  abrBandWidthUpFactor: 0.7,\u000a  // used by abr-controller\u000a  abrMaxWithRealBitrate: false,\u000a  // used by abr-controller\u000a  maxStarvationDelay: 4,\u000a  // used by abr-controller\u000a  maxLoadingDelay: 4,\u000a  // used by abr-controller\u000a  minAutoBitrate: 0,\u000a  // used by hls\u000a  emeEnabled: false,\u000a  // used by eme-controller\u000a  widevineLicenseUrl: void 0,\u000a  // used by eme-controller\u000a  drmSystemOptions: {},\u000a  // used by eme-controller\u000a  requestMediaKeySystemAccessFunc: requestMediaKeySystemAccess,\u000a  // used by eme-controller\u000a  testBandwidth: true\u000a}, timelineConfig()), {}, {\u000a  subtitleStreamController:  true ? subtitle_stream_controller_SubtitleStreamController : undefined,\u000a  subtitleTrackController:  true ? subtitle_track_controller : undefined,\u000a  timelineController:  true ? timeline_controller : undefined,\u000a  audioStreamController:  true ? audio_stream_controller : undefined,\u000a  audioTrackController:  true ? audio_track_controller : undefined,\u000a  emeController:  true ? eme_controller : undefined\u000a});\u000a\u000afunction timelineConfig() {\u000a  return {\u000a    cueHandler: cues_namespaceObject,\u000a    // used by timeline-controller\u000a    enableCEA708Captions: true,\u000a    // used by timeline-controller\u000a    enableWebVTT: true,\u000a    // used by timeline-controller\u000a    captionsTextTrack1Label: 'English',\u000a    // used by timeline-controller\u000a    captionsTextTrack1LanguageCode: 'en',\u000a    // used by timeline-controller\u000a    captionsTextTrack2Label: 'Spanish',\u000a    // used by timeline-controller\u000a    captionsTextTrack2LanguageCode: 'es',\u000a    // used by timeline-controller\u000a    captionsTextTrack3Label: 'Unknown CC',\u000a    // used by timeline-controller\u000a    captionsTextTrack3LanguageCode: '',\u000a    // used by timeline-controller\u000a    captionsTextTrack4Label: 'Unknown CC',\u000a    // used by timeline-controller\u000a    captionsTextTrack4LanguageCode: '',\u000a    // used by timeline-controller\u000a    renderTextTracksNatively: true\u000a  };\u000a}\u000a// CONCATENATED MODULE: ./src/hls.ts\u000afunction hls_ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\u000a\u000afunction hls_objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { hls_ownKeys(Object(source), true).forEach(function (key) { hls_defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { hls_ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\u000a\u000afunction hls_defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\u000a\u000afunction hls_assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError("this hasn't been initialised - super() hasn't been called"); } return self; }\u000a\u000afunction hls_defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\u000a\u000afunction hls_createClass(Constructor, protoProps, staticProps) { if (protoProps) hls_defineProperties(Constructor.prototype, protoProps); if (staticProps) hls_defineProperties(Constructor, staticProps); return Constructor; }\u000a\u000afunction hls_inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a\u000a/**\u000a * @module Hls\u000a * @class\u000a * @constructor\u000a */\u000a\u000avar hls_Hls = /*#__PURE__*/function (_Observer) {\u000a  hls_inheritsLoose(Hls, _Observer);\u000a\u000a  /**\u000a   * @type {boolean}\u000a   */\u000a  Hls.isSupported = function isSupported() {\u000a    return is_supported_isSupported();\u000a  }\u000a  /**\u000a   * @type {HlsEvents}\u000a   */\u000a  ;\u000a\u000a  hls_createClass(Hls, null, [{\u000a    key: "version",\u000a\u000a    /**\u000a     * @type {string}\u000a     */\u000a    get: function get() {\u000a      return "0.14.3";\u000a    }\u000a  }, {\u000a    key: "Events",\u000a    get: function get() {\u000a      return events["default"];\u000a    }\u000a    /**\u000a     * @type {HlsErrorTypes}\u000a     */\u000a\u000a  }, {\u000a    key: "ErrorTypes",\u000a    get: function get() {\u000a      return errors["ErrorTypes"];\u000a    }\u000a    /**\u000a     * @type {HlsErrorDetails}\u000a     */\u000a\u000a  }, {\u000a    key: "ErrorDetails",\u000a    get: function get() {\u000a      return errors["ErrorDetails"];\u000a    }\u000a    /**\u000a     * @type {HlsConfig}\u000a     */\u000a\u000a  }, {\u000a    key: "DefaultConfig",\u000a    get: function get() {\u000a      if (!Hls.defaultConfig) {\u000a        return hlsDefaultConfig;\u000a      }\u000a\u000a      return Hls.defaultConfig;\u000a    }\u000a    /**\u000a     * @type {HlsConfig}\u000a     */\u000a    ,\u000a    set: function set(defaultConfig) {\u000a      Hls.defaultConfig = defaultConfig;\u000a    }\u000a    /**\u000a     * Creates an instance of an HLS client that can attach to exactly one `HTMLMediaElement`.\u000a     *\u000a     * @constructs Hls\u000a     * @param {HlsConfig} config\u000a     */\u000a\u000a  }]);\u000a\u000a  function Hls(userConfig) {\u000a    var _this;\u000a\u000a    if (userConfig === void 0) {\u000a      userConfig = {};\u000a    }\u000a\u000a    _this = _Observer.call(this) || this;\u000a    _this.config = void 0;\u000a    _this._autoLevelCapping = void 0;\u000a    _this.abrController = void 0;\u000a    _this.capLevelController = void 0;\u000a    _this.levelController = void 0;\u000a    _this.streamController = void 0;\u000a    _this.networkControllers = void 0;\u000a    _this.audioTrackController = void 0;\u000a    _this.subtitleTrackController = void 0;\u000a    _this.emeController = void 0;\u000a    _this.coreComponents = void 0;\u000a    _this.media = null;\u000a    _this.url = null;\u000a    var defaultConfig = Hls.DefaultConfig;\u000a\u000a    if ((userConfig.liveSyncDurationCount || userConfig.liveMaxLatencyDurationCount) && (userConfig.liveSyncDuration || userConfig.liveMaxLatencyDuration)) {\u000a      throw new Error('Illegal hls.js config: don\u005c't mix up liveSyncDurationCount/liveMaxLatencyDurationCount and liveSyncDuration/liveMaxLatencyDuration');\u000a    } // Shallow clone\u000a\u000a\u000a    _this.config = hls_objectSpread(hls_objectSpread({}, defaultConfig), userConfig);\u000a\u000a    var _assertThisInitialize = hls_assertThisInitialized(_this),\u000a        config = _assertThisInitialize.config;\u000a\u000a    if (config.liveMaxLatencyDurationCount !== void 0 && config.liveMaxLatencyDurationCount <= config.liveSyncDurationCount) {\u000a      throw new Error('Illegal hls.js config: "liveMaxLatencyDurationCount" must be gt "liveSyncDurationCount"');\u000a    }\u000a\u000a    if (config.liveMaxLatencyDuration !== void 0 && (config.liveSyncDuration === void 0 || config.liveMaxLatencyDuration <= config.liveSyncDuration)) {\u000a      throw new Error('Illegal hls.js config: "liveMaxLatencyDuration" must be gt "liveSyncDuration"');\u000a    }\u000a\u000a    Object(logger["enableLogs"])(config.debug);\u000a    _this._autoLevelCapping = -1; // core controllers and network loaders\u000a\u000a    /**\u000a     * @member {AbrController} abrController\u000a     */\u000a\u000a    var abrController = _this.abrController = new config.abrController(hls_assertThisInitialized(_this)); // eslint-disable-line new-cap\u000a\u000a    var bufferController = new config.bufferController(hls_assertThisInitialized(_this)); // eslint-disable-line new-cap\u000a\u000a    var capLevelController = _this.capLevelController = new config.capLevelController(hls_assertThisInitialized(_this)); // eslint-disable-line new-cap\u000a\u000a    var fpsController = new config.fpsController(hls_assertThisInitialized(_this)); // eslint-disable-line new-cap\u000a\u000a    var playListLoader = new playlist_loader(hls_assertThisInitialized(_this));\u000a    var fragmentLoader = new fragment_loader(hls_assertThisInitialized(_this));\u000a    var keyLoader = new key_loader(hls_assertThisInitialized(_this));\u000a    var id3TrackController = new id3_track_controller(hls_assertThisInitialized(_this)); // network controllers\u000a\u000a    /**\u000a     * @member {LevelController} levelController\u000a     */\u000a\u000a    var levelController = _this.levelController = new level_controller_LevelController(hls_assertThisInitialized(_this)); // FIXME: FragmentTracker must be defined before StreamController because the order of event handling is important\u000a\u000a    var fragmentTracker = new fragment_tracker_FragmentTracker(hls_assertThisInitialized(_this));\u000a    /**\u000a     * @member {StreamController} streamController\u000a     */\u000a\u000a    var streamController = _this.streamController = new stream_controller(hls_assertThisInitialized(_this), fragmentTracker);\u000a    var networkControllers = [levelController, streamController]; // optional audio stream controller\u000a\u000a    /**\u000a     * @var {ICoreComponent | Controller}\u000a     */\u000a\u000a    var Controller = config.audioStreamController;\u000a\u000a    if (Controller) {\u000a      networkControllers.push(new Controller(hls_assertThisInitialized(_this), fragmentTracker));\u000a    }\u000a    /**\u000a     * @member {INetworkController[]} networkControllers\u000a     */\u000a\u000a\u000a    _this.networkControllers = networkControllers;\u000a    /**\u000a     * @var {ICoreComponent[]}\u000a     */\u000a\u000a    var coreComponents = [playListLoader, fragmentLoader, keyLoader, abrController, bufferController, capLevelController, fpsController, id3TrackController, fragmentTracker]; // optional audio track and subtitle controller\u000a\u000a    Controller = config.audioTrackController;\u000a\u000a    if (Controller) {\u000a      var audioTrackController = new Controller(hls_assertThisInitialized(_this));\u000a      /**\u000a       * @member {AudioTrackController} audioTrackController\u000a       */\u000a\u000a      _this.audioTrackController = audioTrackController;\u000a      coreComponents.push(audioTrackController);\u000a    }\u000a\u000a    Controller = config.subtitleTrackController;\u000a\u000a    if (Controller) {\u000a      var subtitleTrackController = new Controller(hls_assertThisInitialized(_this));\u000a      /**\u000a       * @member {SubtitleTrackController} subtitleTrackController\u000a       */\u000a\u000a      _this.subtitleTrackController = subtitleTrackController;\u000a      networkControllers.push(subtitleTrackController);\u000a    }\u000a\u000a    Controller = config.emeController;\u000a\u000a    if (Controller) {\u000a      var emeController = new Controller(hls_assertThisInitialized(_this));\u000a      /**\u000a       * @member {EMEController} emeController\u000a       */\u000a\u000a      _this.emeController = emeController;\u000a      coreComponents.push(emeController);\u000a    } // optional subtitle controllers\u000a\u000a\u000a    Controller = config.subtitleStreamController;\u000a\u000a    if (Controller) {\u000a      networkControllers.push(new Controller(hls_assertThisInitialized(_this), fragmentTracker));\u000a    }\u000a\u000a    Controller = config.timelineController;\u000a\u000a    if (Controller) {\u000a      coreComponents.push(new Controller(hls_assertThisInitialized(_this)));\u000a    }\u000a    /**\u000a     * @member {ICoreComponent[]}\u000a     */\u000a\u000a\u000a    _this.coreComponents = coreComponents;\u000a    return _this;\u000a  }\u000a  /**\u000a   * Dispose of the instance\u000a   */\u000a\u000a\u000a  var _proto = Hls.prototype;\u000a\u000a  _proto.destroy = function destroy() {\u000a    logger["logger"].log('destroy');\u000a    this.trigger(events["default"].DESTROYING);\u000a    this.detachMedia();\u000a    this.coreComponents.concat(this.networkControllers).forEach(function (component) {\u000a      component.destroy();\u000a    });\u000a    this.url = null;\u000a    this.removeAllListeners();\u000a    this._autoLevelCapping = -1;\u000a  }\u000a  /**\u000a   * Attach a media element\u000a   * @param {HTMLMediaElement} media\u000a   */\u000a  ;\u000a\u000a  _proto.attachMedia = function attachMedia(media) {\u000a    logger["logger"].log('attachMedia');\u000a    this.media = media;\u000a    this.trigger(events["default"].MEDIA_ATTACHING, {\u000a      media: media\u000a    });\u000a  }\u000a  /**\u000a   * Detach from the media\u000a   */\u000a  ;\u000a\u000a  _proto.detachMedia = function detachMedia() {\u000a    logger["logger"].log('detachMedia');\u000a    this.trigger(events["default"].MEDIA_DETACHING);\u000a    this.media = null;\u000a  }\u000a  /**\u000a   * Set the source URL. Can be relative or absolute.\u000a   * @param {string} url\u000a   */\u000a  ;\u000a\u000a  _proto.loadSource = function loadSource(url) {\u000a    url = url_toolkit["buildAbsoluteURL"](window.location.href, url, {\u000a      alwaysNormalize: true\u000a    });\u000a    logger["logger"].log("loadSource:" + url);\u000a    this.url = url; // when attaching to a source URL, trigger a playlist load\u000a\u000a    this.trigger(events["default"].MANIFEST_LOADING, {\u000a      url: url\u000a    });\u000a  }\u000a  /**\u000a   * Start loading data from the stream source.\u000a   * Depending on default config, client starts loading automatically when a source is set.\u000a   *\u000a   * @param {number} startPosition Set the start position to stream from\u000a   * @default -1 None (from earliest point)\u000a   */\u000a  ;\u000a\u000a  _proto.startLoad = function startLoad(startPosition) {\u000a    if (startPosition === void 0) {\u000a      startPosition = -1;\u000a    }\u000a\u000a    logger["logger"].log("startLoad(" + startPosition + ")");\u000a    this.networkControllers.forEach(function (controller) {\u000a      controller.startLoad(startPosition);\u000a    });\u000a  }\u000a  /**\u000a   * Stop loading of any stream data.\u000a   */\u000a  ;\u000a\u000a  _proto.stopLoad = function stopLoad() {\u000a    logger["logger"].log('stopLoad');\u000a    this.networkControllers.forEach(function (controller) {\u000a      controller.stopLoad();\u000a    });\u000a  }\u000a  /**\u000a   * Swap through possible audio codecs in the stream (for example to switch from stereo to 5.1)\u000a   */\u000a  ;\u000a\u000a  _proto.swapAudioCodec = function swapAudioCodec() {\u000a    logger["logger"].log('swapAudioCodec');\u000a    this.streamController.swapAudioCodec();\u000a  }\u000a  /**\u000a   * When the media-element fails, this allows to detach and then re-attach it\u000a   * as one call (convenience method).\u000a   *\u000a   * Automatic recovery of media-errors by this process is configurable.\u000a   */\u000a  ;\u000a\u000a  _proto.recoverMediaError = function recoverMediaError() {\u000a    logger["logger"].log('recoverMediaError');\u000a    var media = this.media;\u000a    this.detachMedia();\u000a\u000a    if (media) {\u000a      this.attachMedia(media);\u000a    }\u000a  }\u000a  /**\u000a   * Remove a loaded level from the list of levels, or a level url in from a list of redundant level urls.\u000a   * This can be used to remove a rendition or playlist url that errors frequently from the list of levels that a user\u000a   * or hls.js can choose from.\u000a   *\u000a   * @param levelIndex {number} The quality level index to of the level to remove\u000a   * @param urlId {number} The quality level url index in the case that fallback levels are available. Defaults to 0.\u000a   */\u000a  ;\u000a\u000a  _proto.removeLevel = function removeLevel(levelIndex, urlId) {\u000a    if (urlId === void 0) {\u000a      urlId = 0;\u000a    }\u000a\u000a    this.levelController.removeLevel(levelIndex, urlId);\u000a  }\u000a  /**\u000a   * @type {QualityLevel[]}\u000a   */\u000a  // todo(typescript-levelController)\u000a  ;\u000a\u000a  hls_createClass(Hls, [{\u000a    key: "levels",\u000a    get: function get() {\u000a      return this.levelController.levels;\u000a    }\u000a    /**\u000a     * Index of quality level currently played\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "currentLevel",\u000a    get: function get() {\u000a      return this.streamController.currentLevel;\u000a    }\u000a    /**\u000a     * Set quality level index immediately .\u000a     * This will flush the current buffer to replace the quality asap.\u000a     * That means playback will interrupt at least shortly to re-buffer and re-sync eventually.\u000a     * @param newLevel {number} -1 for automatic level selection\u000a     */\u000a    ,\u000a    set: function set(newLevel) {\u000a      logger["logger"].log("set currentLevel:" + newLevel);\u000a      this.loadLevel = newLevel;\u000a      this.streamController.immediateLevelSwitch();\u000a    }\u000a    /**\u000a     * Index of next quality level loaded as scheduled by stream controller.\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "nextLevel",\u000a    get: function get() {\u000a      return this.streamController.nextLevel;\u000a    }\u000a    /**\u000a     * Set quality level index for next loaded data.\u000a     * This will switch the video quality asap, without interrupting playback.\u000a     * May abort current loading of data, and flush parts of buffer (outside currently played fragment region).\u000a     * @type {number} -1 for automatic level selection\u000a     */\u000a    ,\u000a    set: function set(newLevel) {\u000a      logger["logger"].log("set nextLevel:" + newLevel);\u000a      this.levelController.manualLevel = newLevel;\u000a      this.streamController.nextLevelSwitch();\u000a    }\u000a    /**\u000a     * Return the quality level of the currently or last (of none is loaded currently) segment\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "loadLevel",\u000a    get: function get() {\u000a      return this.levelController.level;\u000a    }\u000a    /**\u000a     * Set quality level index for next loaded data in a conservative way.\u000a     * This will switch the quality without flushing, but interrupt current loading.\u000a     * Thus the moment when the quality switch will appear in effect will only be after the already existing buffer.\u000a     * @type {number} newLevel -1 for automatic level selection\u000a     */\u000a    ,\u000a    set: function set(newLevel) {\u000a      logger["logger"].log("set loadLevel:" + newLevel);\u000a      this.levelController.manualLevel = newLevel;\u000a    }\u000a    /**\u000a     * get next quality level loaded\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "nextLoadLevel",\u000a    get: function get() {\u000a      return this.levelController.nextLoadLevel;\u000a    }\u000a    /**\u000a     * Set quality level of next loaded segment in a fully "non-destructive" way.\u000a     * Same as `loadLevel` but will wait for next switch (until current loading is done).\u000a     * @type {number} level\u000a     */\u000a    ,\u000a    set: function set(level) {\u000a      this.levelController.nextLoadLevel = level;\u000a    }\u000a    /**\u000a     * Return "first level": like a default level, if not set,\u000a     * falls back to index of first level referenced in manifest\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "firstLevel",\u000a    get: function get() {\u000a      return Math.max(this.levelController.firstLevel, this.minAutoLevel);\u000a    }\u000a    /**\u000a     * Sets "first-level", see getter.\u000a     * @type {number}\u000a     */\u000a    ,\u000a    set: function set(newLevel) {\u000a      logger["logger"].log("set firstLevel:" + newLevel);\u000a      this.levelController.firstLevel = newLevel;\u000a    }\u000a    /**\u000a     * Return start level (level of first fragment that will be played back)\u000a     * if not overrided by user, first level appearing in manifest will be used as start level\u000a     * if -1 : automatic start level selection, playback will start from level matching download bandwidth\u000a     * (determined from download of first segment)\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "startLevel",\u000a    get: function get() {\u000a      return this.levelController.startLevel;\u000a    }\u000a    /**\u000a     * set  start level (level of first fragment that will be played back)\u000a     * if not overrided by user, first level appearing in manifest will be used as start level\u000a     * if -1 : automatic start level selection, playback will start from level matching download bandwidth\u000a     * (determined from download of first segment)\u000a     * @type {number} newLevel\u000a     */\u000a    ,\u000a    set: function set(newLevel) {\u000a      logger["logger"].log("set startLevel:" + newLevel); // if not in automatic start level detection, ensure startLevel is greater than minAutoLevel\u000a\u000a      if (newLevel !== -1) {\u000a        newLevel = Math.max(newLevel, this.minAutoLevel);\u000a      }\u000a\u000a      this.levelController.startLevel = newLevel;\u000a    }\u000a    /**\u000a     * set  dynamically set capLevelToPlayerSize against (`CapLevelController`)\u000a     *\u000a     * @type {boolean}\u000a     */\u000a\u000a  }, {\u000a    key: "capLevelToPlayerSize",\u000a    set: function set(shouldStartCapping) {\u000a      var newCapLevelToPlayerSize = !!shouldStartCapping;\u000a\u000a      if (newCapLevelToPlayerSize !== this.config.capLevelToPlayerSize) {\u000a        if (newCapLevelToPlayerSize) {\u000a          this.capLevelController.startCapping(); // If capping occurs, nextLevelSwitch will happen based on size.\u000a        } else {\u000a          this.capLevelController.stopCapping();\u000a          this.autoLevelCapping = -1;\u000a          this.streamController.nextLevelSwitch(); // Now we're uncapped, get the next level asap.\u000a        }\u000a\u000a        this.config.capLevelToPlayerSize = newCapLevelToPlayerSize;\u000a      }\u000a    }\u000a    /**\u000a     * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "autoLevelCapping",\u000a    get: function get() {\u000a      return this._autoLevelCapping;\u000a    }\u000a    /**\u000a     * get bandwidth estimate\u000a     * @type {number}\u000a     */\u000a    ,\u000a\u000a    /**\u000a     * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\u000a     * @type {number}\u000a     */\u000a    set: function set(newLevel) {\u000a      logger["logger"].log("set autoLevelCapping:" + newLevel);\u000a      this._autoLevelCapping = newLevel;\u000a    }\u000a    /**\u000a     * True when automatic level selection enabled\u000a     * @type {boolean}\u000a     */\u000a\u000a  }, {\u000a    key: "bandwidthEstimate",\u000a    get: function get() {\u000a      var bwEstimator = this.abrController._bwEstimator;\u000a      return bwEstimator ? bwEstimator.getEstimate() : NaN;\u000a    }\u000a  }, {\u000a    key: "autoLevelEnabled",\u000a    get: function get() {\u000a      return this.levelController.manualLevel === -1;\u000a    }\u000a    /**\u000a     * Level set manually (if any)\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "manualLevel",\u000a    get: function get() {\u000a      return this.levelController.manualLevel;\u000a    }\u000a    /**\u000a     * min level selectable in auto mode according to config.minAutoBitrate\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "minAutoLevel",\u000a    get: function get() {\u000a      var levels = this.levels,\u000a          minAutoBitrate = this.config.minAutoBitrate;\u000a      var len = levels ? levels.length : 0;\u000a\u000a      for (var i = 0; i < len; i++) {\u000a        var levelNextBitrate = levels[i].realBitrate ? Math.max(levels[i].realBitrate, levels[i].bitrate) : levels[i].bitrate;\u000a\u000a        if (levelNextBitrate > minAutoBitrate) {\u000a          return i;\u000a        }\u000a      }\u000a\u000a      return 0;\u000a    }\u000a    /**\u000a     * max level selectable in auto mode according to autoLevelCapping\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "maxAutoLevel",\u000a    get: function get() {\u000a      var levels = this.levels,\u000a          autoLevelCapping = this.autoLevelCapping;\u000a      var maxAutoLevel;\u000a\u000a      if (autoLevelCapping === -1 && levels && levels.length) {\u000a        maxAutoLevel = levels.length - 1;\u000a      } else {\u000a        maxAutoLevel = autoLevelCapping;\u000a      }\u000a\u000a      return maxAutoLevel;\u000a    }\u000a    /**\u000a     * next automatically selected quality level\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "nextAutoLevel",\u000a    get: function get() {\u000a      // ensure next auto level is between  min and max auto level\u000a      return Math.min(Math.max(this.abrController.nextAutoLevel, this.minAutoLevel), this.maxAutoLevel);\u000a    }\u000a    /**\u000a     * this setter is used to force next auto level.\u000a     * this is useful to force a switch down in auto mode:\u000a     * in case of load error on level N, hls.js can set nextAutoLevel to N-1 for example)\u000a     * forced value is valid for one fragment. upon succesful frag loading at forced level,\u000a     * this value will be resetted to -1 by ABR controller.\u000a     * @type {number}\u000a     */\u000a    ,\u000a    set: function set(nextLevel) {\u000a      this.abrController.nextAutoLevel = Math.max(this.minAutoLevel, nextLevel);\u000a    }\u000a    /**\u000a     * @type {AudioTrack[]}\u000a     */\u000a    // todo(typescript-audioTrackController)\u000a\u000a  }, {\u000a    key: "audioTracks",\u000a    get: function get() {\u000a      var audioTrackController = this.audioTrackController;\u000a      return audioTrackController ? audioTrackController.audioTracks : [];\u000a    }\u000a    /**\u000a     * index of the selected audio track (index in audio track lists)\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "audioTrack",\u000a    get: function get() {\u000a      var audioTrackController = this.audioTrackController;\u000a      return audioTrackController ? audioTrackController.audioTrack : -1;\u000a    }\u000a    /**\u000a     * selects an audio track, based on its index in audio track lists\u000a     * @type {number}\u000a     */\u000a    ,\u000a    set: function set(audioTrackId) {\u000a      var audioTrackController = this.audioTrackController;\u000a\u000a      if (audioTrackController) {\u000a        audioTrackController.audioTrack = audioTrackId;\u000a      }\u000a    }\u000a    /**\u000a     * @type {Seconds}\u000a     */\u000a\u000a  }, {\u000a    key: "liveSyncPosition",\u000a    get: function get() {\u000a      return this.streamController.liveSyncPosition;\u000a    }\u000a    /**\u000a     * get alternate subtitle tracks list from playlist\u000a     * @type {SubtitleTrack[]}\u000a     */\u000a    // todo(typescript-subtitleTrackController)\u000a\u000a  }, {\u000a    key: "subtitleTracks",\u000a    get: function get() {\u000a      var subtitleTrackController = this.subtitleTrackController;\u000a      return subtitleTrackController ? subtitleTrackController.subtitleTracks : [];\u000a    }\u000a    /**\u000a     * index of the selected subtitle track (index in subtitle track lists)\u000a     * @type {number}\u000a     */\u000a\u000a  }, {\u000a    key: "subtitleTrack",\u000a    get: function get() {\u000a      var subtitleTrackController = this.subtitleTrackController;\u000a      return subtitleTrackController ? subtitleTrackController.subtitleTrack : -1;\u000a    }\u000a    /**\u000a     * select an subtitle track, based on its index in subtitle track lists\u000a     * @type {number}\u000a     */\u000a    ,\u000a    set: function set(subtitleTrackId) {\u000a      var subtitleTrackController = this.subtitleTrackController;\u000a\u000a      if (subtitleTrackController) {\u000a        subtitleTrackController.subtitleTrack = subtitleTrackId;\u000a      }\u000a    }\u000a    /**\u000a     * @type {boolean}\u000a     */\u000a\u000a  }, {\u000a    key: "subtitleDisplay",\u000a    get: function get() {\u000a      var subtitleTrackController = this.subtitleTrackController;\u000a      return subtitleTrackController ? subtitleTrackController.subtitleDisplay : false;\u000a    }\u000a    /**\u000a     * Enable/disable subtitle display rendering\u000a     * @type {boolean}\u000a     */\u000a    ,\u000a    set: function set(value) {\u000a      var subtitleTrackController = this.subtitleTrackController;\u000a\u000a      if (subtitleTrackController) {\u000a        subtitleTrackController.subtitleDisplay = value;\u000a      }\u000a    }\u000a  }]);\u000a\u000a  return Hls;\u000a}(Observer);\u000a\u000ahls_Hls.defaultConfig = void 0;\u000a\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/polyfills/number.js":\u000a/*!*********************************!*\u005c\u000a  !*** ./src/polyfills/number.js ***!\u000a  \u005c*********************************/\u000a/*! exports provided: isFiniteNumber, MAX_SAFE_INTEGER */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a__webpack_require__.r(__webpack_exports__);\u000a/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "isFiniteNumber", function() { return isFiniteNumber; });\u000a/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MAX_SAFE_INTEGER", function() { return MAX_SAFE_INTEGER; });\u000avar isFiniteNumber = Number.isFinite || function (value) {\u000a  return typeof value === 'number' && isFinite(value);\u000a};\u000avar MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER || 9007199254740991;\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/utils/get-self-scope.js":\u000a/*!*************************************!*\u005c\u000a  !*** ./src/utils/get-self-scope.js ***!\u000a  \u005c*************************************/\u000a/*! exports provided: getSelfScope */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a__webpack_require__.r(__webpack_exports__);\u000a/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "getSelfScope", function() { return getSelfScope; });\u000afunction getSelfScope() {\u000a  // see https://stackoverflow.com/a/11237259/589493\u000a  if (typeof window === 'undefined') {\u000a    /* eslint-disable-next-line no-undef */\u000a    return self;\u000a  } else {\u000a    return window;\u000a  }\u000a}\u000a\u000a/***/ }),\u000a\u000a/***/ "./src/utils/logger.js":\u000a/*!*****************************!*\u005c\u000a  !*** ./src/utils/logger.js ***!\u000a  \u005c*****************************/\u000a/*! exports provided: enableLogs, logger */\u000a/***/ (function(module, __webpack_exports__, __webpack_require__) {\u000a\u000a"use strict";\u000a__webpack_require__.r(__webpack_exports__);\u000a/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "enableLogs", function() { return enableLogs; });\u000a/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "logger", function() { return logger; });\u000a/* harmony import */ var _get_self_scope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-self-scope */ "./src/utils/get-self-scope.js");\u000a\u000a\u000afunction noop() {}\u000a\u000avar fakeLogger = {\u000a  trace: noop,\u000a  debug: noop,\u000a  log: noop,\u000a  warn: noop,\u000a  info: noop,\u000a  error: noop\u000a};\u000avar exportedLogger = fakeLogger; // let lastCallTime;\u000a// function formatMsgWithTimeInfo(type, msg) {\u000a//   const now = Date.now();\u000a//   const diff = lastCallTime ? '+' + (now - lastCallTime) : '0';\u000a//   lastCallTime = now;\u000a//   msg = (new Date(now)).toISOString() + ' | [' +  type + '] > ' + msg + ' ( ' + diff + ' ms )';\u000a//   return msg;\u000a// }\u000a\u000afunction formatMsg(type, msg) {\u000a  msg = '[' + type + '] > ' + msg;\u000a  return msg;\u000a}\u000a\u000avar global = Object(_get_self_scope__WEBPACK_IMPORTED_MODULE_0__["getSelfScope"])();\u000a\u000afunction consolePrintFn(type) {\u000a  var func = global.console[type];\u000a\u000a  if (func) {\u000a    return function () {\u000a      for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\u000a        args[_key] = arguments[_key];\u000a      }\u000a\u000a      if (args[0]) {\u000a        args[0] = formatMsg(type, args[0]);\u000a      }\u000a\u000a      func.apply(global.console, args);\u000a    };\u000a  }\u000a\u000a  return noop;\u000a}\u000a\u000afunction exportLoggerFunctions(debugConfig) {\u000a  for (var _len2 = arguments.length, functions = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\u000a    functions[_key2 - 1] = arguments[_key2];\u000a  }\u000a\u000a  functions.forEach(function (type) {\u000a    exportedLogger[type] = debugConfig[type] ? debugConfig[type].bind(debugConfig) : consolePrintFn(type);\u000a  });\u000a}\u000a\u000avar enableLogs = function enableLogs(debugConfig) {\u000a  // check that console is available\u000a  if (global.console && debugConfig === true || typeof debugConfig === 'object') {\u000a    exportLoggerFunctions(debugConfig, // Remove out from list here to hard-disable a log-level\u000a    // 'trace',\u000a    'debug', 'log', 'info', 'warn', 'error'); // Some browsers don't allow to use bind on console object anyway\u000a    // fallback to default if needed\u000a\u000a    try {\u000a      exportedLogger.log();\u000a    } catch (e) {\u000a      exportedLogger = fakeLogger;\u000a    }\u000a  } else {\u000a    exportedLogger = fakeLogger;\u000a  }\u000a};\u000avar logger = exportedLogger;\u000a\u000a/***/ })\u000a\u000a/******/ })["default"];\u000a});\u000a\u000a;\u000a
p0
.